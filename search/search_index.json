{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The Spoofax Language Workbench","text":"<p>Spoofax is a platform for developing textual (domain-specific) programming languages. The platform provides the following ingredients:</p> <ul> <li>Meta-languages for high-level declarative language definition</li> <li>An interactive environment for developing languages using these meta-languages</li> <li>Code generators that produces parsers, type checkers, compilers, interpreters, and other tools from language definitions</li> <li>Generation of full-featured Eclipse editor plugins from language definitions</li> <li>An API for programmatically combining the components of a language implementation</li> </ul> <p>With Spoofax you can focus on the essence of language definition and ignore irrelevant implementation details.</p> <p>Get started by downloading and installing Spoofax or build it from source.</p> <p>Looking for Spoofax 3? Visit the Spoofax 3 documentation website.</p>"},{"location":"getting-started/","title":"Getting started","text":"<p>The quickest way to get started with Spoofax by downloading an instance of Eclipse with the latest release. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, use Homebrew on macOS, or download and build Spoofax from source.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>The recommended way to get started with Spoofax is to download an Eclipse instance with the latest Spoofax plugin. The plugin also includes the Spoofax meta-languages. Alternatively, you can install the Spoofax plugin into an existing Eclipse instance, or download and build Spoofax from source. Choose the Eclipse Bundle installation (recommended) or the Eclipse Plugin installation:</p> Eclipse Bundle <p>Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform:</p> <p>+ macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) Windows x86 (32-bit)</p> <p>Installation instructions.</p> <p>Download Eclipse with Spoofax without an embedded JRE.</p> <p>Development releases.</p> Eclipse Plugin <p>Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site:</p> <pre><code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.18/org.metaborg.spoofax.eclipse.updatesite-2.5.18-assembly.zip-unzip/\n</code></pre> <p>Installation instructions.</p> Homebrew ( macOS) <p>On macOS Spoofax can be installed easily using Homebrew.</p> <p>Install the latest release of Spoofax Eclipse as follows:</p> <pre><code>brew tap metaborg/metaborg\nbrew install --cask spoofax\n</code></pre> <p>The optional command-line tools are installed with:</p> <pre><code>brew install strategoxt\n</code></pre> <p>Upgrading the Spoofax cask is not recommended</p> <p>Upgrading the Spoofax cask using <code>brew cask upgrade --greedy</code> will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.</p>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<p>Once installed, create a new Spoofax project:</p> <ol> <li>Right-click the Package Explorer, choose New \u2192 Project, and select Spoofax Language project from the Spoofax category.</li> <li>Provide a name for your new language and click Finish.</li> <li>Select the created language project and press Ctrl+Alt+B (Cmd+Alt+B on macOS) to build the project.</li> <li>Create a new file with the extension registered to your language to test it.</li> <li>Follow one of the tutorials to learn more.</li> </ol> <p>Finding the filename extension of your language</p> <p>If you didn't explicitly specify a filename extension for your language, it is derived from the language name. You can find the filename extension for your language in <code>editor/Main.esv</code> at the <code>extensions</code> property.</p>"},{"location":"background/","title":"Background","text":"<p>This section contains information on the ideas, architecture, and design decisions behind Spoofax. For the Spoofax language reference, see the References section.</p> <ul> <li> <p>Publications: References to papers about the design and implementation of various aspects of Spoofax</p> </li> <li> <p>Statix: More about the Statix language for Static semantics definition</p> </li> <li>Stratego: Motivation for the design of the Stratego transformation language</li> <li>Documentation: Explanation of how this documentation works</li> </ul>"},{"location":"background/bibliography/","title":"Spoofax Bibliography","text":"<p>Spoofax and its meta-languages have been described and motivated extensively in the academic literature. All references to Spoofax-related papers should have been collected in a bibliography on researchr from where the complete collection of bibtex entries can be obtained. (Let us know if we are missing publications in that collection.) This section provides references to that literature.</p>"},{"location":"background/bibliography/#spoofax","title":"Spoofax","text":"<p>The first version of Spoofax was described in an award winning paper OOPSLA 20101. (The paper won the best (student) paper award at OOPSLA 2010 and the Most Influential Paper Award at OOPSLA 2020.) The paper provides motivation for textual language workbenches and discusses the architecture of a language workbench based on declarative meta-languages.</p> <p>An introduction to Spoofax was included along with introductions to MPS and Xtext in V\u00f6lter's DSL Engineering book2.</p> <p>A paper in IEEE Software3 considers Spoofax from a user's perspective.</p> <p>Spoofax was also one of the tools featured in a survey of language workbenches which was first published in SLE'134 and later extended in the Computer Languages journal5.</p>"},{"location":"background/bibliography/#bibliographies","title":"Bibliographies","text":"<ul> <li>SDF3: papers about the syntax definition formalism and its predecessors</li> <li>Statix: papers about the static semantics meta-language and its predecessors</li> <li>Stratego: papers about the transformation meta-language</li> </ul>"},{"location":"background/bibliography/#references","title":"References","text":"<ol> <li> <p>Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010, 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497, doi:10.1145/1869459.1869497.\u00a0\u21a9</p> </li> <li> <p>Markus V\u00f6lter, Sebastian Benz, Christian Dietrich, Birgit Engelmann, Mats Helander, Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. DSL Engineering - Designing, Implementing and Using Domain-Specific Languages. dslbook.org, 2013. ISBN 978-1-4812-1858-0. URL: http://www.dslbook.org.\u00a0\u21a9</p> </li> <li> <p>Guido Wachsmuth, Gabri\u00ebl Konat, and Eelco Visser. Language design with the spoofax language workbench. IEEE Software, 31(5):35\u201343, 2014. URL: http://dx.doi.org/10.1109/MS.2014.100, doi:10.1109/MS.2014.100.\u00a0\u21a9</p> </li> <li> <p>Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Meinte Boersma, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. The state of the art in language workbenches - conclusions from the language workbench challenge. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings, volume 8225 of Lecture Notes in Computer Science, 197\u2013217. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_11, doi:10.1007/978-3-319-02654-1_11.\u00a0\u21a9</p> </li> <li> <p>Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Laurence Tratt, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. Evaluating and comparing language workbenches: existing results and benchmarks for the future. Computer Languages, Systems &amp; Structures, 44:24\u201347, 2015. URL: http://dx.doi.org/10.1016/j.cl.2015.08.007, doi:10.1016/j.cl.2015.08.007.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/bibliography/references/","title":"References","text":"<p>The full Spoofax bibliography.</p> <ol> <li> <p>Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010, 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497, doi:10.1145/1869459.1869497.\u00a0\u21a9</p> </li> <li> <p>Markus V\u00f6lter, Sebastian Benz, Christian Dietrich, Birgit Engelmann, Mats Helander, Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. DSL Engineering - Designing, Implementing and Using Domain-Specific Languages. dslbook.org, 2013. ISBN 978-1-4812-1858-0. URL: http://www.dslbook.org.\u00a0\u21a9</p> </li> <li> <p>Guido Wachsmuth, Gabri\u00ebl Konat, and Eelco Visser. Language design with the spoofax language workbench. IEEE Software, 31(5):35\u201343, 2014. URL: http://dx.doi.org/10.1109/MS.2014.100, doi:10.1109/MS.2014.100.\u00a0\u21a9</p> </li> <li> <p>Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Meinte Boersma, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. The state of the art in language workbenches - conclusions from the language workbench challenge. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings, volume 8225 of Lecture Notes in Computer Science, 197\u2013217. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_11, doi:10.1007/978-3-319-02654-1_11.\u00a0\u21a9</p> </li> <li> <p>Sebastian Erdweg, Tijs van der Storm, Markus V\u00f6lter, Laurence Tratt, Remi Bosman, William R. Cook, Albert Gerritsen, Angelo Hulshout, Steven Kelly, Alex Loh, Gabri\u00ebl Konat, Pedro J. Molina, Martin Palatnik, Risto Pohjonen, Eugen Schindler, Klemens Schindler, Riccardo Solmi, Vlad A. Vergu, Eelco Visser, Kevin van der Vlist, Guido Wachsmuth, and Jimi van der Woning. Evaluating and comparing language workbenches: existing results and benchmarks for the future. Computer Languages, Systems &amp; Structures, 44:24\u201347, 2015. URL: http://dx.doi.org/10.1016/j.cl.2015.08.007, doi:10.1016/j.cl.2015.08.007.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/bibliography/sdf3/","title":"An SDF3 Bibliography","text":"<p>SDF31 is the third generation in the SDF family of syntax definition formalisms, which were developed in the context of the ASF+SDF2, Stratego/XT3, and Spoofax4 language workbenches.</p> <p>Kats et al. decribe the motivation for declarative syntax definition5.</p>"},{"location":"background/bibliography/sdf3/#sdf","title":"SDF","text":"<p>The first SDF6 supported modular composition of syntax definition, a direct correspondence between concrete and abstract syntax, and parsing with the full class of context-free grammars enabled by the Generalized-LR (GLR) parsing algorithm7 8. Its programming environment, as part of the ASF+SDF MetaEnvironment9, focused on live development of syntax definitions through incremental and modular scanner and parser generation10 11 12 in order to provide fast turnaround times during language development.</p>"},{"location":"background/bibliography/sdf3/#sdf2","title":"SDF2","text":"<p>The second generation, SDF2 encompassed a redesign of the internals of SDF without changing the surface syntax. The front-end of the implementation consisted of a transformation pipeline from the rich surface syntax to a minimal core (kernel) language13 that served as input for parser generation. The key change of SDF2 was its integration of lexical and context-free syntax, supported by Scannerless GLR (SGLR) parsing14 15, enabling composition of languages with different lexical syntax16 17.</p>"},{"location":"background/bibliography/sdf3/#sdf3","title":"SDF3","text":"<p>SDF3 is the latest member of the family and inherits many features of its predecessors. The most recognizable change is to the syntax of productions that should make it more familiar to users of other grammar formalisms. Further, it introduces new features in order to support multi-purpose interpretations of syntax definitions. The goals of the design of SDF3 are (1) to support the definition of the concrete and abstract syntax of formal languages (with an emphasis on programming languages), (2) to support declarative syntax definition so that there is no need to understand parsing algorithms in order to understand definitions 5, (3) to make syntax definitions readable and understandable so that they can be used as reference documentation, and (4) to support execution of syntax definitions as parsers, but also for other syntactic operations, i.e to support multi-purpose interpretation based on a single source. The focus on multipurpose interpretation is driven by the role of SDF3 in the Spoofax language workbench 4.</p> <p>Key features of SDF3 include</p> <ul> <li>Template productions18</li> <li>Error recovery19</li> <li>Layout constraints for layout-sensitive syntax20 21</li> <li>Safe and complete disambiguation of expression grammars22</li> <li>Placeholders and syntactic code completion23</li> </ul>"},{"location":"background/bibliography/sdf3/#future-work","title":"Future Work","text":"<p>Parse table composition24, while implemented in a prototype, hasn't made into the production implementation yet.</p>"},{"location":"background/bibliography/sdf3/#references","title":"References","text":"<ol> <li> <p>Luis Eduardo de Souza Amorim and Eelco Visser. Multi-purpose syntax definition with SDF3. In Frank S. de Boer and Antonio Cerone, editors, Software Engineering and Formal Methods - 18th International Conference, SEFM 2020, Amsterdam, The Netherlands, September 14-18, 2020, Proceedings, volume 12310 of Lecture Notes in Computer Science, 1\u201323. Springer, 2020. URL: https://doi.org/10.1007/978-3-030-58768-0_1, doi:10.1007/978-3-030-58768-0_1.\u00a0\u21a9</p> </li> <li> <p>Mark G. J. van den Brand, Arie van Deursen, Jan Heering, H. A. de Jong, Merijn de Jonge, Tobias Kuipers, Paul Klint, Leon Moonen, Pieter A. Olivier, Jeroen Scheerder, Jurgen J. Vinju, Eelco Visser, and Joost Visser. The ASF+SDF meta-environment: a component-based language development environment. In Reinhard Wilhelm, editor, Compiler Construction, 10th International Conference, CC 2001 Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2001 Genova, Italy, April 2-6, 2001, Proceedings, volume 2027 of Lecture Notes in Computer Science, 365\u2013370. Springer, 2001. URL: https://doi.org/10.1016/S1571-0661(04)80917-4, doi:10.1016/S1571-0661(04)80917-4.\u00a0\u21a9</p> </li> <li> <p>Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.17. A language and toolset for program transformation. Science of Computer Programming, 72(1-2):52\u201370, 2008. URL: http://dx.doi.org/10.1016/j.scico.2007.11.003, doi:10.1016/j.scico.2007.11.003.\u00a0\u21a9</p> </li> <li> <p>Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010, 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497, doi:10.1145/1869459.1869497.\u00a0\u21a9\u21a9</p> </li> <li> <p>Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth. Pure and declarative syntax definition: paradise lost and regained. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010, 918\u2013932. Reno/Tahoe, Nevada, 2010. ACM. URL: http://doi.acm.org/10.1145/1869459.1869535, doi:10.1145/1869459.1869535.\u00a0\u21a9\u21a9</p> </li> <li> <p>Jan Heering, P. R. H. Hendriks, Paul Klint, and Jan Rekers. The syntax definition formalism SDF - reference manual. SIGPLAN Notices, 24(11):43\u201375, 1989. doi:10.1145/71605.71607.\u00a0\u21a9</p> </li> <li> <p>Masaru Tomita. An efficient context-free parsing algorithm for natural languages. In IJCAI, 756\u2013764. 1985.\u00a0\u21a9</p> </li> <li> <p>Jan Rekers. Parser Generation for Interactive Environments. PhD thesis, University of Amsterdam, Amsterdam, The Netherlands, January 1992.\u00a0\u21a9</p> </li> <li> <p>Paul Klint. A meta-environment for generating programming environments. ACM Transactions on Software Engineering Methodology, 2(2):176\u2013201, 1993. doi:10.1145/151257.151260.\u00a0\u21a9</p> </li> <li> <p>Jan Heering, Paul Klint, and Jan Rekers. Incremental generation of lexical scanners. ACM Transactions on Programming Languages and Systems, 14(4):490\u2013520, 1992. doi:10.1145/133233.133240.\u00a0\u21a9</p> </li> <li> <p>Jan Heering, Paul Klint, and Jan Rekers. Incremental generation of parsers. IEEE Trans. Software Eng., 16(12):1344\u20131351, 1990.\u00a0\u21a9</p> </li> <li> <p>Jan Heering, Paul Klint, and Jan Rekers. Lazy and incremental program generation. ACM Transactions on Programming Languages and Systems, 16(3):1010\u20131023, 1994. doi:10.1145/177492.177750.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser. A family of syntax definition formalisms. In Mark G. J. van den Brand and Vania Vieira Estrela, editors, ASF+SDF 1995. A Workshop on Generating Tools from Algebraic Specifications. Technical Report P9504, Programming Research Group, University of Amsterdam, May 1995.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser. Syntax Definition for Language Prototyping. PhD thesis, University of Amsterdam, September 1997.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser. Scannerless generalized-LR parsing. Technical Report P9707, Programming Research Group, University of Amsterdam, July 1997.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser. Meta-programming with concrete object syntax. In Don S. Batory, Charles Consel, and Walid Taha, editors, Generative Programming and Component Engineering, ACM SIGPLAN/SIGSOFT Conference, GPCE 2002, Pittsburgh, PA, USA, October 6-8, 2002, Proceedings, volume 2487 of Lecture Notes in Computer Science, 299\u2013315. Springer, 2002. URL: https://doi.org/10.1007/3-540-45821-2_19, doi:10.1007/3-540-45821-2_19.\u00a0\u21a9</p> </li> <li> <p>Martin Bravenboer and Eelco Visser. Concrete syntax for objects: domain-specific language embedding and assimilation without restrictions. In John M. Vlissides and Douglas C. Schmidt, editors, Proceedings of the 19th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2004, 365\u2013383. Vancouver, BC, Canada, 2004. ACM. URL: http://doi.acm.org/10.1145/1028976.1029007, doi:10.1145/1028976.1029007.\u00a0\u21a9</p> </li> <li> <p>Tobi Vollebregt, Lennart C. L. Kats, and Eelco Visser. Declarative specification of template-based textual editors. In Anthony Sloane and Suzana Andova, editors, International Workshop on Language Descriptions, Tools, and Applications, LDTA '12, Tallinn, Estonia, March 31 - April 1, 2012, 1\u20137. ACM, 2012. URL: http://doi.acm.org/10.1145/2427048.2427056, doi:10.1145/2427048.2427056.\u00a0\u21a9</p> </li> <li> <p>Maartje de Jonge, Lennart C. L. Kats, Eelco Visser, and Emma S\u00f6derberg. Natural and flexible error recovery for generated modular language environments. ACM Transactions on Programming Languages and Systems, 34(4):15, 2012. URL: http://doi.acm.org/10.1145/2400676.2400678, doi:10.1145/2400676.2400678.\u00a0\u21a9</p> </li> <li> <p>Sebastian Erdweg, Tillmann Rendel, Christian K\u00e4stner, and Klaus Ostermann. Layout-sensitive generalized parsing. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers, volume 7745 of Lecture Notes in Computer Science, 244\u2013263. Springer, 2012. doi:10.1007/978-3-642-36089-3\\_14.\u00a0\u21a9</p> </li> <li> <p>Luis Eduardo de Souza Amorim, Michael J. Steindorfer, Sebastian Erdweg, and Eelco Visser. Declarative specification of indentation rules: a tooling perspective on parsing and pretty-printing layout-sensitive languages. In David Pearce 0005, Tanja Mayerhofer, and Friedrich Steimann, editors, Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2018, Boston, MA, USA, November 05-06, 2018, 3\u201315. ACM, 2018. URL: https://doi.org/10.1145/3276604.3276607, doi:10.1145/3276604.3276607.\u00a0\u21a9</p> </li> <li> <p>Luis Eduardo de Souza Amorim. Declarative Syntax Definition for Modern Language Workbenches. PhD thesis, Delft University of Technology, Netherlands, 2019. base-search.net (fttudelft:oai:tudelft.nl:uuid:43d7992a-7077-47ba-b38f-113f5011d07f). URL: https://www.base-search.net/Record/261b6c9463c1d4fe309e3c6104cd4d80fbc9d3cc8fbc66006f34130f481b506f.\u00a0\u21a9</p> </li> <li> <p>Luis Eduardo de Souza Amorim, Sebastian Erdweg, Guido Wachsmuth, and Eelco Visser. Principled syntactic code completion using placeholders. In Tijs van der Storm, Emilie Balland, and D\u00e1niel Varr\u00f3, editors, Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, The Netherlands, October 31 - November 1, 2016, 163\u2013175. ACM, 2016. URL: http://dx.doi.org/10.1145/2997364.2997374, doi:10.1145/2997364.2997374.\u00a0\u21a9</p> </li> <li> <p>Martin Bravenboer and Eelco Visser. Parse table composition. In Dragan Gasevic, Ralf L\u00e4mmel, and Eric Van Wyk, editors, Software Language Engineering, First International Conference, SLE 2008, Toulouse, France, September 29-30, 2008. Revised Selected Papers, volume 5452 of Lecture Notes in Computer Science, 74\u201394. Springer, 2009. URL: http://dx.doi.org/10.1007/978-3-642-00434-6_6, doi:10.1007/978-3-642-00434-6_6.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/bibliography/statix/","title":"A Statix Bibliography","text":"<p>The Statix1 2 meta-language provides support for the declarative definition of the static semantics of programming languages in terms of unification constraints and scope graph constraints for name resolution1 guaranteeing query stability2. Here we trace the development of the Statix language.</p>"},{"location":"background/bibliography/statix/#the-nabl-name-binding-language","title":"The NaBL Name Binding Language","text":"<p>The NaBL3 language provides support for the declaration of the name binding rules of programming languages in terms of definitions, references, and scoping.</p> <p>The NaBL task engine supports incremental execution of type checkers based on NaBL4.</p> <p>While the paper used the WebDSL language as example, the NaBL analysis was only applied in production in the SDF3 language.</p> <p>The NaBL language is very declarative, but binding patterns such as sequential let and 'subsequent scope' are difficult to express in it.</p>"},{"location":"background/bibliography/statix/#scope-graphs","title":"Scope Graphs","text":"<p>The study of the semantics of NaBL (and its limits in expressiveness) led to the formulation of a general theory of name resolution based on scope graphs5.</p> <p>The vertices of scope graphs are scopes and the edges model reachability. Declarations are associated with scopes. Name resolution by means of a declarative resolution calculus is defined as finding a path from the scope of a reference to the scope of a declaration taking into account the structure of the scope graph extended with visibility rules formulated in terms of path well-formedness and path specificity.</p>"},{"location":"background/bibliography/statix/#constraint-language","title":"Constraint Language","text":"<p>Based on the theory of name resolution, a constraint language was defined with a declarative and operational semantics6.</p> <p>The language was designed for a two stage type checking process. In the first phase unification and scope constraints are generated, in the second phase these constraints are solved. A distinctive feature of this approach with respect to other constraint-based approaches to type checking, is the fact that name resolution is deferred until constraint resolution. This makes the definition of type-dependent name resolution, e.g. for computing the types of record fields, straightforward.</p> <p>The NaBL2 language was a concrete implementation of this design and was integrated into Spoofax. It featured concrete syntax for unification and scope graph constraints, and rules for mapping AST nodes to constraints.</p> <p>The two stage type checking process entailed limitations for the type systems that could be expressed in NaBL2. In particular, it was not possible to generate constraints based on information computed during the second stage. For example, a subtyping rule operating on types computed during constraint resolution</p> <p>Furthermore, the NaBL2 language itself was untyped, making it easy to make errors in specifications.</p>"},{"location":"background/bibliography/statix/#statix-language","title":"Statix Language","text":"<p>The Statix language1 was designed to overcome the limitations of NaBL2.</p> <p>The language is typed, with signatures describing the types of ASTs, and typing rules declaring the types of predicates. The type system of Statix is expressed in NaBL2, making the specification of rules statically checked and much less prone to errors. This also provided a useful testbed of the ideas of scope graphs and constraints.</p> <p>The generation and resolution of constraints is intertwined, in order to allow computing constraints over inferred information.</p> <p>Furthermore, in order to generalize the notions of visibility supported by the NaBL2 language, Statix features query constraints, in order to relate references to declarations, but also to compute sets of names based on broader criteria. For example, the definition of structural record types can be expressed by a query that produces all fields of a record.</p> <p>Necessarily these changes entail that queries need to be executed in a scope graph that is not in its final form.</p> <p>This necessitate a theory of query stability. Name resolution queries such be scheduled such that they produce stable results, i.e. results that would also be produced at the end of the process. The this end a theory of critical edges was developed that asserts when it is safe to perform a query in a certain scope2.</p> <p>The Statix solver implements the operational semantics on the language in order to automatically derive type checkers from specifications. Optimizations of this solver can be based on the generaly underlying theory and be applied to all languages for which Statix specifications have been written. One such optimization is the derivation of implicitly parallel type checkers from Statix specifications[@AntwerpenV21-preprint].</p>"},{"location":"background/bibliography/statix/#editor-services","title":"Editor Services","text":"<p>A next step in the evolution of Statix is the derivation of semantic editor services such as renaming and code completion from specifications7.</p>"},{"location":"background/bibliography/statix/#references","title":"References","text":"<ol> <li> <p>Hendrik van Antwerpen, Casper Bach Poulsen, Arjen Rouvoet, and Eelco Visser. Scopes as types. Proceedings of the ACM on Programming Languages, 2018. URL: https://doi.org/10.1145/3276484, doi:10.1145/3276484.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Arjen Rouvoet, Hendrik van Antwerpen, Casper Bach Poulsen, Robbert Krebbers, and Eelco Visser. Knowing when to ask: sound scheduling of name resolution in type checkers derived from declarative specifications. Proceedings of the ACM on Programming Languages, 2020. URL: https://doi.org/10.1145/3428248, doi:10.1145/3428248.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Gabri\u00ebl Konat, Lennart C. L. Kats, Guido Wachsmuth, and Eelco Visser. Declarative name binding and scope rules. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers, volume 7745 of Lecture Notes in Computer Science, 311\u2013331. Springer, 2012. URL: http://dx.doi.org/10.1007/978-3-642-36089-3_18, doi:10.1007/978-3-642-36089-3_18.\u00a0\u21a9</p> </li> <li> <p>Guido Wachsmuth, Gabri\u00ebl Konat, Vlad A. Vergu, Danny M. Groenewegen, and Eelco Visser. A language independent task engine for incremental name and type analysis. In Martin Erwig, Richard F. Paige, and Eric Van Wyk, editors, Software Language Engineering - 6th International Conference, SLE 2013, Indianapolis, IN, USA, October 26-28, 2013. Proceedings, volume 8225 of Lecture Notes in Computer Science, 260\u2013280. Springer, 2013. URL: http://dx.doi.org/10.1007/978-3-319-02654-1_15, doi:10.1007/978-3-319-02654-1_15.\u00a0\u21a9</p> </li> <li> <p>Pierre N\u00e9ron, Andrew P. Tolmach, Eelco Visser, and Guido Wachsmuth. A theory of name resolution. In Jan Vitek, editor, Programming Languages and Systems - 24th European Symposium on Programming, ESOP 2015, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2015, London, UK, April 11-18, 2015. Proceedings, volume 9032 of Lecture Notes in Computer Science, 205\u2013231. Springer, 2015. URL: http://dx.doi.org/10.1007/978-3-662-46669-8_9, doi:10.1007/978-3-662-46669-8_9.\u00a0\u21a9</p> </li> <li> <p>Hendrik van Antwerpen, Pierre N\u00e9ron, Andrew P. Tolmach, Eelco Visser, and Guido Wachsmuth. A constraint language for static semantic analysis based on scope graphs. In Martin Erwig and Tiark Rompf, editors, Proceedings of the 2016 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, PEPM 2016, St. Petersburg, FL, USA, January 20 - 22, 2016, 49\u201360. ACM, 2016. URL: http://doi.acm.org/10.1145/2847538.2847543, doi:10.1145/2847538.2847543.\u00a0\u21a9</p> </li> <li> <p>Dani\u00ebl A. A. Pelsmaeker, Hendrik van Antwerpen, and Eelco Visser. Towards language-parametric semantic editor services based on declarative type system specifications (brave new idea paper). In Alastair F. Donaldson, editor, 33rd European Conference on Object-Oriented Programming, ECOOP 2019, July 15-19, 2019, London, United Kingdom, volume 134 of LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2019. URL: https://doi.org/10.4230/LIPIcs.ECOOP.2019.26, doi:10.4230/LIPIcs.ECOOP.2019.26.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/bibliography/stratego/","title":"A Stratego Bibliography","text":"<p>The original publication on Stratego appeared in ICFP'981 and introduced named rewrite rules and a language of strategy combinators with an operational semantics. An important aspect of the design of Stratego is the separation of the language in a core language2 of strategy combinators and a high-level 'sugar' language of rewrite rules that can be desugared to the core language. This is still the way that the Stratego compiler is organized.</p> <p>The original also introduced contextual terms. These where eventually replaced by dynamic rewrite rules3. The paper about dynamic rules3 also provides a comprehensive overview of Stratego and its operational semantics.</p> <p>Stratego and its ecosystem are described in a number of system description papers, including Stratego 0.54, Stratego/XT 0.165, Stratego/XT 0.176</p> <p>Recently, a gradual type system was designed for Stratego7. This design and its incremental compiler8 are the basis for the Stratego2 version of the language.</p>"},{"location":"background/bibliography/stratego/#references","title":"References","text":"<ol> <li> <p>Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming, 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425, doi:10.1145/289423.289425.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science, 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1, doi:10.1016/S1571-0661(05)80027-1.\u00a0\u21a9</p> </li> <li> <p>Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae, 69(1-2):123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06.\u00a0\u21a9\u21a9</p> </li> <li> <p>Eelco Visser. Stratego: a language for program transformation based on rewriting strategies. In Aart Middeldorp, editor, Rewriting Techniques and Applications, 12th International Conference, RTA 2001, Utrecht, The Netherlands, May 22-24, 2001, Proceedings, volume 2051 of Lecture Notes in Computer Science, 357\u2013362. Springer, 2001. URL: https://doi.org/10.1007/3-540-45127-7_27, doi:10.1007/3-540-45127-7_27.\u00a0\u21a9</p> </li> <li> <p>Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.16: components for transformation systems. In John Hatcliff and Frank Tip, editors, Proceedings of the 2006 ACM SIGPLAN Workshop on Partial Evaluation and Semantics-based Program Manipulation, 2006, Charleston, South Carolina, USA, January 9-10, 2006, 95\u201399. ACM, 2006. URL: http://doi.acm.org/10.1145/1111542.1111558, doi:10.1145/1111542.1111558.\u00a0\u21a9</p> </li> <li> <p>Martin Bravenboer, Karl Trygve Kalleberg, Rob Vermaas, and Eelco Visser. Stratego/XT 0.17. A language and toolset for program transformation. Science of Computer Programming, 72(1-2):52\u201370, 2008. URL: http://dx.doi.org/10.1016/j.scico.2007.11.003, doi:10.1016/j.scico.2007.11.003.\u00a0\u21a9</p> </li> <li> <p>Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020, 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928, doi:10.1145/3426425.3426928.\u00a0\u21a9</p> </li> <li> <p>Jeff Smits, Gabri\u00ebl Konat, and Eelco Visser. Constructing hybrid incremental compilers for cross-module extensibility with an internal build system. Programming Journal, 4(3):16, 2020. URL: https://doi.org/10.22152/programming-journal.org/2020/4/16, doi:10.22152/programming-journal.org/2020/4/16.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/documentation/","title":"Documentation","text":"<p>This section explains the documentation's technology and structure, and how you can contribute.</p>"},{"location":"background/documentation/#technology","title":"Technology","text":"<p>This documentation uses MkDocs, a fast and simple static site generated that's geared towards building project documentation from Markdown files. In particular, this website uses MkDocs Material, which provides a clean look, easy customization, and many features for technical documentation.</p>"},{"location":"background/documentation/#structure","title":"Structure","text":"<p>The structure of this documentation follows the Grand Unified Theory of Documentation where documentation is split into four categories:</p> <ul> <li>Tutorials: oriented to learning, enabling newcomers to get started through a lesson, analogous to teaching a child how to cook.</li> <li>How-Tos: oriented to a particular goal, showing how to solve a specific problem through a series of steps, analogous to a recipe in a cookbook.</li> <li>Reference: oriented to information, describing the machinery through dry description, analogous to an encyclopaedia article.</li> <li>Background: oriented to understanding, explaining through discursive explanation, analogous to an article on culinary social history.</li> </ul>"},{"location":"background/documentation/#contributing","title":"Contributing","text":"<p>Contributing to the documentation is easy. Quick changes and fixing typos can be done by clicking the  button in the top-right corner of a page, and editing and saving the underlying Markdown file.</p> <p>More considerable contributions can be made by cloning this repository locally, and editing the Markdown files there. The easiest way to get a live preview (automatically reloading) of your changes, is by installing Docker and executing <code>make</code> from the root directory. This will serve the latest changes to localhost:8000.</p> <p> MkDocs Reference  Extensions Reference</p>"},{"location":"background/documentation/citations/","title":"How to cite in documentation","text":"<p>To cite a paper or work, first ensure the citation is in a bibliography (<code>.bib</code>) file in the <code>/bibliographies/</code> directory. For example, in the <code>bibliographies/spoofax.bib</code> file, we find:</p> <pre><code>@inproceedings{KatsV10,\ntitle = {The {Spoofax} language workbench: rules for declarative specification of languages and {IDEs}},\nauthor = {Lennart C. L. Kats and Eelco Visser},\nyear = {2010},\ndoi = {10.1145/1869459.1869497},\nurl = {https://doi.org/10.1145/1869459.1869497},\npages = {444-463},\nbooktitle = {Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010},\n}\n</code></pre> Adding References <p>To add a reference, add it on Researchr to the Spoofax bibliography. Then on the command-line, invoke the following to regenerate the <code>spoofax.bib</code> file:</p> <pre><code>make bib\n</code></pre> <p>Do not change the <code>spoofax.bib</code> file manually, it is generated and updated through Researchr.</p> <p>Then reference the work like this:</p> <pre><code>The Spoofax language workbench[@KatsV10] is vital to declarative language development.</code></pre> <p>Finally, add a place for the bibliography footnotes to be added (usually at the end of the file) by adding the following line to the file:</p> <pre><code>\\bibliography</code></pre> <p>The line will be rendered as:</p> <p>The Spoofax language workbench1 is vital to declarative language development.</p> <p>And the references will be at the bottom of this page.</p> <p>If the citation appears rendered as <code>Spoofax language workbench[^1]</code>, then you might have forgotten to add a place for the bibliography.</p> <ol> <li> <p>Lennart C. L. Kats and Eelco Visser. The Spoofax language workbench: rules for declarative specification of languages and IDEs. In William R. Cook, Siobh\u00e1n Clarke, and Martin C. Rinard, editors, Proceedings of the 25th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2010, 444\u2013463. Reno/Tahoe, Nevada, 2010. ACM. URL: https://doi.org/10.1145/1869459.1869497, doi:10.1145/1869459.1869497.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/documentation/code-highlighting/","title":"Documentation Code Highlighting","text":""},{"location":"background/documentation/code-highlighting/#block-highlighting","title":"Block Highlighting","text":"<p>To apply code highlighting to a block of code, surround it with triple backticks (<code>```</code>) and write the name of the language after the starting backticks, like this:</p> Markdown <pre><code>```python\ndef foo():\n    pass\n```\n</code></pre> Output <pre><code>def foo():\n    pass\n</code></pre>"},{"location":"background/documentation/code-highlighting/#inline-highlighting","title":"Inline Highlighting","text":"<p>To apply code highlighting to inline code, surround the code with single backticks (<code>`</code>) and add <code>#!</code> after the initial backtick, followed by the language name:</p> Markdown <pre><code>Call the `#!python def foo()` function.\n</code></pre> Output <p>Call the <code>def foo()</code> function.</p>"},{"location":"background/documentation/code-highlighting/#languages","title":"Languages","text":"<p>The highlighter supports all languages supported by Pygments.</p> <p>The Pygments project has a list of all supported languages. To use a language, refer to it through one of its short names.</p> <p>Additionally, in this Spoofax documentation these Spoofax languages are supported:</p> Short name Language <code>aterm</code> ATerms. <code>dynsem</code> DynSem. <code>esv</code> ESV. <code>flowspec</code> FlowSpec. <code>nabl</code> NaBL. <code>nabl2</code> NaBL2. <code>sdf3</code> SDF3. <code>statix</code> Statix. <code>stratego</code> Stratego."},{"location":"background/documentation/guis-and-menus/","title":"How to document GUIs and Menus","text":"<p>To describe (a sequence of) menu items or GUI elements, you can format them using the <code>gui</code> inline language, and separate them with <code>&gt;</code>. For example, this describes a preferences sequence in Eclipse:</p> <pre><code>Open the `#!gui General &gt; Startup and Shutdown` settings page.\n</code></pre> <p>It is rendered as:</p> <p>Open the General \u2023 Startup and Shutdown settings page.</p>"},{"location":"background/documentation/internal-links/","title":"How to write internal links","text":"<p>Links to other parts of the documentation should be written as relative links and point to specific Markdown files. For example, to add a link to <code>tutorials</code> from the <code>background/index.md</code> page, the link should read:</p> <pre><code>[Tutorials](../tutorials/index.md)\n</code></pre> <p>To link to the index page of a section, link to the <code>index.md</code> file.</p> <p>Avoid internal links without <code>.md</code></p> <p>Even if it might seem to work, do not link to an internal page without specifying the <code>.md</code> file to link to. For example, do not use <code>[Background](../background/)</code>. These links will not work once the documentation has been deployed.</p> <p>Additionally, you won't see any warnings about these (possibly broken) links in the console when running <code>mkdocs</code> or its Docker image.</p> <p>Absolute Links are Not Supported</p> <p>Even if it might seem to work, do not link to an internal page using an absolute link. For example, do not use <code>[Background](/background/index.md)</code>. These links are not properly converted and will break once the documentation has been deployed.</p>"},{"location":"background/documentation/pages/","title":"How to add a new documentation page","text":"<p>To add a new page to the documentation:</p> <ol> <li>Create a Markdown (<code>.md</code>) file in an appropriate location in the <code>docs/</code> folder;</li> <li> <p>Add the page to the <code>nav</code> element in the <code>mkdocs.yml</code> file in the root of the repository.</p> Overriding the title <p>By default, the title shown in the Table of Contents is the title of the page. To override this, specify a title in the <code>nav</code> element explicitly. For example:</p> <pre><code>nav:\n- Home:\n- index.md\n- Installation: getting-started.md\n</code></pre> </li> </ol> <p>By convention, the first page mentioned in <code>nav</code> under a section should be some <code>index.md</code> (without a title), and will be used as the index page (home page) for that section.</p>"},{"location":"background/documentation/structure/","title":"Documentation Structure","text":"<p>The structure of the documentation repository is as follows (hover over any of the files to see its description):</p> <pre>\n\ud83d\udce6 /\n \u2523 \ud83d\udcc1 .github\n \u2523 \ud83d\udcc2 bibliographies\n \u2523 \ud83d\udcc2 docs\n \u2503 \u2523 \ud83d\udcc2 assets\n \u2503 \u2503 \u2523 \ud83d\udcdc favicon.png\n \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-dark.svg\n \u2503 \u2503 \u2523 \ud83d\udcdc hero-border-light.svg\n \u2503 \u2503 \u2523 \ud83d\udcdc hero.svg\n \u2503 \u2503 \u2523 \ud83d\udcdc logo.svg\n \u2503 \u2503 \u2517 \ud83d\udcdc styles.css\n \u2503 \u2523 \ud83d\udcc2 background\n \u2503 \u2523 \ud83d\udcc2 howtos\n \u2503 \u2523 \ud83d\udcc2 reference\n \u2503 \u2523 \ud83d\udcc2 release\n \u2503 \u2523 \ud83d\udcc2 support\n \u2503 \u2523 \ud83d\udcc2 tutorials\n \u2503 \u2517 \ud83d\udcdc index.md\n \u2523 \ud83d\udcc1 overrides\n \u2503 \u2523 \ud83d\udcdc index.html\n \u2503 \u2517 \ud83d\udcdc main.html\n \u2523 \ud83d\udcdc .gitignore\n \u2523 \ud83d\udcdc Dockerfile\n \u2523 \ud83d\udcdc LICENSE\n \u2523 \ud83d\udcdc Makefile\n \u2523 \ud83d\udcdc mkdocs_requirements.txt\n \u2523 \ud83d\udcdc mkdocs.yml\n \u2517 \ud83d\udcdc README.md\n</pre>"},{"location":"background/documentation/troubleshooting/","title":"Documentation Troubleshooting","text":""},{"location":"background/documentation/troubleshooting/#macro-syntax-error-missing-end-of-comment-tag","title":"Macro Syntax Error: Missing end of comment tag","text":"<p>The macros in the documentation, including in code blocks, is expanded through the <code>mkdocs-macros</code> plugin which uses the Jinja2 template processor. Its template syntax is very advanced, allowing not only to replace simple references, but also more complex statements and comments. In this case, Jinja sees <code>{#</code> and interprets it as a comment. Of course, then it cannot find the end of the comment and produces an error.</p> <pre><code>INFO - [macros] - ERROR # _Macro Syntax Error_\n       _Line 11 in Markdown file:_ **Missing end of comment tag**\n       ```python\n       {# This is not a Jinja comment }\n       ```\n</code></pre> <p>To work around this, wrap the block in a <code>{% raw %}</code> and <code>{% endraw %}</code> tag. For example:</p> <pre><code>{% raw %}\n```\n{# This is not a Jinja comment }\n```\n{% endraw %}\n</code></pre> <p>Alternatively, if you still want to use other macros in the code, wrap the offending character sequence in a template:</p> <pre><code>{{'{#'}}\n</code></pre> <p>For example:</p> <pre><code>```\n{{'{#'}} This is not a Jinja comment }\n```\n</code></pre> <p>In both cases the example gets rendered as:</p> <pre><code>{# This is not a Jinja comment }\n</code></pre>"},{"location":"background/statix/","title":"Statix Background","text":"<ul> <li>rule selection</li> <li>open/closed world reasoning (<code>try</code>/DWF/DLeq)</li> <li>desugaring of functional rules</li> <li>Internal representation of scope graphs</li> <li>Query Scheduling/Permission to Extend</li> </ul>"},{"location":"background/statix/rule-selection/","title":"The Semantics of Rule Selection","text":"<p>In this background article, we consider the precise semantics of Statix' rule selection, and motivate it. In the first section we consider the components of which a user-defined constraint in Statix is composed. After that, we consider how a constraint is solved. Next, we explain how Statix chooses an appropriate rule for a constraint, and finally, we explain the analysis Statix performs over specifications that guarantees that, for any constraint with ground arguments, at most one single rule is available.</p>"},{"location":"background/statix/rule-selection/#the-anatomy-of-a-user-defined-constraint","title":"The Anatomy of a User-Defined Constraint","text":"<p>Statix allows users to define their own constraints. Before explaining how these constraints are evaluated, we explain the components of which user-defined constraints and their rules are built. We use the following specification snippet as an example.</p> <pre><code>rules\n\ntypeOfExpr: scope * Expr -&gt; TYPE\n\n[T-Int]typeOfExpr(s, IntLit(_)) = INT().\n\n[T-Add]typeOfExpr(s, Add(e1, e2)) = INT() :-\ntypeOfExpr(s, e1) == INT(),\ntypeOfExpr(s, e2) == INT().\n</code></pre> <p>In this example, a user-defined constraint <code>typeOfExpr</code> is defined. A user constraint consists of a constraint declaration and a collection of rules. A constraint declaration (line 3 of the example) introduces a user constraint by declaring its name and signature. This declaration indicates that propositions of the form <code>typeOfExpr/3</code> can be proven. In order to prove such statements, rules (such as <code>T-Int</code> and <code>T-Add</code>) can be declared.</p> <p>Rules can be split in two parts: the head and the body. The head is the part before the turnstile (<code>:-</code> symbol), while the body comes after it. Declaratively, such rules read as \"from body, head can be derived\".</p> <p>A rule head consists of three components: the rule name, the constraint id, and the head pattern. The rule name (<code>T-Int</code> and <code>T-Add</code> in the example) is optional, and only serves documentation purposes. The constraint identifier indicates the predicate for which this rule can prove constraints. Finally, the head pattern determines which constraints can be proven using this rule.</p>"},{"location":"background/statix/rule-selection/#solving-a-user-defined-constraint","title":"Solving a User-Defined Constraint","text":"<p>Given such constraint simplification rules, how can we solve constraints with them? The way this works in Statix is as follows. Statix takes a top-down approach. This means that it starts with an initial constraint, which it will simplify until a solution for the original constraint is found. For a user-defined constraint, this simplification proceeds in three steps:</p> <ol> <li>Based on the predicate arguments, a matching rule is selected. A rule matches    a constraint when the constraint arguments match agains the head pattern.</li> <li>Based on the match, all head pattern variables in the constraint body are    substituted with the values assigned to them by the head matching.</li> <li>All constraints in the substituted body are added to the active constraint    set, while the original (now simplified) constraint is removed from    the set of active constraints.</li> </ol> <p>For example, suppose the initial constraint is <code>typeOfExpr(#s, Add(IntLit(20), IntLit(22))) == INT()</code>. This constraint only matches the <code>T-Add</code> rule. Therefore that rule is selected. When matching the following pattern variable bindings are created: <pre><code>  s  |-&gt; #s\ne1 |-&gt; IntLit(20)\ne2 |-&gt; IntLit(22)\n</code></pre> These bindings are substituted in the body of the <code>T-Add</code> rule, yielding the following constraints:</p> <p><pre><code>  typeOfExpr(#s, IntLit(20)) == INT()\ntypeOfExpr(#s, IntLit(22)) == INT()\n</code></pre> These constraints are added to the set of active constraints, and then subsequently solved.</p>"},{"location":"background/statix/rule-selection/#choosing-from-multiple-applicable-rules","title":"Choosing from Multiple Applicable Rules","text":"<p>Now the question naturally arises what happens when multiple rules can be applied to try to solve a single constraint. For example, consider solving the constraint <code>subtype(NULL(INT()), NULL(INT()))</code> using the following specification. <pre><code>rules\n\nsubtype: TYPE * TYPE -&gt; TYPE\n\n[S-Eq]subtype(T, T).\n\n[S-Null]subtype(NULL(T1), T2) :-\nsubtype(T1, T2).\n</code></pre> Both rules can be used to simplify the original constraint, but only <code>S-Eq</code> will ensure the constraint will be solved. Selecting <code>S-Null</code> yields <code>subtype(NULL(INT()), INT())</code>, as simplified constraint, for which no applicable rule exists.</p> <p>At a first glance, the most robust option seems to try all possible rules, until a rule is found that ensures the constraint is solved. When the simplified constraints of a particular rule application cannot be fully solved, the modifications to the solver state are undone, and another rule is tried.</p> <p>However, there are multiple problems with this approach. Perhaps most important, in a type-system we prefer to assign principal types. Principal types should be unique, and correspond to a minimal model. However, for such a backtracking approach, it is not guaranteed that a unique minimal solution for a constraint exists. For example, consider solving <code>lub(INT(), INT()) == ?T</code> with the following specification:</p> <p><pre><code>rules\nlub: TYPE * TYPE -&gt; TYPE\n\nlub(T, T) = T.\nlub(_, _) = ANY().\n</code></pre> In this case, the rules show that both <code>?T |-&gt; INT()</code> and <code>?T |-&gt; ANY()</code> are solutions for this problem. However, one cannot derive from the specification (with the backtracking semantics) which solution is the intended one.</p> <p>Additionally, backtracking comes with significant performance drawbacks. Consider backtracking on an edge assertion. All scope graph queries that traversed that edge now need to be undone, including all constraints over their answers. Although it is never tried for Statix itself, we expect such operations to become very bad in performance, limiting the scalability of Statix.</p> <p>Specificity Ordering. Instead of backtracking, we employ a committed choice approach. That is, once Statix selects a rule, it will never backtrack on that choice. The rule that is selected is not arbitrary, but instead Statix tries to find the most specific rule that applies to the constraint. More precisely, the 'most specific' rule to select is determined as follows. First, we call the collection of term that match on a pattern the domain of the pattern. For example, <code>NULL(T)</code> matches <code>NULL(INT())</code> and <code>NULL(BOOL())</code> (i.e., those are in the domain of <code>NULL(T)</code>), but not <code>INT()</code>. Second, we call a pattern P1 more specific than another pattern P2 when the domain of P1 is strictly contained in the domain of P2. So, for example, the pattern <code>NULL(INT())</code> is more specific than <code>NULL(_)</code>, but of <code>FUN(BOOL(), _)</code> and <code>FUN(INT(), _)</code>, neither is more specific than the other. We use this notion of pattern specificity to deterministically select a rule for a constraint as follows. When two rules (say R1 and R2) can both be used to solve a constraint C, we compare the argument patterns from R1 and R2 from left to right, and select the rule for which we first encounter a more specific pattern. This way of ordering rules is usually referred to as specificity ordering.</p> <p>We explain this rule by applying them to the previous examples. Consider the rules <code>S-Eq</code> and <code>S-Null</code> again. When comparing these rules, first the patterns <code>T</code> (from <code>S-Eq</code>) and <code>NULL(T)</code> (from <code>S-Null</code>) are compared. It can easily be seen that <code>T</code> is more generic that <code>NULL(T)</code>. Therefore, for the example constraint, <code>S-Null</code> is chosen.</p> <p>An attentive reader might observe that choosing <code>S-Null</code> is perhaps not the intended choice of the specification writer. To solve this, an additional rule <code>subtype(NULL(T), NULL(T))</code> (or, shorter but equivalent: <code>subtype(T@NULL(_), T)</code>) must be added. This rule takes precedence over the first rule, because <code>NULL(T)</code> is more specific than <code>T</code>. Moreover, it is also preferred over the second rule, as the following discussion will explain.</p> <p>Non-linear Patterns. Looking to the <code>lub(INT(), INT())</code> example, we first compare <code>T</code> with <code>_</code>. As both of them match all terms of their sort, they are considered equal. Hence the rule selection procedure continues with comparing the second pair of arguments. Again, the patterns <code>T</code> and <code>_</code> are compared. While it seems that these patterns are again similar, that is not actually the case. Because the <code>T</code> variable did already occur earlier (that is, more to the left) in the pattern, its domain is restricted to the value assigned to the first occurrence of <code>T</code>. Therefore, the first constraint is selected, and <code>INT()</code> is determined to be the unique upper bound of two <code>INT()</code> types.</p> <p>To see why this treatment of non-linear patterns (i.e., patterns in which a variable occurs multiple times) makes sense, consider selecting a rule for <code>lub(INT(), BOOL()) == ?T</code>. It is obvious that this constraint does not match the first rule, because the pattern variable <code>T</code> cannot be assigned both <code>INT()</code> and <code>BOOL()</code> at the same time. In the selection strategy outlined in the previous paragraph, this is accounted for by treating the second <code>T</code> as restricted to the value of its first occurrence.</p> <p>This leads us to a last subtlety. Consider the constraint <code>c(C(), C(), C())</code> in the following specification: <pre><code>rules\nc: S * S * S\n\n[C-1]c(T, _, T).\n[C-2]c(_, T, T) :- false\n</code></pre> Applying the left-to-right comparison will regard the first two argument pairs equal, as both compare a wildcard with a new variable. When comparing the third pair of patterns (<code>T</code> and <code>T</code>), both of them are restricted by their earlier occurrence. In order to 'break ties' here, the rule in which the bound variable occurred the earliest is chosen. In this case, the <code>T</code> occurred at argument position 1 in <code>C-1</code>, while it occurred at position 2 in <code>C-2</code>. Therefore, for this constraint, rule <code>C-1</code> is chosen.</p> <p>In summary, given two applicable rules for a constraint, the rule to choose is decided using the following rules:</p> <ol> <li>When pairwise comparing the arguments of the rules from left to right, the    rule for which a more specific argument pattern is encountered first is    chosen.</li> <li>For non-linear patterns, a second occurrence of a variable is regarded as    more specific than a first occurrence of a variable. When both variables are    bound already, the one bound the earliest is considered the most specific.</li> </ol>"},{"location":"background/statix/rule-selection/#guaranteeing-rule-selection-uniqueness","title":"Guaranteeing Rule Selection Uniqueness","text":"<p>The rules outlined above cannot prioritize all pairs of rules. Therefore Statix statically prevents rules with overlapping patterns. In this section, we discuss which rule patterns are not allowed to co-exist.</p> <p>Obviously, two equivalent patterns is not allowed. Consider for example the following specification: <pre><code>rules\nrule: S * S\n\nrule(T, T).\nrule(S, S) :- false.\n</code></pre> In this specification, there are two rules with fully equivalent patterns. Thus it is not possible to prioritize a particular rule over another. Therefore Statix will statically reject this specification.</p> <p>More intricate cases happen when non-linear patterns are involved. Consider this specification as an example: <pre><code>rules\nsubtype: TYPE * TYPE\n\n[S-Null]subtype(_, NULL()).\n[S-Any]subtype(_, ANY()).\n\n[S-Eq]subtype(T, T).\n</code></pre> In this specification, <code>S-Null</code> and <code>S-Any</code> can co-exist without problems, because their domains do not overlap. However, this does not hold for <code>S-Null</code> and <code>S-Eq</code>, because <code>subtype(NULL(), NULL())</code> matches both. In addition, they cannot be ordered using the rule ordering we explained so far. The first terms (<code>_</code>) are obviously equal, while the second terms (<code>NULL()</code> and <code>ANY()</code>) have no ordering. To prevent such runtime non-determinism, Statix will statically compare all rule heads using the rules outlined above. In case the heads of a pair of rules have overlapping domains, but can not be ordered (such as <code>S-Eq</code> and <code>S-Null</code>), a static error is emitted.</p> <p>On the subset of possible rules that adheres to the static analysis described above, an ordering is defined on any pair of rules with overlapping domains. Therefore, for each constraint, a single rule is selected deterministically. This ensures constraints have a unique solution, giving Statix the desirable properties of confluence and efficiency.</p>"},{"location":"background/statix/rule-selection/#conclusion","title":"Conclusion","text":"<p>Statix uses a deterministic, committed-choice, rule selection mechanism to solve user-defined constraints. The choice mechanism prefers rules with a smaller domain (if applicable) over more general ones. In case of incomparable domains, a left-to-right comparison of the individual arguments is made. A static analysis on Statix specifications ensures there exist no rules that incomparable using this method in a real specification.</p>"},{"location":"background/stratego/","title":"Stratego","text":"<p>The Stratego transformation was born from a pure rewriting approach to program transformation by the introduction of traversal combinators1 and programmable rewriting strategies2.</p>"},{"location":"background/stratego/#strategic-rewriting","title":"Strategic Rewriting","text":"<p>This section reviews the classic definition of term rewriting and motivates the transition to strategic rewriting.</p> <ul> <li>Term rewriting</li> <li>Limitations of term rewriting</li> <li>Factoring out Traversal</li> <li>Strategic Rewriting</li> </ul>"},{"location":"background/stratego/#strategy-combinators","title":"Strategy Combinators","text":"<p>Rather than defining high-level strategies as primitives, Stratego provides basic strategies combinators for composing strategies. The section in the reference manual provides a definition of all the combinators. Here we expand that description with many examples.</p> <ul> <li>Sequential combinators</li> <li>Term combinators</li> <li>Traveral combinators</li> <li>Type unifying traversals</li> </ul>"},{"location":"background/stratego/#origin-tracking","title":"Origin Tracking","text":"<p>Origin tracking is a term rewriting feature that has been put into Stratego to track connections between terms through a transformation. If you for example parse a file into an abstract syntax tree (AST) and the parser leaves some information about what term refers to what part of the file, you can keep track of that even after transformations.</p> <p>However, origin tracking in Stratego is rather limited, and people are often confused about how it works. On the page for Origin Tracking you can find an explanation of origin tracking, how it works in Stratego, and plans on future improvements. </p>"},{"location":"background/stratego/#references","title":"References","text":"<ol> <li> <p>Bas Luttik and Eelco Visser. Specification of rewriting strategies. In M. P. A. Sellink, editor, 2nd International Workshop on the Theory and Practice of Algebraic Specifications (ASF+SDF 1997), Electronic Workshops in Computing. Berlin, November 1997. Springer-Verlag.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming, 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425, doi:10.1145/289423.289425.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/stratego/origin-tracking/","title":"Origin Tracking","text":"<p>Origin tracking is the idea to build an origin relation between input and output terms of a transformation in a term transformation system (TRS). It was first proposed by Van Deursen et al. in 1993 in the eponymous article1. The origin relation can be used to traverse from a result term, to the term before the final transformation happened. This relation can be followed further, all the way back to the original input term before all transformations. Examples of uses for this relation (from the paper) are: constructing language-specific debuggers, visualising program execution, and associating positional information with messages in error reports. The first two examples relate to using the TRS to implement evaluation (interpretation) of a programming language, where the abstract syntax tree (AST) of a program is a term that is transformed to execute it. The origin relation allows a debugger or visualiser to show the execution one step at a time. The third example uses the origin relation transitively to reach the original AST of a program and extract positional information from it which was left by the process that created the AST (e.g. a parser or projectional editor). </p> <p>Spoofax, in particular Stratego inside of Spoofax, can also do some origin tracking. This origin relation is used as a one-to-one relation to the original AST only, as it is mostly used for accessing the positional information on the original AST, left there by the parser. Stratego origin tracking as it is implemented today is rather limited and confusing to users. Therefore this page describes how it works today, what the original paper described, and how origin tracking might be improved in Stratego 2. </p>"},{"location":"background/stratego/origin-tracking/#origin-tracking-in-asf","title":"Origin Tracking in ASF","text":"<p>Caveat Lector</p> <p>This is a summary based on the first and last sections of the paper. The high-level explanation was intuitive so this is based only on that and not the formal definition in the middle.</p> <p>The TRS used in the paper was the ASF+SDF meta-environment, of which the ASF part, the algebraic specification formalism, was a conditional term transformation system (CRTS). The origin tracking system was a static analysis applied to rewrite rules to find the origin relations between the left-hand side terms and the right-hand side terms. Through a number of rules this system would track relations between contexts, common variables, common subterms, and the redex. Let's quickly go over </p>"},{"location":"background/stratego/origin-tracking/#common-variables","title":"Common Variables","text":"<p>Because of non-linear rewrite rules, e.g. <code>plus(X,X) -&gt; mul(2, X)</code>, an origin relation could be from a term captured by variable <code>X</code> and both the subterms of <code>plus</code> on the left. That's the only special case, otherwise it's just a matter of the thing captured in variables and used on both sides of the rule have the obvious relation.</p>"},{"location":"background/stratego/origin-tracking/#common-subterms","title":"Common Subterms","text":"<p>Common subterms are related. This is not only the case of variables, but also for constants (e.g. <code>empty-list</code> in <code>append(E,empty-list) -&gt; cons(E,empty-list)</code>), and larger combinations (e.g. <code>while(Ezp,S-list)</code> in <code>ev-stat(while(Ezp,S-list) , Env) -&gt; ev-stat (while (Ezp, S-list), ev-list (S-list, Env) ) when ev-exp(Exp, Env) =  true</code>). (Capitalized things are variables in ASF). </p>"},{"location":"background/stratego/origin-tracking/#redex-contractum","title":"Redex-Contractum","text":"<p>If not related by a previous rule, the left-hand topmost term and righ-hand topmost term are related. For example, the rule <code>real-const(Char-list) -&gt; real-type</code> which returns a type for an expression, relates the type <code>real-type</code> on the right to the expression <code>real-const(...)</code> on the left. </p>"},{"location":"background/stratego/origin-tracking/#conditional-rewriting","title":"Conditional Rewriting","text":"<p>Because ASF is a conditional rewrite system, there can be <code>when</code> clauses that bind more variables and deep pattern matches etc. This means that certain deeper terms on the right-hand side may not get an origin, such as the second <code>seq</code> and <code>add</code> in <code>trans(plus(E1,E2)) -&gt; seq(trans(El), seq(trans(E2), add))</code>. </p>"},{"location":"background/stratego/origin-tracking/#origin-tracking-in-stratego","title":"Origin Tracking in Stratego","text":"<p>Origin tracking in Stratego is implemented in the runtime. Calling it a dynamic analysis would be generous, it looks more like an afterthought that's hacked in quickly. </p> <p>The place where origin tracking is implemented is the runtime of the <code>all</code>, <code>some</code> and <code>one</code> language constructs. These will make an origin relation between the origin of the term on which the construct is applied, and the result term. This is so the origin relation is always directly to the original AST. This works for tuples and constructor applications, where children are actually changed by the given strategy to apply to the children. The construct also work on lists. There is an extra hack where the origin tracking goes one level deeper in lists (directly implemented in <code>all</code>, implemented in the <code>OriginTermFactory</code> for <code>some</code> and <code>one</code>). Therefore the Stratego strategy <code>origin-track-forced(s) = ![&lt;id&gt;]; map(s); ?[&lt;id&gt;]</code> adds the \"redex-contractum\" style origin tracking to a strategy <code>s</code> (<code>map</code> is implemented in terms of <code>all</code> in a performance override for the Java implementation of the Stratego runtime). </p> <p>So, the reason why origin tracking in Stratego seems to be broken in edge-cases that you can never quite remember, is because it is only applied by generic traversals, mapping over lists, and other strategies that internally use <code>all</code>, <code>some</code>, or <code>one</code>. Still, this approach allowed for a very quick addition of origin tracking to Stratego without a need to change the compiled (for the static analysis), and in fact Stratego and its compiler don't even really know of origins as a thing that terms can have. </p>"},{"location":"background/stratego/origin-tracking/#a-proposal-for-improved-origin-tracking-in-stratego","title":"A Proposal for Improved Origin Tracking in Stratego","text":"<p>Attempting to replicate the static analysis of ASF for Stratego would be a rather large task that would influence the CTree format between the front-end and back-end of the compiler. That format has been stable for a long time, and changing it could have unexpected effects throughout the codebase of Spoofax. It would also require quite some effort to integrate into both the front-end of the compiler and make the corresponding changes to the back-end, check all the code in between can handle the changed CTree format, etc. And we'll inherit the shortcoming of that analysis, in particular how some terms will still not have origins, and other terms have multiple origins. The first is annoying, and we can possibly overcome it, the second is more dangerous as it breaks the interface Spoofax expects of exactly one origin term. </p> <p>So instead my proposal has the following properties: (1) all terms get an origin, (2) which origin is still fairly easy to understand, (3) the implementation effort is minimized. The downsides are: (1) origins may be a bit suboptimal in some situations, (2) a certain (hypothetical!) optimisation of Stratego becomes more complicated.</p>"},{"location":"background/stratego/origin-tracking/#the-proposal-the-origin-of-a-newly-built-term-is-the-current-term","title":"The proposal: the origin of a newly built term is the current term","text":"<p>To avoid the whole static analysis, changing the CTree format, etc, the origin tracking rule needs to be dead simple. This proposal will allow for origin tracking to be implemented in back-end of the compiler without extra analysis and support in the front-end, side-stepping the CTree format changes. This does mean that we've lost the information on what were strategy and what were rules in the source text of the Stratego program. But we want origin tracking to be defined for even the most basic strategy expressions anyway, and this seems like the most reasonable approach there. With minor changes to the code generation code in the Stratego compiler, we can target already available methods of the <code>ITermFactory</code> to set the origin of a newly built term as the current term. </p> <p>Desugared rules will have the correct redex-contractum origin relation. Common variable work as expected due to sharing. In the case of non-linear rewrite rules the leftmost occurrence of the variable is the origin. Common subterms will not get the, perhaps expected, origin relation, instead a subterm will be related to the whole term of the left-hand side. Once this rule is established and understood by Stratego users, they will find code patterns to work around with this. The origin term will still be close to the desired one, just higher up in the tree. </p> <p>Apart from suboptimal origins for subterms sometimes, there is the question of optimisation, really of semantics. In core Stratego, you could have a sequence of two builds. In general we cannot optimise this to only the second build, because the first can fail if it uses an unbound variable. But now that the current term is relevant for any build that constructs a new term (rather than only a variable), there will be more edge-cases to keep in mind when attempting to optimise sequences of builds. This is not a concern that affects any current optimisations in Stratego though. But it should be noted as the current term and origins are not explicitly mentioned anywhere in the AST of a Stratego program. </p>"},{"location":"background/stratego/origin-tracking/#performance-implications","title":"Performance implications","text":"<p>Estimated performance impact of the changes proposed above should be minimal, but expectations like that should of course be verified. This will require the construction of a general Stratego benchmark, which we currently do not have available (although there is some source code available from some TRS benchmarking contests). The current API of the <code>ITermFactory</code> would require that each term build would need an extra method call to track origins. This short method is expected to be inlined by the JIT compiler, but it could be expensive. If that turns out to be the case, the <code>ITermFactory</code> interface could be expanded to allow for a single method to build a new term and provide the origin term as well. Some of these methods already exist, but their semantics is rather constrained. Making proper, backward compatible changes that keep bootstrapping in mind should be possible and not particularly challenging. </p>"},{"location":"background/stratego/origin-tracking/#references","title":"References","text":"<ol> <li> <p>Arie van Deursen, Paul Klint, and Frank Tip. Origin tracking. Journal of Symbolic Computation, 15(\u215a):523\u2013545, 1993.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/","title":"Limitations of Rewriting","text":"<p>Term rewriting can be used to implement transformations on programs represented by means of terms. Term rewriting involves exhaustively applying rules to subterms until no more rules apply. This requires a strategy for selecting the order in which subterms are rewritten. The <code>innermost</code> strategy applies rules automatically throughout a term from inner to outer terms, starting with the leaves. The nice thing about term rewriting is that there is no need to define traversals over the syntax tree; the rules express basic transformation steps and the strategy takes care of applying it everywhere. However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for programming languages will often be non-terminating and/or non-confluent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances.</p> <p>Consider for example, the following extension of prop-dnf-rules with distribution rules to achieve conjunctive normal forms:</p> <pre><code>module prop-cnf\nimports prop-eval-rules\nrules\nE : Or(And(x, y), z) -&gt; And(Or(x, z), Or(y, z))\nE : Or(z, And(x, y)) -&gt; And(Or(z, x), Or(z, y))\nstrategies\ncnf = innermost(E)\n</code></pre> <p>This rewrite system is non-terminating because after applying one of the and-over-or distribution rules, the or-over-and distribution rules introduced here can be applied, and vice versa.</p> <pre><code>   And(Or(Atom(\"p\"),Atom(\"q\")), Atom(\"r\"))\n-&gt;\nOr(And(Atom(\"p\"), Atom(\"r\")), And(Atom(\"q\"), Atom(\"r\")))\n-&gt;\nAnd(Or(Atom(\"p\"), And(Atom(\"q\"), Atom(\"r\"))),\nOr(Atom(\"r\"), And(Atom(\"q\"), Atom(\"r\"))))\n-&gt;\n...\n</code></pre> <p>There are a number of solutions to this problem. We will first discuss a couple of solutions within pure rewriting, and then show how programmable rewriting strategies can overcome the problems of these solutions.</p>"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#attempt-1-remodularization","title":"Attempt 1: Remodularization","text":"<p>The non-termination of <code>prop-cnf</code> is due to the fact that the and-over-or and or-over-and distribution rules interfere with each other. This can be prevented by refactoring the module structure such that the two sets of rules are not present in the same rewrite system. For example, we could split module prop-dnf-rules into <code>prop-simplify</code> and <code>prop-dnf2</code> as follows:</p> <pre><code>module prop-simplify\nimports prop-eval-rules\nrules\nE : Impl(x, y) -&gt; Or(Not(x), y)\nE : Eq(x, y)   -&gt; And(Impl(x, y), Impl(y, x))\n\nE : Not(Not(x)) -&gt; x\n\nE : Not(And(x, y)) -&gt; Or(Not(x), Not(y))\nE : Not(Or(x, y))  -&gt; And(Not(x), Not(y))\n</code></pre> <pre><code>module prop-dnf2\nimports prop-simplify\nrules\nE : And(Or(x, y), z) -&gt; Or(And(x, z), And(y, z))\nE : And(z, Or(x, y)) -&gt; Or(And(z, x), And(z, y))\nstrategies\ndnf  = innermost(E)\n</code></pre> <p>Now we can reuse the rules from prop-simplify without the and-over-or distribution rules to create a <code>prop-cnf2</code> for normalizing to conjunctive normal form:</p> <pre><code>module prop-cnf2\nimports prop-simplify\nrules\nE : Or(And(x, y), z) -&gt; And(Or(x, z), Or(y, z))\nE : Or(z, And(x, y)) -&gt; And(Or(z, x), Or(z, y))\nstrategies\ncnf  = innermost(E)\n</code></pre> <p>Although this solves the non-termination problem, it is not an ideal solution. In the first place it is not possible to apply the two transformations in the same program. In the second place, extrapolating the approach to fine-grained selection of rules might require definition of a single rule per module.</p>"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#attempt-2-functionalization","title":"Attempt 2: Functionalization","text":"<p>Another common solution to this kind of problem is to introduce additional constructors that achieve normalization under a restricted set of rules. That is, the original set of rules <code>p1 -&gt; p2</code> is transformed into rules of the form <code>f(p_1) -&gt; p_2'</code>, where <code>f</code> is some new constructor symbol and the right-hand side of the rule also contains such new constructors. In this style of programming, constructors such as <code>f</code> are called functions and are distinguished from constructors. Normal forms over such rewrite systems are assumed to be free of these function symbols; otherwise the function would have an incomplete definition.</p> <p>To illustrate the approach we adapt the DNF rules by introducing the function symbols <code>Dnf</code> and <code>DnfR</code>. (We ignore the evaluation rules in this example.)</p> <pre><code>module prop-dnf3\nimports libstrategolib prop\nsignature\nconstructors\nDnf  : Prop -&gt; Prop\nDnfR : Prop -&gt; Prop\nrules\nE : Dnf(Atom(x))    -&gt; Atom(x)\nE : Dnf(Not(x))     -&gt; DnfR(Not(Dnf(x)))\nE : Dnf(And(x, y))  -&gt; DnfR(And(Dnf(x), Dnf(y)))\nE : Dnf(Or(x, y))   -&gt; Or(Dnf(x), Dnf(y))\nE : Dnf(Impl(x, y)) -&gt; Dnf(Or(Not(x), y))\nE : Dnf(Eq(x, y))   -&gt; Dnf(And(Impl(x, y), Impl(y, x)))\n\nE : DnfR(Not(Not(x)))      -&gt; x\nE : DnfR(Not(And(x, y)))   -&gt; Or(Dnf(Not(x)), Dnf(Not(y)))\nE : DnfR(Not(Or(x, y)))    -&gt; Dnf(And(Not(x), Not(y)))\nD : DnfR(Not(x))           -&gt; Not(x)\n\nE : DnfR(And(Or(x, y), z)) -&gt; Or(Dnf(And(x, z)), Dnf(And(y, z)))\nE : DnfR(And(z, Or(x, y))) -&gt; Or(Dnf(And(z, x)), Dnf(And(z, y)))\nD : DnfR(And(x, y))        -&gt; And(x, y)\nstrategies\ndnf = innermost(E &lt;+ D)\n</code></pre> <p>The <code>Dnf</code> function mimics the innermost normalization strategy by recursively traversing terms. The auxiliary transformation function <code>DnfR</code> is used to encode the distribution and negation rules. The <code>D</code> rules are default rules that are only applied if none of the <code>E</code> rules apply, as specified by the strategy expression <code>E &lt;+ D</code>.</p> <p>In order to compute the disjunctive normal form of a term, we have to apply the <code>Dnf</code> function to it, as illustrated in the following application of the <code>prop-dnf3</code> program:</p> <pre><code>&lt;dnf&gt; Dnf(And(Impl(Atom(\"r\"), And(Atom(\"p\"), Atom(\"q\"))), Atom(\"p\")))\n=&gt; Or(And(Not(Atom(\"r\")),Atom(\"p\")),\nAnd(And(Atom(\"p\"),Atom(\"q\")),Atom(\"p\")))\n</code></pre>"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#intermezzo-dnf-in-spoofaxeclipse-move-to-tutorial","title":"Intermezzo: DNF in Spoofax/Eclipse (move to tutorial?)","text":"<p>If you\u2019re going to try to run this example in Spoofax/Eclipse, a few words of caution. First, it\u2019s easiest to just accumulate all of the different test modules as imports in your main language <code>\u201c.str\u201d</code> file. But if you do that, all of the rules will be in the same namespace. So you\u2019re going to want to use different identifiers (say <code>E3</code> and <code>D3</code>) in place of <code>E</code> and <code>D</code> in your prop-dnf3.str file. Also, the concrete syntax has no way to represent the \u201cextra\u201d function symbol <code>Dnf</code> that is used here, so you\u2019ll want to use alternate triggering strategies like</p> <pre><code>make-nf = innermost(E3 &lt;+ D3)\ndnf3 : x -&gt; &lt;make-nf&gt; Dnf(x)\n</code></pre> <p>that wrap the input in <code>Dnf( ... )</code> themselves.</p> <p>For conjunctive normal form we can create a similar definition, which can now co-exist with the definition of <code>DNF</code>. Indeed, we could then simultaneously rewrite one subterm to <code>DNF</code> and the other to <code>CNF</code>.</p> <pre><code>E : DC(x) -&gt; (Dnf(x), Cnf(x))\n</code></pre>"},{"location":"background/stratego/strategic-rewriting/limitations-of-rewriting/#evaluation","title":"Evaluation","text":"<p>In the solution above, the original rules have been completely intertwined with the <code>Dnf</code> transformation. The rules for negation cannot be reused in the definition of normalization to conjunctive normal form. For each new transformation a new traversal function and new transformation functions have to be defined. Many additional rules had to be added to traverse the term to find the places to apply the rules. In the modular solution we had 5 basic rules and 2 additional rules for DNF and 2 rules for CNF, 9 in total. In the functionalized version we needed 13 rules for each transformation, that is 26 rules in total.</p>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/","title":"Strategic Rewriting","text":""},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#limitations-of-term-rewriting","title":"Limitations of Term Rewriting","text":"<p>Term rewriting involves exhaustively applying rules to subterms until no more rules apply. This requires a strategy for selecting the order in which subterms are rewritten. The innermost strategy applies rules automatically throughout a term from inner to outer terms, starting with the leaves. The nice thing about term rewriting is that there is no need to define traversals over the syntax tree; the rules express basic transformation steps and the strategy takes care of applying it everywhere. However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for programming languages will often be non-terminating and/or non-confluent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances.</p> <p>The usual solution is to encode the strategy in the rewrite rules. But this intertwines the strategy with the rules, and makes the latter unreusable.</p>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#programmable-rewriting-strategies","title":"Programmable Rewriting Strategies","text":"<p>In general, there are two problems with the functional approach to encoding the control over the application of rewrite rules, when comparing it to the original term rewriting approach: traversal overhead and loss of separation of rules and strategies.</p> <p>In the first place, the functional encoding incurs a large overhead due to the explicit specification of traversal. In pure term rewriting, the strategy takes care of traversing the term in search of subterms to rewrite. In the functional approach traversal is spelled out in the definition of the function, requiring the specification of many additional rules. A traversal rule needs to be defined for each constructor in the signature and for each transformation. The overhead for transformation systems for real languages can be inferred from the number of constructors for some typical languages:</p> <pre><code>language : constructors\nTiger    : 65\nC        : 140\nJava     : 140\nCOBOL    : 300 - 1200\n</code></pre> <p>In the second place, rewrite rules and the strategy that defines their application are completely intertwined. Another advantage of pure term rewriting is the separation of the specification of the rules and the strategy that controls their application. Intertwining these specifications makes it more difficult to understand the specification, since rules cannot be distinguished from the transformation they are part of. Furthermore, intertwining makes it impossible to reuse the rules in a different transformation.</p> <p>Stratego introduces the paradigm of programmable rewriting strategies with generic traversals, a unifying solution in which application of rules can be carefully controlled, while incurring minimal traversal overhead and preserving separation of rules and strategies1.</p> <p>The following are the design criteria for strategies in Stratego:</p> <ul> <li>Separation of rules and strategy: Basic transformation rules can be defined separately from the strategy that applies them, such that they can be understood independently.</li> <li>Rule selection: A transformation can select the necessary set of rules from a collection (library) of rules.</li> <li>Control: A transformation can exercise complete control over the application of rules. This control may be fine-grained or course-grained depending on the application.</li> <li>No traversal overhead: Transformations can be defined without overhead for the definition of traversals.</li> <li>Reuse of rules: Rules can be reused in different transformations. Reuse of traversal schemas: Traversal schemas can be defined generically and reused in different transformations.</li> </ul>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#idioms-of-strategic-rewriting","title":"Idioms of Strategic Rewriting","text":"<p>We will examine the language constructs that Stratego provides for programming with strategies, starting with the low-level actions of building and matching terms. To get a feeling for the purpose of these constructs, we first look at a couple of typical idioms of strategic rewriting.</p>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#cascading-transformations","title":"Cascading Transformations","text":"<p>The basic idiom of program transformation achieved with term rewriting is that of cascading transformations. Instead of applying a single complex transformation algorithm to a program, a number of small, independent transformations are applied in combination throughout a program or program unit to achieve the desired effect. Although each individual transformation step achieves little, the cumulative effect can be significant, since each transformation feeds on the results of the ones that came before it.</p> <p>One common cascading of transformations is accomplished by exhaustively applying rewrite rules to a subject term. In Stratego the definition of a cascading normalization strategy with respect to rules <code>R1</code>, \u2026 , <code>Rn</code> can be formalized using the innermost strategy that we saw before:</p> <pre><code>simplify = innermost(R1 &lt;+ ... &lt;+ Rn)\n</code></pre> <p>The argument strategy of innermost is a selection of rules. By giving different names to rules, we can control the selection used in each transformation. There can be multiple applications of innermost to different sets of rules, such that different transformations can co-exist in the same module without interference. Thus, it is now possible to develop a large library of transformation rules that can be called upon when necessary, without having to compose a rewrite system by cutting and pasting. For example, the following module defines the normalization of proposition formulae to both disjunctive and to conjunctive normal form:</p> <pre><code>module prop-laws\nimports prop\nrules\n\nDefI : Impl(x, y) -&gt; Or(Not(x), y)\nDefE : Eq(x, y)   -&gt; And(Impl(x, y), Impl(y, x))\n\nDN   : Not(Not(x)) -&gt; x\n\nDMA  : Not(And(x, y)) -&gt; Or(Not(x), Not(y))\nDMO  : Not(Or(x, y))  -&gt; And(Not(x), Not(y))\n\nDAOL : And(Or(x, y), z) -&gt; Or(And(x, z), And(y, z))\nDAOR : And(z, Or(x, y)) -&gt; Or(And(z, x), And(z, y))\n\nDOAL : Or(And(x, y), z) -&gt; And(Or(x, z), Or(y, z))\nDOAR : Or(z, And(x, y)) -&gt; And(Or(z, x), Or(z, y))\n\nstrategies\n\ndnf = innermost(DefI &lt;+ DefE &lt;+ DAOL &lt;+ DAOR &lt;+ DN &lt;+ DMA &lt;+ DMO)\ncnf = innermost(DefI &lt;+ DefE &lt;+ DOAL &lt;+ DOAR &lt;+ DN &lt;+ DMA &lt;+ DMO)\n</code></pre> <p>The rules are named, and for each strategy different selections from the rule set are made.</p>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#one-pass-traversals","title":"One-pass Traversals","text":"<p>Cascading transformations can be defined with other strategies as well, and these strategies need not be exhaustive, but can be simpler one-pass traversals. For example, constant folding of Boolean expressions only requires a simple one-pass bottom-up traversal. This can be achieved using the bottomup strategy according the following scheme:</p> <pre><code>simplify = bottomup(repeat(R1 &lt;+ ... &lt;+ Rn))\n</code></pre> <p>The bottomup strategy applies its argument strategy to each subterm in a bottom-to-top traversal. The repeat strategy applies its argument strategy repeatedly to a term.</p> <p>Module <code>prop-eval2</code> defines the evaluation rules for Boolean expressions and a strategy for applying them using this approach:</p> <pre><code>module prop-eval2\nimports libstrategolib prop\nrules\nEval : Not(True())      -&gt; False()\nEval : Not(False())     -&gt; True()\nEval : And(True(), x)   -&gt; x\nEval : And(x, True())   -&gt; x\nEval : And(False(), x)  -&gt; False()\nEval : And(x, False())  -&gt; False()\nEval : Or(True(), x)    -&gt; True()\nEval : Or(x, True())    -&gt; True()\nEval : Or(False(), x)   -&gt; x\nEval : Or(x, False())   -&gt; x\nEval : Impl(True(), x)  -&gt; x\nEval : Impl(x, True())  -&gt; True()\nEval : Impl(False(), x) -&gt; True()\nEval : Impl(x, False()) -&gt; Not(x)\nEval : Eq(False(), x)   -&gt; Not(x)\nEval : Eq(x, False())   -&gt; Not(x)\nEval : Eq(True(), x)    -&gt; x\nEval : Eq(x, True())    -&gt; x\nstrategies\nmain = io-wrap(eval)\neval = bottomup(repeat(Eval))\n</code></pre> <p>The strategy eval applies these rules in a bottom-up traversal over a term, using the <code>bottomup(s)</code> strategy. At each sub-term, the rules are applied repeatedly until no more rule applies using the <code>repeat(s)</code> strategy. This is sufficient for the <code>Eval</code> rules, since the rules never construct a term with subterms that can be rewritten.</p> <p>Another typical example of the use of one-pass traversals is desugaring, that is rewriting language constructs to more basic language constructs. Simple desugarings can usually be expressed using a single top-to-bottom traversal according to the scheme</p> <pre><code>simplify = topdown(try(R1 &lt;+ ... &lt;+ Rn))\n</code></pre> <p>The <code>topdown</code> strategy applies its argument strategy to a term and then traverses the resulting term. The try strategy tries to apply its argument strategy once to a term.</p> <p>Module <code>prop-desugar</code> defines a number of desugaring rules for Boolean expressions, defining propositional operators in terms of others. For example, rule <code>DefN</code> defines <code>Not</code> in terms of <code>Impl</code>, and rule <code>DefI</code> defines <code>Impl</code> in terms of <code>Or</code> and <code>Not</code>. So not all rules should be applied in the same transformation or non-termination would result.</p> <pre><code>module prop-desugar\nimports prop libstrategolib\n\nrules\n\nDefN  : Not(x)     -&gt; Impl(x, False())\nDefI  : Impl(x, y) -&gt; Or(Not(x), y)\nDefE  : Eq(x, y)   -&gt; And(Impl(x, y), Impl(y, x))\nDefO1 : Or(x, y)   -&gt; Impl(Not(x), y)\nDefO2 : Or(x, y)   -&gt; Not(And(Not(x), Not(y)))\nDefA1 : And(x, y)  -&gt; Not(Or(Not(x), Not(y)))\nDefA2 : And(x, y)  -&gt; Not(Impl(x, Not(y)))\n\nIDefI : Or(Not(x), y) -&gt; Impl(x, y)\n\nIDefE : And(Impl(x, y), Impl(y, x)) -&gt; Eq(x, y)\n\nstrategies\n\ndesugar =\ntopdown(try(DefI &lt;+ DefE))\n\nimpl-nf =\ntopdown(repeat(DefN &lt;+ DefA2 &lt;+ DefO1 &lt;+ DefE))\n\nmain-desugar =\nio-wrap(desugar)\n\nmain-inf =\nio-wrap(impl-nf)\n</code></pre> <p>The strategies <code>desugar</code> and <code>impl-nf</code> define two different desugaring transformation based on these rules. The desugar strategy gets rid of the implication and equivalence operators, while the <code>impl-nf</code> strategy reduces an expression to implicative normal-form, a format in which only implication (<code>Impl</code>) and <code>False()</code> are used.</p> <p>A final example of a one-pass traversal is the <code>downup</code> strategy, which applies its argument transformation during a traversal on the way down, and again on the way up:</p> <pre><code>simplify = downup(repeat(R1 &lt;+ ... &lt;+ Rn))\n</code></pre> <p>An application of this strategy is a more efficient implementation of constant folding for Boolean expressions:</p> <pre><code>eval = downup(repeat(Eval))\n</code></pre> <p>This strategy reduces terms such as</p> <pre><code>And(... big expression ..., False())\n</code></pre> <p>in one step (to <code>False()</code> in this case), while the bottomup strategy defined above would first evaluate the big expression.</p>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#staged-transformations","title":"Staged Transformations","text":"<p>Cascading transformations apply a number of rules one after another to an entire tree. But in some cases this is not appropriate. For instance, two transformations may be inverses of one another, so that repeatedly applying one and then the other would lead to non-termination. To remedy this difficulty, Stratego supports the idiom of staged transformation.</p> <p>In staged computation, transformations are not applied to a subject term all at once, but rather in stages. In each stage, only rules from some particular subset of the entire set of available rules are applied. In the TAMPR program transformation system this idiom is called sequence of normal forms, since a program tree is transformed in a sequence of steps, each of which performs a normalization with respect to a specified set of rules. In Stratego this idiom can be expressed directly according to the following scheme:</p> <pre><code>strategies\n\nsimplify =\ninnermost(A1 &lt;+ ... &lt;+ Ak)\n; innermost(B1 &lt;+ ... &lt;+ Bl)\n; ...\n    ; innermost(C1 &lt;+ ... &lt;+ Cm)\n</code></pre>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#local-transformations","title":"Local Transformations","text":"<p>In conventional program optimization, transformations are applied throughout a program. In optimizing imperative programs, for example, complex transformations are applied to entire programs. In GHC-style compilation-by-transformation, small transformation steps are applied throughout programs. Another style of transformation is a mixture of these ideas. Instead of applying a complex transformation algorithm to a program we use staged, cascading transformations to accumulate small transformation steps for large effect. However, instead of applying transformations throughout the subject program, we often wish to apply them locally, i.e., only to selected parts of the subject program. This allows us to use transformations rules that would not be beneficial if applied everywhere.</p> <p>One example of a strategy which achieves such a transformation is</p> <pre><code>strategies\n\ntransformation =\nalltd(\ntrigger-transformation\n; innermost(A1 &lt;+ ... &lt;+ An)\n)\n</code></pre> <p>The strategy <code>alltd(s)</code> descends into a term until a subterm is encountered for which the transformation s succeeds. In this case the strategy trigger-transformation recognizes a program fragment that should be transformed. Thus, cascading transformations are applied locally to terms for which the transformation is triggered. Of course more sophisticated strategies can be used for finding application locations, as well as for applying the rules locally. Nevertheless, the key observation underlying this idiom remains: Because the transformations to be applied are local, special knowledge about the subject program at the point of application can be used. This allows the application of rules that would not be otherwise applicable.</p>"},{"location":"background/stratego/strategic-rewriting/strategic-rewriting/#references","title":"References","text":"<ol> <li> <p>Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming, 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425, doi:10.1145/289423.289425.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/stratego/strategic-rewriting/term-rewriting/","title":"Term Rewriting","text":"<p>In term rewriting a term is transformed by repeated application of rewrite rules. To see how this works we take as example the language of propositional formulae, also known as Boolean expressions:</p> <pre><code>module prop\nsignature\nsorts Prop\nconstructors\nFalse : Prop\nTrue  : Prop\nAtom  : String -&gt; Prop\nNot   : Prop -&gt; Prop\nAnd   : Prop * Prop -&gt; Prop\nOr    : Prop * Prop -&gt; Prop\nImpl  : Prop * Prop -&gt; Prop\nEq    : Prop * Prop -&gt; Prop\n</code></pre> <p>Given this signature we can write terms such as <code>And(Impl(True(),False()),False())</code>, and <code>And(Atom(\"p\"),False()))</code>. Atoms are also known as proposition letters; they are the variables in propositional formulae. That is, the truth value of an atom should be provided in order to fully evaluate an expression. Here we will evaluate expressions as far as possible, a transformation also known as constant folding. We will do this using rewrite rules that define how to simplify a single operator application.</p>"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#term-patterns","title":"Term Patterns","text":"<p>A term pattern is a term with meta variables, which are identifiers that are not declared as (nullary) constructors. For example, <code>And(x, True())</code> is a term pattern with variable <code>x</code>. Variables in term patterns are sometimes called meta variables, to distinguish them from variables in the source language being processed. For example, while atoms in the proposition expressions are variables from the point of view of the language, they are not variables from the perspective of a Stratego program.</p> <p>A term pattern <code>p</code> matches with a term <code>t</code>, if there is a substitution that replaces the variables in <code>p</code> such that it becomes equal to <code>t</code>. For example, the pattern <code>And(x, True())</code> matches the term <code>And(Impl(True(),Atom(\"p\")),True())</code> because replacing the variable <code>x</code> in the pattern by <code>Impl(True(),Atom(\"p\"))</code> makes the pattern equal to the term. Note that <code>And(Atom(\"x\"),True())</code> does not match the term <code>And(Impl(True(),Atom(\"p\")),True())</code>, since the subterms <code>Atom(\"x\")</code> and <code>Impl(True(),Atom(\"p\"))</code> do not match.</p>"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#rewrite-rules","title":"Rewrite Rules","text":"<p>An unconditional rewrite rule has the form <code>L : p1 -&gt; p2</code>, where <code>L</code> is the name of the rule, <code>p1</code> is the left-hand side and <code>p2</code> the right-hand side term pattern. A rewrite rule <code>L : p1 -&gt; p2</code> applies to a term <code>t</code> when the pattern <code>p1</code> matches <code>t</code>. The result is the instantiation of <code>p2</code> with the variable bindings found during matching. For example, the rewrite rule</p> <pre><code>E : Eq(x, False()) -&gt; Not(x)\n</code></pre> <p>rewrites the term <code>Eq(Atom(\"q\"),False())</code> to <code>Not(Atom(\"q\"))</code>, since the variable <code>x</code> is bound to the subterm <code>Atom(\"q\")</code>.</p>"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#evaluation-rules","title":"Evaluation Rules","text":"<p>Now we can create similar evaluation rules for all constructors of sort <code>Prop</code>:</p> <pre><code>module prop-eval-rules\nimports prop\nrules\nE : Not(True())      -&gt; False()\nE : Not(False())     -&gt; True()\nE : And(True(), x)   -&gt; x\nE : And(x, True())   -&gt; x\nE : And(False(), x)  -&gt; False()\nE : And(x, False())  -&gt; False()\nE : Or(True(), x)    -&gt; True()\nE : Or(x, True())    -&gt; True()\nE : Or(False(), x)   -&gt; x\nE : Or(x, False())   -&gt; x\nE : Impl(True(), x)  -&gt; x\nE : Impl(x, True())  -&gt; True()\nE : Impl(False(), x) -&gt; True()\nE : Impl(x, False()) -&gt; Not(x)\nE : Eq(False(), x)   -&gt; Not(x)\nE : Eq(x, False())   -&gt; Not(x)\nE : Eq(True(), x)    -&gt; x\nE : Eq(x, True())    -&gt; x\nstrategies\neval = innermost(E)\n</code></pre> <p>Note that all rules have the same name, which is allowed in Stratego.</p> <p>The module defines the <code>eval</code> strategy to apply <code>innermost(E)</code> to the input term. The innermost strategy from the library exhaustively applies its argument transformation to the term it is applied to, starting with inner subterms.</p> <p>As an aside, we have now seen Stratego modules with rules and strategies sections. It is worth noting that a module can have any number of sections of either type, and that there is no actual semantic difference between the two section headings. In fact, either rewrite rules and/or strategy definitions can occur in either kind of section. Nevertheless, it often helps with making your transformations clearer to generally segregate rules and strategy definitions, and so both headings are allowed so you can punctuate your Stratego modules with them to improve readability.</p> <p>The next commands apply the eval strategy to various terms.</p> <pre><code>&lt;eval&gt; And(Impl(True(),And(False,True)),True) =&gt; False\n\n&lt;eval&gt; And(Impl(True,And(Atom(\"p\"),Atom(\"q\"))),Atom(\"p\"))\n=&gt; And(And(Atom(\"p\"),Atom(\"q\")),Atom(\"p\"))\n</code></pre>"},{"location":"background/stratego/strategic-rewriting/term-rewriting/#adding-rules-to-a-rewrite-system","title":"Adding Rules to a Rewrite System","text":"<p>Next we extend the rewrite rules above to rewrite a Boolean expression to disjunctive normal form. A Boolean expression is in disjunctive normal form if it conforms to the following signature:</p> <pre><code>signature\nsorts Or And NAtom Atom\nconstructors\nOr   : Or * Or -&gt; Or\n: And -&gt; Or\nAnd  : And * And -&gt; And\n: NAtom -&gt; And\nNot  : Atom -&gt; NAtom\n: Atom -&gt; NAtom\nAtom : String -&gt; Atom\n</code></pre> <p>We use this signature only to describe what a disjunctive normal form is, not in an the actual Stratego program. This is not necessary, since terms conforming to the DNF signature are also Prop terms as defined before. For example, the disjunctive normal form of</p> <pre><code>And(Impl(Atom(\"r\"),And(Atom(\"p\"),Atom(\"q\"))),Atom(\"p\"))\n</code></pre> <p>is</p> <pre><code>Or(And(Not(Atom(\"r\")),Atom(\"p\")),\nAnd(And(Atom(\"p\"),Atom(\"q\")),Atom(\"p\")))\n</code></pre> <p>Module <code>prop-dnf-rules</code> extends the rules defined in prop-eval-rules with rules to achieve disjunctive normal forms:</p> <pre><code>module prop-dnf-rules\nimports prop-eval-rules\nrules\nE : Impl(x, y) -&gt; Or(Not(x), y)\nE : Eq(x, y)   -&gt; And(Impl(x, y), Impl(y, x))\n\nE : Not(Not(x)) -&gt; x\n\nE : Not(And(x, y)) -&gt; Or(Not(x), Not(y))\nE : Not(Or(x, y))  -&gt; And(Not(x), Not(y))\n\nE : And(Or(x, y), z) -&gt; Or(And(x, z), And(y, z))\nE : And(z, Or(x, y)) -&gt; Or(And(z, x), And(z, y))\nstrategies\ndnf = innermost(E)\n</code></pre> <p>The first two rules rewrite implication (<code>Impl</code>) and equivalence (<code>Eq</code>) to combinations of <code>And</code>, <code>Or</code>, and <code>Not</code>. The third rule removes double negation. The fifth and sixth rules implement the well known DeMorgan laws. The last two rules define distribution of conjunction over disjunction.</p>"},{"location":"background/stratego/strategic-rewriting/traversal-with-rules/","title":"Factoring out Traversal","text":"<p>Continuing the inspection of limitations of term rewriting, we explore how term traversal can be factored out into separate rules.</p>"},{"location":"background/stratego/strategic-rewriting/traversal-with-rules/#attempt-3-using-rules-for-traversal","title":"Attempt 3: Using Rules for Traversal","text":"<p>We saw the following definition of the map strategy, which applies a strategy to each element of a list:</p> <pre><code>map(s) : [] -&gt; []\nmap(s) : [x | xs] -&gt; [&lt;s&gt; x | &lt;map(s)&gt; xs]\n</code></pre> <p>The definition uses explicit recursive calls to the strategy in the right-hand side of the second rule. What map does is to traverse the list in order to apply the argument strategy to all elements. We can use the same technique to other term structures as well.</p> <p>We will explore the definition of traversals using the propositional formulae, where we introduced the following rewrite rules:</p> <pre><code>module prop-rules\nimports libstrategolib prop\nrules\nDefI : Impl(x, y)       -&gt; Or(Not(x), y)\nDefE : Eq(x, y)         -&gt; And(Impl(x, y), Impl(y, x))\nDN   : Not(Not(x))      -&gt; x\nDMA  : Not(And(x, y))   -&gt; Or(Not(x), Not(y))\nDMO  : Not(Or(x, y))    -&gt; And(Not(x), Not(y))\nDAOL : And(Or(x, y), z) -&gt; Or(And(x, z), And(y, z))\nDAOR : And(z, Or(x, y)) -&gt; Or(And(z, x), And(z, y))\nDOAL : Or(And(x, y), z) -&gt; And(Or(x, z), Or(y, z))\nDOAR : Or(z, And(x, y)) -&gt; And(Or(z, x), Or(z, y))\n</code></pre> <p>Above we saw how a functional style of rewriting could be encoded using extra constructors. In Stratego we can achieve a similar approach by using rule names, instead of extra constructors. Thus, one way to achieve normalization to disjunctive normal form, is the use of an explicitly programmed traversal, implemented using recursive rules, similarly to the map example above:</p> <pre><code>module prop-dnf4\nimports libstrategolib prop-rules\nstrategies\nmain = io-wrap(dnf)\nrules\ndnf : True()     -&gt;          True()\ndnf : False()    -&gt;          False()\ndnf : Atom(x)    -&gt;          Atom(x)\ndnf : Not(x)     -&gt; &lt;dnfred&gt; Not (&lt;dnf&gt;x)\ndnf : And(x, y)  -&gt; &lt;dnfred&gt; And (&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnf : Or(x, y)   -&gt;          Or  (&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnf : Impl(x, y) -&gt; &lt;dnfred&gt; Impl(&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnf : Eq(x, y)   -&gt; &lt;dnfred&gt; Eq  (&lt;dnf&gt;x, &lt;dnf&gt;y)\nstrategies\ndnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf)\n</code></pre> <p>The <code>dnf</code> rules recursively apply themselves to the direct subterms and then apply dnfred to actually apply the rewrite rules.</p> <p>We can reduce this program by abstracting over the base cases. Since there is no traversal into <code>True</code>, <code>False</code>, and <code>Atom</code>s, these rules can be be left out.</p> <pre><code>module prop-dnf5\nimports libstrategolib prop-rules\nstrategies\nmain = io-wrap(dnf)\nrules\ndnft : Not(x)     -&gt; &lt;dnfred&gt; Not (&lt;dnf&gt;x)\ndnft : And(x, y)  -&gt; &lt;dnfred&gt; And (&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnft : Or(x, y)   -&gt;          Or  (&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnft : Impl(x, y) -&gt; &lt;dnfred&gt; Impl(&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnft : Eq(x, y)   -&gt; &lt;dnfred&gt; Eq  (&lt;dnf&gt;x, &lt;dnf&gt;y)\nstrategies\ndnf    = try(dnft)\ndnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf)\n</code></pre> <p>The <code>dnf</code> strategy is now defined in terms of the <code>dnft</code> rules, which implement traversal over the constructors. By using <code>try(dnft)</code>, terms for which no traversal rule has been specified are not transformed.</p> <p>We can further simplify the definition by observing that the application of <code>dnfred</code> does not necessarily have to take place in the right-hand side of the traversal rules.</p> <pre><code>module prop-dnf6\nimports libstrategolib prop-rules\nstrategies\nmain = io-wrap(dnf)\nrules\ndnft : Not(x)     -&gt; Not (&lt;dnf&gt;x)\ndnft : And(x, y)  -&gt; And (&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnft : Or(x, y)   -&gt; Or  (&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnft : Impl(x, y) -&gt; Impl(&lt;dnf&gt;x, &lt;dnf&gt;y)\ndnft : Eq(x, y)   -&gt; Eq  (&lt;dnf&gt;x, &lt;dnf&gt;y)\nstrategies\ndnf    = try(dnft); dnfred\ndnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf)\n</code></pre> <p>In this program <code>dnf</code> first calls <code>dnft</code> to transform the subterms of the subject term, and then calls <code>dnfred</code> to apply the transformation rules (and possibly a recursive invocation of <code>dnf</code>).</p> <p>The program above has two problems. First, the traversal behavior is mostly uniform, so we would like to specify that more concisely. We will address that concern below. Second, the traversal is not reusable, for example, to define a conjunctive normal form transformation. This last concern can be addressed by factoring out the recursive call to <code>dnf</code> and making it a parameter of the traversal rules.</p> <pre><code>module prop-dnf7\nimports libstrategolib prop-rules\nstrategies\nmain = io-wrap(dnf)\nrules\nproptr(s) : Not(x)     -&gt; Not (&lt;s&gt;x)\nproptr(s) : And(x, y)  -&gt; And (&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Or(x, y)   -&gt; Or  (&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Impl(x, y) -&gt; Impl(&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Eq(x, y)   -&gt; Eq  (&lt;s&gt;x, &lt;s&gt;y)\nstrategies\ndnf    = try(proptr(dnf)); dnfred\ndnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf)\ncnf    = try(proptr(cnf)); cnfred\ncnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DOAL &lt;+ DOAR); cnf)\n</code></pre> <p>Now the traversal rules are reusable and used in two different transformations, by instantiation with a call to the particular strategy in which they are used (<code>dnf</code> or <code>cnf</code>).</p> <p>But we can do better, and also make the composition of this strategy reusable.</p> <pre><code>module prop-dnf8\nimports libstrategolib prop-rules\nstrategies\nmain = io-wrap(dnf)\nrules\nproptr(s) : Not(x)     -&gt; Not (&lt;s&gt;x)\nproptr(s) : And(x, y)  -&gt; And (&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Or(x, y)   -&gt; Or  (&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Impl(x, y) -&gt; Impl(&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Eq(x, y)   -&gt; Eq  (&lt;s&gt;x, &lt;s&gt;y)\nstrategies\npropbu(s) = try(proptr(propbu(s))); s\nstrategies\ndnf    = propbu(dnfred)\ndnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf)\ncnf    = propbu(cnfred)\ncnfred = try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DOAL &lt;+ DOAR); cnf)\n</code></pre> <p>That is, the <code>propbu(s)</code> strategy defines a complete bottom-up traversal over proposition terms, applying the strategy <code>s</code> to a term after transforming its subterms. The strategy is completely independent of the <code>dnf</code> and <code>cnf</code> transformations, which instantiate the strategy using the dnfred and cnfred strategies.</p> <p>Come to think of it, <code>dnfred</code> and <code>cnfred</code> are somewhat useless now and can be inlined directly in the instantiation of the <code>propbu(s)</code> strategy:</p> <pre><code>module prop-dnf9\nimports libstrategolib prop-rules\nstrategies\nmain = io-wrap(dnf)\nrules\nproptr(s) : Not(x)     -&gt; Not (&lt;s&gt;x)\nproptr(s) : And(x, y)  -&gt; And (&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Or(x, y)   -&gt; Or  (&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Impl(x, y) -&gt; Impl(&lt;s&gt;x, &lt;s&gt;y)\nproptr(s) : Eq(x, y)   -&gt; Eq  (&lt;s&gt;x, &lt;s&gt;y)\nstrategies\npropbu(s) = try(proptr(propbu(s))); s\nstrategies\ndnf = propbu(try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf))\ncnf = propbu(try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DOAL &lt;+ DOAR); cnf))\n</code></pre> <p>Now we have defined a transformation independent traversal strategy that is specific for proposition terms.</p>"},{"location":"background/stratego/strategy-combinators/sequential/","title":"Sequential Combinators","text":"<p>Rather than defining rewrite rules and high-level strategies as primitives of the language, Stratego provides strategy combinators as basic building blocks from which these can defined1. Thus, Stratego consists of a core language2 and a 'sugar' language defined by reduction to the core language.</p>"},{"location":"background/stratego/strategy-combinators/sequential/#identity-and-failure","title":"Identity and Failure","text":"<p>The most basic operations in Stratego are <code>id</code> and <code>fail</code>. The identity strategy <code>id</code> always succeeds and behaves as the identity function on terms. The failure strategy <code>fail</code> always fails. The operations have no side effects.</p>"},{"location":"background/stratego/strategy-combinators/sequential/#sequential-composition","title":"Sequential Composition","text":"<p>The sequential composition <code>s1 ; s2</code> of the strategies <code>s1</code> and <code>s2</code> first applies the strategy <code>s1</code> to the subject term and then <code>s2</code> to the result of that first application. The strategy fails if either <code>s1</code> or <code>s2</code> fails.</p> <p>Sequential composition is associative. Identity is a left and right unit for sequential composition; since <code>id</code> always succeeds and leaves the term alone, it has no additional effect to the strategy that it is composed with. Failure is a left zero for sequential composition; since <code>fail</code> always fails the next strategy will never be reached. This leads to the following equations:</p> <pre><code>(s1; s2) ; s3 = s1; (s2; s3)\n\nid; s = s\n\ns; id = s\n\nfail; s = fail\n</code></pre> <p>However, not for all strategies <code>s</code> we have that failure is a right zero for sequential composition:</p> <pre><code>s ; fail = fail   // is not a law\n</code></pre> <p>Although the composition <code>s; fail</code> will always fail, the execution of <code>s</code> may have side effects that are not performed by <code>fail</code>. For example, consider printing a term in <code>s</code>.</p> <p>As an example of the use of sequential composition consider the following rewrite rules.</p> <pre><code>A : P(Z(),x) -&gt; x\nB : P(S(x),y) -&gt; P(x,S(y))\n</code></pre> <p>The following applications shows the effect of first applying <code>B</code> and then <code>A</code>:</p> <pre><code>&lt;B&gt; !P(S(Z()), Z()) =&gt; P(S(Z),Z)\n\n&lt;A&gt; P(Z,S(Z)) =&gt; S(Z)\n</code></pre> <p>Using the sequential composition of the two rules, this effect can be achieved \u2018in one step\u2019:</p> <pre><code>&lt;B; A&gt; !P(S(Z()),Z()) =&gt; S(Z)\n</code></pre> <p>The following application shows that the application of a composition fails if the second strategy in the composition fails to apply to the result of the first:</p> <pre><code>&lt;B; B&gt; !P(S(Z()),Z()) // fails\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#left-choice","title":"Left Choice","text":"<p>Choosing between rules to apply is achieved using one of several choice combinators, all of which are based on the guarded choice combinator. The common approach is that failure to apply one strategy leads to backtracking to an alternative strategy.</p> <p>The left choice or deterministic choice <code>s1 &lt;+ s2</code> tries to apply <code>s1</code> and <code>s2</code> in that order. That is, it first tries to apply <code>s1</code>, and if that succeeds the choice succeeds. However, if the application of <code>s1</code> fails, <code>s2</code> is applied to the original term.</p> <p>Properties. Left choice is associative. Identity is a left zero for left choice; since id always succeeds, the alternative strategy will never be tried. Failure is a left and right unit for left choice; since fail always fails, the choice will always backtrack to the alternative strategy, and use of fail as alternative strategy is pointless.</p> <pre><code>(s1 &lt;+ s2) &lt;+ s3 = s1 &lt;+ (s2 &lt;+ s3)\n\nid &lt;+ s  = id\n\nfail &lt;+ s = s\n\ns &lt;+ fail = s\n</code></pre> <p>However, identity is not a right zero for left choice. That is, not for all strategies s we have that</p> <pre><code>s &lt;+ id =  s    // is not a law\n</code></pre> <p>The expression <code>s &lt;+ id</code> always succeeds, even (especially) in the case that <code>s</code> fails, in which case the right-hand side of the equation fails of course.</p> <p>Local Backtracking. The left choice combinator is a local backtracking combinator. That is, the choice is committed once the left-hand side strategy has succeeded, even if the continuation strategy fails. This is expressed by the fact that the property</p> <pre><code>(s1 &lt;+ s2); s3 = (s1; s3) &lt;+ (s2; s3)    // is not a law\n</code></pre> <p>does not hold for all <code>s1</code>, <code>s2</code>, and <code>s3</code>. The difference is illustrated by the following applications:</p> <pre><code>&lt;(B &lt;+ id); B&gt; P(S(Z),Z) // fails\n\n&lt;(B; B) &lt;+ (id; B)&gt; P(S(Z()),Z()) =&gt; P(Z,S(Z))\n</code></pre> <p>In the application of <code>(B &lt;+ id); B</code>, the first application of <code>B</code> succeeds after which the choice is committed. The subsequent application of <code>B</code> then fails. This is equivalent to first applying <code>(B &lt;+ id)</code> and then applying <code>B</code> to the result. The application of <code>(B; B) &lt;+ (id; B)</code>, however, is successful; the application of <code>B; B</code> fails, after which the choice backtracks to <code>id; B</code>, which succeeds.</p>"},{"location":"background/stratego/strategy-combinators/sequential/#choosing-between-transformations","title":"Choosing between Transformations.","text":"<p>The typical use of left choice is to create a composite strategy trying one from several possible transformations. If the strategies that are composed are mutually exclusive, that is, don\u2019t succeed for the same terms, their sum is a transformation that (deterministically) covers a larger set of terms. For example, consider the following two rewrite rules:</p> <pre><code>PlusAssoc : Plus(Plus(e1, e2), e3) -&gt; Plus(e1, Plus(e2, e3))\nPlusZero  : Plus(Int(\"0\"),e) -&gt; e\n</code></pre> <p>These rules are mutually exclusive, since there is no term that matches the left-hand sides of both rules. Combining the rules with left choice into <code>PlusAssoc &lt;+ PlusZero</code> creates a strategy that transforms terms matching both rules as illustrated by the following applications:</p> <pre><code>&lt;PlusAssoc&gt;\nPlus(Int(\"0\"),Int(\"3\")) // fails\n\n&lt;PlusAssoc &lt;+ PlusZero&gt;\nPlus(Int(\"0\"),Int(\"3\")) =&gt; Int(\"3\")\n\n&lt;PlusZero&gt;\nPlus(Plus(Var(\"x\"),Int(\"42\")),Int(\"3\")) // fails\n\n&lt;PlusAssoc &lt;+ PlusZero&gt;\nPlus(Plus(Var(\"x\"),Int(\"42\")),Int(\"3\")) =&gt; Plus(Var(\"x\"),Plus(Int(\"42\"),Int(\"3\")))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#ordering-overlapping-rules","title":"Ordering Overlapping Rules.","text":"<p>When two rules or strategies are mutually exlusive the order of applying them does not matter. In cases where strategies are overlapping, that is, succeed for the same terms, the order becomes crucial to determining the semantics of the composition. For example, consider the following rewrite rules reducing applications of Mem:</p> <pre><code>Mem1 : Mem(x,[]) -&gt; False()\nMem2 : Mem(x,[x|xs]) -&gt; True()\nMem3 : Mem(x,[y|ys]) -&gt; Mem(x,ys)\n</code></pre> <p>Rules <code>Mem2</code> and <code>Mem3</code> have overlapping left-hand sides. Rule <code>Mem2</code> only applies if the first argument is equal to the head element of the list in the second argument. Rule <code>Mem3</code> applies always if the list in the second argument is non-empty.</p> <pre><code>&lt;Mem2&gt;Mem(1, [1,2,3]) =&gt; True()\n&lt;Mem3&gt;Mem(1, [1,2,3]) =&gt; Mem(1,[2,3])\n</code></pre> <p>In such situations, depending on the order of the rules, different results are produced. (The rules form a non-confluent rewriting system.) By ordering the rules as <code>Mem2 &lt;+ Mem3</code>, rule <code>Mem2</code> is tried before <code>Mem3</code>, and we have a deterministic transformation strategy.</p>"},{"location":"background/stratego/strategy-combinators/sequential/#try","title":"Try","text":"<p>A useful application of <code>&lt;+</code> in combination with <code>id</code> is the reflexive closure of a strategy s:</p> <pre><code>try(s) = s &lt;+ id\n</code></pre> <p>The user-defined strategy combinator try tries to apply its argument strategy <code>s</code>, but if that fails, just succeeds using <code>id</code>.</p>"},{"location":"background/stratego/strategy-combinators/sequential/#guarded-left-choice","title":"Guarded Left Choice","text":"<p>Sometimes it is not desirable to backtrack to the alternative specified in a choice. Rather, after passing a guard, the choice should be committed. This can be expressed using the guarded left choice operator <code>s1 &lt; s2 + s3</code>. If <code>s1</code> succeeds <code>s2</code> is applied, else <code>s3</code> is applied. If <code>s2</code> fails, the complete expression fails; no backtracking to <code>s3</code> takes place.</p> <p>Properties. This combinator is a generalization of the left choice combinator <code>&lt;+</code>.</p> <pre><code>s1 &lt;+ s2 = s1 &lt; id + s2\n</code></pre> <p>The following laws make clear that the \u2018branches\u2019 of the choice are selected by the success or failure of the guard:</p> <pre><code>id &lt; s2 + s3  = s2\n\nfail &lt; s2 + s3 = s3\n</code></pre> <p>If the right branch always fails, the construct reduces to the sequential composition of the guard and the left branch.</p> <pre><code>s1 &lt; s2 + fail = s1; s2\n</code></pre> <p>Guarded choice is not associative:</p> <pre><code>(s1 &lt; s2 + s3) &lt; s4 + s5 = s1 &lt; s2 + (s3 &lt; s4 + s5)    // not a law\n</code></pre> <p>To see why consider the possible traces of these expressions. For example, when <code>s1</code> and <code>s2</code> succeed subsequently, the left-hand side expression calls <code>s4</code>, while the right-hand side expression does not.</p> <p>However, sequential composition distributes over guarded choice from left and right:</p> <pre><code>(s1 &lt; s2 + s3); s4 = s1 &lt; (s2; s4) + (s3; s4)\n\ns0; (s1 &lt; s2 + s3) = (s0; s1) &lt; s2 + s3\n</code></pre> <p>Examples. The guarded left choice operator is most useful for the implementation of higher-level control-flow strategies. For example, the negation <code>not(s)</code> of a strategy <code>s</code>, succeeds if <code>s</code> fails, and fails when it succeeds:</p> <pre><code>not(s) = s &lt; fail + id\n</code></pre> <p>Since failure discards the effect of a (successful) transformation, this has the effect of testing whether <code>s</code> succeeds. So we have the following laws for not:</p> <pre><code>not(id) = fail\nnot(fail) = id\n</code></pre> <p>However, side effects performed by <code>s</code> are not undone, of course. Therefore, the following equation does not hold:</p> <pre><code>not(not(s)) = s   // not a law\n</code></pre> <p>Another example of the use of guarded choice is the restore-always combinator:</p> <pre><code>restore-always(s, r) = s &lt; r + (r; fail)\n</code></pre> <p>It applies a \u2018restore\u2019 strategy <code>r</code> after applying a strategy <code>s</code>, even if <code>s</code> fails, and preserves the success/failure behavior of <code>s</code>. Since <code>fail</code> discards the transformation effect of <code>r</code>, this is mostly useful for ensuring that some side-effecting operation is done (or undone) after applying <code>s</code>.</p>"},{"location":"background/stratego/strategy-combinators/sequential/#if-then-else","title":"If-then-else","text":"<p>The guarded choice combinator is similar to the traditional if-then-else construct of programming languages. The difference is that the \u2018then\u2019 branch applies to the result of the application of the condition. Stratego\u2019s <code>if s1 then s2 else s3 end</code> construct is more like the traditional construct since both branches apply to the original term. The condition strategy is only used to test if it succeeds or fails, but it\u2019s transformation effect is undone. However, the condition strategy <code>s1</code> is still applied to the current term. The <code>if s1 then s2 end</code> strategy is similar; if the condition fails, the strategy succeeds.</p> <p>The if-then-else-end strategy is just syntactic sugar for a combination of guarded choice and the where combinator:</p> <pre><code>    if s1 then s2 else s3 end\n==&gt; // transforms to\nwhere(s1) &lt; s2 + s3\n</code></pre> <p>The strategy <code>where(s)</code> succeeds if <code>s</code> succeeds, but returns the original subject term. The implementation of the <code>where</code> combinator is discussed in the section on matching and building terms. The following laws show that the branches are selected by success or failure of the condition:</p> <pre><code>if id   then s2 else s3 end  =  s2\n\nif fail then s2 else s3 end  =  s3\n</code></pre> <p>The if-then-end strategy is an abbreviation for the if-then-else-end with the identity strategy as right branch:</p> <pre><code>if s1 then s2 end  =  where(s1) &lt; s2 + id\n</code></pre> <p>Examples. The inclusive or <code>or(s1, s2)</code> succeeds if one of the strategies <code>s1</code> or <code>s2</code> succeeds, but guarantees that both are applied, in the order <code>s1</code> first, then <code>s2</code>:</p> <pre><code>or(s1, s2) =\nif s1 then try(where(s2)) else where(s2) end\n</code></pre> <p>This ensures that any side effects are always performed, in contrast to <code>s1 &lt;\\+ s2</code>, where <code>s2</code> is only executed if <code>s1</code> fails. (Thus, left choice implements a short circuit Boolean or.)</p> <p>Similarly, the following <code>and(s1, s2)</code> combinator is the non-short circuit version of Boolean conjunction:</p> <pre><code>and(s1, s2) =\nif s1 then where(s2) else where(s2); fail end\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#switch","title":"Switch","text":"<p>The switch construct is an n-ary branching construct similar to its counter parts in other programming languages. It is defined in terms of guarded choice. The switch construct has the following form:</p> <pre><code>switch s0\ncase s1 : s1'\n  case s2 : s2'\n  ...\n  otherwise : sdef\nend\n</code></pre> <p>The <code>switch</code> first applies the <code>s0</code> strategy to the current term <code>t</code> resulting in a term <code>t'</code>. Then it tries the cases in turn applying each <code>si</code> to <code>t'</code>. As soon as this succeeds the corresponding case is selected and <code>si'</code> is applied to the <code>t</code>, the term to which the switch was applied. If none of the cases applies, the default strategy <code>sdef</code> from the <code>otherwise</code> is applied.</p> <p>The <code>switch</code> construct is syntactic sugar for a nested if-then-else:</p> <pre><code>{x : where(s0 =&gt; x);\nif &lt;s1&gt; x\nthen s1'\n    else if &lt;s2&gt; x\nthen s2'\n        else if ...\n            then ...\n            else sdef\nend\nend\nend}\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#non-deterministic-choice","title":"Non-Deterministic Choice","text":"<p>The deterministic left choice operator prescribes that the left alternative should be tried before the right alternative, and that the latter is only used if the first fails. There are applications where it is not necessary to define the order of the alternatives. In those cases non-deterministic choice can be used.</p> <p>The non-deterministic choice operator <code>s1 + s2</code> chooses one of the two strategies <code>s1</code> or <code>s2</code> to apply, such that the one it chooses succeeds. If both strategies fail, then the choice fails as well. Operationally the choice operator first tries one strategy, and, if that fails, tries the other. The order in which this is done is undefined, i.e., arbitrarily chosen by the compiler.</p> <p>The <code>+</code> combinator is used to model modular composition of rewrite rules and strategies with the same name, but in different modules. Multiple definitions with the same name in different modules, are merged into a single definition with that name, where the bodies are composed with <code>+</code>. The following transformation illustrates this:</p> <pre><code>module A\nf = s1\nmodule B   f = s2  module main\nimports A B\n=&gt;\nf = s2 + s1\n</code></pre> <p>This transformation is somewhat simplified; the complete transformation needs to take care of local variables and parameters.</p> <p>While the <code>+</code> combinator is used internally by the compiler for this purpose, programmers are advised not to use this combinator, but rather use the left choice combinator <code>&lt;+</code> to avoid surprises.</p> <p>In the past, the <code>+</code> combinator was also used to compose definitions with the same name within a module. This has been replaced by interpreting such compositions with the textual order of the definitions. The following transformation illustrates this:</p> <pre><code>module A\nf = s1\nf = s2\n=&gt;\nf = s1 &lt;+ s2\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#recursion","title":"Recursion","text":"<p>Repeated application of a strategy can be achieved with recursion. There are two styles for doing this; with a recursive definition or using the fixpoint operator <code>rec</code>. A recursive definition is a normal strategy definition with a recursive call in its body.</p> <pre><code>f(s) = ... f(s) ...\n</code></pre> <p>Another way to define recursion is using the fixpoint operator <code>rec x(s)</code>, which recurses on applications of x within s. For example, the definition</p> <pre><code>f(s) = rec x(... x ...)\n</code></pre> <p>is equivalent to the one above. The advantage of the rec operator is that it allows the definition of an unnamed strategy expression to be recursive. For example, in the definition</p> <pre><code>g(s) = foo; rec x(... x ...); bar\n</code></pre> <p>the strategy between foo and bar is a recursive strategy that does not recurse to <code>g(s)</code>.</p> <p>Originally, the <code>rec</code> operator was the only way to define recursive strategies. It is still in the language in the first place because it is widely used in many existing programs, and in the second place because it can be a concise expression of a recursive strategy, since call parameters are not included in the call. Furthermore, all free variables remain in scope.</p> <p>The <code>repeat</code> strategy applies a transformation <code>s</code> until it fails. It is defined as a recursive definition using <code>try</code> as follows:</p> <pre><code>try(s)    = s &lt;+ id\nrepeat(s) = try(s; repeat(s))\n</code></pre> <p>An equivalent definition using <code>rec</code> is:</p> <pre><code>repeat(s) = rec x(try(s; x))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#a-library-of-iteration-strategies","title":"A Library of Iteration Strategies.","text":"<p>Using sequential composition, choice, and recursion a large variety of iteration strategies can be defined. The following definitions are part of the Stratego Library (in module strategy/iteration).</p> <pre><code>repeat(s) =\nrec x(try(s; x))\n\nrepeat(s, c) =\n(s; repeat(s, c)) &lt;+ c\n\nrepeat1(s, c) =\ns; (repeat1(s, c) &lt;+ c)\n\nrepeat1(s) =\nrepeat1(s, id)\n\nrepeat-until(s, c) =\ns; if c then id else repeat-until(s, c) end\n\nwhile(c, s) =\nif c then s; while(c, s) end\n\ndo-while(s, c) =\ns; if c then do-while(s, c) end\n</code></pre>"},{"location":"background/stratego/strategy-combinators/sequential/#references","title":"References","text":"<ol> <li> <p>Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming, 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425, doi:10.1145/289423.289425.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science, 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1, doi:10.1016/S1571-0661(05)80027-1.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/stratego/strategy-combinators/term/","title":"Term Combinators","text":"<p>Previously we have presented rewrite rules as basic transformation steps. However, rules are not atomic transformation actions. To see this, consider what happens when the rewrite rule</p> <pre><code>DAO : And(Or(x, y), z) -&gt; Or(And(x, z), And(y, z))\n</code></pre> <p>is applied. First it matches the subject term against the pattern <code>And(Or(x, y), z)</code> in the left-hand side. This means that a substitution for the variables <code>x</code>, <code>y</code>, and <code>z</code> is sought, that makes the pattern equal to the subject term. If the match fails, the rule fails. If the match succeeds, the pattern <code>Or(And(x, z), And(y, z))</code> on the right-hand side is instantiated with the bindings found during the match of the left-hand side. The instantiated term then replaces the original subject term. Furthermore, the rule limits the scope of the variables occurring in the rule. That is, the variables <code>x</code>, <code>y</code>, <code>z</code> are local to this rule. After the rule is applied the bindings to these variables are invisible again.</p> <p>Thus, rather than considering rules as the atomic actions of transformation programs, Stratego provides their constituents, that is building terms from patterns and matching terms against patterns, as atomic actions, and makes these available to the programmer. In this section we define the basic actions and their use in the composition of more complex operations such as various flavors of rewrite rules.</p>"},{"location":"background/stratego/strategy-combinators/term/#building-terms","title":"Building Terms","text":"<p>The build operation <code>!p</code> replaces the subject term with the instantiation of the pattern <code>p</code> using the bindings from the environment to the variables occurring in <code>p</code>. For example, the strategy <code>!Or(And(x, z), And(y, z))</code> replaces the subject term with the instantiation of <code>Or(And(x, z), And(y, z))</code> using bindings to variables <code>x</code>, <code>y</code> and <code>z</code>.</p> <pre><code>!Int(\"10\") =&gt; Int(\"10\")\n!Plus(Var(\"a\"), Int(\"10\")) =&gt; Plus(Var(\"a\"), Int(\"10\"))\n</code></pre> <p>It is possible to build terms with variables. We call this building a term pattern. A pattern is a term with meta-variables. The current term is replaced by an instantiation of pattern <code>p</code>.</p> <p>For example, in a context where <code>e</code> is bound to <code>Var(\"b\")</code></p> <pre><code>!Plus(Var(\"a\"),e) =&gt; Plus(Var(\"a\"),Var(\"b\"))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#matching-terms","title":"Matching Terms","text":"<p>Pattern matching allows the analysis of terms. The simplest case is matching against a literal term. The match operation <code>?t</code> matches the subject term against the term <code>t</code>.</p> <pre><code>&lt;?Plus(Var(\"a\"),Int(\"3\"))&gt; Plus(Var(\"a\"),Int(\"3\")) // succeeds\n&lt;?Plus(Int(\"3\"),Var(\"b\"))&gt; Plus(Var(\"a\"),Int(\"3\")) // fails\n</code></pre> <p>Matching against a term pattern with variables binds those variables to (parts of) the current term. The match strategy <code>?x</code> compares the current term (<code>t</code>) to variable <code>x</code>. It binds variable <code>x</code> to term <code>t</code> in the environment. A variable can only be bound once, or to the same term.</p> <pre><code>&lt;?e&gt; Plus(Var(\"a\"), Int(\"3\")) // binds e to Plus(Var(\"a\"),Int(\"3\"))\n&lt;?e&gt; !Int(\"17\")               // fails\n</code></pre> <p>The general case is matching against an arbitrary term pattern. The match strategy <code>?p</code> compares the current term to a pattern <code>p</code>. It will add bindings for the variables in pattern p to the environment. The wildcard <code>_</code> in a match will match any term.</p> <pre><code>&lt;?Plus(e,_)&gt;Plus(Var(\"a\"),Int(\"3\")) // e is bound to Var(\"a\")\n</code></pre> <p>Patterns may be non-linear. Multiple occurrences of the same variable can occur and each occurrence has to match the same term.</p> <pre><code>&lt;?Plus(e,e)&gt; Plus(Var(\"a\"),Int(\"3\")) // fails\n&lt;?Plus(e,e)&gt;!Plus(Var(\"a\"),Var(\"a\")) // e is bound to Var(\"a\")\n</code></pre> <p>Non-linear pattern matching is a way to test equality of terms. Indeed the equality predicates from the Stratego Library are defined using non-linear pattern matching:</p> <pre><code>equal = ?(x, x)\nequal(|x) = ?x\n</code></pre> <p>The equal strategy tests whether the current term is a a pair of the same terms. The <code>equal(|x)</code> strategy tests whether the current term is equal to the argument term.</p> <pre><code>&lt;equal&gt;(\"a\", \"a\")               // succeeds\n&lt;equal&gt;(\"a\", \"b\")               // fails\n&lt;equal(|Foo(Baz()))&gt; Foo(Bar()) // fails\n&lt;equal(|Foo(Bar()))&gt; Foo(Bar()) // succeeds\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#implementing-rewrite-rules","title":"Implementing Rewrite Rules","text":"<p>Match and build are first-class citizens in Stratego, which means that they can be used and combined just like any other strategy expressions. In particular, we can implement rewrite rules using these operations, since a rewrite rule is basically a match followed by a build. For example, consider the following combination of match and build:</p> <pre><code>&lt;?Plus(e1, e2); !Plus(e2, e1)&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Int(\"3\"), Var(\"a\"))\n</code></pre> <p>This combination first recognizes a term, binds variables to the pattern in the match, and then replaces the current term with the instantiation of the build pattern. Note that the variable bindings are propagated from the match to the build.</p> <p>Stratego provides syntactic sugar for various combinations of match and build.</p>"},{"location":"background/stratego/strategy-combinators/term/#anonymous-rewrite-rule","title":"Anonymous Rewrite Rule","text":"<p>An anonymous rewrite rule <code>(p1 -&gt; p2)</code> transforms a term matching <code>p1</code> into an instantiation of <code>p2</code>. Such a rule is equivalent to the sequence <code>?p1; !p2</code>.</p> <pre><code>&lt;(Plus(e1, e2) -&gt; Plus(e2, e1))&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Int(\"3\"), Var(\"a\"))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#term-variable-scope","title":"Term variable scope","text":"<p>Once a variable is bound it cannot be rebound to a different term. Thus, when we have applied an anonymous rule once, its variables are bound and the next time it is applied it only succeeds for the same term. For example, in the next session the second application of the rule fails, because <code>e2</code> is bound to <code>Int(\"3\")</code> and does not match with <code>Var(\"b\")</code>.</p> <pre><code>&lt;(Plus(e1, e2) -&gt; Plus(e2, e1))&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Int(\"3\"), Var(\"a\"))\n// e1 is bound to Var(\"a\")\n// e2 is bound to Int(\"3\")\n\n&lt;(Plus(e1, e2) -&gt; Plus(e2, e1))&gt; Plus(Var(\"a\"), Var(\"b\")) // fails\n</code></pre> <p>To use a variable name more than once Stratego provides term variable scope. A scope <code>{x1,...,xn : s}</code> locally undefines the variables <code>xi</code>. That is, the binding to a variable <code>xi</code> outside the scope is not visible inside it, nor is the binding to <code>xi</code> inside the scope visible outside it. For example, to continue the session above, if we wrap the anonymous swap rule in a scope for its variables, it can be applied multiple times.</p> <pre><code>&lt;{e3,e4 : (Plus(e3,e4) -&gt; Plus(e4,e3))}&gt;\nPlus(Var(\"a\"),Int(\"3\")) =&gt; Plus(Var(\"a\"),Int(\"3\"))\n// e3 is not bound to a term\n\n&lt;{e3,e4 : (Plus(e3,e4) -&gt; Plus(e4,e3))}&gt;\nPlus(Var(\"a\"),Var(\"b\")) =&gt; Plus(Var(\"b\"),Var(\"a\"))\n</code></pre> <p>Of course we can name such a scoped rule using a strategy definition, and then invoke it by its name:</p> <pre><code>SwapArgs = {e1,e2 : (Plus(e1,e2) -&gt; Plus(e2,e1))}\n\n&lt;SwapArgs&gt;Plus(Var(\"a\"),Int(\"3\")) =&gt; Plus(Int(\"3\"),Var(\"a\"))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#implicit-variable-scope","title":"Implicit Variable Scope","text":"<p>When using match and build directly in a strategy definition, rather than in the form of a rule, the definition contains free variables. Strictly speaking such variables should be declared using a scope, that is one should write</p> <pre><code>SwapArgs = {e1,e2 : (Plus(e1,e2) -&gt; Plus(e2,e1))}\n</code></pre> <p>However, since declaring all variables at the top of a definition is distracting and does not add much to the definition, such a scope declaration can be left out. Thus, one can write</p> <pre><code>SwapArgs = (Plus(e1,e2) -&gt; Plus(e2,e1))\n</code></pre> <p>instead. The scope is automatically inserted by the compiler. This implies that there is no global scope for term variables. Of course, variables in inner scopes should be declared where necessary. In particular, note that variable scope is not inserted for strategy definitions in a let binding, such as</p> <pre><code>let SwapArgs = (Plus(e1,e2) -&gt; Plus(e2,e1)) in ... end\n</code></pre> <p>While the variables are bound in the enclosing definition, they are not restricted to <code>SwapArgs</code> in this case, since in a let you typically want to use bindings to variables in the enclosing code.</p>"},{"location":"background/stratego/strategy-combinators/term/#where","title":"Where","text":"<p>Often it is useful to apply a strategy only to test whether some property holds or to compute some auxiliary result. For this purpose, Stratego provides the <code>where(s)</code> combinator, which applies <code>s</code> to the current term, but restores that term afterwards. Any bindings to variables are kept, however.</p> <pre><code>&lt;where(?Plus(Int(i),Int(j)); &lt;addS&gt;(i,j) =&gt; k)&gt;\nPlus(Int(\"14\"),Int(\"3\")) =&gt; Plus(Int(\"14\"),Int(\"3\"))\n// i is bound to \"14\"\n// k is bound to \"17\"\n</code></pre> <p>With the match and build constructs <code>where(s)</code> is in fact just syntactic sugar for <code>{x: ?x; s; !x}</code> with <code>x</code> a fresh variable not occurring in <code>s</code>. Thus, the current subject term is saved by binding it to a new variable <code>x</code>, then the strategy <code>s</code> is applied, and finally, the original term is restored by building <code>x</code>.</p>"},{"location":"background/stratego/strategy-combinators/term/#conditional-rewrite-rules","title":"Conditional Rewrite Rules","text":"<p>A simple rewrite rule succeeds if the match of the left-hand side succeeds. Sometimes it is useful to place additional requirements on the application of a rule, or to compute some value for use in the right-hand side of the rule. This can be achieved with conditional rewrite rules. A conditional rule <code>L: p1 -&gt; p2</code> where <code>s</code> is a simple rule extended with an additional computation <code>s</code> which should succeed in order for the rule to apply. The condition can be used to test properties of terms in the left-hand side, or to compute terms to be used in the right-hand side. The latter is done by binding such new terms to variables used in the right-hand side.</p> <p>For example, the <code>EvalPlus</code> rule in the following session uses a condition to compute the sum of <code>i</code> and <code>j</code>:</p> <pre><code>EvalPlus:\nPlus(Int(i),Int(j)) -&gt; Int(k)\nwhere !(i,j); addS; ?k\n\n&lt;EvalPlus&gt; Plus(Int(\"14\"),Int(\"3\")) =&gt; Int(\"17\")\n</code></pre> <p>A conditional rule can be desugared similarly to an unconditional rule. That is, a conditional rule of the form</p> <pre><code>L : p1 -&gt; p2 where s\n</code></pre> <p>is syntactic sugar for</p> <pre><code>L = ?p1; where(s); !p2\n</code></pre> <p>Thus, after the match with <code>p1</code> succeeds the strategy <code>s</code> is applied to the subject term. Only if the application of <code>s</code> succeeds, is the right-hand side <code>p2</code> built. Note that since <code>s</code> is applied within a where, the build <code>!p2</code> is applied to the original subject term; only variable bindings computed within <code>s</code> can be used in <code>p2</code>.</p> <p>As an example, consider the following constant folding rule, which reduces an addition of two integer constants to the constant obtained by computing the addition.</p> <pre><code>EvalPlus : Add(Int(i),Int(j)) -&gt; Int(k) where !(i,j); addS; ?k\n</code></pre> <p>The addition is computed by applying the primitive strategy addS to the pair of integers <code>(i,j)</code> and matching the result against the variable <code>k</code>, which is then used in the right-hand side. This rule is desugared to</p> <pre><code>EvalPlus = ?Add(Int(i),Int(j)); where(!(i,j); addS; ?k); !Int(k)\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#lambda-rules","title":"Lambda Rules","text":"<p>Sometimes it is useful to define a rule anonymously within a strategy expression. The syntax for anonymous rules with scopes is a bit much since it requires enumerating all variables. A lambda rule of the form</p> <pre><code>\\ p1 -&gt; p2 where s \\\n</code></pre> <p>is an anonymous rewrite rule for which the variables in the left-hand side <code>p1</code> are local to the rule, that is, it is equivalent to an expression of the form</p> <pre><code>{x1,...,xn : (p1 -&gt; p2 where s)}\n</code></pre> <p>with <code>x1</code>,\u2026,<code>xn</code> the variables of <code>p1</code>. This means that any variables used in <code>s</code> and <code>p2</code> that do not occur in <code>p1</code> are bound in the context of the rule.</p> <p>A typical example of the use of an anonymous rule is</p> <pre><code>&lt;map(\\ (x, y) -&gt; x \\ )&gt; [(1,2),(3,4),(5,6)] =&gt; [1,3,5]\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#apply-and-match","title":"Apply and Match","text":"<p>One frequently occuring scenario is that of applying a strategy to a term and then matching the result against a pattern. This typically occurs in the condition of a rule. In the constant folding example above we saw this scenario:</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwhere !(i,j); addS; ?k\n</code></pre> <p>In the condition, first the term <code>(i,j)</code> is built, then the strategy <code>addS</code> is applied to it, and finally the result is matched against the pattern <code>k</code>.</p> <p>To improve the readability of such expressions, the following two constructs are provided. The operation <code>&lt;s&gt; p</code> captures the notion of applying a strategy to a term, i.e., the scenario <code>!p; s</code>. The operation <code>s =&gt; p</code> capture the notion of applying a strategy to the current subject term and then matching the result against the pattern <code>p</code>, i.e., <code>s; ?p</code>. The combined operation <code>&lt;s&gt; p1 =&gt; p2</code> thus captures the notion of applying a strategy to a term <code>p1</code> and matching the result against <code>p2</code>, i.e, <code>!p1; s; ?p2</code>. Using this notation we can improve the constant folding rule above as</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwhere &lt;addS&gt;(i,j) =&gt; k\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#applying-strategies-in-build","title":"Applying Strategies in Build","text":"<p>Sometimes it useful to apply a strategy directly to a subterm of a pattern, for example in the right-hand side of a rule, instead of computing a value in a condition, binding the result to a variable, and then using the variable in the build pattern. The constant folding rule above, for example, could be further simplified by directly applying the addition in the right-hand side:</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(&lt;addS&gt;(i,j))\n</code></pre> <p>This abbreviates the conditional rule above. In general, a strategy application in a build pattern can always be expressed by computing the application before the build and binding the result to a new variable, which then replaces the application in the build pattern.</p> <p>Another example is the following definition of the map(s) strategy, which applies a strategy to each term in a list:</p> <pre><code>map(s) : [] -&gt; []\nmap(s) : [x | xs] -&gt; [&lt;s&gt; x | &lt;map(s)&gt; xs]\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#auxiliary-values","title":"Auxiliary Values","text":"<p>As mentioned above, it can be convenient to apply a strategy only to compute some auxiliary result. Although the <code>where</code> construct created to constrain when a rule or strategy may apply (as covered above) can be used for this purpose, often it is better to use the <code>with</code> strategy specifically designed with computing auxiliaries in mind.</p> <p>Specifically, if <code>s</code> is any strategy, the strategy <code>with(s)</code> executes <code>s</code> on the current subject term and then restores the current subject term. In other words, <code>s</code> is executed solely for its side effects, such as binding variables. In this respect, with is like <code>where</code>. However, <code>with(s)</code> differs in a key way: if the strategy <code>s</code> fails, Stratego immediately stops with an error, reporting the strategy that failed. Thus, if <code>with(s)</code> is used for auxiliary computations that really should not fail if the transformation is proceeding properly, there is no opportunity for Stratego to backtrack and/or continue applying other strategies, potentially creating an error at a point far removed from the place that things actually went awry. In short, using <code>with(s)</code> instead of <code>where(s)</code> any time the intention is not to constrain the applicability of a rule or strategy generally makes debugging your Stratego program significantly easier.</p> <p>Also as with <code>where</code>, we can add a <code>with</code> clause to a rewrite rule in exactly the same way. In other words,</p> <pre><code>L : p1 -&gt; p2 with s\n</code></pre> <p>is syntactic sugar for</p> <pre><code>L = ?p1; with(s); !p2\n</code></pre> <p>So as an example, the <code>where</code> version of <code>EvalPlus</code> above would be better cast as</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwith &lt;addS&gt;(i,j) =&gt; k\n</code></pre> <p>because after all, there is no chance that Stratego will be unable to add two integers, and so if the contents of the <code>with</code> clause fails it means something has gone wrong \u2013 perhaps an <code>Int</code> term somehow ended up with a parameter that does not actually represent an integer \u2013 and Stratego should quit now.</p>"},{"location":"background/stratego/strategy-combinators/term/#assignment","title":"Assignment","text":"<p>The assignment combinator <code>:=</code> is a variation of apply-and-match with terms on both sides of the assignment. The strategy <code>p1 := p2</code> builds <code>p2</code> and matches the result against <code>p1</code>, i.e. it is syntactic sugar for <code>!p2; ?p1</code>. The strategy is often combine with strategy application into <code>p1 := &lt;s&gt;p2</code>, which is equivalent to <code>&lt;s&gt;p2 =&gt; p1</code>, but more familiar to an audience with an imperative mindset.</p> <p>For example, consider the following rewrite rule</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwith k := &lt;addS&gt;(i,j)\n</code></pre>"},{"location":"background/stratego/strategy-combinators/term/#term-wrap","title":"Term Wrap","text":"<p>One often write rules of the form <code>x -&gt; Foo(Bar(x))</code>, i.e. wrapping a term pattern around the current term. Using rule syntax this is quite verbose. The syntactic abstraction of term wraps, allows the concise specification of such little transformations as <code>!Foo(Bar(&lt;id&gt;))</code>.</p> <p>In general, a term wrap is a build strategy <code>!p[&lt;s&gt;]</code> containing one or more strategy applications <code>&lt;s&gt;</code> that are not applied to a term. When executing the the build operation, each occurrence of such a strategy application <code>&lt;s&gt;</code> is replaced with the term resulting from applying <code>s</code> to the current subject term, i.e., the one that is being replaced by the build. The following applications illustrate some uses of term wraps:</p> <pre><code>&lt;!(&lt;id&gt;,&lt;id&gt;)&gt; 3 =&gt; (3,3)\n\n&lt;(&lt;Fst; inc&gt;,&lt;Snd&gt;)&gt; (3,3) =&gt; (4,3)\n\n&lt;!Call(&lt;id&gt;, [])&gt; \"foobar\" =&gt; Call(\"foobar\", [])\n\nmod2 = &lt;mod&gt;(&lt;id&gt;,2)\n\n&lt;mod2&gt; 6 =&gt; 0\n</code></pre> <p>As should now be a common pattern, term projects are implemented by translation to a combination of match and build expressions. Thus, a term wrap <code>!p[&lt;s&gt;]</code> is translated to a strategy expression</p> <pre><code>{x: where(s =&gt; x); !p[x]}\n</code></pre> <p>where <code>x</code> is a fresh variable not occurring in <code>s</code>. In other words, the strategy <code>s</code> is applied to the current subject term, i.e., the term to which the build is applied.</p> <p>As an example, the term wrap <code>!Foo(Bar(&lt;id&gt;))</code> is desugared to the strategy</p> <pre><code>{x: where(id =&gt; x); !Foo(Bar(x))}\n</code></pre> <p>which after simplification is equivalent to <code>{x: ?x; !Foo(Bar(x))}</code>, i.e., exactly the original lambda rule <code>\\x -&gt; Foo(Bar(x))\\</code>.</p>"},{"location":"background/stratego/strategy-combinators/term/#term-project","title":"Term Project","text":"<p>Term projections are the match dual of term wraps. Term projections can be used to project a subterm from a term pattern. For example, the expression <code>?And(&lt;id&gt;,x)</code> matches terms of the form <code>And(t1,t2)</code> and reduces them to the first subterm <code>t1</code>. Another example is the strategy</p> <pre><code>map(?FunDec(&lt;id&gt;,_,_))\n</code></pre> <p>which reduces a list of function declarations to a list of the names of the functions, i.e., the first arguments of the <code>FunDec</code> constructor. Here are some more examples:</p> <pre><code>&lt;?[_|&lt;id&gt;]&gt; [1,2,3] =&gt; [2,3]\n\n&lt;?Call(&lt;id&gt;, [])&gt; Call(\"foobar\", []) =&gt;  \"foobar\"\n</code></pre> <p>Term projections can also be used to apply additional constraints to subterms in a match pattern. For example, <code>?Call(x, &lt;?args; length =&gt; 3&gt;)</code> matches only with function calls with three arguments.</p> <p>A match expression <code>?p[&lt;s&gt;]</code> is desugared as</p> <pre><code>{x: ?p[x]; &lt;s&gt; x}\n</code></pre> <p>That is, after the pattern <code>p[x]</code> matches, it is reduced to the subterm bound to <code>x</code> to which s is applied. The result is also the result of the projection. When multiple projects are used within a match the outcome is undefined, i.e., the order in which the projects will be performed can not be counted on.</p>"},{"location":"background/stratego/strategy-combinators/traversal/","title":"Traversal Combinators","text":"<p>There are many ways to traverse a tree. For example, a bottom-up traversal, visits the subterms of a node before it visits the node itself, while a top-down traversal visits nodes before it visits children. One-pass traversals traverse the tree one time, while fixed-point traversals, such as innermost, repeatedly traverse a term until a normal form is reached.</p> <p>Rather than provide built-in implementations for all traversals needed in transformations, Stratego defines traversals in terms of the primitive ingredients of traversal. For example, a top-down, one-pass traversal strategy will first visit a node, and then descend to the children of a node in order to recursively traverse all subterms. Similarly, the bottom-up, fixed-point traversal strategy innermost, will first descend to the children of a node in order to recursively traverse all subterms, then visit the node itself, and possibly recursively reapply the strategy.</p> <p>Traversal in Stratego is based on the observation1 that a full term traversal is a recursive closure of a one-step descent, that is, an operation that applies a strategy to one or more direct subterms of the subject term. By separating this one-step descent operator from recursion, and making it a first-class operation, many different traversals can be defined.</p> <p>Here we explore the ways in which Stratego supports the definition of traversal strategies. We start with explicitly programmed traversals using recursive traversal rules. Next, congruences operators provide a more concise notation for such data-type specific traversal rules. Finally, generic traversal operators support data type independent definitions of traversals, which can be reused for any data type. Given these basic mechanisms, we conclude with an exploration of idioms for traversal and standard traversal strategies in the Stratego Library.</p>"},{"location":"background/stratego/strategy-combinators/traversal/#congruence-operators","title":"Congruence Operators","text":"<p>Congruence operators provide a convenient abbreviation of traversal with rewrite rules. A congruence operator applies a strategy to each direct subterm of a specific constructor. For each n-ary constructor <code>c</code> declared in a signature, there is a corresponding congruence operator <code>c(s1 , ..., sn)</code>, which applies to terms of the form <code>c(t1 , ..., tn)</code> by applying the argument strategies to the corresponding argument terms. A congruence fails if the application of one the argument strategies fails or if constructor of the operator and that of the term do not match.</p> <p>For example, consider the following signature of expressions:</p> <pre><code>module expressions\nsignature\nsorts Exp\nconstructors\nInt   : String -&gt; Exp\nVar   : String -&gt; Exp\nPlus  : Exp * Exp -&gt; Exp\nTimes : Exp * Exp -&gt; Exp\n</code></pre> <p>The following applications apply the congruence operators <code>Plus</code> and <code>Times</code> to a term:</p> <pre><code>&lt;Plus(!Var(\"a\"), id)&gt; Plus(Int(\"14\"),Int(\"3\")) =&gt; Plus(Var(\"a\"),Int(\"3\"))\n\n&lt;Times(id, !Int(\"42\"))&gt; Plus(Var(\"a\"),Int(\"3\")) // fails\n</code></pre> <p>The first application shows how a congruence transforms a specific subterm, that is the strategy applied can be different for each subterm. The second application shows that a congruence only succeeds for terms constructed with the same constructor.</p>"},{"location":"background/stratego/strategy-combinators/traversal/#defining-traversals-with-congruences","title":"Defining Traversals with Congruences","text":"<p>Since congruence operators define a one-step traversal for a specific constructor, they capture the pattern of traversal rules. That is, a traversal rule such as</p> <pre><code>proptr(s) : And(x, y) -&gt; And(&lt;s&gt;x, &lt;s&gt;y)\n</code></pre> <p>can be written by the congruence <code>And(s,s)</code>. Applying this to the <code>prop-dnf</code> program we can replace the traversal rules by congruences as follows:</p> <pre><code>module prop-dnf10\nimports prop-rules\nstrategies\nproptr(s) = Not(s) &lt;+ And(s, s) &lt;+ Or(s, s) &lt;+ Impl(s, s) &lt;+ Eq(s, s)\npropbu(s) = try(proptr(propbu(s))); s\nstrategies\ndnf = propbu(try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf))\ncnf = propbu(try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DOAL &lt;+ DOAR); cnf))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/traversal/#traversing-tuples-and-lists","title":"Traversing Tuples and Lists","text":"<p>Congruences can also be applied to tuples, <code>(s1,s2,...,sn)</code>, and lists, <code>[s1,s2,...,sn]</code>. A special list congruence is <code>[]</code> which \u2018visits\u2019 the empty list. As an example, consider again the definition of <code>map(s)</code> using recursive traversal rules:</p> <pre><code>map(s) : [] -&gt; []\nmap(s) : [x | xs] -&gt; [&lt;s&gt; x | &lt;map(s)&gt; xs]\n</code></pre> <p>Using list congruences we can define this strategy as:</p> <pre><code>map(s) = [] &lt;+ [s | map(s)]\n</code></pre> <p>The <code>[]</code> congruence matches an empty list. The <code>[s | map(s)]</code> congruence matches a non-empty list, and applies <code>s</code> to the head of the list and <code>map(s)</code> to the tail. Thus, <code>map(s)</code> applies <code>s</code> to each element of a list:</p> <pre><code>&lt;map(inc)&gt; [1,2,3] =&gt; [2,3,4]\n</code></pre> <p>Note that <code>map(s)</code> only succeeds if <code>s</code> succeeds for each element of the list. The <code>fetch</code> and <code>filter</code> strategies are variations on map that use the failure of <code>s</code> to list elements.</p> <pre><code>fetch(s) = [s | id] &lt;+ [id | fetch(s)]\n</code></pre> <p>The <code>fetch</code> strategy traverses a list until it finds a element for which <code>s</code> succeeds and then stops. That element is the only one that is transformed.</p> <pre><code>filter(s) = [] + ([s | filter(s)] &lt;+ ?[ |&lt;id&gt;]; filter(s))\n</code></pre> <p>The <code>filter</code> strategy applies <code>s</code> to each element of a list, but only keeps the elements for which it succeeds.</p> <pre><code>even = where(&lt;eq&gt;(&lt;mod&gt;(&lt;id&gt;,2),0))\n\n&lt;filter(even)&gt; [1,2,3,4,5,6,7,8] =&gt; [2,4,6,8]\n</code></pre>"},{"location":"background/stratego/strategy-combinators/traversal/#format-checking","title":"Format Checking","text":"<p>Another application of congruences is in the definition of format checkers. A format checker describes a subset of a term language using a recursive pattern. This can be used to verify input or output of a transformation, and for documentation purposes. Format checkers defined with congruences can check subsets of signatures or regular tree grammars. For example, the subset of terms of a signature in a some normal form.</p> <p>As an example, consider checking the output of the <code>dnf</code> and <code>cnf</code> transformations.</p> <pre><code>conj(s) = And(conj(s), conj(s)) &lt;+ s\ndisj(s) = Or (disj(s), disj(s)) &lt;+ s\n\n// Conjunctive normal form\nconj-nf = conj(disj(Not(Atom(id)) &lt;+ Atom(id)))\n\n// Disjunctive normal form\ndisj-nf = disj(conj(Not(Atom(id)) &lt;+ Atom(id)))\n</code></pre> <p>The strategies <code>conj(s)</code> and <code>disj(s)</code> check that the subject term is a conjunct or a disjunct, respectively, with terms satisfying s at the leaves. The strategies <code>conj-nf</code> and <code>disj-nf</code> check that the subject term is in conjunctive or disjunctive normal form, respectively.</p>"},{"location":"background/stratego/strategy-combinators/traversal/#generic-traversal","title":"Generic Traversal","text":"<p>Using congruence operators we constructed a generic, i.e. transformation independent, bottom-up traversal for proposition terms. The same can be done for other data types. However, since the sets of constructors of abstract syntax trees of typical programming languages can be quite large, this may still amount to quite a bit of work that is not reusable across data types; even though a strategy such as bottom-up traversal, is basically data-type independent. Thus, Stratego provides generic traversal by means of several generic one-step descent operators. The operator <code>all</code>, applies a strategy to all direct subterms. The operator <code>one</code>, applies a strategy to one direct subterm, and the operator <code>some</code>, applies a strategy to as many direct subterms as possible, and at least one.</p>"},{"location":"background/stratego/strategy-combinators/traversal/#visiting-all-subterms","title":"Visiting All Subterms","text":"<p>The <code>all(s)</code> strategy transforms a constructor application by applying the parameter strategy <code>s</code> to each direct subterm. An application of <code>all(s)</code> fails if the application to one of the subterms fails. The following example shows how all (1) applies to any term, and (2) applies its argument strategy uniformly to all direct subterms. That is, it is not possible to do something special for a particular subterm (that\u2019s what congruences are for).</p> <pre><code>&lt;all(!Var(\"a\"))&gt;\nPlus(Int(\"14\"), Int(\"3\")) =&gt; Plus(Var(\"a\"), Var(\"a\"))\n\n&lt;all(!Var(\"z\"))&gt;\nTimes(Var(\"b\"), Int(\"3\")) =&gt; Times(Var(\"z\"), Var(\"z\"))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/traversal/#defining-traversals-with-all","title":"Defining Traversals with All","text":"<p>The <code>all(s)</code> operator is really the ultimate replacement for the traversal with rules idiom. Instead of specifying a rule or congruence for each constructor, the single application of the <code>all</code> operator takes care of traversing all constructors. Thus, we can replace the <code>propbu</code> strategy by a completely generic definition of bottom-up traversal. Consider again the last definition of <code>propbu</code>:</p> <pre><code>proptr(s) = Not(s) &lt;+ And(s, s) &lt;+ Or(s, s) &lt;+ Impl(s, s) &lt;+ Eq(s, s)\npropbu(s) = try(proptr(propbu(s))); s\n</code></pre> <p>The role of <code>proptr(s)</code> in this definition can be replaced by <code>all(s)</code>, since that achieves exactly the same, namely applying <code>s</code> to the direct subterms of constructors:</p> <pre><code>propbu(s) = all(propbu(s)); s\n</code></pre> <p>Moreover, <code>all</code> succeeds on any constructor in any signature, so we can also drop the <code>try</code> as well, which was there only because <code>proptr</code> fails on the <code>Atom(...)</code>, <code>True()</code>, and <code>False()</code> nodes at the leaves.</p> <p>However, the strategy now is completely generic, i.e. independent of the particular structure it is applied to. In the Stratego Library this strategy is called <code>bottomup(s)</code>, and defined as follows:</p> <pre><code>bottomup(s) = all(bottomup(s)); s\n</code></pre> <p>It first recursively transforms the subterms of the subject term and then applies <code>s</code> to the result. Using this definition, the normalization of propositions now reduces to the following module, which is only concerned with the selection and composition of rewrite rules:</p> <pre><code>module prop-dnf11\nimports prop-rules\nstrategies\ndnf = bottomup(try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR); dnf))\ncnf = bottomup(try(DN &lt;+ (DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DOAL &lt;+ DOAR); cnf))\n</code></pre> <p>In fact, these definitions still contain a reusable pattern. With a little squinting we see that the definitions match the following pattern:</p> <pre><code>dnf = bottomup(try(dnf-rules; dnf))\ncnf = bottomup(try(cnf-rules; cnf))\n</code></pre> <p>In which we can recognize the definition of innermost reduction, which the Stratego Library defines as:</p> <pre><code>innermost(s) = bottomup(try(s; innermost(s)))\n</code></pre> <p>The <code>innermost</code> strategy performs a bottom-up traversal of a term. After transforming the subterms of a term it tries to apply the transformation <code>s</code>. If successful the result is recursively transformed with an application of <code>innermost</code>. This brings us to the final form for the proposition normalizations:</p> <pre><code>module prop-dnf12\nimports prop-rules\nstrategies\ndnf = innermost(DN &lt;+ DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DAOL &lt;+ DAOR)\ncnf = innermost(DN &lt;+ DefI &lt;+ DefE &lt;+ DMA &lt;+ DMO &lt;+ DOAL &lt;+ DOAR)\n</code></pre> <p>Different transformations can be achieved by using a selection of rules and a strategy, which is generic, yet defined in Stratego itself using strategy combinators.</p>"},{"location":"background/stratego/strategy-combinators/traversal/#visiting-one-subterm","title":"Visiting One Subterm","text":"<p>The <code>one(s)</code> strategy transforms a constructor application by applying the parameter strategy <code>s</code> to exactly one direct subterm. An application of <code>one(s)</code> fails if the application to all of the subterms fails. The following applications illustrate the behavior of the combinator:</p> <pre><code>&lt;one(!Var(\"a\"))&gt;\nPlus(Int(\"14\"), Int(\"3\")) =&gt; Plus(Var(\"a\"), Int(\"3\"))\n\n&lt;one(\\ Int(x) -&gt; Int(&lt;addS&gt;(x,\"1\")) \\ )&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Var(\"a\"), Int(\"4\"))\n\n&lt;one(?Plus(_,_))&gt;\nPlus(Var(\"a\"), Int(\"4\")) // fails\n</code></pre>"},{"location":"background/stratego/strategy-combinators/traversal/#defining-traversals-with-one","title":"Defining Traversals with One","text":"<p>A frequently used application of <code>one</code> is the <code>oncetd(s)</code> traversal, which performs a left to right depth first search/transformation that stops as soon as s has been successfully applied.</p> <pre><code>oncetd(s) = s &lt;+ one(oncetd(s))\n</code></pre> <p>Thus, <code>s</code> is first applied to the root of the subject term. If that fails, its direct subterms are searched one by one (from left to right), with a recursive call to <code>oncetd(s)</code>.</p> <p>An application of <code>oncetd</code> is the <code>contains(|t)</code> strategy, which checks whether the subject term contains a subterm that is equal to t.</p> <pre><code>contains(|t) = oncetd(?t)\n</code></pre> <p>Through the depth first search of <code>oncetd</code>, either an occurrence of <code>t</code> is found, or all subterms are verified to be unequal to <code>t</code>.</p> <p>Here are some other one-pass traversals using the one combinator:</p> <pre><code>oncebu(s)  = one(oncebu(s)) &lt;+ s\nspinetd(s) = s; try(one(spinetd(s)))\nspinebu(s) = try(one(spinebu(s))); s\n</code></pre> <p>Here are some fixe-point traversals, i.e., traversals that apply their argument transformation exhaustively to the subject term.</p> <pre><code>reduce(s)     = repeat(rec x(one(x) + s))\noutermost(s)  = repeat(oncetd(s))\ninnermostI(s) = repeat(oncebu(s))\n</code></pre> <p>The difference is the subterm selection strategy.</p>"},{"location":"background/stratego/strategy-combinators/traversal/#visiting-some-subterms","title":"Visiting Some Subterms","text":"<p>The <code>some(s)</code> strategy transforms a constructor application by applying the parameter strategy <code>s</code> to as many direct subterms as possible and at least one. An application of <code>some(s)</code> fails if the application to all of the subterms fails.</p> <p>Some one-pass traversals based on some:</p> <pre><code>sometd(s) = s &lt;+ some(sometd(s))\nsomebu(s) = some(somebu(s)) &lt;+ s\n</code></pre> <p>A fixed-point traversal with some:</p> <pre><code>reduce-par(s) = repeat(rec x(some(x) + s))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/traversal/#references","title":"References","text":"<ol> <li> <p>Bas Luttik and Eelco Visser. Specification of rewriting strategies. In M. P. A. Sellink, editor, 2nd International Workshop on the Theory and Practice of Algebraic Specifications (ASF+SDF 1997), Electronic Workshops in Computing. Berlin, November 1997. Springer-Verlag.\u00a0\u21a9</p> </li> </ol>"},{"location":"background/stratego/strategy-combinators/type-unifying/","title":"Type Unifying Traversal","text":"<p>In this section we consider the class of type unifying strategies, in which terms of different types are mapped onto one type. The application area for this type of strategy is analysis of expressions with examples such as free variables collection and call-graph extraction.</p> <p>We consider the following example problems:</p> <ul> <li><code>term-size</code>: Count the number of nodes in a term</li> <li><code>occurrences</code>: Count number of occurrences of a subterm in a term</li> <li><code>collect-vars</code>: Collect all variables in expression</li> <li><code>free-vars</code>: Collect all free variables in expression</li> </ul> <p>These problems have in common that they reduce a structure to a single value or to a collection of derived values. The structure of the original term is usually lost.</p> <p>We start with examining these problems in the context of lists, and then generalize the solutions we find there to arbitrary terms using generic term deconstruction, which allows concise implementation of generic type unifying strategies.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#type-unifying-list-transformations","title":"Type Unifying List Transformations","text":"<p>We start with considering type-unifying operations on lists.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#sum","title":"Sum","text":"<p>Reducing a list to a value can be conveniently expressed by means of a <code>fold</code>, which has as parameters operations for reducing the list constructors. The <code>foldr/2</code> strategy reduces a list by replacing each <code>Cons</code> by an application of <code>s2</code>, and the empty list by <code>s1</code>.</p> <pre><code>foldr(s1, s2) =\n[]; s1 &lt;+ \\ [y|ys] -&gt; &lt;s2&gt;(y, &lt;foldr(s1, s2)&gt; ys) \\\n</code></pre> <p>Thus, when applied to a list with three terms the result is</p> <pre><code>&lt;foldr(s1,s2)&gt; [t1,t2,t3] =&gt; &lt;s2&gt;(t1, &lt;s2&gt;(t2, &lt;s2&gt;(t3, &lt;s1&gt; [])))\n</code></pre> <p>A typical application of <code>foldr/2</code> is <code>sum</code>, which reduces a list to the sum of its elements. It sums the elements of a list of integers, using 0 for the empty list and add to combine the head of a list and the result of folding the tail.</p> <pre><code>sum = foldr(!0, add)\n</code></pre> <p>The effect of <code>sum</code> is illustrated by the following application:</p> <pre><code>&lt;foldr(!0,add)&gt;\n[1,2,3]\n=&gt; &lt;add&gt;(1, &lt;add&gt;(2, &lt;add&gt;(3, &lt;!0&gt; [])))\n=&gt; 6\n</code></pre> <p>Note the build operator for replacing the empty list with <code>0</code>; writing <code>foldr(0, add)</code> would be wrong, since <code>0</code> by itself is a congruence operator, which basically matches the subject term with the term <code>0</code> (rather than replacing it).</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#size","title":"Size","text":"<p>The <code>foldr/2</code> strategy does not touch the elements of a list. The <code>foldr/3</code> strategy is a combination of fold and map that extends <code>foldr/2</code> with a parameter that is applied to the elements of the list.</p> <pre><code>foldr(s1, s2, f) =\n[]; s1 &lt;+ \\ [y|ys] -&gt; &lt;s2&gt;(&lt;f&gt;y, &lt;foldr(s1,s2,f)&gt;ys) \\\n</code></pre> <p>Thus, when applying it to a list with three elements, we get:</p> <pre><code>&lt;foldr(s1, s2)&gt;\n[t1, t2, t3] =&gt; &lt;s2&gt;(&lt;f&gt;t1, &lt;s2&gt;(&lt;f&gt;t2, &lt;s2&gt;(&lt;f&gt;t3, &lt;s1&gt; [])))\n</code></pre> <p>Now we can solve our first example problem <code>term-size</code>. The size of a list is its length, which corresponds to the sum of the list with the elements replaced by <code>1</code>.</p> <pre><code>length = foldr(!0, add, !1)\n</code></pre>"},{"location":"background/stratego/strategy-combinators/type-unifying/#number-of-occurrences","title":"Number of occurrences","text":"<p>The number of occurrences in a list of terms that satisfy some predicate, entails only counting those elements in the list for which the predicate succeeds. (Where a predicate is implemented with a strategy that succeeds only for the elements in the domain of the predicate.) This follows the same pattern as counting the length of a list, but now only counting the elements for which s succeeds.</p> <pre><code>list-occurrences(s) = foldr(!0, add, s &lt; !1 + !0)\n</code></pre> <p>Using <code>list-occurrences</code> and a match strategy we can count the number of variables in a list:</p> <pre><code>list-occurrences(?Var(_))\n</code></pre>"},{"location":"background/stratego/strategy-combinators/type-unifying/#collect","title":"Collect","text":"<p>The next problem is to collect all terms for which a strategy succeeds. We have already seen how to do this for lists. The <code>filter</code> strategy reduces a list to the elements for which its argument strategy succeeds.</p> <pre><code>filter(s) = [] &lt;+ [s | filter(s)] &lt;+ ?[ |&lt;filter(s)&gt;]\n</code></pre> <p>Collecting the variables in a list is a matter of filtering with the <code>?Var(_)</code> match.</p> <pre><code>filter(?Var(_))\n</code></pre> <p>The final problem, collecting the free variables in a term, does not really have a counter part in lists, but we can mimick this if we consider having two lists; where the second list is the one with the bound variables that should be excluded.</p> <pre><code>(filter(?Var(_)),id); diff\n</code></pre> <p>This collects the variables in the first list and subtracts the variables in the second list.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#extending-fold-to-expressions","title":"Extending Fold to Expressions","text":"<p>We have seen how to do typical analysis transformations on lists. How can we generalize this to arbitrary terms? The general idea of a folding operator is that it replaces the constructors of a data-type by applying a function to combine the reduced arguments of constructor applications. For example, the following definition is a sketch for a fold over abstract syntax trees:</p> <pre><code>fold-exp(binop, assign, if, ...) = rec f(\nfold-binop(f, binop)\n&lt;+ fold-assign(f, assign)\n&lt;+ fold-if(f, if)\n&lt;+ ... )\n\nfold-binop(f, s)  : BinOp(op, e1, e2) -&gt; &lt;s&gt;(op, &lt;f&gt;e1, &lt;f&gt;e2)\nfold-assign(f, s) : Assign(e1, e2)    -&gt; &lt;s&gt;(&lt;f&gt;e1, &lt;f&gt;e2)\nfold-if(f, s)     : If(e1, e2, e3)    -&gt; &lt;s&gt;(&lt;f&gt;e1, &lt;f&gt;e2, &lt;f&gt;e3)\n</code></pre> <p>For each constructor of the data-type the fold has an argument strategy and a rule that matches applications of the constructor, which it replaces with an application of the strategy to the tuple of subterms reduced by a recursive invocation of the fold.</p> <p>Instantiation of this strategy requires a rule for each constructor of the data-type. For instance, the following instantiation defines <code>term-size</code> using <code>fold-exp</code> by providing rules that sum up the sizes of the subterms and add one (<code>inc</code>) to account for the node itself.</p> <pre><code>term-size  = fold-exp(BinOpSize, AssignSize, IfSize, ...)\n\nBinOpSize  : (Plus(), e1, e2) -&gt; &lt;add; inc&gt;(e1, e2)\nAssignSize : (e1, e2)         -&gt; &lt;add; inc&gt;(e1, e2)\nIfSize     : (e1, e2, e3)     -&gt; &lt;add; inc&gt;(e1, &lt;add&gt;(e2, e3))\n</code></pre> <p>This looks suspiciously like the traversal with rules pattern. Defining folds in this manner has several limitations. In the definition of fold, one parameter for each constructor is provided and traversal is defined explicitly for each constructor. Furthermore, in the instantiation of fold, one rule for each constructor is needed, and the default behaviour is not generically specified.</p> <p>One solution would be to use the generic traversal strategy bottomup to deal with fold:</p> <pre><code>fold-exp(s) = bottomup(s)\n\nterm-size   = fold-exp(BinOpSize &lt;+ AssignSize &lt;+ IfSize &lt;+ ...)\n\nBinOpSize   : BinOp(Plus(), e1, e2) -&gt; &lt;add&gt;(1, &lt;add&gt;(e1, e2))\nAssignSize  : Assign(e1, e2)        -&gt; &lt;add&gt;(e1, e2)\nIfSize      : If(e1, e2, e3)        -&gt; &lt;add&gt;(e1, &lt;add&gt;(e2, e3))\n</code></pre> <p>Although the recursive application to subterms is now defined generically, one still has to specify rules for the default behavior.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#generic-term-deconstruction","title":"Generic Term Deconstruction","text":"<p>Instead of having folding rules that are specific to a data type, such as</p> <pre><code>BinOpSize  : BinOp(op, e1, e2) -&gt; &lt;add&gt;(1, &lt;add&gt;(e1, e2))\nAssignSize : Assign(e1, e2)    -&gt; &lt;add&gt;(1, &lt;add&gt;(e1, e2))\n</code></pre> <p>we would like to have a generic definition of the form</p> <pre><code>CSize : c(e1, e2, ...) -&gt; &lt;add&gt;(e1, &lt;add&gt;(e2, ...))\n</code></pre> <p>This requires generic decomposition of a constructor application into its constructor and the list with children. This can be done using the <code>#</code> operator. The match strategy <code>?p1#(p2)</code> decomposes a constructor application into its constructor name and the list of direct subterms. Matching such a pattern against a term of the form <code>C(t1,...,tn)</code> results in a match of <code>\"C\"</code> against <code>p1</code> and a match of <code>[t1,...,tn]</code> against <code>p2</code>.</p> <pre><code>&lt;?c#(xs)&gt; Plus(Int(\"1\"), Var(\"2\"))\n// variable c bound to \"Plus\"\n// variable xs bound to [Int(\"1\"), Var(\"2\")]\n</code></pre>"},{"location":"background/stratego/strategy-combinators/type-unifying/#crush","title":"Crush","text":"<p>Using generic term deconstruction we can generalize the type unifying operations on lists to arbitrary terms. In analogy with the generic traversal operators we need a generic one-level reduction operator. The <code>crush/3</code> strategy reduces a constructor application by folding the list of its subterms using <code>foldr/3</code>.</p> <pre><code>crush(nul, sum, s) : c#(xs) -&gt; &lt;foldr(nul, sum, s)&gt; xs\n</code></pre> <p>Thus, <code>crush</code> performs a fold-map over the direct subterms of a term as illustrated by the following application:</p> <pre><code>&lt;crush(s1, s2, f)&gt; C(t1, t2) =&gt; &lt;s2&gt;(&lt;f&gt;t1, &lt;s2&gt;(&lt;f&gt;t2, &lt;s1&gt;[]))\n</code></pre> <p>The following application instantiates this application in two ways:</p> <pre><code>&lt;crush(id, id, id)&gt;\nPlus(Int(\"1\"),Var(\"2\")) =&gt; (Int(\"1\"),(Var(\"2\"),[]))\n\n&lt;crush(!Tail(&lt;id&gt;), !Sum(&lt;Fst&gt;,&lt;Snd&gt;), !Arg(&lt;id&gt;))&gt;\nPlus(Int(\"1\"), Var(\"2\"))\n=&gt; Sum(Arg(Int(\"1\")), Sum(Arg(Var(\"2\")), Tail([])))\n</code></pre> <p>The <code>crush</code> strategy is the tool we need to implement solutions for the example problems above.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#size_1","title":"Size","text":"<p>Counting the number of direct subterms of a term is similar to counting the number of elements of a list. The definition of <code>node-size</code> is the same as the definition of <code>length</code>, except that it uses <code>crush</code> instead of <code>foldr</code>:</p> <pre><code>node-size = crush(!0, add, !1)\n</code></pre> <p>Counting the number of subterms (nodes) in a term is a similar problem. But, instead of counting each direct subterm as <code>1</code>, we need to count its subterms.</p> <pre><code>term-size = crush(!1, add, term-size)\n</code></pre> <p>The <code>term-size</code> strategy achieves this simply with a recursive call to itself.</p> <pre><code>&lt;node-size&gt; Plus(Int(\"1\"), Var(\"2\")) =&gt; 2\n\n&lt;term-size&gt; Plus(Int(\"1\"), Var(\"2\")) =&gt; 5\n</code></pre>"},{"location":"background/stratego/strategy-combinators/type-unifying/#occurrences","title":"Occurrences","text":"<p>Counting the number of occurrences of a certain term in another term, or more generally, counting the number of subterms that satisfy some predicate is similar to counting the term size. However, only those terms satisfying the predicate should be counted. The solution is again similar to the solution for lists, but now using crush.</p> <pre><code>om-occurrences(s) = s &lt; !1 + crush(!0, add, om-occurrences(s))\n</code></pre> <p>The <code>om-occurrences</code> strategy counts the outermost subterms satisfying <code>s</code>. That is, the strategy stops counting as soon as it finds a subterm for which <code>s</code> succeeds.</p> <p>The following strategy counts all occurrences:</p> <pre><code>occurrences(s) = &lt;add&gt;(&lt;s &lt; !1 + !0&gt;, &lt;crush(!0, add, occurrences(s))&gt;)\n</code></pre> <p>It counts the current term if it satisfies <code>s</code> and adds that to the occurrences in the subterms.</p> <pre><code>&lt;om-occurrences(?Int(_))&gt;\nPlus(Int(\"1\"), Plus(Int(\"34\"), Var(\"2\"))) =&gt; 2\n\n&lt;om-occurrences(?Plus(_,_))&gt;\nPlus(Int(\"1\"), Plus(Int(\"34\"), Var(\"2\"))) =&gt; 1\n\n&lt;occurrences(?Plus(_,_))&gt;\nPlus(Int(\"1\"), Plus(Int(\"34\"), Var(\"2\"))) =&gt; 2\n</code></pre>"},{"location":"background/stratego/strategy-combinators/type-unifying/#collect_1","title":"Collect","text":"<p>Collecting the subterms that satisfy a predicate is similar to counting, but now a list of subterms is produced. The <code>collect(s)</code> strategy collects all outermost occurrences satisfying <code>s</code>.</p> <pre><code>collect(s) = ![&lt;s&gt;] &lt;+ crush(![], union, collect(s))\n</code></pre> <p>When encountering a subterm for which <code>s</code> succeeds, a singleton list is produced. For other terms, the matching subterms are collected for each direct subterm, and the resulting lists are combined with union to remove duplicates.</p> <p>A typical application of collect is the collection of all variables in an expression, which can be defined as follows:</p> <pre><code>get-vars = collect(?Var(_))\n</code></pre> <p>Applying <code>get-vars</code> to an expression AST produces the list of all subterms matching <code>Var(_)</code>.</p> <p>The <code>collect-all(s)</code> strategy collects all occurrences satisfying s.</p> <pre><code>collect-all(s) =\n![&lt;s&gt; | &lt;crush(![], union, collect(s))&gt;]\n&lt;+ crush(![], union, collect(s))\n</code></pre> <p>If <code>s</code> succeeds for the subject term combines the subject term with the collected terms from the subterms.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#free-variables","title":"Free Variables","text":"<p>Collecting the variables in an expression is easy, as we saw above. However, when dealing with languages with variable bindings, a common operation is to extract only the free variables in an expression or block of statements. That is, the occurrences of variables that are not bound by a variable declaration. For example, in the expression</p> <pre><code>x + let var y := x + 1 in f(y, a + x + b) end\n</code></pre> <p>the free variables are <code>{x, a, b}</code>, but not <code>y</code>, since it is bound by the declaration in the let. Similarly, in the function definition</p> <pre><code>function f(x : int) = let var y := h(x) in x + g(z) * y end\n</code></pre> <p>the only free variable is <code>z</code> since <code>x</code> and <code>y</code> are declared.</p> <p>Here is a free variable extraction strategy for Tiger expressions.</p> <p>The <code>crush</code> alternative takes care of the non-special constructors, while <code>ExpVars</code> and <code>FreeVars</code> deal with the special cases, i.e. variables and variable binding constructs:</p> <pre><code>free-vars =\nExpVars\n&lt;+ FreeVars(free-vars)\n&lt;+ crush(![], union, free-vars)\n\nExpVars :\nVar(x) -&gt; [x]\n\nFreeVars(fv) :\nLet([VarDec(x, t, e1)], e2) -&gt; &lt;union&gt;(&lt;fv&gt; e1, &lt;diff&gt;(&lt;fv&gt; e2, [x]))\n\nFreeVars(fv) :\nLet([FunctionDec(fdecs)], e2) -&gt; &lt;diff&gt;(&lt;union&gt;(&lt;fv&gt; fdecs, &lt;fv&gt;e2), fs)\nwhere &lt;map(?FunDec(&lt;id&gt;,_,_,_))&gt; fdecs =&gt; fs\n\nFreeVars(fv) :\nFunDec(f, xs, t, e) -&gt; &lt;diff&gt;(&lt;fv&gt;e, xs)\nwhere &lt;map(Fst)&gt; xs =&gt; xs\n</code></pre> <p>The <code>FreeVars</code> rules for binding constructs use their <code>fv</code> parameter to recursively get the free variables from subterms, and they subtract the bound variables from any free variables found using diff.</p> <p>We can even capture the pattern exhibited here in a generic collection algorithm with support for special cases:</p> <pre><code>collect-exc(base, special : (a -&gt; b) * a -&gt; b) =\nbase\n&lt;+ special(collect-exc(base, special))\n&lt;+ crush(![], union, collect-exc(base, special))\n</code></pre> <p>The special parameter is a strategy parameterized with a recursive call to the collection strategy. The original definition of <code>free-vars</code> above, can now be replaced with</p> <pre><code>free-vars = collect-exc(ExpVars, FreeVars)\n</code></pre>"},{"location":"background/stratego/strategy-combinators/type-unifying/#generic-term-construction","title":"Generic Term Construction","text":"<p>It can also be useful to construct terms generically. For example, in parse tree implosion, application nodes should be reduced to constructor applications. Hence build operators can also use the # operator. In a strategy <code>!p1#(p2)</code>, the current subject term is replaced by a constructor application, where the constructor name is provided by <code>p1</code> and the list of subterms by <code>p2</code>. So, if <code>p1</code> evaluates to <code>\"C\"</code> and <code>p2</code> evaluates to <code>[t1,...,tn]</code>, the expression <code>!p1#(p2)</code> build the term <code>C(t1,...,tn)</code>.</p>"},{"location":"background/stratego/strategy-combinators/type-unifying/#imploding-parse-trees","title":"Imploding Parse Trees","text":"<p>A typical application of generic term construction is the implosion of parse trees to abstract syntax trees performed by <code>implode-asfix</code>. Parse trees produced by sglr have the form:</p> <pre><code>appl(prod(sorts, sort, attrs([cons(\"C\")])),[t1,...,tn])\n</code></pre> <p>That is, a node in a parse tree consists of an encoding of the original production from the syntax definition, and a list with subtrees. The production includes a constructor annotation <code>cons(\"C\")</code> with the name of the abstract syntax tree constructor. Such a tree node should be imploded to an abstract syntax tree node of the form <code>C(t1,...,tn)</code>. Thus, this requires the construction of a term with constructor <code>C</code> given the string with its name. The following implosion strategy achieves this using generic term construction:</p> <pre><code>implode =\nappl(id, map(implode)); Implode\n\nImplode :\nappl(prod(sorts, sort, attrs([cons(c)])), ts) -&gt; c#(ts)\n</code></pre> <p>The <code>Implode</code> rule rewrites an <code>appl</code> term to a constructor application, by extracting the constructor name from the production and then using generic term construction to apply the constructor.</p> <p>Note that this is a gross over simplification of the actual implementation of <code>implode-asfix</code>. See the source code for the full strategy.</p> <p>Generic term construction and deconstruction support the definition of generic analysis and generic translation problems. The generic solutions for the example problems term size, number of occurrences, and subterm collection demonstrate the general approach to solving these types of problems.</p>"},{"location":"howtos/","title":"How-To's","text":"<p>These are some How-To's that help you to get to a specific goal or result with Spoofax. For hands-on tutorials on learning Spoofax, see the Tutorials section. For the Spoofax languages references, see the References section.</p>"},{"location":"howtos/#spoofax-installation","title":"Spoofax Installation","text":"<ul> <li>Install the Eclipse with Spoofax Plugin Bundle</li> <li>Install the Spoofax Eclipse Plugin Manually</li> <li>Install Spoofax from Source</li> </ul>"},{"location":"howtos/#statix","title":"Statix","text":"<ul> <li>Debugging Statix Specifications</li> </ul>"},{"location":"howtos/#stratego","title":"Stratego","text":"<ul> <li>How to generate Stratego signatures</li> <li>How to run Stratego programs</li> <li>How to generate pretty-printers</li> <li>How to debug Stratego programs</li> <li>Exchange Terms</li> <li>Inspect Terms</li> <li>How to upgrade from Stratego 1 to Stratego 2</li> </ul>"},{"location":"howtos/#editor-services","title":"Editor Services","text":"<ul> <li>Add Rename Refactoring to an Existing Project</li> </ul>"},{"location":"howtos/#spoofax-development","title":"Spoofax Development","text":"<ul> <li>Install Requirements for Spoofax</li> <li>Install Maven for Spoofax</li> <li>Build Spoofax</li> <li>Develop Spoofax</li> <li>Release Spoofax</li> </ul>"},{"location":"howtos/development/","title":"Spoofax Development","text":"<p>This is the reference manual for building and developing Spoofax, as well as information about its internals.</p>"},{"location":"howtos/development/#introduction","title":"Introduction","text":"<p>Spoofax is the integration of many different tools, compilers, (meta-)languages, (meta-)libraries, and runtime components. This integration is made concrete in the spoofax-releng Git repository on GitHub. This repository contains all components via Git submodules, which are updated by our build farm that builds Spoofax whenever one of its components in a submodule changes.</p> <p>Spoofax currently contains the following subcomponents as submodules:</p> <ul> <li><code>releng</code> - Release engineering scripts for managing and building the spoofax-releng repostory.</li> <li>Java libraries and runtimes<ul> <li><code>mb-rep</code> \u2014 Libraries for program representation such as abstract terms</li> <li><code>mb-exec</code> \u2014 Stratego interpreter and utilities</li> <li><code>jsglr</code> \u2014 JSGLR parser</li> <li><code>spoofax</code> \u2014 Spoofax Core, a cross platform API to Spoofax languages</li> <li><code>spoofax-maven</code> \u2014 Maven integration for Spoofax Core</li> <li><code>spoofax-sunshine</code> \u2014 Command-line integration for Spoofax Core</li> <li><code>spoofax-eclipse</code> \u2014 Eclipse plugin for Spoofax Core</li> <li><code>spoofax-intellij</code> \u2014 IntelliJ plugin for Spoofax Core</li> </ul> </li> <li>Meta-languages and libraries<ul> <li><code>esv</code> \u2014 Editor service language</li> <li><code>sdf</code> \u2014 Syntax Definition Formalisms, containing the SDF2 and SDF 3 languages</li> <li><code>stratego</code> and <code>strategoxt</code> \u2014 Stratego compiler, runtime, and editor</li> <li><code>nabl</code> \u2014 Name binding languages, containing the NaBL and NaBL2 languages, and support libraries for NaBL2</li> <li><code>ts</code> \u2014 Type system language</li> <li><code>dynsem</code> \u2014 Dynamic semantics language</li> <li><code>metaborg-coq</code> \u2014 Coq signatures and syntax definition</li> <li><code>spt</code> \u2014 Spoofax testing language</li> <li><code>runtime-libraries</code> \u2014 NaBL support libraries, incremental task engine for incremental name and type analysis</li> </ul> </li> </ul> <p>Furthermore, this repository contains a Bash script <code>./b</code> that redirects into the Python release engineering scripts in the <code>releng</code> submodule. These scripts support managing this Git repository, version management, generation of Eclipse instances, building Spoofax, and releasing new versions of Spoofax.</p> <p>The following how-tos explain how to set up Maven and other required tools for building and developing Spoofax, how to build and develop Spoofax, how to write this documentation, and explains some of the internals of Spoofax components.</p> <ul> <li>Requirements</li> <li>Maven</li> <li>Building</li> <li>Developing</li> <li>Releasing</li> </ul>"},{"location":"howtos/development/build-spoofax/","title":"How to build Spoofax","text":"<p>This how-to guides you on how to build Spoofax from scratch, via the command-line.</p>"},{"location":"howtos/development/build-spoofax/#cloning-the-source-code","title":"Cloning the Source Code","text":"<p>Clone the source code from the <code>spoofax-releng</code> repository with the following commands:</p>  macOS <pre><code>git clone --recursive https://github.com/metaborg/spoofax-releng.git\ncd spoofax-releng\n</code></pre> <p> macOS Catalina, Big Sur, or newer</p> <p>On macOS Catalina, Big Sur, or newer, you have to install <code>coreutils</code> and Docker to be able to build Spoofax. This is temporary, until the 32-bit binaries for <code>sdf2table</code> and <code>implodePT</code> have been phased out.</p> <p>See the requirements for Spoofax Development for more information.</p>  Linux <pre><code>git clone --recursive https://github.com/metaborg/spoofax-releng.git\ncd spoofax-releng\n</code></pre>  Windows <pre><code>git clone --recursive https://github.com/metaborg/spoofax-releng.git\ncd spoofax-releng\n\ncd releng\\releng\npy -m pip install -r .\\requirements.txt\n</code></pre> <p>Cloning and updating submodules can take a while, since we have many submodules and some have a large history.</p>"},{"location":"howtos/development/build-spoofax/#start-a-build","title":"Start a Build","text":"<p>To build Spoofax, simply execute:</p>  macOS <pre><code>./b build all\n</code></pre>  Linux <pre><code>./b build all\n</code></pre>  Windows <pre><code>.\\bd.bat build all\n</code></pre> <p>This downloads the latest Stratego/XT, and builds Spoofax. If you also want to build Stratego/XT from scratch, execute:</p>  macOS <pre><code>./b build -st all\n</code></pre>  Linux <pre><code>./b build -st all\n</code></pre>  Windows <pre><code>.\\bd.bat build -st all\n</code></pre> <p>The <code>-s</code> flag build Stratego/XT instead of downloading it, and <code>-t</code> skips the Stratego/XT tests since they are very lengthy. The <code>all</code> part of the command indicates that we want to build all components. For example, if you would only like to build the Java components of Spoofax, and skip the Eclipse plugins, execute:</p>  macOS <p><pre><code>./b build java\n</code></pre> Use <code>./b build</code> to get a list of components available for building, and <code>./b build --help</code> for help on all the command-line flags and switches.</p>  Linux <p><pre><code>./b build java\n</code></pre> Use <code>./b build</code> to get a list of components available for building, and <code>./b build --help</code> for help on all the command-line flags and switches.</p>  Windows <p><pre><code>.\\bd.bat build java\n</code></pre> Use <code>.\\bd.bat build</code> to get a list of components available for building, and <code>.\\bd.bat build --help</code> for help on all the command-line flags and switches.</p> <p>If you have opened a project in the repository in Eclipse, you must turn off Project \u2023 Build Automatically in Eclipse, otherwise the Maven and Eclipse compilers will interfere and possibly fail the build. After the Maven build is finished, enable Build Automatically again.</p>"},{"location":"howtos/development/build-spoofax/#updating-the-source-code","title":"Updating the Source Code","text":"<p>If you want to update the repository and submodules, execute:</p>  macOS <pre><code>git pull --rebase\n./b checkout\n./b update\n</code></pre>  Linux <pre><code>git pull --rebase\n./b checkout\n./b update\n</code></pre>  Windows <pre><code>git pull --rebase\n.\\bd.bat checkout\n.\\bd.bat update\n</code></pre> <p>The <code>git pull</code> command will update any changes in the main repository. The <code>./b checkout</code> command will check out the correct branches in all submodules, because Git does not do this automatically. The <code>./b update</code> command will update all submodules.</p>"},{"location":"howtos/development/build-spoofax/#switching-to-a-different-branch","title":"Switching to a Different Branch","text":"<p>Switching to a different branch, for example the <code>spoofax-release</code> branch, is done with the following commands:</p>  macOS <pre><code>git checkout spoofax-release\ngit pull --rebase\ngit submodule update --init --remote --recursive\n./b checkout\n./b update\n</code></pre>  Linux <pre><code>git checkout spoofax-release\ngit pull --rebase\ngit submodule update --init --remote --recursive\n./b checkout\n./b update\n</code></pre>  Windows <pre><code>git checkout spoofax-release\ngit pull --rebase\ngit submodule update --init --remote --recursive\n.\\bd.bat checkout\n.\\bd.bat update\n</code></pre>"},{"location":"howtos/development/build-spoofax/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howtos/development/build-spoofax/#resetting-and-cleaning","title":"Resetting and Cleaning","text":"<p>If updating or checking out a branch of submodule fails (because of unstaged or conflicting changes), you can try to resolve it yourself, or you can reset and clean everything. Reset and clean all submodules using:</p>  macOS <pre><code>./b reset\n./b clean\n</code></pre>  Linux <pre><code>./b checkout\n./b update\n</code></pre>  Windows <pre><code>.\\bd.bat reset\n.\\bd.bat clean\n</code></pre> <p>Risk of loss of data</p> <p>Resetting and cleaning deletes uncommitted and unpushed changes, which can cause permanent data loss. Make sure all your changes are committed and pushed!</p>"},{"location":"howtos/development/build-spoofax/#weird-compilation-errors","title":"Weird Compilation Errors","text":"<p>If you get any weird compilation errors during the command-line build, make sure that Project \u2023 Build Automatically is turned off in Eclipse.</p>"},{"location":"howtos/development/custom-configuration/","title":"How to provide a custom configuration","text":"<p>There are several valid reasons why the configuration specified in <code>metaborg.yaml</code> should be overridden or completely ignored. This quick how-to will show the high-level steps to provide a custom configuration in code for a Spoofax 2 project.</p>"},{"location":"howtos/development/custom-configuration/#override-read-method","title":"Override <code>read()</code> method","text":"<p>To specify your own configuration reader, extend the <code>AConfigurationReaderWriter</code> class. The <code>createNew()</code> method should create a new empty configuration, whereas the <code>read()</code> method reads a configuration from a file in the specified <code>rootFolder</code>. The latter we can override to provide our own custom configuration:</p> <pre><code>@Override\npublic HierarchicalConfiguration&lt;ImmutableNode&gt; read(Reader reader, @Nullable FileObject rootFolder)\nthrows IOException, ConfigurationException {\nfinal HierarchicalConfiguration&lt;ImmutableNode&gt; config = new BaseHierarchicalConfiguration();\nString folderName = path.getFilename().getBaseName();\nLanguageVersion version = new LanguageVersion(0, 1, 0, \"-SNAPSHOT\");\n\n// Basic properties\nconfig.setProperty(\"name\", \"MyProject\");\nconfig.setProperty(\"id\", new LanguageIdentifier(\"org.metaborg\", folderName, version));\n\n// Contributions\nconfig.setProperty(\"contributions(0).name\", \"mylang\");\nconfig.setProperty(\"contributions(0).id\", new LanguageIdentifier(\"org.metaborg\", \"mylang\", version));\n\n// Stratego\nconfig.setProperty(\"language.stratego.format\", \"jar\");\n\n// SDF\nconfig.setProperty(\"language.sdf.enabled\", true);\nconfig.setProperty(\"language.sdf.sdf2table\", \"java\");\n\nreturn config;\n}\n</code></pre>"},{"location":"howtos/development/custom-configuration/#override-module","title":"Override Module","text":"<p>Spoofax 2 uses the Guice dependency injection framework. To use the new configuration reader, override the <code>MetaborgModule</code> class <code>bindConfigMisc()</code> method:</p> <pre><code>@Override\nprotected void bindConfigMisc() {\nbind(AConfigurationReaderWriter.class)\n.to(MyCustomConfigurationReaderWriter.class)\n.in(Singleton.class);\n}\n</code></pre>"},{"location":"howtos/development/develop-spoofax/","title":"How to develop Spoofax","text":"<p>If you are developing a project that is included in Spoofax, it is recommended to set up a development environment. This how-to describes how to set up such a development environment.</p> <p>A working Spoofax build is required before being able to develop. You must be able to successfully build Spoofax by running <code>./b build all</code>. Do not continue if this does not work. See the instructions on how to build Spoofax.</p>"},{"location":"howtos/development/develop-spoofax/#eclipse","title":"Eclipse","text":"<p>Currently, an Eclipse development environment is the most supported environment. An Eclipse development environment can be generated with our scripts.</p>"},{"location":"howtos/development/develop-spoofax/#generating-an-eclipse-instance","title":"Generating an Eclipse Instance","text":"<p>The <code>./b</code> script in the <code>spoofax-releng</code> repository can generate an Eclipse installation for you. Change directory into the <code>spoofax-releng</code> repository and run:</p> <pre><code>./b gen-spoofax -l -d ~/eclipse/spoofax-dev\n</code></pre> <p>This will download and install Eclipse into <code>~/eclipse/spoofax-dev</code> with the right plugins and <code>eclipse.ini</code> for Spoofax development. The locally built version of the Spoofax plugin will be installed into that Eclipse. Generating an Eclipse installation can take several minutes. After it\u2019s done generating, open the Eclipse installation and confirm that it works by creating a Spoofax project.</p> RuntimeError: Eclipse generation failed <p>If you get the error \"RuntimeError: Eclipse generation failed\", then ensure you're building Eclipse using JDK 8.</p> Installation failed. Cannot complete the install because of a conflicting dependency <p>If you get an error \"Installation failed. Cannot complete the install because of a conflicting dependency.\", then make sure there is not an existing Eclipse instance at the destination.</p>  macOS: To open \u201cEclipse\u201d you need to install the legacy Java SE 6 runtime <p>If upon starting Eclipse you get the error \"To open \u201cEclipse\u201d you need to install the legacy Java SE 6 runtime\", then you should install a Java JDK 8 or newer for Eclipse to use. If you installed one through SDKMAN! then you have to point Eclipse to it. To do this, edit the <code>Contents/Eclipse/eclipse.ini</code> file in the Eclipse application package content. Add the following lines at the start of the file, where  is your username: <pre><code>-vm\n/Users/&lt;USERNAME&gt;/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib\n</code></pre>"},{"location":"howtos/development/develop-spoofax/#fixing-eclipse-settings","title":"Fixing Eclipse Settings","text":"<p>Some Eclipse settings unfortunately have sub-optimal defaults. Go to the Eclipse preferences and set these options:</p> <ul> <li>General<ul> <li>Enable: Keep next/previous editor, view and perspectives dialog open</li> </ul> </li> <li>General \u2023 Startup and Shutdown<ul> <li>Enable: Refresh workspace on startup</li> </ul> </li> <li>General \u2023 Workspace<ul> <li>Enable: Refresh using native hooks or polling</li> </ul> </li> <li>Maven<ul> <li>Enable: Do not automatically update dependencies from remote repositories</li> <li>Enable: Download Artifact Sources</li> <li>Enable: Download Artifact JavaDoc</li> </ul> </li> <li>Maven \u2023 Annotation Processing<ul> <li>Enable: Automatically configure JDT APT</li> </ul> </li> <li>Maven \u2023 User Interface<ul> <li>Enable: Open XML page in the POM editor by default</li> </ul> </li> <li>Run/Debug \u2023 Launching<ul> <li>Disable: Build (if required) before launching</li> </ul> </li> </ul>"},{"location":"howtos/development/develop-spoofax/#developing","title":"Developing","text":"<p>Import the projects you\u2019d like to develop. To import Java and language projects, use Import \u2023 Maven \u2023 Existing Maven Projects. Eclipse plugins are still imported with Import \u2023 General \u2023 Existing Projects into Workspace.</p>"},{"location":"howtos/development/develop-spoofax/#running","title":"Running","text":"<p>To test your changes in the Spoofax Eclipse plugin, import the <code>org.metaborg.spoofax.eclipse</code> project from the <code>spoofax-eclipse</code> repository, which provides launch configurations for starting new Eclipse instances (a \u201cguest\u201d Eclipse). Press the little down arrow next to the bug icon (next to the play icon) and choose Spoofax Eclipse Plugin to start a new Eclipse instance that contains your changes. If it is not in the list of recently used configurations, click Debug configurations..., it should be under Eclipse Application configurations.</p> <p>Some tricks:</p> <ul> <li>If you change a (meta-)language and want to test it in a new Eclipse instance, import that language\u2019s corresponding Eclipse plugin project. For example, <code>org.metaborg.meta.lang.nabl</code> has Eclipse plugin project <code>org.metaborg.meta.lang.nabl.eclipse</code>. Then compile both those projects from the command-line (don\u2019t forget to turn off Build Automatically in Eclipse), and start a new Eclipse instance.</li> <li>A different way to test the (meta-)language change is to import that language project into the workspace of the guest Eclipse. Because we use Maven snapshot versions, the built-in version will be overridden when you build the language in the guest eclipse.</li> </ul>"},{"location":"howtos/development/develop-spoofax/#troubleshooting","title":"Troubleshooting","text":"<p>If there are many errors in a project, try updating the Maven project. Right click the project and choose Maven \u2023 Update Project..., uncheck Clean projects in the new dialog and press OK. This will update the project from the POM file, update any dependencies, and trigger a build. If this does not solve the problems, try it again but this time with Clean projects checked. Note that if you clean a language project, it has to be rebuilt from the command-line. Restarting Eclipse and repeating these steps may also help.</p> <p>Multiple projects can be updated by selecting multiple projects in the package/project explorer, or by checking projects in the update dialog.</p> <p>If you have particular trouble with <code>org.eclipse.*</code> plugins in the <code>MANIFEST.MF</code> file that do not resolve, try the following. Go to Preferences \u2023 Plug-in Development \u2023 Target Platform, most likely there will not be an active Running Platform there. You can use Add... to add a new one if there isn\u2019t one already. Select the Default option, click Next, then click Finish. Check the box next to the platform to activate it.</p>"},{"location":"howtos/development/develop-spoofax/#advanced-developing-from-scratch","title":"Advanced: Developing from Scratch","text":"<p>In some cases it can be beneficial to have full control over all projects, instead of relying on Maven artifacts and the installed Spoofax plugin. To develop completely from scratch, uninstall Spoofax from Eclipse, and import all projects by importing <code>releng/eclipse/import/pom.xml</code>, which will import all relevant projects automatically.</p> <p>If you change a language project, build them on the command-line, because languages cannot be built inside Eclipse without the Spoofax plugin.</p>"},{"location":"howtos/development/develop-spoofax/#intellij","title":"IntelliJ","text":"<p>Easiest is to install the latest release of the Spoofax plugin in an installation of IntelliJ IDEA.</p> <p>Otherwise, you may want to build it from source, and to run the built plugin inside a special sandbox-instance of IntelliJ IDEA, execute the following command:</p> <pre><code>./gradlew runIdea\n</code></pre> <p>Alternatively, in IntelliJ IDEA you can invoke the IntelliJ Plugin run/debug configuration. You can use this to run or debug the IntelliJ IDEA plugin code. However, this cannot be used to debug the JPS Spoofax build process.</p> <p>To debug the JPS Spoofax build process, you need to execute the following command:</p> <pre><code>./gradlew debugJps\n</code></pre> <p>...or invoke the IntelliJ Plugin (Debug JPS) run configuration (not debug) from IntelliJ. Then in the sandbox IntelliJ IDEA instance you enable the Debug Build Process action (Ctrl+Shift+A). Then you start a build. IntelliJ will wait for a debugger to be attached to port 5005. Attach a debugger, and the build will continue. From the Spoofax plugin\u2019s IntelliJ IDEA project, you can invoke the JPS Plugin remote debug configuration to attach the debugger.</p>"},{"location":"howtos/development/develop-spoofax/#logging","title":"Logging","text":"<p>To get debug logging in IntelliJ, locate the <code>bin/log.xml</code> file in the IntelliJ folder and add the following snippet in the <code>&lt;log4j:configuration&gt;</code> element, just above the <code>&lt;root&gt;</code> element:</p> <pre><code>&lt;category name=\"#org.metaborg\" additivity=\"true\"&gt;\n&lt;priority value=\"DEBUG\"/&gt;\n&lt;appender-ref ref=\"CONSOLE-DEBUG\"/&gt;\n&lt;appender-ref ref=\"FILE\"/&gt;\n&lt;/category&gt;\n</code></pre>"},{"location":"howtos/development/publish-spoofax/","title":"How to publish a new release of Spoofax","text":"<p>This how-to describes how to release Spoofax.</p>"},{"location":"howtos/development/publish-spoofax/#requirements","title":"Requirements","text":"<p>To release Spoofax, you must first be able to build Spoofax. Follow the Maven and Building guides first.</p> <p>To publish releases, you will need write access to the <code>spoofax-releng</code> repository, to all submodule repositories in that repository, and to this documentation repository. An account with deploy access to our artifact server is required. Ask an administrator of the Programming Languages group to get access to the repositories and artifact server.</p>"},{"location":"howtos/development/publish-spoofax/#instructions","title":"Instructions","text":"<ol> <li> <p>Prepare Maven deploy settings.</p> <ol> <li> <p>Open your <code>~/.m2/settings.xml</code> file.</p> </li> <li> <p>Add a <code>&lt;servers&gt;&lt;/servers&gt;</code> section if it does not exist.</p> </li> <li> <p>Add a server to the <code>servers</code> section with id <code>metaborg-nexus</code> that contains your username and password to our artifact server:</p> <pre><code>&lt;server&gt;\n&lt;id&gt;metaborg-nexus&lt;/id&gt;\n&lt;username&gt;myusername&lt;/username&gt;\n&lt;password&gt;mypassword&lt;/password&gt;\n&lt;/server&gt;\n</code></pre> </li> <li> <p>Optionally encrypt your password by following the Password Encryption guide.</p> </li> </ol> </li> <li> <p>Prepare the repository containing the build scripts.</p> <ol> <li> <p>Clone or re-use an existing clone of <code>spoofax-releng</code> on the <code>master</code> branch. See Cloning the source code.</p> </li> <li> <p>Update it to the latest commit with:</p> <pre><code>git pull --rebase &amp;&amp; ./b checkout -y &amp;&amp; ./b update\n</code></pre> </li> <li> <p>To enable Git pushing without having to supply a username and password via Git over HTTPS, run the following command to set the submodule remotes to SSH URLs:</p> <pre><code>./b set-remote -s\n</code></pre> </li> </ol> </li> <li> <p>Prepare the source code repository.</p> <ol> <li>Make a separate clone (or re-use an existing one if you have released Spoofax before) of the <code>spoofax-release</code> branch of <code>spoofax-releng</code>. This must be a separate clone in a different directory from the first one. See Cloning the source code.</li> </ol> Why two separate clones of <code>spoofax-releng</code>? <p>The reason for two separate clones of <code>spoofax-releng</code> is that the release script will modify the files in the repository, which could include files of the release script itself. Therefore, we make a separate clone which the release script acts upon, so that it does not interfere with itself.</p> <ol> <li> <p>If reusing an existing clone, ensure that it is checked out to <code>spoofax-release</code> with:     <pre><code>git checkout spoofax-release\n</code></pre>     ...and update it to the latest commit with:     <pre><code>git pull --rebase &amp;&amp; ./b checkout -y &amp;&amp; ./b update\n</code></pre></p> </li> <li> <p>If there are new submodules repositories, follow the steps for preparing new submodules below.</p> </li> <li> <p>To enable Git pushing without having to supply a username and password via Git over HTTPS, run the following command to set the submodule remotes to SSH URLs:</p> <pre><code>./b set-remote -s\n</code></pre> </li> </ol> </li> <li> <p>Perform the release.</p> <ol> <li> <p>Change directory into the repository cloned in step 2. For example:</p> <pre><code>cd /Users/gohla/spoofax/master/spoofax-releng\n</code></pre> </li> <li> <p>Get an absolute path to the repository cloned in step 3. For example:     <pre><code>/Users/gohla/spoofax/release/spoofax-releng\n</code></pre></p> </li> <li> <p>Determine whether the release will be patch or minor/major. For a patch release, we do not bump the development version. For a minor or major release, we do.</p> </li> <li> <p>Figure out what the current development version of Spoofax is, what the next release version should be, and if doing a non-patch release, what the next development version should be. The release script will change the current development version into the next release version, deploy that, and then change the current development version to the next development version, and commit that. Setting the next development version is optional.</p> </li> <li> <p>Execute the release script with the parameters you gathered:</p> <pre><code>./b --repo &lt;release-repository&gt; release \\\nspoofax-release &lt;release-version&gt; \\\nmaster &lt;current-development-version&gt; \\\n--non-interactive \\\n--maven-deploy \\\n--maven-deploy-identifier metaborg-nexus \\\n--maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\\n--nexus-deploy \\\n--nexus-username &lt;artifact-server-username&gt; \\\n--nexus-password &lt;artifact-server-password&gt; \\\n--nexus-repo releases\n</code></pre> <p>...or for a major version, with <code>--next-develop-version</code>:</p> <pre><code>./b --repo &lt;release-repository&gt; release \\\nspoofax-release &lt;release-version&gt; \\\nmaster &lt;current-development-version&gt; \\\n--next-develop-version &lt;next-development-version&gt; \\\n--non-interactive \\\n--maven-deploy \\\n--maven-deploy-identifier metaborg-nexus \\\n--maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\\n--nexus-deploy \\\n--nexus-username &lt;artifact-server-username&gt; \\\n--nexus-password &lt;artifact-server-password&gt; \\\n--nexus-repo releases\n</code></pre> <p>For example, if we currently are at development version <code>2.6.0-SNAPSHOT</code>, and would like to release minor version <code>2.6.0</code>, and update the development version to <code>2.7.0-SNAPSHOT</code>, we would execute the following command:</p> <pre><code>cd /Users/gohla/spoofax/master/spoofax-releng\n./b --repo /Users/gohla/spoofax/release/spoofax-releng release \\\nspoofax-release 2.6.0 \\\nmaster 2.6.0-SNAPSHOT \\\n--next-develop-version 2.7.0-SNAPSHOT \\\n--non-interactive \\\n--maven-deploy \\\n--maven-deploy-identifier metaborg-nexus \\\n--maven-deploy-url http://artifacts.metaborg.org/content/repositories/releases/ \\\n--nexus-deploy \\\n--nexus-username myusername \\\n--nexus-password mypassword \\\n--nexus-repo releases\n</code></pre> <p>Unfortunately, it is currently not possible to encrypt the artifact server password passed to the build script.</p> </li> </ol> </li> </ol>"},{"location":"howtos/development/publish-spoofax/#new-spoofax-releng-submodules","title":"New <code>spoofax-releng</code> Submodules","text":"<p>When adding a new submodule to the <code>spoofax-releng</code> repository, the following steps must be performed before starting the automated release process:</p> <ul> <li>Add a <code>spoofax-release</code> branch to the submodule (pointing to the current <code>master</code> branch), and push that branch.</li> <li>Add the submodule to the <code>.gitmodule</code> file in the <code>spoofax-release</code> branch of the <code>spoofax-releng</code> repository. Make sure that the branch of the submodule is set to <code>spoofax-release</code>, and that the remote is using an <code>https</code> URL. Commit and push this change.</li> </ul>"},{"location":"howtos/development/publish-spoofax/#updating-the-release-archive","title":"Updating the Release Archive","text":"<p>To update the release archive of this documentation site, perform the following steps after a release:</p> <ul> <li> Update include files:<ul> <li> Copy <code>include/hyperlink/download-&lt;current-release-version&gt;.rst</code> to new file <code>include/hyperlink/download-&lt;release-version&gt;.rst</code>, replace all instances of <code>&lt;current-release-version&gt;</code> in that new file with <code>&lt;release-version&gt;</code>, and update the date to the current date.</li> <li> In <code>include/hyperlink/download-rel.rst</code>, replace all instances of <code>&lt;current-release-version&gt;</code> with <code>&lt;release-version&gt;</code>.</li> <li> In <code>include/hyperlink/download-dev.rst</code>, update the development version to <code>&lt;next-development-version&gt;</code>.</li> <li> In <code>include/_all.rst</code>, add a new line to include the newly copied file: <pre><code>.. include:: /include/hyperlink/download-&lt;release-version&gt;.rst.\n</code></pre></li> </ul> </li> <li> Update <code>source/release/migrate/&lt;release-version&gt;.rst</code> (only if migrations are necessary):<ul> <li> Remove stub notice.</li> </ul> </li> <li> Update <code>source/release/note/&lt;release-version&gt;.rst</code>:<ul> <li> Remove stub notice.</li> <li> Add small summary of the release as an introduction.</li> <li> Include download links, which can be copied and have their versions replaced from a previous release.</li> </ul> </li> <li> Create new stub files for the next release:<ul> <li> Create a new migration guide stub file.</li> <li> Create a new release notes stub file.</li> </ul> </li> <li> Update <code>source/release/note/index.rst</code>:<ul> <li> Move stub for this release to the top of the notes.</li> <li> Add new stub file at the bottom of the notes.</li> </ul> </li> <li> Update <code>source/release/migrate/index.rst</code>:<ul> <li> Move stub for this release to the top of the migration guides.</li> <li> Add new stub file at the bottom of the migration guides.</li> </ul> </li> <li> Update <code>conf.py</code>:<ul> <li> Update <code>version</code> variable.</li> <li> Update <code>copyright</code>variable with new year, if needed.</li> </ul> </li> </ul>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/","title":"How to setup Maven for Spoofax development","text":"<p>Maven is a project management and build tool for software projects. Most components in Spoofax are built with Maven. This how-to will guide you to setup Maven for Spoofax 2 development.</p>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#installation","title":"Installation","text":"<p>Maven can be downloaded and installed from https://maven.apache.org/download.cgi. We require Maven 3.5.4 or newer (except Maven 3.6.1 and 3.6.2). On macOs, Maven can be easily installed with Homebrew by executing:</p> <pre><code>brew install maven\n</code></pre> <p>Confirm the installation was successful and the version is supported by running <code>mvn --version</code>.</p>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#memory-allocation","title":"Memory Allocation","text":"<p>By default, Maven does not assign a lot of memory to the JVM that it runs in, which may lead to out-of-memory exceptions during builds. To increase the allocated memory, execute before building:</p> <pre><code>export MAVEN_OPTS=\"-Xms512m -Xmx1024m -Xss16m\"\n</code></pre> <p>Such an export is not permanent. To make it permanent, add that line to <code>~/.bashrc</code> or equivalent for your OS/shell (create the file if it does not exist), which will execute it whenever a new shell is opened.</p>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#proxy-settings","title":"Proxy Settings","text":"<p>If you are behind a proxy, please put the proxy settings in your <code>~/.m2/settings.xml</code> file. When you use the <code>./b</code> script to build Spoofax, the <code>MAVEN_OPTS</code> environment variable is overridden to ensure the memory options above are supplied, so using command-line options in the environment variable for the proxy settings does not work.</p>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#spoofax-maven-artifacts","title":"Spoofax Maven Artifacts","text":"<p>Spoofax\u2019s Maven artifacts are hosted on our artifact server at artifacts.metaborg.org. To use these artifacts, repositories have to be added to your Maven configuration. This configuration is required when building and developing Spoofax. Repositories can be added to your local Maven settings file (which is recommended), or to a project\u2019s POM file.</p>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#simple-local-settings-file","title":"Simple: Local Settings File","text":"<p>The recommended approach is to add repositories to your local Maven settings file, located at <code>~/.m2/settings.xml</code>. If you have not created this file yet, or want to completely replace it, simply create it with the following content:</p> <code>~/.m2/settings.xml</code> <pre><code>&lt;?xml version=\"1.0\" ?&gt;\n&lt;settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"&gt;\n&lt;profiles&gt;\n&lt;profile&gt;\n&lt;id&gt;add-metaborg-release-repos&lt;/id&gt;\n&lt;activation&gt;\n&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;\n&lt;/activation&gt;\n&lt;repositories&gt;\n&lt;repository&gt;\n&lt;id&gt;metaborg-release-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/releases/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/repository&gt;\n&lt;/repositories&gt;\n&lt;pluginRepositories&gt;\n&lt;pluginRepository&gt;\n&lt;id&gt;metaborg-release-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/releases/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/pluginRepository&gt;\n&lt;/pluginRepositories&gt;\n&lt;/profile&gt;\n&lt;profile&gt;\n&lt;id&gt;add-metaborg-snapshot-repos&lt;/id&gt;\n&lt;activation&gt;\n&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;\n&lt;/activation&gt;\n&lt;repositories&gt;\n&lt;repository&gt;\n&lt;id&gt;metaborg-snapshot-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/snapshots/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/repository&gt;\n&lt;/repositories&gt;\n&lt;pluginRepositories&gt;\n&lt;pluginRepository&gt;\n&lt;id&gt;metaborg-snapshot-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/snapshots/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/pluginRepository&gt;\n&lt;/pluginRepositories&gt;\n&lt;/profile&gt;\n&lt;/profiles&gt;\n&lt;mirrors&gt;\n&lt;mirror&gt;\n&lt;id&gt;metaborg-central-mirror&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/central/&lt;/url&gt;\n&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n&lt;/mirror&gt;\n&lt;/mirrors&gt;\n&lt;/settings&gt;\n</code></pre> <p>If you\u2019ve already created a settings file before and want to add the repositories, just add the <code>profile</code> element (and the <code>profiles</code> element if it does not exist yet) to the settings file.</p>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#advanced-project-pom-file","title":"Advanced: Project POM File","text":"<p>Repositories can also be added directly to a project\u2019s POM file, which only set the repositories for that particular project. This is not recommended, because it makes repositories harder to change by users, and duplicates the configuration. But it can be convenient, because it does not require an external settings file.</p> <p>To do this, just add the the following content to the POM file:</p> <code>~/.m2/settings.xml</code> <pre><code>&lt;repositories&gt;\n&lt;repository&gt;\n&lt;id&gt;metaborg-release-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/releases/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/repository&gt;\n&lt;repository&gt;\n&lt;id&gt;metaborg-snapshot-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/snapshots/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/repository&gt;\n&lt;/repositories&gt;\n\n&lt;pluginRepositories&gt;\n&lt;pluginRepository&gt;\n&lt;id&gt;metaborg-release-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/releases/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/pluginRepository&gt;\n&lt;pluginRepository&gt;\n&lt;id&gt;metaborg-snapshot-repo&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/snapshots/&lt;/url&gt;\n&lt;releases&gt;\n&lt;enabled&gt;false&lt;/enabled&gt;\n&lt;/releases&gt;\n&lt;snapshots&gt;\n&lt;enabled&gt;true&lt;/enabled&gt;\n&lt;/snapshots&gt;\n&lt;/pluginRepository&gt;\n&lt;/pluginRepositories&gt;\n</code></pre>"},{"location":"howtos/development/setup-maven-for-spoofax-dev/#maven-central-repository-mirror","title":"Maven Central Repository Mirror","text":"<p>Artifacts of most open source projects are hosted in the Maven Central Repository. If you are building any project using Maven, many artifacts will be downloaded from that server. While it is a fast server, it can still take a while to download all required artifacts for big projects.</p> <p>If you are on the TU Delft network, you can use our local mirror of Maven Central to speed things up. Using the mirroring requires a change in your local <code>~/.m2/settings.xml</code> file. If this file does not exist, create it with the following content:</p> <code>~/.m2/settings.xml</code> <pre><code>&lt;?xml version=\"1.0\" ?&gt;\n&lt;settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"&gt;\n&lt;mirrors&gt;\n&lt;mirror&gt;\n&lt;id&gt;metaborg-central-mirror&lt;/id&gt;\n&lt;url&gt;https://artifacts.metaborg.org/content/repositories/central/&lt;/url&gt;\n&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n&lt;/mirror&gt;\n&lt;/mirrors&gt;\n&lt;/settings&gt;\n</code></pre> <p>If you\u2019ve already created a settings file before and want to add the mirror configuration, just add the <code>mirror</code> element (and the <code>mirrors</code> element if it does not exist yet) to the settings file.</p>"},{"location":"howtos/development/spoofax-dev-requirements/","title":"Spoofax Development Requirements","text":"<p>This how-to will instruct you which requirements you need to install to do Spoofax 2 development. Spoofax can be run on macOS, Linux, and Windows. Building is directly supported on macOS and Linux. Building on Windows is supported through the Windows Subsystem for Linux (Bash on Windows).</p> <p>The following tools are required to build and develop Spoofax:</p> Git 1.8.2 or newer <p>Required to check out the source code from our GitHub repositories. Instructions on how to install Git for your platform can be found here: https://git-scm.com/downloads.</p> <p>If you run macOs and have Homebrew installed, you can install Git by executing <code>brew install git</code>. Confirm your Git installation by executing <code>git version</code>.</p> Java JDK 8u141 or newer <p>Required to build and run Java components. The latest JDK can be downloaded and installed from: https://www.oracle.com/technetwork/java/javase/downloads/index.html. If using Java 8, 8u141 or newer is required because of issues with Let's Encrypt certificates.</p> <p>On macOS, it can be a bit tricky to use the installed JDK, because Apple by default installs JRE 6. To check which version of Java you are running, execute the <code>java -version</code> command. If this tells you that the Java version is 1.8 or newer, or Java 9 or newer, everything is fine. If not, you can either install a newer Java version through Homebrew (<code>brew install --cask adoptopenjdk8</code>), or use a JDK manager such as SDKMAN!.</p> Python 3.4 or newer <p>Python scripts are used to orchestrate the build. Instructions on how to install Python for your platform can be found here: https://www.python.org/downloads/.</p> <p>If you run macOs and have Homebrew installed, you can install Python by executing <code>brew install python3</code>. Confirm your Python installation by executing <code>python3 --version</code> or <code>python --version</code>, depending on how your package manager sets up Python.</p> <p>During a build of Spoofax, Pip will install some Python dependencies into a virtual environment. No extra Python dependencies are required for this (with one small exception, see the note below). The latest version of Pip will automatically be installed inside the virtual environment.</p> <p>Debian and derivatives (like Ubuntu) do not include the full standard library when installing Python (bug 1290847), so you will need to install <code>python3-venv</code> to ensure the virtual environment can be created.</p> Maven 3.5.4 or newer (except Maven 3.6.1 and 3.6.2) <p>Maven is required to build most components of Spoofax. Our Maven artifact server must also be registered with Maven since the build depends on artifacts from previous builds for bootstrapping purposes. We explain how to install and set up Maven in this how-to.</p> <p>Spoofax cannot be built using Maven 3.6.1 or 3.6.2 due to bugs MNG-6642 and MNG-6765.</p> Docker <p>Required on macOS Catalina, Big Sur, Monterey, and newer to be able to run the <code>sdf2table</code> and <code>implodePT</code> legacy binaries. On macOS, install it though the Docker for Mac website.</p> Coreutils <p>Required on macOS to be able to run the <code>sdf2table</code> and <code>implodePT</code> legacy binaries. On macOS with Homebrew installed, you can install them by running <code>brew install coreutils</code>.</p>"},{"location":"howtos/development/troubleshooting/","title":"Spoofax development troubleshooting","text":"<p>This page provides some troubleshooting information.</p>"},{"location":"howtos/development/troubleshooting/#developing-on-macos-catalina-and-newer","title":"Developing on macOS Catalina and newer","text":"<p>Due to some legacy 32-bit binaries (<code>sdf2table</code> and <code>implodePT</code>) that are required to build some of the Spoofax meta-languages, building on  macOS Catalina or newer (Big Sur, Monterey) requires the following additional components to be installed:</p> <ul> <li><code>coreutils</code></li> <li>Docker for Mac</li> </ul> <p>Refer to the Requirements page for more information and installation instructions. The following subsections detail some problems that can occur when developing on macOS Catalina or newer.</p>"},{"location":"howtos/development/troubleshooting/#realpath-command-not-found","title":"realpath: command not found","text":"<p>You should install <code>coreutils</code>. Refer to the Requirements page for installation instructions.</p> <p>Invoke the following command to test it (it should return the full path to the current directory):</p> <pre><code>realpath -s .\n</code></pre>"},{"location":"howtos/development/troubleshooting/#mounts-denied-the-path-is-not-shared-the-host-and-is-not-known-to-docker","title":"Mounts denied: The path is not shared the host and is not known to Docker","text":"<pre><code>Error response from daemon: Mounts denied:\nThe path /var/folders/a_/foo0000bar/T/vfs_cache-345/tmp_123_macosx/sdf2table-macosx\nis not shared from the host and is not known to Docker.\n</code></pre> <p>Ensure the root of the path (<code>/var/folders</code> in this example) is shared in Docker for Mac. Go to Docker for Mac Preferences \u2023 Resources \u2023 File Sharing and add the path to the list. The default list should contain:</p> <ul> <li><code>/Users</code></li> <li><code>/Volumes</code></li> <li><code>/private</code></li> <li><code>/tmp</code></li> <li><code>/var/folders</code></li> </ul>"},{"location":"howtos/development/troubleshooting/#invalid-mount-config-for-type-bind-bind-source-path-does-not-exist","title":"invalid mount config for type \"bind\": bind source path does not exist","text":"<pre><code>Error response from daemon: invalid mount config for type \"bind\":\nbind source path does not exist:\n/var/folders/a_/foo0000bar/T/vfs_cache-345/tmp_123_macosx\n</code></pre> <p>Ensure that both Docker and the terminal from which you are invoking the build have full-disk access. Go to macOS Preferences \u2023 Security and Privacy \u2023 Full Disk Access and check the checkboxes next to Docker and your terminal (Terminal and/or iTerm).</p>"},{"location":"howtos/editor-services/rename-refactoring/","title":"Add Rename Refactoring to an Existing Project","text":"<p>Rename Refactoring is the ability for the user to select a reference or declaration and rename it to across the whole program while not introducing errors and not touching syntactically equal names.</p>"},{"location":"howtos/editor-services/rename-refactoring/#renaming-in-statix","title":"Renaming in Statix","text":"<p>To enable the Rename Refactoring for an existing Spoofax Language project that uses Statix, create an action that calls the <code>rename-action</code> strategy from the <code>statixruntime</code> library. The parameters are explained in the reference. For example:</p> <pre><code>module renaming\n\nimports\nstatixruntime\nstatix/runtime/renaming\n\npp\nanalysis\n\nrules\nrename-menu-action = rename-action(construct-textual-change,\neditor-analyze, id)\n</code></pre>"},{"location":"howtos/editor-services/rename-refactoring/#renaming-in-nabl2","title":"Renaming in NaBL2","text":"<p>There also exists a version of the Rename refactoring that works with languages using NaBL2. It can be added with a Stratego module like this:</p> <pre><code>module renaming\n\nimports\nnabl2/runtime\n\npp\nanalysis\n\nrules\nrename-menu-action = nabl2-rename-action(construct-textual-change,\neditor-analyze, id)\n</code></pre>"},{"location":"howtos/editor-services/rename-refactoring/#menu-action","title":"Menu Action","text":"<p>The rename refactoring is triggered from an entry in the Spoofax menu. To add it to an existing project a menu like the following can be implemented in an ESV file:</p> <pre><code>module Refactoring\n\nmenus\nmenu: \"Refactoring\"\naction: \"Rename\" = rename-menu-action\n</code></pre>"},{"location":"howtos/editor-services/rename-refactoring/#see-also","title":"See Also","text":"<ul> <li>Reference: Rename Refactoring</li> </ul>"},{"location":"howtos/installation/install-eclipse-bundle/","title":"Install the Eclipse with Spoofax Plugin Bundle","text":"<p>Install an Eclipse instance with the latest stable release of the Spoofax plugin pre-installed for your platform:</p> Eclipse with JRE (recommended) <p>Eclipse bundle including the Spoofax plugin with embedded Java Runtime Environment (JRE) (recommended):</p> <p>+ macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit)</p> Eclipse <p>Eclipse bundle including the Spoofax plugin (no embedded JRE):</p> <p>macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit)</p> <p>Development releases.</p>"},{"location":"howtos/installation/install-eclipse-bundle/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howtos/installation/install-eclipse-bundle/#macos-eclipse-cannot-be-opened-because-the-developer-could-not-be-verified","title":"macOS: \"Eclipse\" cannot be opened because the developer could not be verified","text":"<p>macOS puts unverified binaries in 'quarantine' and disallows their execution. To remove the <code>com.apple.quarantine</code> attribute, do:</p> <pre><code>xattr -rc Eclipse.app\n</code></pre>"},{"location":"howtos/installation/install-eclipse-bundle/#eclipse-does-not-start-or-complains-about-missing-java","title":"Eclipse does not start, or complains about missing Java","text":"<p>Download the Eclipse bundle with embedded JRE. Otherwise, ensure you have a distribution of Java installed. Then in <code>eclipse.ini</code>, add a <code>-vm</code> line at the top of the file, followed by the path to the Java installation. For example, with SDKMan! on macOS:</p> <pre><code>-vm\n/Users/myusername/.sdkman/candidates/java/current/jre/lib/jli/libjli.dylib\n</code></pre>"},{"location":"howtos/installation/install-eclipse-plugin-manually/","title":"Install the Spoofax Eclipse Plugin Manually","text":"<p>Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer.</p> <ol> <li>In Eclipse, go to menu Help \u2192 Install New Software.</li> <li> <p>In the Work with: text area, type:</p> <pre><code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.18/org.metaborg.spoofax.eclipse.updatesite-2.5.18-assembly.zip-unzip/\n</code></pre> <p>(Development releases).</p> </li> <li> <p>Uncheck Group items by category to make the plugin visible.</p> </li> <li>Check Spoofax Eclipse meta-tooling, Spoofax Eclipse meta-tooling M2E integration and Spoofax Eclipse runtime.</li> <li>Click Install and go through the remaining steps.</li> <li>Restart Eclipse.</li> </ol>"},{"location":"howtos/installation/install-from-source/","title":"Install Spoofax from Source","text":"<p>Perform a manual build and installation of cutting-edge Spoofax from source, by first cloning the Git repository:</p> HTTPS <pre><code>git clone https://github.com/metaborg/spoofax-releng.git\n</code></pre> SSH <pre><code>git clone git@github.com:metaborg/spoofax-releng.git\n</code></pre> GitHub CLI <pre><code>gh repo clone metaborg/spoofax-releng\n</code></pre> <p>Then:</p> <ol> <li>Using a terminal, navigate to the root of the <code>spoofax-releng</code> repository.</li> <li> <p>(Optional.) Generate a new Maven <code>~/.m2/settings.xml</code> with the Spoofax repository information.</p> <pre><code>./b gen-mvn-settings\n</code></pre> <p>This will overwrite your existing <code>~/.m2/settings.xml</code> file!</p> </li> <li> <p>Invoke the following command to build Spoofax and its submodules and meta-languages:</p> <pre><code>./b build all\n</code></pre> </li> <li> <p>(Optional.) Generate a new Eclipse instance with the Spoofax plugin embedded into it:</p> <pre><code>./b gen-eclipse --destination Spoofax.app\n</code></pre> </li> </ol>"},{"location":"howtos/statix/debugging/","title":"Debugging","text":"<p>This section describes several techniques that can be used to debug your Statix specification if it does not work as you expect.</p> <p>Important</p> <p>The single most useful thing you can do when debugging is to make the problem as small as possible! All the techniques you can use for debugging are more effective when the problem is as small as possible. Try to find the smallest example program and Statix specification that still exhibits your problem, and focus on those.</p> <p>There are three main categories of problems you may encounter:</p> <ol> <li>Errors reported in your Statix files. These may come from syntax errors,    unresolved names for modules or predicates, type errors, or problems with    illegal scope extension. When these errors are unexpected and not mentioned    in Some Common Problems, follow the steps in    Basic Checklist and    Creating Minimal Examples. If that does not    help out, please follow the steps in    Getting Help and Reporting Issues.</li> <li>Unexpected behavior when running Statix on files of your language. This is    the most common kind of problems. All debugging techniques after the    Basic Checklist are focused on finding and debugging    problems in the definitions in your specification. Note that it is useless to    try to solve problems of this kind when your specification still has errors!</li> <li>Analysis fails altogether. This usually results in Analysis failed errors    at the top of files or on the project in the Package Explorer. Check the    Console and Error Log for reported Java exceptions that can be included    in a bug report.</li> </ol>"},{"location":"howtos/statix/debugging/#basic-checklist","title":"Basic Checklist","text":"<p>These are some basic things that should always be checked when you encounter a problem:</p> <ul> <li>See if the disappears after a clean build (run <code>Project &gt; Clean...</code> and then   <code>Project &gt; Build Project</code> on your project). If the problem disappears after a   clean build, but then consistently reappears after subsequent editing or   building, it should be reported as a potential bug.</li> <li>Are there errors on any Statix files? The behavior of running Statix on your   language files is undefined when the specification itself has errors. Check   the Package Explorer as well as the Problems and Console views to make   sure none of the Statix files have errors on them. Fix such errors before   debugging any other issues!</li> <li>Check for errors in the Package Explorer and in open editors, as well as in   the Console, Problems, and Error Log views.</li> <li>See whether the section on Some Common Problems or   the remainder of the documentation answers your question already.</li> </ul>"},{"location":"howtos/statix/debugging/#checking-ast-traversal","title":"Checking AST Traversal","text":"<p>Ensure that your Statix rules are applied to the AST nodes. It is easy to forget to apply a predicate to a subterm, especially for bigger languages. If you are not sure if the rules are applied to a certain AST node, add a forced note (e.g. <code>try { false } | note \"text\"</code>) to that AST node as follows:</p> <pre><code>extendsOk(s_lex, Extends(m), s_mod) :- {s_mod'}\ntry { false } | note \"extendsOK applied\",\nresolveMod(s_lex, m) == s_mod',\ns_mod -EXT-&gt; s_mod'.\n</code></pre> <p>Build your project and check if the note appears where you expect it. If it does not appear, find the places where those AST nodes may appear and ensure the predicate is applied.</p>"},{"location":"howtos/statix/debugging/#checking-reference-resolution","title":"Checking Reference Resolution","text":"<p>Setting ref attributes on references allows you to check reference resolution interactively in example programs of your language. The following rule shows how to do that using <code>@x.ref := x'</code>:</p> <pre><code>resolveVar(s, x) = T :- {x'}\nquery typeOfDecl\nfilter P* and { x' :- x' == x }\nmin $ &lt; P and true\nin s |-&gt; [(_, (x', T))],\n@x.ref := x'.\n</code></pre> <p>This requires that <code>x</code> and <code>x'</code> are both names from the AST. Now write some example programs and check if references resolve to the definitions you expect, by Ctrl+Click / Cmd+Right Click on the reference.</p> <p>Note that <code>statix/References</code> must be included in one of your ESV files for this to work. This is by default the case for generated projects that use Statix.</p>"},{"location":"howtos/statix/debugging/#interpreting-error-messages","title":"Interpreting Error Messages","text":"<p>Statix can be configured to contain a trace as part of the error messages for failing constraints, which can be a great help for debugging. Two parameters control message formatting. The first, <code>message-trace-length</code> controls whether a trace is included in the message, and how long it will be. A value of <code>0</code> means no trace (if no custom message is provided, the failing constraint itself is still shown), <code>-1</code> means the full trace. The default is set to <code>0</code>, as showing traces is mostly helpful for debugging when writing the spec and it slows down message formatting. The second, <code>message-term-depth</code> controls the depth up to which terms in messages are formatted. A value of <code>-1</code> means full terms. The default is set to <code>3</code>, which is usually enough to understand the terms involved, without choking up Eclipse or the console with large error messages. It is not recommended to set both settings to <code>-1</code>, because then every message will contain the full AST.</p> <p>The configuration settings are part of the <code>metaborg.yaml</code> file of the project containing the language files (not the project containing the specification!), and look as follows:</p> <pre><code>runtime:\nstatix:\nmessage-trace-length: 5 # default: 0, full trace: -1\nmessage-term-depth: 3 # -1 = max\n</code></pre> <p>A typical error message including a trace may look as follows:</p> <pre><code>  [(?q.unit-wld61-10,(?q.unit-x'-11,?q.unit-T-5))] == []\n&gt; query filter ((Label(\"units/name-resolution/interface!EXT\"))* Label(\"units/name-resolution/default-impl!var\")) and { (?x',_) :- ?x' == \"q\" } min irrefl trans anti-sym { &lt;edge&gt;Label(\"units/name-resolution/default-impl!var\") &lt; &lt;edge&gt;Label(\"units/name-resolution/interface!EXT\"); } and { _, _ :- true } in #p.unit-s_mod_4-4 |-&gt; [(?q.unit-wld61-10,(?q.unit-x'-11,?q.unit-T-5))]\n&gt; units/name-resolution/interface!resolveVar(#q.unit-s_mod_2-4, QDefRef(QModInModRef(ModRef(\"P\"),\"B\"),\"q\"),?q.unit-T-5)\n&gt; units/statics!typeOfExpr(#q.unit-s_mod_2-4, VarRef(QDefRef(QModInModRef(ModRef(\u2026),\"B\"),\"q\")), ?q.unit-T-5)\n&gt; units/statics!defOk(#q.unit-s_mod_2-4, VarDef(\"e\",VarRef(QDefRef(QModInModRef(\u2026,\u2026),\"q\"))), #q.unit-s_mod_2-4)\n&gt; ... trace truncated ...\n</code></pre> <p>As this looks daunting at first, we break it down. At the top is the constraint that failed; in this case an equality constraint. Below that are several lines prefixed with <code>&gt;</code> that show where the constraint above it originated. We see that the equality originated from a <code>query</code>, which itself originated from one of the rules of <code>resolveVar</code>, which was applied in one of the rules of <code>typeOfExpr</code> etc. As these traces can get very long, they are truncated to five entries.</p> <p>Now we explain some more details of what we can see here:</p> <ul> <li>Errors may contain unification variables of the form <code>?FILENAME-VARNAME-NUM</code>   or <code>?VARNAME-NUM</code>. These are instantiations of the meta-variables in the   specification. The variable name <code>VARNAME</code> corresponds to the name of the   meta-variable that was instantiated, and can be helpful in reasoning about the   origin of a unification variable. When the name corresponds to a functional   predicate name, it is a return value from that predicate. The file name is the   file that was being checked when the unification variable was created. Due to   Statix's operation, this can sometimes be the project root instead of the actual file.</li> <li>Scope values are shown as <code>#FILENAME-VARNAME-NUM</code> or <code>#VARNAME-NUM</code>. (Rarely   they appear in the exploded form <code>Scope(\"FILENAME\", \"VARNAME-NUM\")</code>).</li> <li>Predicate names are prefixed with the name of the module they are defined in.   For example, <code>defOk</code> is defined in <code>units/statics</code> and therefore appears as   <code>units/statics!defOk</code> in the trace. Note that the predicate name is prefixed   with the Statix module that defines the predicate. (The rules for the   predicate may be defined in other modules.)</li> <li>The trace shows which predicates were applied, and to which arguments. It does   not show which predicate rule was chosen! This can often be deduced from the   line above it in the trace, but if unsure, use a forced note (see   Inspecting Variables) to check your expectation.</li> <li>Error messages are fully instantiated with the final result. This means that   variables that appear in error messages are free in the final result of this   Statix execution. Therefore, we do not have to consider the order of   execution or the moment when the error message was generated when interpreting   error messages!</li> </ul> <p>Since Spoofax 2.5.17, error messages for unsolved constraints will additionally display information on why they are delayed, and which critical edges these constraints prevented to be closed. Examples of such messages are:</p> <p><pre><code>(unsolved) statics/modules/imports!declareImportedValues(#p.unit-imps_42-8, ?p.unit-imp-49) delayed on vars {?p.unit-imp-49} preventing completion of { #p.unit-imps_42-8: {&lt;edge&gt;Label(\"statics/names/relations!value\"): 1} }\n</code></pre> and <pre><code>(unsolved) query filter ((Label(\"statics/main!EXT\"))* Label(\"statics/names/relations!value\")) and { (?x',_) :- ?x' == \"q\" } min irrefl trans anti-sym { &lt;edge&gt;Label(\"statics/names/relations!value\") &lt; &lt;edge&gt;Label(\"statics/main!EXT\"); } and { _, _ :- true } in #p.unit-imps_42-8 |-&gt; [(?q.unit-wld61-10,(?q.unit-x'-11,?q.unit-T-5))] delayed on critial edges { #p.unit-imps_42-8-&lt;edge&gt;Label(\"statics/names/relations!value\") }\n</code></pre></p> <p>In this first message, the <code>delayed on vars {?p.unit-imp-49}</code> fragment indicates that progress on this constraint could be made when <code>?p.unit-imp-49</code> would be refined to a particular value. Because the unfolding of this constraint migth create declarations for the <code>value</code> relation in <code>#p.unit-imps_42-8</code>, the tail of the message indicates that edge cannot be closed, and hence queries over such an edge cannot proceed. The second message is delayed precisely because that edge cannot be closed. This is indicated by the <code>delayed on critial edges { #p.unit-imps_42-8-&lt;edge&gt;Label(\"statics/names/relations!value\") }</code> part of the second message.</p> <p>In such cases, the way to proceed is trying to rewrite the specification in such a way the constraint that prevents the critical edge from being closed can make progress. When it turnes out that this constraint is dependent on the result of a query that is delayed on that edge, there is a 'cyclic dependency' on these constraint. Statix cannot handle those, and therefore a redesign of the name binding model is required. If there is a constraint that is delayed on a critical edge, but no constraint preventing that edge from being closed is displayed, this should be reported as an error.</p> <p>Tip</p> <p>The section on Common Problems contains tips on how to deal with many error messages.</p>"},{"location":"howtos/statix/debugging/#inspecting-variables","title":"Inspecting Variables","text":"<p>Inspecting the values assigned to meta-variables can be very helpful to debug a specification. Variables cannot be automatically inspected, but we can show their values by forcing a note in the rule where the variable appears. The following rule shows how to do this for the intermediate type <code>T</code> of the assigned variable:</p> <pre><code>stmtOk(s, Assign(x, e)) :- {T U}\nT == resolveVar(s, x),\ntry { false } | note $[assignee has type [T]],\nU == typeOfExp(s, e),\nsubtype(U, T).\n</code></pre>"},{"location":"howtos/statix/debugging/#inspecting-the-scope-graph","title":"Inspecting the Scope Graph","text":"<p>Inspecting the scope graph that is constructed by Statix can be very helpful in debugging problems with scoping and name resolution queries. After type checking, view the scope graph of a file using the <code>Spoofax &gt; Statix &gt; Show scope graph</code> menu. Note that in multi-file mode, the scope graph is always the graph of the whole project. Therefore, creating a small example project with only a few files can be very helpful (see also Creating Minimal Examples).</p> <p>Here is an example of such a scope graph:</p> <pre><code>scope graph\n  #q.unit-s_mod_2-4 {\n    relations {\n      units/name-resolution/default-impl!var : (\"e\", UNIT())\n    }\n    edges {\n      units/name-resolution/interface!LEX : #s_1-1\n    }\n  }\n  #p.unit-s_mod_4-4 {\n    relations {\n      units/name-resolution/default-impl!var : (\"b\", UNIT())\n    }\n    edges {\n      units/name-resolution/interface!LEX : #p.unit-s_mod_2-6\n    }\n  }\n  #p.unit-s_mod_2-6 {\n    relations {\n      units/name-resolution/default-impl!mod : (\"B\", #p.unit-s_mod_4-4)\n    }\n    edges {\n      units/name-resolution/interface!LEX : #s_1-1\n    }\n  }\n  #s_1-1 {\n    relations {\n      units/name-resolution/default-impl!mod : (\"E\", #q.unit-s_mod_2-4)\n                                               (\"P\", #p.unit-s_mod_2-6)\n    }\n  }\n</code></pre> <p>The scope graph is presented as a list of scopes, with the relation entries and outgoing edges from that scope. Remember that the names of the scopes match the names of the meta-variables in the specification! For example, <code>#p.unit-s_mod_4-4</code> originated from a meta-variable <code>s_mod</code>. Paying attention to this is very helpful in figuring out the structure of the graph.</p> <p>Some useful questions you can ask yourself when inspecting the scope graph for debugging:</p> <ul> <li>Does the graph have the structure I expect from the current example program?   Are all the scopes that I expect there, and are all the scopes that are there   expected? Do all scopes have the expected relations in them? Do the have the   expected outgoing edges?</li> <li>When you are debugging a certain query, consider the scope in which the query   starts, and execute the query in the given graph. Are the necessary edges   present? Does the regular expression allow those edges to be traversed? Are   you querying the correct relation, and is the filter predicate correct for the   data you want to match?</li> </ul> <p>When considering these questions, it can be helpful to use the ideas from Inspecting Variables to verify the scope a query is executed in, or to show the scope that is created for a definition, and match those with what you see in the scope graph.</p>"},{"location":"howtos/statix/debugging/#testing-predicates","title":"Testing Predicates","text":"<p>Sometimes creating a minimal example program in your language is not enough to fix a problem. In such cases writing Statix tests is a great way to test your definitions in even more detail. In a Statix test you can specify a constraint and evaluate it to see how it behaves. For example, if you suspect a bug in the definition of the <code>subtype</code> predicate, you could test it as follows:</p> <pre><code>// file: debug.stxtest\nresolve {T}\nT == typeOfExp(Int(\"42\")),\nsubtype(T, LONG())\nimports\nstatics\n</code></pre> <p>The <code>.stxtest</code> file starts with <code>resolve</code> and a constraint, which can be anything that can appear in a rule body. After that, the test may specify <code>imports</code>, <code>signature</code> and <code>rules</code> sections like a regular Statix module. A test is executed using the <code>Spoofax &gt; Evaluate &gt; Evaluate Test</code> menu. Evaluation outputs a <code>.stxresult</code> file, which looks as follows:</p> <pre><code>substitution\n  T |-&gt; INT()\n\nanalysis\n  scope graph\n\nerrors\n  *   INT() == LONG()\n    &gt; statics!subtype(INT(), LONG())\n    &gt; ... trace truncated ...\n\nwarnings\n\nnotes\n</code></pre> <p>The test result shows the value of top-level variables from the <code>resolve</code> block (in this case <code>T</code>), the scope graph that was constructed (in this case empty), and any messages that were generated (in this case one error).</p> <p>These tests are a great way to verify that the predicate definitions work as you expect. Apply your predicates to different arguments to check their behavior. Even more complicated mechanisms such as queries can be debugged this way. Simply construct a scope graph in the <code>resolve</code> block (using <code>new</code>, edges, and declarations), and execute your querying predicate on the scopes you have created. As a starting point, you can take the AST of your example program (using the <code>Spoofax &gt; Syntax &gt; Show parse AST</code> menu), and use that as an argument to your  top-level predicate.</p> <p>Creating a self-contained Statix test is a good way to isolate a problem. Instead of importing all your definitions, copy the relevant definitions to the test (in a <code>rules</code> section), and try to create the smallest set of rules and predicate arguments that still exhibit the problem you are debugging. A self-contained test is also very helpful when asking others for help, as it is much easier to review and run than having to setup and build a complete language project.</p>"},{"location":"howtos/statix/debugging/#creating-minimal-examples","title":"Creating Minimal Examples","text":"<p>Creating a minimal example is one of the most useful things you can do when debugging. It helps you to get to the core of the problem, but it also benefits all of the other techniques we have discussed so far. Having a smaller example makes it easier to inspect the scope graph, makes it easier to inspect variables as there are fewer, and reduced the number of error messages to review.</p> <p>An example is a file, or a set of files, in your language, where Statix does not behave as you expect. A minimal example is usually created by starting from a big example that exhibits the problem. Try to eliminate files and simplify the example program while keeping the unexpected behavior. The smaller the program and the fewer rules in your specification are used for this program, the easier it is to debug.</p>"},{"location":"howtos/statix/debugging/#creating-self-containted-tests-from-examples","title":"Creating Self-Containted Tests from Examples","text":"<p>While a small example in an example language is already helpful to debug Statix issues, a self-contained Statix test file is even more useful. The recommended approach to create a self-contained Statix test from an example is as follows:</p> <ol> <li>Create a test with all ASTs from the example</li> <li>Manually unfold user-defined constraints in the test.</li> <li>Copy imported definitions in the test file.</li> </ol> <p>These steps will now be discussed in more detail below</p> <p>First, create a Statix test file that mimics the example literally. Assuming that <code>AST ?</code> are placeholders for real ASTs (which can be obtained using the <code>Spoofax &gt; Analysis &gt; Show Pre-Analysis AST</code> menu option), such test files roughly look as follows:</p> <p><pre><code>resolve {s}\nnew s,\nprojectOk(s),\nfileOk(s, &lt;AST 1&gt;),\nfileOk(s, &lt;AST 2&gt;),\n...\nfileOk(s, &lt;AST N&gt;)\n\nimports\n\nmylang/base\n</code></pre> Before going on, first check whether this test still exhibits the issue at hand.</p> <p>Second, simplify this test by manually reducing its size. This step consists of repeated application of the following substeps:</p> <ol> <li>Discard irrelevant constraints</li> <li>Inline constraints</li> <li>Manually apply rules</li> </ol> <p>Constraints that do not have to do with the issue can sometimes be removed completely. A common example is the <code>projectOk</code> constraint, but also declaration name uniqueness checks and such can often just be omitted.</p> <p>In the second substep we try to reduce the number of constraint by simplification. Examples of simplification include inlining unification with variables (e.g. replacing <code>{T} T == INT(), subtype(T, T)</code> with <code>subtype(INT(), INT())</code>), or solving deterministic queries (e.g. replacing <code>!var[\"x\", INT()] in s, query var ... in s |-&gt; [(_, (_, T))]</code> with <code>T == INT()</code>).</p> <p>The third substep entails choosing the correct rule for a user-defined constraint, and replacing the user-defined constraint with the properly applied body. For example, when the specification constains a rule <code>fileOk(s, File(imp, decls)):- importsOk(s, imp), declsOk(decls)</code>, the <code>fileOk(s, &lt;AST 1&gt;)</code> constraint in the test above can be replaced with <code>importsOk(s, &lt;IMPs 1&gt;),declsOk(s, &lt;DECLS 1&gt;)</code>. Be aware to properly introduce new names for variables from the rule head. Additionally, it is required to update the imported modules when new user-defined constraints are introduced by application.</p> <p>Warning</p> <p>At each step, execute your test to verify whether it still exposes the issue. When it does not, you have either discarded a relevant constraint, or made a mistake when simplifying.</p> <p>Try to apply these steps exhaustively, until only built-in constraints remain.</p> <p>Now that we have a minimal test case, the third step is to make it self-contained by removing imports. This just involved copying the relevant constraint declarations and rules in a <code>rules</code> section in the test, and removing the import.</p>"},{"location":"howtos/statix/debugging/#some-common-problems","title":"Some Common Problems","text":"<p>1. Predicates fail with <code>amb(...)</code> terms as arguments. These terms indicate parsing ambiguities, which should be fixed in the grammar (SDF3) files.</p> <p>2. Errors in your specification appear at incorrect places (e.g. sort or constructor declarations). In such cases, the declaration is referenced from an invalid position anywhere in your specification, but due to the non-deterministic order of constraint solving the error appears at the observed position. The best approach to solve these issues is to comment away all usages, until the error disappears. Then, in the last commented position, the declaration is used incorrectly.</p> <p>3. One or both of the <code>programOk(...)</code> (for single-file analysis), <code>fileOk(...)</code>  or <code>projectOk(...)</code> (for multi-file analysis) predicates fail immediately, for example  with the error messages:</p> <pre><code>statics!fileOk(#s_1-1,Test([Prog(\"A.mod\",Decls(\u2026)),Prog(\"B.mod\",Decls(\u2026)),Prog(\"C.mod\",Decls(\u2026))])) (no origin information)\nstatics!projectOk(#s_1-1) (no origin information)\n</code></pre> <p>In such cases, you have probably renamed the top-level file, or moved the declarations of these predicates to another file that is imported. Assuming the predicates are now defined in the module <code>statics/mylang</code> as follows:</p> <pre><code>// file: trans/statics/mylang.stx\nmodule statics/mylang\nimports statics/mylang/program\n\nrules\n\n  projectOk : scope\n  projectOk(s).\n\n  fileOk : scope * Start\n  fileOk(s, p) :- programOk(s, p).\n</code></pre> <p>If this module is the top-level module of your specification, then you have to change the call to <code>stx-editor-analyze</code> in <code>trans/analysis.str</code> such that the first term argument (which specifies the module to use, by default <code>\"statics\"</code>) is the new module name (in this case <code>statics/mylang</code>).</p> <p>On the other hand, if you kept <code>statics</code> as the top-level module and have it import the module <code>statics/mylang</code>, then you have to change the call to <code>stx-editor-analyze</code> in <code>trans/analysis.str</code> such that the second and third term argument (which specify the predicates to apply to projects and files, respectively) are qualified by the module name (in this case <code>\"statics/mylang!projectOk\"</code> and <code>\"statics/mylang!fileOk\"</code>, respectively).</p> <p>4. Files of your language are only analyzed by Statix after they are opened in an editor in Eclipse. There are several reasons why this may be hapening:</p> <ul> <li> <p>The project containing the files is not a Spoofax project. A spoofax project   must contain a <code>metaborg.yaml</code>. If it is a Maven project, the <code>packaging</code> must   be one of <code>spoofax-{language,test,project}</code>.</p> </li> <li> <p>The project containing the files does not have a dependency on your language.   Spoofax only analyzes files of your language if the <code>metaborg.yaml</code> configuration   contains a <code>compile</code> dependency on the language definition. This should look   similar to the following:</p> </li> </ul> <pre><code>  dependencies:\ncompile:\n- org.example:your-language:1.0.0-SNAPSHOT\n</code></pre> <ul> <li> <p>The language is missing. If a language dependency is missing, this is reported   with errors on the console. Make sure your language definition project is open   in Eclipse and that is is successfully built.</p> </li> <li> <p>Eclipse is not configured to automatically build files. This can be enabled by   selecting Project \u2023 Build automatically from the Eclipse menu.</p> </li> <li> <p>The project in Eclipse did not get the Spoofax nature. Imported Maven projects   with one of the <code>spoofax-*</code> packagings normally get the Spoofax nature   automatically, but sometimes this doesn't work correctly. Non-Maven projects   always have to be assigned the Spoofax nature manually. This can be done with   Spoofax \u2023 Add Spoofax nature in the context-menu of the project   containing the files.</p> </li> </ul> <p>5. A lot of errors are reported. It happens that a single problem in the type checked program leads to the failure of other constraints (cascading errors). For example, an unresolved name might lead to errors about subtype checks that cannot be solved, import edges that cannot be created, etc. Here are some tips to help you find the root cause of the probem:</p> <ul> <li> <p>Differentiate between failed and unsolved constraints. The cause of a problem   is usually found best by looking at the failed constraints. For example, an   unresolved name might result in an error on the equality constraint between   the expected and actual query result. Errors on unsolved constraints are marked   as Unsolved. Unsolved errors are often the result of uninstantiated logical variables.   </p><p>Predicates remain unsolved if the uninstantiated variable prevents the selection   of an applicable rule for the predicate. For example, an unsolved error   <code>subtype(INT(), ?T-1)</code> is caused by the free variable <code>?T-1</code> which prevents   selecting the appropriate rule of the <code>subtype</code> predicate.   </p><p>Queries remain unsolved if the query scope is not instantiated, or if variables   used in the matching predicate (such as the name to resolve) remained free.   For example, an unsolved error <code>query filter (e Label(\"typeOfDecl\")) and   { (?x',_) :- ?x' == ?x-5 } min irrefl trans anti-sym { &lt;edge&gt;Label(\"typeOfDecl\")   &lt; &lt;edge&gt;Label(\"P\"); } and { _, _ :- true } in ?s-3 |-&gt; [(?wld0-1,(?x'-2,?T-4))]</code>   cannot be resolved because the scope variable <code>?s-3</code> is free, and the free   variable <code>?x-5</code> would prevent matching declarations. Use of the variables <code>?x'-2</code>   and <code>?T-4</code> might cause more unsolved constraints, since these also remain   free when the query cannot be solved.   </p><p>Edge and declaration assertions remain unsolved if the scopes are not instantiated.   For example, the edge assertion <code>#s_2-1 -Label(\"P\")-&gt; ?s'-5</code> cannot be solved   because the variable for the target scope <code>?s'-5</code> is not instantiated. Unsolved   edge constraints in particular can lead to lots of cascading errors, as they   block all queries going through the source scope of the edge.</p> </li> <li> <p>If it is not immediately clear which error is the root of a problem, it helps   to figure out the free variable dependencies between reported errors. Consider   the following small example of three reported errors:</p> <ul> <li><code>subtype(?T-5, LONG)</code></li> <li><code>#s_3-1 -Label(\"P\")-&gt; ?s'-6</code></li> <li><code>query filter ((Label(\"P\"))* Label(\"typeOfDecl\")) and { (?x',_) :- ?x' == \"v\" } min irrefl trans anti-sym { &lt;edge&gt;Label(\"typeOfDecl\") &lt; &lt;edge&gt;Label(\"P\"); } and { _, _ :- true } in #s_3-1 |-&gt; [(?wld4-1,(?x'-2,?T-5))]</code> <p>For each of these we can see which variables are necessary for the   constraint to be solved, and which they might instantiate when solved. The   <code>subtype</code> predicate is blocked on the variable <code>?T-5</code>. The edge assertion is   blocked on the scope variable <code>?s'-6</code>. The query does not seem blocked on a   variable (both the scope and the filter predicate are instantiated), but would   instantiate the variables <code>?x'-2</code> and <code>?T-5</code> when solved.   </p><p>We can conclude that the <code>subtype</code> constraint depends on solving the   query, so we focus our attention on the query. Now we realize that we query in   the scope of the unsolved edge assertion. So, the query depends on the edge   assertion, and our task is to figure out why the scope variable in the edge   target is not instantiated.   </p><ul> </ul> </li> </ul> <p>Info</p> <p>Since Spoofax 2.5.17, many cascading errors should not be displayed anymore. If you encounter a message that is clearly a cascading error from another constraint, and not part of a cycle of unsolved constraints, consider reporting this as a bug.</p> <p>Also, the delays and unclosed critical edges should be displayed explicitly on the message of unsolved constraints. This helps figuring out dependencies between failed constraints.</p> <p>6. Constraint solving does not terminate. This is caused by infinite recursion in a user-defined constraint. Three common causes of this problem are.</p> <p>First, the specification contains recursive predicates, such as <code>rule(x, T) :- /* ... */, rule(x, T), /* ... */.</code>. As can be trivially seen, the solver will simplify <code>rule(x, T)</code> infinitely many times.</p> <p>Second, the specification contains a rule that creates a declaration, queries it, and then calls itself on the query result. If the result contains the declaration made by the rule, it will instantiate itself infinitely. An example of such a specification is:</p> <pre><code>declareTVar(s, x, T) :- {Tvs}\n!tvar[x, T] in s,\nquery tvar /* */ in s |-&gt; Tvs,\ndeclareTVars(s, Tvs).\n</code></pre> <p>Often, this pattern is not easily observable, since the recursion may be indirect, and the declarations, queries and recursive calls are specified in different rules.</p> <p>Info</p> <p>This pattern often occurs in incorrect specifications for parametric types with lazy substitution.</p> <p>Third, for a user-defined constraint on a existential variable, optimistic rule selection can cause infinite generation and refinement of new, unconstrained variables. Consider for example the following specification:</p> <pre><code>rules\nruleWithoutBaseCase: list(int)\nruleWithoutBaseCase([x|xs]) :- ruleWithoutBaseCase(xs).\n</code></pre> <p>Although the recursive call seems to be on a strictly smaller term (namely, the tail of the list), infinite recursion can still happen when this rule is instantiated with a free variable, such as in this constraint:</p> <pre><code>{x} ruleWithoutBaseCase(x), x == [].\n</code></pre> <p>While this constraint should fail, it can be that the solver decides to simplify <code>ruleWithoutBaseCase(x)</code> first. Due to optimistic rule selection, it will refine <code>x</code> to <code>[x1 | xs]</code>, and simplify to <code>ruleWithoutBaseCase(xs)</code>. When later the constraint <code>x == []</code> is solved, it will simply fail. But since <code>xs</code> is free, the sequence of simplifying <code>ruleWithoutBaseCase</code> on a free variable repeats indefinitely.</p> <p>The Statix normalization often introduces new existential variables. Therefore it might not be completely obvious that a specification is susceptible to this behavior. Consider for example the following specification:</p> <pre><code>rules\nruleWithoutBaseCase: list(int)\nruleWithoutBaseCase([x|xs]) :- ruleWithoutBaseCase(xs).\n\nnil: -&gt; list(int)\nnil() = [].\n\ntest:\ntest() :- ruleWithoutBaseCase(nil()).\n</code></pre> <p>Although this specification does not seem to have existential variables, its normalized equivalent (see below), actually does.</p> <pre><code>rules\nruleWithoutBaseCase: list(int)\nruleWithoutBaseCase([x|xs]) :- ruleWithoutBaseCase(xs).\n\nnil: list(int)\nnil([]).\n\ntest:\ntest() :- {nil1} ruleWithoutBaseCase(nil1), nil(nil1).\n</code></pre> <p>Now, it can be seen that the normalized <code>test</code> rule is again susceptile to this type of infinite recursion.</p> <p>In order to debug non-terminating specifications, first add base cases like <code>rule(_, _, ..) :- false</code> for all user-defined constraints that do not yet have those. This prevents recursion by optimistic rule selection. Potential errors that pop up now demonstrate which rule was incorrectly selected optimistically. If that does not work out, the other techniques in this section should be applied to isolate the recursion.</p>"},{"location":"howtos/statix/debugging/#getting-help-and-reporting-issues","title":"Getting Help and Reporting Issues","text":"<p>If the techniques above did not help to solve your problem, you can ask us for help or report the issue you found. To make this process as smooth as possible, we ask you to follow the following template when asking a Statix related question:</p> <ol> <li>Single sentence description of the issue.</li> <li>Spoofax version. See About Eclipse; Installation Details; Features, and    search for Spoofax.</li> <li>Statix configuration: single-file or multi-file mode. Multi-file mode is    enabled when the <code>observer</code> setting in in your ESV looks like <code>observer:    editor-analyze (constraint) (multifile)</code>.</li> <li>Steps to reproduce. Best is to include a small, self-contained test (see    Testing Predicates above) so that others can easily    run the test and reproduce the issue! If that is not possible, provide a    (link to) a project, including an example file, that shows the problem. Keep    the project and the example as small as possible, and be specific about the    relevant parts of your program and of your specification.</li> <li>Description of the observed behavior. Also mention if the problem occurs    consistently, or only sometimes? If only sometimes, does it occur always/never    after a clean build, or does it occur always/never after editing and/or    building without cleaning?</li> <li>Description of the expected behavior.</li> <li>Extra information that you think is relevant to the problem. For example,    things you have tried already, pointers to the part of the rules you think    are relevant to the problem etc. If you tried other examples that show some    light on the issue, this is a good place to put those. Again, it is best if    these also come as self-contained tests!</li> </ol> <p>An example bug report described using the format above:</p> <pre><code>Issue:\nSpoofax version: 2.6.0.20210208-173259-master\nStatix setup: multi-file\n\nSteps to reproduce:\nExecute the test in `example1.stxtest`.\n\nObserved behavior:\nSometimes an error is reported that the `query` failed.\nThe problem does not occur consistently. On some runs, the error appears, but\nnot on others. This does not seem related to cleaning or building the project.\n\nExpected behavior:\nThe test is executed and no errors are reported. Scope `s1` is reachable from\n`s2`, so the query return a single result, and `ps != []` should therefore hold.\n\n\nExtra information:\nThe test in `example2.stxtest` is very similar. The only difference is that the\npredicate `nonempty` has an extra rule for the empty list. The predicate is\nsemantically the same, as the extra rule fails, just as the general rule would\ndo on the empty list. However, this example never gives the unexpected error.\n</code></pre> <p>The bug report is accompanied by two self-contained tests. One illustrates the problem, while the other shows a very similar variant that does not exhibit the problem.</p> <pre><code>// example1.stxtest\nresolve {s1 s2}\nnew s1, new s2, s2 -I-&gt; s1,\nreachable(s1, s2)\n\nsignature\nname-resolution\nlabels\nI\n\nrules\n\nreachable : scope * scope\nreachable(s1, s2) :- {ps}\nquery () filter I*\n             and { s1' :- s1' == s1 }\nmin and true\nin s2 |-&gt; ps,\nnonempty(ps).\n\nnonempty : list((path * scope))\nnonempty(ps) :- ps != [].\n</code></pre> <pre><code>// example2.stxtest\nresolve {s1 s2}\nnew s1, new s2, s2 -I-&gt; s1,\nreachable(s1, s2)\n\nsignature\nname-resolution\nlabels\nI\n\nrules\n\nreachable : scope * scope\nreachable(s1, s2) :- {ps}\nquery () filter I*\n             and { s1' :- s1' == s1 }\nmin and true\nin s2 |-&gt; ps,\nnonempty(ps).\n\nnonempty : list((path * scope))\nnonempty(ps) :- ps != [].\nnonempty([]) :- false.\n</code></pre>"},{"location":"howtos/statix/migrating-from-nabl2/","title":"Migrate to Statix from NaBL2","text":""},{"location":"howtos/statix/migrating-from-nabl2/#signature","title":"Signature","text":"<p>All sorts and constructors must be explicitly defined in Statix in <code>sorts</code> and <code>constructors</code> signatures. Sorts in Statix are mostly similar to terms in NaBL2. Notable differences:</p> <ul> <li>There is no catch-all sort <code>term</code> in Statix.</li> <li>There are no sort variables in Statix.</li> <li>List sorts in Statix are written as <code>list(X)</code> for some sort <code>X</code>.</li> </ul> <p>Statix signatures for language syntax can be generated from SDF3 definitions with the signature generator.</p>"},{"location":"howtos/statix/migrating-from-nabl2/#name-resolution","title":"Name-resolution","text":"<p>Name resolution in NaBL2 heavily relies on occurrences and their unique identity. In Statix, the notion of a stand-alone reference is replaced by the notion of a query. Therefore, the use of occurrences is now discouraged in favour of regular terms, relations, and and predicates for the different namespaces.</p> <pre><code>signature\n\nnamespaces\nVar\n\nname resolution\nlabels P\nwell-formedness P*\n    order D &lt; P\n\nrules\n\n[[ Def(x, T) ^ (s) ]] :=\nVar{x} &lt;- s,\nVar{x} : T.\n\n[[ Var(x) ^ (s) : T ]] :=\nVar{x} -&gt; s,\nVar{x} |-&gt; d,\nd : T.\n</code></pre> <pre><code>signature\n\nrelations\nvar : string * TYPE\n\nname-resolution\nlabels P\n\nrules\n\ndeclareVar : scope * string * TYPE\n\ndeclareVar(s, x, T) :-\n!var[x, T] in s.\n\nresolveVar : scope * string -&gt; TYPE\n\nresolveVar(s, x) = T :-\n{x'}\nquery var\nfilter P* and { x' :- x' == x}\nmin $ &lt; P and true\nin s |-&gt; [(_, (x, T))],\n@x.ref := x'.\n\nrules\n\nstmtOk : scope * Stmt\n\nstmtOk(s, Def(x, T)) :-\ndeclareVar(s, x, T);\n\ntypeOfExp : scope * Exp -&gt; TYPE\n\ntypeOfExp(s, Var(x)) = T :-\nT == resolveVar(s, x).\n</code></pre> <p>Things to note:</p> <ul> <li>Each namespace gets its own relation, and set of predicates to   declare and resolve in that namespace (<code>declareXXX</code> and   <code>resolveXXX</code>).</li> <li>The regular expression and order on labels is not global anymore,   but part of the query in the <code>resolveXXX</code> rules.</li> <li>If a declaration should have a type associated with it, it is now   part of the relation. The fact that it appears after the arrow   <code>-&gt;</code> indicates that each declaration has a single type.  As a   result, <code>declareXXX</code> combines the constraints <code>XXX{...} &lt;- s,   XXX{...} : T</code>. Similarly, <code>resolveXXX</code> combines the constraints   <code>XXX{...} -&gt; s, XXX{...} |-&gt; d, d : T</code>.</li> <li>The end-of-path label, called <code>D</code> in NaBL2, now has a special   symbol <code>$</code>, instead of the reserved name.</li> </ul>"},{"location":"howtos/statix/migrating-from-nabl2/#functions","title":"Functions","text":"<p>NaBL2 functions can be translated to Statix predicates in a straight-forward manner. Note that if the function was used overloaded,it is necessary to defined different predicates for the different argument types.</p> <pre><code>signature\n\nfunctions\n\nplusType : (Type * Type) -&gt; Type {\n(IntTy()  , IntTy()  ) -&gt; IntTy(),\n(StrTy()  , _        ) -&gt; StrTy(),\n(ListTy(a), a        ) -&gt; ListTy(a),\n(ListTy(a), ListTy(a)) -&gt; ListTy(a)\n}\n</code></pre> <pre><code>plusType : Type * Type -&gt; Type\n\nplusType(IntTy()  , IntTy()  ) = IntTy().\nplusType(StrTy()  , _        ) = StrTy().\nplusType(ListTy(a), a        ) = ListTy(a).\nplusType(ListTy(a), ListTy(a)) = ListTy(a).\n</code></pre>"},{"location":"howtos/statix/migrating-from-nabl2/#relations","title":"Relations","text":"<p>Relations as they exist in NaBL2 are not supported in Statix.</p> <p>An example of a subtyping relation in NaBl2 would translate as follows:</p> <pre><code>signature\n\n  relations\n    reflexive, transitive, anti-symmetric sub : Type * Type {\n      FunT(-sub, +sub),\n      ListT(+sub)\n    }\n\nrules\n\n  [[ Class(x, superX, _) ^ (s) ]] :=\n    ... more constraints ...,\n    ClassT(x) &lt;sub! ClassT(superX).\n\n  [[ Def(x, T, e) ^ (s) ]] :=\n    [[ e ^ (s) : T' ]],\n    T1 &lt;sub? T2.\n</code></pre> <pre><code>rules\n\nsubType : TYPE * TYPE\n\nsubType(FunT(T1, T2), FunT(U1, U2)) :-\nsubType(U1, T1),\nsubType(T2, T1).\n\nsubType(ListT(T), ListT(U)) :-\nsubType(T, U).\n\nsubType(ClassT(s1), ClassT(s2)) :-\n... check connectivity of s1 and s2 in the scope graph ...\n</code></pre> <p>In this case implementing the <code>subType</code> rule for <code>ClassT</code> requires changing the encoding of class types. Instead of using names, we use the class scope to identify the class type. This pattern is know as Scopes as Types. Subtyping between class scopes can be checked by checking if one scope is reachable from the other.</p>"},{"location":"howtos/statix/migrating-from-nabl2/#rules","title":"Rules","text":"<p>NaBL2 constraint generation rules must be translated to Statix predicates and corresponding rules. Predicates in Statix are explcitly typed, and a predicate has to be defined for each sort for which constraint generation rules are defined.</p> <p>Here are some example rules for expressions in NaBL2:</p> <pre><code>[[ Let(binds, body) ^ (s) : T ]] :=\nnew s_let, s_let -P-&gt; s,\nMap1[[ binds ^ (s, s_let) ]],\n[[ body ^ (s_let) : T ]].\n\n[[ Bind(x, e) ^ (s, s_let) ]] :-\n[[ e ^ (s) : T ]],\nVar{x} &lt;- s_let,\nVar{x} : T.\n</code></pre> <p>In Statix these would be encoded as:</p> <pre><code>typeOfExp : scope * Exp -&gt; TYPE\n\ntypeOfExp(s, e@Let(binds, body)) = T :- {s_let}\nnew s_let, s_let -P-&gt; s,\nbindsOk(s, binds, s_let),\nT == typeOfExp(s_let, body),\n@e.type := T.\n\n\nbindOk : scope * Bind * scope\nbindsOk maps bindOk(*, list(*))\n\nbindOk(s, Bind(x, e), s_let) :- {T}\nT == typeOfExp(s, e),\ndeclareVar(s_let, x, T).\n</code></pre>"},{"location":"howtos/statix/migrating-to-concurrent-solver/","title":"Migrating to the Concurrent Solver","text":"<p>In this how-to guide, we explain what changes should be made to enable the concurrent solver for a Statix project.</p>"},{"location":"howtos/statix/migrating-to-concurrent-solver/#enabling-the-concurrent-solver-for-a-language","title":"Enabling the Concurrent solver for a Language","text":"<p>To enable the concurrent solver for a language, set the <code>language.statix.concurrent</code> property in the <code>metaborg.yaml</code> file to <code>true</code>. This ensures that the concurrent solver is used for all sources in the language.</p> <pre><code>id: org.example:mylang:0.1.0-SNAPSHOT\nname: mylang\nlanguage:\nstatix:\nmode: concurrent\n</code></pre>"},{"location":"howtos/statix/migrating-to-concurrent-solver/#enabling-the-concurrent-solver-for-an-example-project-only","title":"Enabling the Concurrent solver for an Example Project only","text":"<p>To enable the concurrent solver for a particular project only, set the <code>runtime.statix.modes</code> property in the <code>metaborg.yaml</code> file to a map that contains all names of the languages for which you want to use the concurrent solver, and their corresponding modes. The name of the language should correspond to the <code>name</code> property in the <code>metaborg.yaml</code> of the language definition project.</p> <pre><code>id: org.example:mylang.example:0.1.0-SNAPSHOT\nruntime:\nstatix:\nmodes:\n- mylang: concurrent\n</code></pre>"},{"location":"howtos/statix/migrating-to-concurrent-solver/#indirect-type-declaration","title":"Indirect Type Declaration","text":"<p>Type checking with the concurrent solver might result in deadlock when type-checkers have mutual dependencies on their declarations. This problem can be solved by adding an intermediate declaration that splits the part of the declaration data that is filtered on (usually the declaration name), and the part that is processed further by the querying unit (usually the type). This pattern is best explained with an example:</p> <pre><code>signature\nrelations\ntype : ID -&gt; TYPE\n\nrules\ndeclareType : scope * ID * TYPE\nresolveType : scope * ID -&gt; TYPE\n\ndeclareType(s, x, T) :-\n!type[x, T] in s.\n\nresolveType(s, x) = T :-\nquery type\nfilter P* I* and { x' :- x' == x }\nin s |-&gt; [(_, (_, T))].\n</code></pre> <p>This specification needs to be changed in the following:</p> <pre><code>signature\nrelations\ntype   : ID -&gt; scope\ntypeOf : TYPE\n\nrules\ndeclareType : scope * ID * TYPE\nresolveType : scope * ID -&gt; TYPE\n\ndeclareType(s, x, T) :-\n!type[x, withType(T)] in s.\n\nresolveType(s, x) = typeOf(T) :-\nquery type\nfilter P* I* and { x' :- x' == x }\nin s |-&gt; [(_, (_, T))].\n\nrules\nwithType : TYPE -&gt; scope\ntypeOf   : scope -&gt; TYPE\n\nwithType(T) = s :-\nnew s, !typeOf[T] in s.\n\ntypeOf(s) = T :-\nquery typeOf filter e in s |-&gt; [(_, T)].\n</code></pre> <p>We now discuss the changes one-by-one. First, the signature of relation <code>type</code> is be changed to <code>ID -&gt; scope</code>. In this scope, we store the type using the newly introduced <code>typeOf</code> relation. This relation only carries a single <code>TYPE</code> term. In this way, the original term is still indirectly present in the outer declaration.</p> <p>The <code>withType</code> and <code>typeOf</code> rules allow to convert between these representations. The <code>withType</code> rule creates a scope with a <code>typeOf</code> declaration that contains the type.  In the adapted <code>declareType</code> rule, this constraint is used to convert the <code>T</code> argument to the representation that the <code>type</code> relation accepts. Likewise, the <code>typeOf</code> rule queries the <code>typeOf</code> declaration to extract the type from a scope. This rule is used in the <code>resolveType</code> rule to convert back to the term representation of a type.</p> <p>Performing this change should resolve potential deadlocks when executing your specifications. Because the signatures of the rules in the original specification did not change, and the new specification should have identical semantics, the remainder of the specification should not be affected.</p>"},{"location":"howtos/statix/migrating-to-concurrent-solver/#using-grouping","title":"Using Grouping","text":"<p>The traditional solver uses two special constraints as entry points: the project constraint (usually named <code>projectOk</code>) was solved once for each project, while the file constraint (usually called <code>fileOk</code>) was solved for each file in that project. The concurrent solver adds the concepts of groups in between these concepts. Files can be organized in groups, while groups can in addition contain subgroups. This gives rise to a tree-shaped hierarchy, where the project is the root node, the files are the leaf nodes, and all nodes in between are groups. Most often, this hierarchy follows the directory structure of a project. In order to use grouping, two steps need to be performed.</p> <p>First, a group constraint must be defined. The group constraint must have the signature <code>scope * string * scope</code>. For each group, this constraint will be instantiated with the parent group scope, group name and own group scope as arguments (in that order).</p> <p>A simple example of a group constraint can look as follows:</p> <pre><code>signature\n\nsorts MODULE constructors\nMODULE: scope -&gt; MODULE\n\nrelations\nmod: string * MODULE\n\nrules\n\ngroupOk: scope * string * scope\ngroupOk(s_prnt, name, s_grp) :-\n!mod[name, MODULE(s_grp)] in s_prnt.\n</code></pre> <p>In this fragment, we define the <code>groupOk</code> constraint, which has the appropriate signature. The body of the rule for this constraint simply declares that a module with the appropriate name exists in the parent scope.</p> <p>Second, the builder needs to be adapted in two ways: the name of the group constraint must be passed to the solver, and a strategy that determines the group of a file must be provided to the solver. Such a strategy should have type <code>(String * AST) -&gt; List(String)</code>. The input arguments represent the file path and its AST, respectively. The output list should contain all group identifiers from project root to the respective file. For example, a Java specification should return <code>[\"java\", \"lang\", \"Object\"]</code> for the <code>Object</code> class in the <code>java.lang</code> package. Note that the file must be assigned a name, and that that name should be included in the output list.</p> <p>A project that uses the directory structure as its grouping structure could call the <code>stx-editor-analyze</code> as follows:</p> <pre><code>rules\n\neditor-analyze = stx-editor-analyze(pre-analyze,group-key,post-analyze|\"statics\", \"projectOk\", \"groupOk\", \"fileOk\")\n\ngroup-key: (resource, ast) -&gt; key\nwith rel-path := &lt;current-language-relative-source-or-include-path&gt; resource\n; key := &lt;string-tokenize&gt; (['/','\\'], rel-path)\n</code></pre> <p>In this snippet, the <code>\"groupOk\"</code> argument between the file and project constraint names points to our newly defined group constraint. The <code>group-key</code> strategy, passed between the pre and post transformation strategies, is the strategy that performs the grouping. It first makes the path relative to the project root, and then splits it on each <code>'/'</code> or <code>'\\'</code> character.</p>"},{"location":"howtos/statix/migrating-to-concurrent-solver/#using-libraries","title":"Using Libraries","text":"<p>Secondly, the concurrent solver allows to export the scope graph of a project in a library. These libraries can be linked with other projects, potentially decreasing analysis times significantly. Statix libraries can be generated and linked by following three steps.</p> <p>As a first step, use the Spoofax \u2023 Statix \u2023 Make project library menu on a file in your library project to export its scope graph. A <code>project.stxlib</code> file will now appear in the root directory of that project.</p> <p>Project Scope Configuration</p> <p>Currently, the project scope in the <code>project.stxlib</code> file must still be configured manually. Some understanding of the Statix library format is helpful for that. The signature for Statix libraries looks roughly as follows:</p> <pre><code>sorts Library constructors\nLibrary : list(Scope) * list(Scope) * ScopeGraph -&gt; Library\n\nsorts ScopeGraph constructors\nScopeGraph: list((Scope * Datum? * list(Edge))) -&gt; ScopeGraph\n</code></pre> <p>The top-level <code>Library</code> term contains (in this order): the list of shared scopes, the list of all scopes of the library, and the actual scope graph. A scope graph consists of scope entries, which are defined as three-tuples of: scope, datum associated to that scope, and the list of outgoing edges for that scope.</p> <p>In order to configure the root scopes correctly, perform the following steps:</p> <ol> <li>Identify the project scope. Names of the project scope are:    <code>Scope(\"/.\", \"s_prj-0\")</code> for project scopes generated by the concurrent solver,    and <code>Scope(\"\", \"s_1-1\")</code> for project scopes generated by the traditional solver.</li> <li>Add the project scope to the list of shared scopes in the exported library.    Instead of <code>Library([], ...)</code>, this term should now look like <code>Library([Scope(\"/.\", \"s_prj-0\")], ...)</code>.</li> <li>If it is present, remove the project root scope from the second list    in the <code>Library</code> term.</li> <li>Remove the datum on the project scope. To do this, find the project scope    entry in the scope graph, and change its second argument from <code>Some(...)</code>    to <code>None()</code>. The entry should now roughly look like <code>(Scope(\"/.\", \"s_prj-0\"), None(), [...])</code>.</li> </ol> <p>The second step is to copy this file in the <code>lib/</code> directory of the project that will use the library. Additionally, you might rename the file to something more descriptive (e.g. <code>stdlib</code>), but ensure that the <code>.stxlib</code> extension is preserved.</p> <p>Thirdly, the library must be enabled. To enable the library, create a <code>lib/stxlibs</code> file (no extension) that contains a list of enabled library names. Continuing our previous example, the content of that file would be <code>[\"stdlib\"]</code>.</p> <p>Project-level Declarations</p> <p>When the project constraint asserts declarations, these will be duplicated, because the project constraint is solved both when analyzing the library and when analyzing the project using the library. As a general principle, project constraints should not make declarations. Instead, libraries are meant as a replacement for the project constraint to declare built-in types.</p> Multiple Libraries <p>Using multiple libraries is supported by adding multple <code>*.stxlib</code> files in the <code>lib/</code> directory, and having multiple entries in the <code>stxlibs</code> file. An example of such a file could look like <code>[\"lib1\", \"lib2\"]</code>. Note however that libraries will not link properly when different exports are used, due to the fact that scope identities are not deterministic.</p>"},{"location":"howtos/statix/migrating-to-concurrent-solver/#incremental-solver","title":"Incremental Solver","text":"<p>Thirdly, there is experimental support for incremental analysis. To enable this, the following options for the <code>mode</code>/<code>modes</code> settings are available:</p> <ul> <li>In language projects: <code>incremental-scope-graph-diff</code>.</li> <li>In example projects: <code>incremental-deadlock</code> or <code>incremental-scope-graph-diff</code>.</li> </ul>"},{"location":"howtos/statix/signature-generator/","title":"Use the Statix Signature Generator","text":"<p>It is quite cumbersome to write Statix signatures. Thankfully, the <code>sdf3.ext.statix</code> project can generate these signatures for you.</p>"},{"location":"howtos/statix/signature-generator/#well-formed-sdf3-requirements","title":"Well-Formed SDF3 Requirements","text":"<p>For the generator to work correctly, your SDF3 must be well formed. In particular, you must:</p> <ul> <li>explicitly declare each sort exactly once in your project</li> <li>declare lexical sorts in a <code>lexical sorts</code> block</li> <li>declare context-free sorts in a <code>context-free sorts</code> block</li> <li>for every use of a sort: either have a local declaration of a sort, or an import of a file that declares the sort</li> <li>not declare sorts that are not used in any rules</li> <li>not use any implicitly declared sorts</li> <li>not use complex injections, such as <code>Pair = Expr Expr</code>. However, list injections without terminal syntax, such as <code>List = Elem*</code>, are allowed.</li> <li>constructors must start with an upper-case letter</li> <li>not use <code>sdf2table: c</code></li> </ul> <p>The generator generates strategies and signatures for each explicit declaration of a sort in SDF3, which is why each sort must be declared exactly once. SDF3 does not generate Stratego signatures for placeholders for sorts that have no corresponding rules, causing errors in the generated Statix injection explication strategies. Complex injections are not supported across Spoofax. Optional sorts cannot be represented in Statix.</p>"},{"location":"howtos/statix/signature-generator/#applying-the-generator-in-spoofax-2","title":"Applying the Generator in Spoofax 2","text":"<p>In your language project's <code>metaborg.yaml</code> file, change your compile dependencies to include <code>org.metaborg:sdf3.ext.statix</code>. For example:</p> <pre><code>   dependencies:\ncompile:\n- org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion}\n- org.metaborg:sdf3.ext.statix:${metaborgVersion}\n</code></pre> <p>Clean the project and restart Eclipse when changing the <code>metaborg.yaml</code> file.</p> <p>Once you clean your project, the extension automatically generates the following:</p> <ul> <li>Statix signatures declarations (in <code>src-gen/statix/signatures/</code>)</li> <li>Stratego strategies for explicating and removing injections (in <code>src-gen/injections/</code>)</li> </ul>"},{"location":"howtos/statix/signature-generator/#using-the-generated-injection-strategies","title":"Using the Generated Injection strategies","text":"<p>The generator generates strategies for explicating and removing injections. This is unfortunately needed since Statix does not support injections directly. To use these strategies, import <code>injections/-</code> and call the <code>explicate-injections-MyLang-Start</code> and <code>implicate-injections-MyLang-Start</code> strategies for the analysis pre-processing and post-processing respectively, where <code>MyLang</code> is the name of your language and <code>Start</code> is your language's start symbol (as specified in <code>Syntax.esv</code>). For example, in <code>trans/analysis.str</code>:</p> <pre><code>module analysis\n\nimports\n\nlibspoofax/sdf/pp\n\nstatixruntime\nstatix/api\n\ninjections/-\nlibspoofax/term/origin\n\nrules\n\neditor-analyze = stx-editor-analyze(pre-analyze, post-analyze|\"static-semantics\", \"programOk\")\npre-analyze  = origin-track-forced(explicate-injections-MyLang-Start)\npost-analyze = origin-track-forced(implicate-injections-MyLang-Start)\n</code></pre>"},{"location":"howtos/statix/signature-generator/#using-the-generated-signatures","title":"Using the Generated Signatures","text":"<p>Using the generated Statix signatures is quite simple: just import them into your Statix specification. Each SDF3 file gets an associated Statix file with the signatures. For example, if your syntax is defined across two files named <code>MyLang.sdf3</code> and <code>Common.sdf3</code>, then in Statix you should add the following imports:</p> <pre><code>imports\nsignatures/MyLang-sig\nsignatures/Common-sig\n</code></pre> <p>Because Statix does not support injections, you have to use explicit constructor names for injections. For example, the following SDF3 syntax:</p> <pre><code>context-free sorts\nStmt VarName\n\nlexical sorts\nID\n\ncontext-free syntax\nStmt.VarDecl = &lt;var &lt;VarName&gt;;&gt;\nVarName.Wildcard = &lt;_&gt;\nVarName = ID\n\nlexical syntax\nID = [a-zA-Z] [a-zA-Z0-9\\_]* lexical restrictions\nID -/- [a-zA-Z0-9\\_]\n</code></pre> <p>would approximately produce the following signatures:</p> <pre><code>module signatures/Test-sig\n\nimports\n\nsignature\nsorts\nStmt\nVarName\nID = string\nconstructors\nStmt-Plhdr : Stmt\nVarName-Plhdr : VarName\n\nsignature\nconstructors\nVarDecl : VarName -&gt; Stmt\nWildcard : VarName\nID2VarName : ID -&gt; VarName\n</code></pre> <p>Now, in Statix if you just want to capture the term of sort <code>VarName</code> in the <code>VarDecl</code> constructor, this would suffice:</p> <pre><code>VarDecl(x)\n</code></pre> <p>But if you want to match the term only if it has the sort <code>ID</code>, then you have to use the explicit injection constructor name <code>ID2VarName</code>:</p> <pre><code>VarDecl(ID2VarName(x))\n</code></pre> <p>In this example, <code>ID</code> is a lexical sort, so it is an alias for <code>string</code> in the Statix specification.</p>"},{"location":"howtos/statix/signature-generator/#excluding-modules","title":"Excluding Modules","text":"<p>If an SDF3 module's name ends with <code>_StrategoMix</code>, its generated signatures are generated as <code>.txt</code> files, effectively rendering them inert. This can be used, as the name suggests, to avoid generating signatures for modules that provide Stratego mix syntax for the current language.</p> <pre><code>module test_StrategoMix\n\n// ...\n</code></pre> <p>Debug menu</p> <p>The SDF3 debug menu entries in Spoofax, Statix Integration still generate files with the actual language's extension. This is to aid in debugging. However, there will be a comment at the top of the file indicating that (and why) the file was skipped.</p>"},{"location":"howtos/statix/signature-generator/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howtos/statix/signature-generator/#calls-non-existing","title":"Calls non-existing","text":"<p>Build fails with errors such as this:</p> <pre><code>[ strj | error ] *** (\"is-MyLang-MySort-or-inj\",0,0) calls non-existing (\"is-MyLang-ID-or-inj\",0,0)\n[ strj | error ] *** (\"explicate-injections-MyLang-MySort\",0,0) calls non-existing (\"explicate-injections-MyLang-ID\",0,0)\n[ strj | error ] *** (\"implicate-injections-MyLang-MySort\",0,0) calls non-existing (\"implicate-injections-MyLang-ID\",0,0)\nExecuting strj failed: {}\nFailing builder was required by \"Generate sources\".\nBUILD FAILED\n</code></pre> <p>To solve this, ensure you have declared <code>ID</code> (in this example) as a <code>lexical sort</code> in your syntax, and make sure that the syntax file with rules for <code>MySort</code> that reference <code>ID</code> import the syntax file that declares <code>ID</code>.</p>"},{"location":"howtos/statix/signature-generator/#transformation-failed-unexpectedly","title":"Transformation failed unexpectedly","text":"<p>Clean or build fails with an error such as this:</p> <pre><code>ERROR: Optional sorts are not supported by Statix: Opt(Sort(\"MySort\"))\nTransformation failed unexpectedly for eclipse:///mylang/syntax/mysyntax.sdf3\norg.metaborg.core.transform.TransformException: Invoking Stratego strategy generate-statix failed at term:\n  CfSignature(\"MySort\", Some(\"MyCons\"), [ Param(Opt(Sort(\"MySort\")), \"mySort\") ])\nStratego trace:\n  generate_statix_0_0\n  generate_statix_abstract_0_0\n  geninj_generate_statix_0_0\n  geninj_module_to_sig_0_0\n  with_1_1\n  flatfilter_1_0\n  filter_1_0\n  with_1_1 &lt;==\n  map_1_0\n  geninj_symbol_to_stxsig_0_0\nInternal error: 'with' clause failed unexpectedly in 'geninj-sig-to-stxsig'\n</code></pre> <p>Note the first line with <code>ERROR</code>, it tells you that something is not supported. In this case, the use of optional sorts such as <code>MySort?</code> is not supported by Statix and the Statix signature generator.</p> <p>To solve this, rewrite a syntax rule with an optional sort such as:</p> <pre><code>Stmt.VarDecl    = &lt;&lt;Type?&gt; &lt;ID&gt; = &lt;Exp&gt;&gt;\n</code></pre> <p>Into a rule with an explicit sort:</p> <pre><code>Stmt.VarDecl    = &lt;&lt;Type-OPT&gt; &lt;ID&gt; = &lt;Exp&gt;&gt;\nType-OPT.NoType = &lt;&gt;\nType-OPT        = Type\n</code></pre> <p>Note that the <code>-OPT</code> suffix has no special meaning. You can name the sort differently, such as <code>OptionalType</code>.</p>"},{"location":"howtos/statix/signature-generator/#constructor-mysort-plhdr0-not-declared","title":"Constructor MySort-Plhdr/0 not declared","text":"<p>Build fails with an error such as this:</p> <pre><code>[ strj | error ] in rule explicate-injections-MyLang-MySort(0|0): constructor MySort-Plhdr/0 not declared\n-     MySort-Plhdr()\nExecuting strj failed: {}\nBUILD FAILED\n</code></pre> <p>You have declared a sort for which you don't have any syntax rules. Remove the sort from the <code>context-free sorts</code> or <code>sorts</code> block.</p>"},{"location":"howtos/statix/signature-generator/#no-pp-entry-found-cannot-rewrite-to-box","title":"No pp entry found, cannot rewrite to box","text":"<p>Clean fails with an error such as this:</p> <pre><code>[ identity crisis | error ] No pp entry found for: (1,[\"declSortLex\"])\n- [ identity crisis | error ] Cannot rewrite to box: \n-         declSortLex(\"MySort\")\n</code></pre> <p>You are using the old <code>sdf2table: c</code>. Change this in <code>metaborg.yaml</code> into <code>sdf2table: java</code>.</p>"},{"location":"howtos/statix/signature-generator/#spt-analysis-tests-calling-stratego-strategies-fail","title":"SPT analysis tests calling Stratego strategies fail","text":"<p>An SPT test can run an arbitrary Stratego strategy on an analyzed AST and compare the results with the expected AST. If the origin of the is not tracked properly, the root constructor of the resulting analyzed AST will be missing and the comparison will fail.</p> <p>To fix this, ensure the <code>pre-analyze</code> and <code>post-analyze</code> strategies in <code>analysis.str</code> call <code>origin-track-forced</code>:</p> <pre><code>imports libspoofax/term/origin\n\nrules\npre-analyze  = origin-track-forced(explicate-injections-MyLang-Start)\npost-analyze = origin-track-forced(implicate-injections-MyLang-Start)\n</code></pre>"},{"location":"howtos/statix/signature-generator/#signatures-are-not-generated","title":"Signatures are not generated","text":"<p>Ensure the module name does not end with <code>_StrategoMix</code>, as such files are skipped.</p>"},{"location":"howtos/stratego/concrete-syntax/","title":"Concrete Syntax","text":"<p>When writing language-to-language transformations in Stratego, it is possible to use different approaches, for example, writing AST-to-AST transformations. However, to write such transformations, the language engineer needs to know the constructors of both languages. Moreover, AST nodes in rules that define such transformations may contain many nested children, making the work of writing such rules cumbersome and error-prone. Note that Stratego only statically checks the name and arity of constructors, thus, errors would only be detected when pretty-printing the generated AST to the target language.</p> <p>As an example of this approach, the rule below specifies a transformation of a Calc program to a Java program.</p> <pre><code>program-to-java :\nProgram(stats) -&gt; CompilationUnit(None()\n, []\n, [ ClassDeclaration(\n[Public()]\n, Id(\"Program\")\n, None()\n, None()\n, None()\n, [ MethodDecl(\n[Public(), Static()]\n, MethodHeader(\njava-type\n, Id(\"eval\")\n, NoParams()\n, []\n, None()\n)\n, Block(\n[ java-stats*\n                                                ]\n)\n)\n]\n)\n]\n)\nwith\njava-type   := ...\n      java-stats* := ...\n</code></pre> <p>An alternative approach consists of using string interpolation. Instead of generating abstract terms of the target language, transformations generate source code directly, interpolating strings with boilerplate code of the target language and variables defined in the transformation itself. The problem with this approach is that syntax errors in the string fragments of the target language are not detected statically.</p> <p>Consider the rule shown previously, rewritten below using string interpolation (the code between $[ and ]). Note that if the fragment would contain a typo, the syntax error would only be detected after the code had been generated. Note also that one can interpolate Stratego variables with the fragment of the target language by escaping them between [ and ].</p> <pre><code>program-to-java :\nProgram(stats) -&gt; $[public class Program {\npublic static [java-type] eval() {\n[java-stats]\n}\n}\n]\nwith\njava-type   := ...\n      java-stats  := ...\n</code></pre> <p>The third option is to use concrete syntax. When using concrete syntax, the transformation is still AST-to-AST but the AST of the target language is abstracted over using the concrete syntax of the language instead. That is, the concrete syntax fragment is parsed internally producing an AST, and that AST is resulted from the transformation.</p> <p>The same rule defined using concrete syntax is shown below. Note that any syntax error in the fragment would in fact, be detected by the editor, as the fragment is being parsed internally. Moreover, the fragment also has the syntax highlighting of the target language when shown by the editor.</p> <pre><code>program-to-java :\nProgram(stats) -&gt; compilation-unit\n|[ public class Program {\npublic static ~type:java-type eval() {\n~bstm*:java-stats*\n                           }\n}\n]|\nwith\njava-type   := ...\n    java-stats* := ...\n</code></pre> <p>There are two aspects to consider when enabling concrete syntax inside Spoofax. The first one is being able to write Stratego transformations with fragments of a target (or source) language. In other words, the first aspect consists of generating a mixed parse table that embeds the desired target language inside Stratego. The second aspect consists of including the parse table inside an Spoofax project, adding an additional .meta file to then enable concrete syntax for a specific Stratego file. Below, we describe both aspects with more detail.</p>"},{"location":"howtos/stratego/concrete-syntax/#mixing-grammars","title":"Mixing Grammars","text":"<p>To generate a mixed parse table that embeds a language inside Stratego, it is necessary to modify the original Stratego grammar, extending it with the desired language. One problem that may occur when combining the grammars of two different languages is name clashing, i.e., non-terminals that have the same name in Stratego and the embedded language. For that reason, the embedding occurs using a modified Stratego grammar, which renames all Stratego context-free non-terminals using by prefixing it with <code>StrategoLang</code>, avoiding name clashes. Inside Spoofax, you can add a source dependency on the <code>org.metaborg:stratego.lang:${metaborgVersion}</code> project in you <code>metaborg.yaml</code> file, then you can import the so-called namespaced grammar.</p> <p>Once you have access to the namespaced grammar, the next step consists of defining the embedding grammar, the grammar that actually mixes the two languages. A grammar that embeds one language into another may contain three types of productions: productions that define quotations for elements of the target language in the host language, productions that define anti-quotations back to the host language from the target language, and variables, which are shortcuts to anti-quotations, and may appear inside the target language fragments.</p> <p>When embedding a language into Stratego, it is common to allow fragments of the host language as Stratego terms. For that reason, quotation productions are injected into Stratego terms. For example, the productions below, written in SDF3, indicates that a Java compilation unit can occur in Stratego in a place where a Stratego term can occur.</p> <pre><code>imports\nStrategoLang/sugar/terms-namespaced\njava/packages/CompilationUnits\n\ncontext-free syntax\nStrategoLang-PreTerm.ToTerm = &lt;compilation-unit |[ &lt;CompilationUnit&gt; ]|&gt;\nStrategoLang-PreTerm.ToTerm = &lt;|[ &lt;CompilationUnit&gt; ]|&gt;\n</code></pre> <p>Anti-quotation productions define points to insert elements of the host language inside fragments of the target language. For example, with the production below, we allow Stratego terms to occur in a Java fragment whenever a non-terminal <code>Type</code> can occur.</p> <pre><code>imports\njava/types/Main\n\ncontext-free syntax\nType.FromTerm = [~[StrategoLang-Term]]\nType.FromTerm = [~type:[StrategoLang-Term]]\n</code></pre> <p>Note that the constructor <code>FromTerm</code> indicates that productions represent anti-quotations. Furthermore, note that anti-quotations may also be named after the non-terminal being referenced (e.g., <code>~type:</code>).</p> <p>Using anti-quotations might make the fragment of the target language quite verbose. Therefore, it is also possible to define variables as shortcuts to anti-quotations. For example, the productions below define variables to reference anti-quotations to <code>Type</code> fragments. That is, instead of reference to a Stratego variable <code>X</code> by using <code>~type:X</code>, one may name this variable <code>t_1</code> which corresponds to a variable for a non-terminal <code>Type</code>.</p> <pre><code>variables\nType = \"t_\" [0-9\\']* {prefer}\n</code></pre> <p>The <code>prefer</code> annotation indicates that in case of an ambiguity, the variable production should be preferred.</p> <p>Using the three types of productions above, it is possible to specify which fragments one wants to write using concrete syntax and which symbols may appear inside these fragments as Stratego variables (using anti-quotation or variables with a specific name).</p> <p>Finally, it is necessary to define a module <code>Stratego-&lt;LanguageName&gt;</code> that should import the Stratego grammar and the embedding grammar. This module should be defined in a file named <code>Stratego-&lt;LanguageName&gt;.sdf3</code> and put in the <code>syntax</code> folder so that Spoofax can locate it and build the mixed table. That is, if we define the module for our <code>Stratego-Java</code> mixed grammar:</p> <pre><code>module Stratego-Java\n\nimports\nEmbeddedJava\nStrategoLang/import-namespaced\n\ncontext-free start-symbols\nStrategoLang-Module\n</code></pre> <p>Note that it is necessary to define the start symbol of the mixed grammar as <code>StrategoLang-Module</code>. After defining the embedding grammar and the <code>Stratego-&lt;LanguageName&gt;</code> module, Spoofax generates the mixed table inside the trans folder when rebuilding the project.</p>"},{"location":"howtos/stratego/concrete-syntax/#using-mixed-parse-tables-to-allow-concrete-syntax","title":"Using Mixed Parse Tables to Allow Concrete Syntax","text":"<p>Assuming a mixed parse table has been successfully generated or already exists, the next step is to allow concrete syntax in transformations using that table. The table needs to be in a folder that can be discovered by the Stratego compiler. By default it will be generated in the <code>trans</code> folder of the project that defines the mixed grammar, to be used within the project. If you wish to use the mixed grammar in another project, make sure to export the generate table by adding an entry for it in the <code>metaborg.yaml</code> file. Then any other project that depends on your mixed grammar project with a source dependency will also provide the table file to the Stratego compiler.</p> <p>Next, together with the file in which we would like to enable concrete syntax, it is necessary to create a <code>.meta</code> file with the same name. That is, to enable concrete syntax in a file <code>generate.str</code>, it is necessary to create, in the same directory, an addition file <code>generate.meta</code>. This file should indicate which mixed table should be used to parse <code>generate.str</code>. For that reason it should contain:</p> <pre><code>Meta([Syntax(\"&lt;ParseTableName&gt;\")])\n</code></pre> <p>where <code>&lt;ParseTableName&gt;</code> is the filename of the parse table without extension, <code>Stratego-Java</code> in our example.</p> <p>With the configuration above, Spoofax automatically detects that the file contains concrete syntax and use that table to parse it. In that file, one may write rules containing concrete syntax as defined by the productions in the mixed grammar.</p>"},{"location":"howtos/stratego/debug-stratego/","title":"Debug Stratego Programs","text":"<p>Debugging Stratego programs can be frustrating. In strategic programming failure is a first-class citizen and the language supports dynamically typed programming. Thes are useful features for realizing generic and modular programming. However, this may mean that that errors may show up late in the game. A program fails much later then where the error occurs. Often during pretty-printing. Here we discuss some remedies for finding the problem.</p>"},{"location":"howtos/stratego/debug-stratego/#signatures","title":"Signatures","text":"<pre><code>signature\nsorts Exp\nconstructors\nAdd : Exp * Exp -&gt; Exp\n</code></pre> <p>Define a good signature for your terms.</p> <p>Ideally define the syntax of your language in a syntax definition in SDF3, and declare all sorts explicitly, and avoid injections. This will ensure that a signature and matching pretty-printer are generated automatically, as well as a signature for Statix.</p>"},{"location":"howtos/stratego/debug-stratego/#types","title":"Types","text":"<pre><code>translate :: Exp -&gt; List(Instr)\n</code></pre> <p>Define type signatures for transformations.</p> <p>Starting with Stratego2, the language supports the definition of type signatures for transformations. This will catch many obvious errors.</p>"},{"location":"howtos/stratego/debug-stratego/#use-with-instead-of-where","title":"Use With instead of Where","text":"<pre><code>translate :\nAdd(e1, e2) -&gt; &lt;concat&gt;[instrs1, instrs2, [Add()]]\nwith &lt;translate&gt; e1 =&gt; instrs1\nwith &lt;translate&gt; e2 =&gt; instrs2\n</code></pre> <p>The with clause expresses that you expect a premisse of a rewrite rule to succeed in all cases. When this expectation is violated, the rule will throw an exception and display a stack trace, instead of silently failing.</p>"},{"location":"howtos/stratego/debug-stratego/#define-spt-tests","title":"Define SPT tests","text":"<pre><code>test translate [[\n  1 + 2\n]] run translate\n</code></pre> <p>Define unit tests in the SPT testing language.</p>"},{"location":"howtos/stratego/debug-stratego/#debug","title":"Debug","text":"<pre><code>dbg(|\"translate/Add: \")\n</code></pre> <p>In case the measures above fail, use <code>dbg</code> to figure out where the error is in your program.</p>"},{"location":"howtos/stratego/exchange-terms/","title":"Exchange Terms","text":"<p>The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.</p>"},{"location":"howtos/stratego/generate-pretty-printer/","title":"How to Generate a Pretty-Printer","text":"<p>A pretty-printer is a mapping from abstract syntax trees (terms) to text. The resulting text should observe the syntactic rules</p>"},{"location":"howtos/stratego/generate-pretty-printer/#production-templates","title":"Production Templates","text":""},{"location":"howtos/stratego/generate-pretty-printer/#generate-pretty-printer","title":"Generate Pretty-Printer","text":"<p>automatically in build</p> <p>generates rules for translation from AST to Box</p> <p>Example. Generate pretty-print rules</p>"},{"location":"howtos/stratego/generate-pretty-printer/#use-pretty-printer","title":"Use Pretty-Printer","text":""},{"location":"howtos/stratego/generate-pretty-printer/#define-builder","title":"Define Builder","text":"<p>for interactive use</p>"},{"location":"howtos/stratego/generate-pretty-printer/#define-menu-action","title":"Define Menu Action","text":"<p>to invoke the builder</p>"},{"location":"howtos/stratego/generate-signature/","title":"How to Generate a Stratego Signature","text":"<p>It is tedious to write a signature that is in sync with a syntax definition. Therefore, Spoofax automatically generates a signature from a syntax definition for the abstract syntax trees that the parser for that syntax definition produces.</p>"},{"location":"howtos/stratego/generate-signature/#write-a-syntax-definition","title":"Write a Syntax Definition","text":"<p>In the <code>/syntax/</code> directory in your language project for language <code>lang</code> write a syntax definition in file <code>lang.sdf3</code>.</p> <p>Possibly write additional syntax defininitions modules and import the in <code>lang.sdf3</code>.</p> <p>Example. Consider the following SDF3 syntax definition:</p> <pre><code>module lang\nimports Base\n\nlexical sorts IntConst\nlexical syntax\nIntConst = [0-9]+\nsorts Exp\ncontext-free syntax\nExp.Int     = IntConst  Exp.Plus    = [[Exp] + [Exp]]   {left}\nExp.Minus   = [[Exp] - [Exp]]   {left}\nExp         = [([Exp])] {bracket}\ncontext-free priorities\n{left : Exp.Plus Exp.Minus}\n</code></pre>"},{"location":"howtos/stratego/generate-signature/#generate-signature","title":"Generate Signature","text":"<p>The build for your language project will invoke the SDF3 compiler to generate a signature file for each SDF3 file in your project in directory <code>/src-gen/signatures/</code> with suffix <code>-sig</code> and extension <code>.str</code>.</p> <p>The build should be invoked as soon as you save a file.</p> <p>Thus <code>lang.sdf3</code> generates <code>/src-gen/signatures/lang-sig.str</code>.</p> <p>Example. For the SDF3 file above, the following signature is automatically generated:</p> <pre><code>module signatures/lang-sig\nimports signatures/Base-sig\n\nsignature\nsorts IntConst\nsorts Exp\nconstructors\n: string -&gt; IntConst\nInt            : IntConst -&gt; Exp\nPlus           : Exp * Exp -&gt; Exp\nMinus          : Exp * Exp -&gt; Exp\nIntConst-Plhdr : IntConst\nExp-Plhdr      : Exp\nIntConst-Plhdr : COMPLETION-INSERTION -&gt; IntConst\nExp-Plhdr      : COMPLETION-INSERTION -&gt; Exp\n</code></pre> <p>The injection from strings into the lexical <code>IntConst</code> sort reflects the fact that tokens are represented as strings in ASTs. The placeholder constructors generated for the sorts are used to represent incomplete programs and syntactic code completion1.</p>"},{"location":"howtos/stratego/generate-signature/#use-signature","title":"Use Signature","text":"<p>To use the signature, import it into the Stratego module that uses its constructors.</p> <p>Example. To use the signature for the example import it as follows:</p> <pre><code>module desugar\nimports signatures/lang-sig\nrules\n// ...\n</code></pre>"},{"location":"howtos/stratego/generate-signature/#references","title":"References","text":"<ol> <li> <p>Luis Eduardo de Souza Amorim, Sebastian Erdweg, Guido Wachsmuth, and Eelco Visser. Principled syntactic code completion using placeholders. In Tijs van der Storm, Emilie Balland, and D\u00e1niel Varr\u00f3, editors, Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, The Netherlands, October 31 - November 1, 2016, 163\u2013175. ACM, 2016. URL: http://dx.doi.org/10.1145/2997364.2997374, doi:10.1145/2997364.2997374.\u00a0\u21a9</p> </li> </ol>"},{"location":"howtos/stratego/inspect-terms/","title":"Inspect Terms","text":"<p>As a Stratego programmer you will be looking a lot at raw ATerms. Stratego pioneers did this by opening an ATerm file in emacs and trying to get a sense of the structure by parenthesis highlighting and inserting newlines here and there. These days your life is much more pleasant through pretty-printing ATerms, which adds layout to a term to make it readable. For example, parsing the following program</p> <pre><code>   let function fact(n : int) : int =\n          if n &lt; 1 then 1 else (n * fact(n - 1))\n     in printint(fact(10))\n    end\n</code></pre> <p>produces the following ATerm:</p> <pre><code>    Let([FunDecs([FunDec(\"fact\",[FArg(\"n\",Tp(Tid(\"int\")))],Tp(Tid(\"int\")),\n    If(Lt(Var(\"n\"),Int(\"1\")),Int(\"1\"),Seq([Times(Var(\"n\"),Call(Var(\"fact\"),\n    [Minus(Var(\"n\"),Int(\"1\"))]))])))])],[Call(Var(\"printint\"),[Call(Var(\n    \"fact\"),[Int(\"10\")])])])\n</code></pre> <p>By pretty-printing the term we get a much more readable term:</p> <pre><code>    Let(\n      [ FunDecs(\n          [ FunDec(\n              \"fact\"\n            , [FArg(\"n\", Tp(Tid(\"int\")))]\n            , Tp(Tid(\"int\"))\n            , If(\n                Lt(Var(\"n\"), Int(\"1\"))\n              , Int(\"1\")\n              , Seq([ Times(Var(\"n\"), Call(Var(\"fact\"), [Minus(Var(\"n\"), Int(\"1\"))]))\n                    ])\n              )\n            )\n          ]\n        )\n      ]\n    , [ Call(Var(\"printint\"), [Call(Var(\"fact\"), [Int(\"10\")])])\n      ]\n    )\n</code></pre> <p>In Spoofax/Eclipse, you will find that in some contexts ATerms are automatically pretty-printed, whereas in others they are simply printed linearly. However, you can obtain assistance with perceiving the structure of any ATerm by writing it into a file with the \".aterm\" extension and opening it in the Spoofax Editor in Eclipse. On the right there will be a convenient Outline Navigator which allows you to select any node in the ATerm and see the entire subtree below it highlighted in the editor.</p>"},{"location":"howtos/stratego/run-stratego-programs/","title":"How to Run Stratego Programs","text":"<p>Stratego programs that are part of a language project in Spoofax/Eclipse are run by creating a menu entry that invokes a strategy in your program.</p>"},{"location":"howtos/stratego/run-stratego-programs/#extend-spoofax-menu","title":"Extend Spoofax Menu","text":"<pre><code>module $ModuleName\nmenus\nmenu: \"$Menu\" (openeditor)\naction: \"$MenuEntry\" = $Id\n</code></pre> <p>Add a new ESV file in the <code>editor/</code> directory of your project or use an existing one.</p> <p>In the <code>menus</code> section, create a menu with an appropriate name. Adding the attribute <code>openeditor</code> ensures that the result of running the program will be opened in an editor.</p> <p>Add an action entry to the menu with the name of the menu entry and the name of the builder strategy to invoke.</p> <p>This should add a menu entry <code>Spoofax &gt; Menu &gt; Action</code> to the editor for your language.</p>"},{"location":"howtos/stratego/run-stratego-programs/#define-builder","title":"Define Builder","text":"<pre><code>$Id:\n(node, _, _, path, project-path) -&gt; (filename, result)\nwith filename := &lt;guarantee-extension(|$Extension)&gt; path\nwith result   := &lt;$Strategy&gt;node\n</code></pre> <p>In your Stratego program, probably in some top-level file in the <code>trans/</code> directory of your project, add a 'builder' rewrite rule. Such a rewrite rule defines the interface between the user-interface (action menu entry) and your program.</p> <p>A builder has the interface shown above. When invoking the builder, Spoofax takes care of parsing the program and converting it to abstract syntax term. It takes a quintuple of the selected AST <code>node</code>, the entire <code>ast</code>, the file <code>path</code>, and the <code>project-path</code> and returns a pair of the <code>filename</code> and <code>result</code>.</p> <p>The results are computed in the conditions of the builder rule. The new <code>filename</code> is typically derived from the old file name in <code>path</code> The <code>result</code> is computed by invoking a strategy on the selected <code>node</code> or on the entire <code>ast</code>.</p>"},{"location":"howtos/stratego/run-stratego-programs/#example-parser","title":"Example: Parser","text":"<pre><code>module Syntax\n//...\nmenus\nmenu: \"Syntax\" (openeditor)\naction: \"Show parsed AST\" = debug-show-aterm (source)\n</code></pre> <pre><code>debug-show-aterm:\n(node, _, _, path, project-path) -&gt; (filename, result)\nwith\nfilename := &lt;guarantee-extension(|\"aterm\")&gt; path\n; result   := node\n</code></pre> <p>The <code>debug-show-aterm</code> provided with new Spoofax projects returns the selected <code>node</code> as result. Since Spoofax ensures that the content of the editor is parsed, this returns the AST of the editor content as a (pretty-printed) term.</p>"},{"location":"howtos/stratego/run-stratego-programs/#example-term-builder","title":"Example: Term Builder","text":"<pre><code>module Compilation\nmenus\nmenu: \"Compilation\" (openeditor)\naction: \"Desugar (AST)\" = desugar-aterm\n</code></pre> <pre><code>rules\n\ndesugar-aterm:\n(node, _, _, path, project-path) -&gt; (filename, result)\nwith filename := &lt;guarantee-extension(|\"d.aterm\")&gt; path\nwith result   := &lt;desugar&gt;node\n</code></pre> <p>The <code>Desugar (AST)</code> menu action calls the <code>desugar-aterm</code> builder, which in turn uses the <code>desugar</code> strategy to transform the selected <code>node</code>. The result is returned in a file with extension <code>d.aterm</code>.</p>"},{"location":"howtos/stratego/run-stratego-programs/#example-pretty-printing-builder","title":"Example: Pretty Printing Builder","text":"<pre><code>module Compilation\nmenus\nmenu: \"Compilation\" (openeditor)\naction: \"Desugar\" = desugar-pp\n</code></pre> <pre><code>rules\n\ndesugar-pp:\n(node, _, _, path, project-path) -&gt; (filename, result)\nwith filename := &lt;guarantee-extension(|\"d.tig\")&gt; path\nwith result   := &lt;desugar; pp-tiger-string&gt;node  </code></pre> <p>The <code>Desugar</code> menu action calls the <code>desugar-pp</code> builder. That strategy transforms the selected <code>node</code> with <code>desugar</code> and pretty-prints the resulting term with <code>pp-tiger-string</code>. The result is returned in a file with extension <code>d.tig</code>.</p>"},{"location":"howtos/stratego/run-stratego-programs/#define-spt-tests","title":"Define SPT Tests","text":"<p>An alternative way to run transformations is to test them using SPT tests.</p> <p>This allows you to systematically run a transformation on a number of typical cases.</p>"},{"location":"howtos/stratego/run-stratego-programs/#run-on-save","title":"Run On Save","text":"<p>When a Stratego program is applied in production, a transformation can be applied automatically whenever a program in your language is saved.</p>"},{"location":"howtos/stratego/stratego-1-to-2/","title":"Migrating from Stratego 1 to Stratego 2","text":"Stratego 2 is somewhat unstable <p>Stratego 2 is quite new and has a lot of exciting new things going for it. But it is therefore also more unstable, with errors popping up somewhat regularly. Your project build may break or your code may behave in unexpected ways. Of course you can file bug reports.</p> <p>Stratego 2 is the new version of Stratego that provides access to the incremental compiler and gradual type system that were developed for Stratego. Stratego 2 is accessible separately because it is organised quite differently from Stratego 1 and it provides a clear distinction and documentable upgrade path. This is that documented upgrade path. This How-To will guide you through the changes you need to make in your Spoofax project in order to use Stratego 2.</p> <ol> <li>Make sure you run the development version of Spoofax. This step will become obsolete in the future but currently Stratego 2 development is moving quickly and fixing bugs every week. </li> <li>In your <code>metaborg.yaml</code> file:<ol> <li>Add a compile dependency (<code>dependencies.compile</code>) on <code>org.metaborg:stratego.lang:${metaborgVersion}</code> (the Stratego 2 language)</li> <li>Add a source dependency on <code>org.metaborg:strategolib:${metaborgVersion}</code> (the Stratego 2 version of strategolib, the standard library)</li> <li>Add a java dependency on <code>org.metaborg:strategolib:${metaborgVersion}</code> (this is necessary for code generated by the Stratego compiler to find the standard library)</li> <li>Remove from <code>language.stratego.args</code> the <code>-la</code> and <code>stratego-lib</code> lines (2 lines, leave the other <code>-la</code>)</li> <li>Remove <code>language.stratego.build</code> if there, it is now ignored, all compilation will be incremental</li> <li>Remove <code>language.stratego.format</code> if there, it is now ignored, the compilation is always to jar. If the format option you remove is <code>ctree</code>, also search your <code>.esv</code> files for a line <code>provider : target/metaborg/stratego.ctree</code>, likely in <code>editor/Main.esv</code>, and remove it. </li> </ol> </li> <li>Rename all <code>.str</code> files in your project that are not in <code>src-gen</code> to <code>.str2</code>. Generated Stratego files in <code>src-gen</code> should already have a <code>.str2</code> version next to the <code>.str</code> version of the file.</li> <li>Remove any imports to <code>libstratego-lib</code> or <code>libstrategolib</code> in those renamed files.</li> <li>Add the <code>strategolib</code> import to all your <code>.str2</code> files outside of <code>src-gen</code>.</li> </ol> Stratego versions <p>The version numbers of Stratego are a little strange, Stratego and Stratego/XT used to number up to 0.17, then did not receive any more numbered releases even though small bugfixes and changes were released through Spoofax 1 and 2. In the current documentation we now consider this post-0.17 Stratego in Spoofax to be Stratego 1. This is not necessarily a statement of stability and matureness of the language but more to distinguish it from the new Stratego 2 project.</p>"},{"location":"howtos/stratego/stratego-1-to-2/#imports-in-stratego-2","title":"Imports in Stratego 2","text":"<p>At this point your project may be buildable again, but perhaps you are still getting errors about unresolved strategies or constructors. Stratego 2 has a stricter import policy than Stratego 1. If you use a strategy, rule or constructor, you must either define that strategy/rule/constructor in the module or import a module that defines it. Imports are no longer transitive for name resolution. </p>"},{"location":"references/","title":"References","text":"<p>This are the Spoofax and meta-language references. For more background information on the ideas, architecture, and design decisions behind Spoofax and its meta-languages, see the Background section.</p> <p>The reference section should explain language constructs (syntax, statics, dynamics) and be structured following a taxonomy of the language</p>"},{"location":"references/#table-of-contents","title":"Table of Contents","text":"<ul> <li>SDF3 (Jasper)</li> <li>Statix (Aron)</li> <li>FlowSpec (Matthijs, Jeff)</li> <li>Stratego (Eelco, Jeff)</li> <li>PIE (Ivo, Gabri\u00ebl)</li> <li>MkDocs (Dani\u00ebl)</li> <li>bibtex</li> <li>syntax highlighting</li> <li>ESV / editor services  </li> <li>Reviewing</li> <li>Peter</li> <li>Toine</li> </ul>"},{"location":"references/config/","title":"Configuration","text":"<p>This section describes the configuration options for Spoofax languages and projects in the <code>metaborg.yaml</code> file.</p>"},{"location":"references/config/language/","title":"Language Configuration","text":"<p>This page describes the options in the <code>metaborg.yaml</code> file of a language definition project.</p>"},{"location":"references/config/language/#language","title":"<code>language</code>","text":""},{"location":"references/config/language/#statix","title":"<code>statix</code>","text":"<p>There is one option for Statix in a language definition project: <code>mode</code>. The available options are <code>traditional</code> (default), <code>concurrent</code> and <code>incremental</code>.</p>"},{"location":"references/config/project/","title":"Project Configuration","text":"<p>This page describes the configuration options in a <code>metaborg.yaml</code> file of a Spoofax project (i.e., a project that uses a Spoofax language definition).</p>"},{"location":"references/config/project/#runtime","title":"<code>runtime</code>","text":""},{"location":"references/config/project/#statix","title":"<code>statix</code>","text":"<p>All options under the <code>runtime.statix</code> options configure the behavior of the Statix solver in this project. The available options are:</p> Option Values Default Description <code>test-log</code> <code>none|error|warn|info|debug|trace</code> <code>none</code> Executing an <code>stxtest</code> will emit logging with the specified level in the Eclipse Console. <code>suppress-cascading-errors</code> <code>true|false</code> <code>true</code> When set to <code>true</code>, the solver will not emit messages for constraints that could not be solved due to other constraints failing. <code>message-trace-length</code> An integer <code>0</code> The number of constraints in the causation trace to print below the error message. <code>-1</code> prints the full trace. <code>message-term-depth</code> An integer <code>3</code> The depth in which terms are printed inside an error message. For deeper terms, and ellipsis is printed. <code>-1</code> prints infinite terms. <p>In addition, there is a <code>modes</code> parameter, which manages the solver modes in this project. This parameter contains subnodes consisting of a language name as key, and either <code>traditional</code> (default), <code>concurrent</code> of <code>incremental</code> as value. This setting overrides the default solver mode set by the language definition.</p> <p>The Statix segment of an configuration file can look as follows. <pre><code>runtime:\nstatix:\ntest-log: debug\nsuppress-cascading-errors: true\nmessage-trace-length: 4\nmessage-term-depth: -1\nmodes:\nMyLang: concurrent\n</code></pre></p>"},{"location":"references/editor-services/","title":"Editor Services","text":"<p>Most editor services are configured in an ESV file. This way the following editor services can be defined:</p> <ul> <li>Action Menus</li> <li>Analysis</li> <li>File Extensions</li> <li>Hover Tooltips</li> <li>On-Save Handlers</li> <li>Outline View</li> <li>Parsing</li> <li>Reference Resolution</li> <li>Stratego Strategies</li> <li>Syntax Highlighting</li> </ul> <p>Additionally, the following editor services are configured in a different way:</p> <ul> <li>Rename Refactoring</li> </ul>"},{"location":"references/editor-services/analysis/","title":"Analysis","text":"<p>The analyzer strategy is used to perform static analyses such as name and type analysis, on the AST that a parser produces. An analysis context provides a project-wide store to facilitate multi-file analysis and incrementality. There are four ways to configure the analysis, which set the analyzer strategy with the <code>observer</code> and <code>context</code> keys in an ESV file.</p> <pre><code>language\n\ncontext  : $Context\n  observer : $Strategy\n</code></pre>"},{"location":"references/editor-services/analysis/#no-analysis","title":"No Analysis","text":"<p>To completely disable analysis, do not set an observer and set the context to none:</p> <pre><code>language\n\ncontext : none\n</code></pre>"},{"location":"references/editor-services/analysis/#stratego","title":"Stratego","text":"<p>Stratego-based analysis allows you to implement your analysis in Stratego:</p> <pre><code>language\n\ncontext  : legacy\n  observer : editor-analyze\n</code></pre> <p>The identifier after the colon refers to the Stratego strategy that performs the analysis. It must take as input a 3-tuple <code>(ast, path, projectPath)</code>. As output it must produce a 4-tuple <code>(ast, error*, warning*, note*)</code>. The following Stratego code is an example of a strategy that implements this signature:</p> <pre><code>editor-analyze: (ast, path, projectPath) -&gt; (ast', errors, warnings, notes)\nwith ast'     := &lt;analyze&gt; ast\n; errors   := &lt;collect-all(check-error)&gt; ast'\n     ; warnings := &lt;collect-all(check-warning)&gt; ast'\n     ; notes    := &lt;collect-all(check-note)&gt; ast'\n</code></pre>"},{"location":"references/editor-services/analysis/#statix","title":"Statix","text":"<p>To use Statix as the meta-language for name and type analysis, use the <code>editor-analyze</code> strategy defined in <code>trans/analysis.str</code>, annotate it with the <code>(constraint)</code> modifier, and set no context:</p> <pre><code>language\n\nobserver : editor-analyze (constraint)\n</code></pre> <p>By default, the Statix analyzer works in single-file mode and does not consider multi-file name resolution. To enable that, add the <code>(multifile)</code> modifier:</p> <pre><code>language\n\nobserver : editor-analyze (constraint) (multifile)\n</code></pre>"},{"location":"references/editor-services/esv/","title":"ESV","text":"<p>The Editor Service (ESV) language is a declarative meta-language for configuring the editor services of a language. For example, the following ESV code fragment configures the syntax highlighting for a language, based on the types of tokens:</p> <pre><code>module color\n\ncolorer\n\n  keyword    : 153 51 153\n  identifier : black\n  string     : 177 47 2\n  number     : 17 131 22\n  operator   : black\n  layout     : 63 127 95 italic\n</code></pre>"},{"location":"references/editor-services/esv/#structure","title":"Structure","text":"<p>ESV files end with the <code>.esv</code> extension, and are by convention placed in the <code>editor/</code> folder of a language project. Each ESV file defines a module for the file, followed by import statements and then the main configuration sections. Each section consists of a number of keys and values.</p> <p>Main File</p> <p>By convention, the main ESV file of a language project must live at <code>editor/Main.esv</code> (default) or <code>editor/main.esv</code>. Other ESV files can be (transitively) imported from the main ESV file.</p>"},{"location":"references/editor-services/esv/#module-definition","title":"Module Definition","text":"<p>An ESV file starts with a module definition at the top of the file:</p> <pre><code>module $ModuleName\n</code></pre> <p>The module name is the filename of the ESV file without the exttension, and relative to the <code>editor/</code> directory. For example, the module <code>editor/mylang/Syntax.esv</code> would have the following module name:</p> <pre><code>module mylang/Syntax\n</code></pre> <p>Module names can only contains the alphanumeric characters  and dash, underscore, and period, and use the forward slash (<code>/</code>) as the path separator.</p> <p>Module names cannot be in parent directories, so <code>../Syntax</code> is not allowed.</p>"},{"location":"references/editor-services/esv/#imports","title":"Imports","text":"<p>The imports section is an optional section immediately following the module definition. When specified it is given as:</p> <pre><code>imports\n$Imports\n</code></pre> <p>For example, to import <code>editor/Syntax.esv</code> and <code>editor/Analysis.esv</code>:</p> <pre><code>imports\nSyntax\n    Analysis\n</code></pre> <p>Imports are transitive.</p> <p>At most one imports section is permitted. When specified, the <code>imports</code> section cannot be empty.</p>"},{"location":"references/editor-services/esv/#configuration-sections","title":"Configuration Sections","text":"<p>The main body of an ESV file consists of any number of configuration sections. An example of a configuration section is:</p> <pre><code>language\nline comment:  \"//\"\nblock comment: \"/*\" \"*/\"\n</code></pre> <p>The configuration sections are hard-coded in the ESV language, but mostly use a consistent syntax for the keys and values.</p> <p>The following configuration sections are currently defined:</p> <ul> <li><code>colorer</code><ul> <li>Syntax Highlighting</li> </ul> </li> <li><code>language</code><ul> <li>Language File Extensions</li> <li>Parsing</li> <li>Analysis</li> <li>On-Save Handlers</li> <li>Stratego Strategies</li> </ul> </li> <li><code>menus</code><ul> <li>Action menus</li> </ul> </li> <li><code>references</code><ul> <li>Hover Tooltips</li> <li>Reference Resolutions</li> </ul> </li> <li><code>views</code><ul> <li>Outline View</li> </ul> </li> </ul> <p>The following sections have been deprecated:</p> <ul> <li><code>analysis</code></li> <li><code>builders</code></li> <li><code>completions</code></li> <li><code>folding</code></li> <li><code>outliner</code></li> <li><code>refactorings</code></li> </ul>"},{"location":"references/editor-services/file-extensions/","title":"Language File Extensions","text":"<p>The file extensions that the editor should recognize as files belonging to the language definition, are configured in the <code>language</code> section <code>extensions</code> key of an ESV file. They are specified without a leading dot:</p> <pre><code>language\n\nextensions : ent\n</code></pre> <p>Multiple extensions can be set with a comma-separated list:</p> <pre><code>language\n\nextensions : ent, entity, entities\n</code></pre> <p>This will assign for example <code>foo.ent</code>, <code>foo.entity</code>, and <code>foo.entities</code> to the language.</p>"},{"location":"references/editor-services/hover/","title":"Hover Tooltips","text":"<p>Hover tooltips show a textual tooltip with extra information, when hovering part of the text. Hover tooltips are created by a Stratego strategy, but are configured in an ESV file under the <code>references</code> section:</p> <pre><code>references\n\n  hover _ : $Strategy\n</code></pre> <p>For example:</p> <pre><code>references\n\n  hover _ : editor-hover\n</code></pre> <p>The identifier after the colon refers to the Stratego strategy that creates the hover tooltip. The Stratego strategy takes an AST node, and either fails if no tooltip should be produced, or returns a tooltip string.</p> <p>The string may contain a few simple HTML tag to style the output. The following tags are supported:</p> <ul> <li><code>&lt;br/&gt;</code> \u2014 line break</li> <li><code>&lt;b&gt;text&lt;/b&gt;</code> \u2014 bold</li> <li><code>&lt;i&gt;text&lt;/i&gt;</code> \u2014 italic</li> <li><code>&lt;pre&gt;code&lt;/pre&gt;</code> \u2014 preformatted (code) text</li> </ul> <p>Unrecognized HTML tags are stripped from the hover tooltip. Escape angled brackets and ampersands to show them verbatim in the tooltip.</p>"},{"location":"references/editor-services/menus/","title":"Action Menus","text":"<p>Menus are used to bind actions of your language, such as transformations, to a menu in the IDE. Menus are defined using the <code>menu</code> keyword under a <code>menus</code> section in an ESV file, and can themselves contain submenus, actions, and separators.</p> <pre><code>menu : $String $MenuOptions\n  $MenuContribs\n</code></pre>"},{"location":"references/editor-services/menus/#menu-contributions","title":"Menu Contributions","text":"<p>A menu has zero or more <code>$MenuContrib</code>, which are: <code>action</code>, <code>submenu</code>, or <code>separator</code>.</p>"},{"location":"references/editor-services/menus/#actions","title":"Actions","text":"<p>Actions (sometimes called builders) are defined under a menu or submenu with syntax:</p> <pre><code>action : $String = $StrategoCall $MenuOptions\n</code></pre>"},{"location":"references/editor-services/menus/#submenus","title":"Submenus","text":"<p>Submenus allow grouping of actions in nested menus. Their syntax is:</p> <pre><code>submenu : $String $MenuOptions\n  $MenuContribs\nend\n</code></pre>"},{"location":"references/editor-services/menus/#separators","title":"Separators","text":"<p>Separators allow inserting a separator in a menu list using the syntax: <pre><code>separator\n</code></pre></p>"},{"location":"references/editor-services/menus/#menu-options","title":"Menu Options","text":"<p>The menu options specify the behavior of the menu item. The following modifiers are supported:</p> Modifier Description <code>(source)</code> Action is performed on the parsed AST instead of the default analyzed AST. <code>(openeditor)</code> The result should be opened in a new editor. <code>(realtime)</code> <code>(meta)</code>"},{"location":"references/editor-services/menus/#example","title":"Example","text":"<p>An example menu:</p> <pre><code>menus\n\nmenu: \"Generate\"\naction: \"To normal form\" = to-normal-form (source)\nsubmenu: \"To Java\"\naction: \"Abstract\" = to-java-abstract (openeditor)\naction: \"Concrete\" = to-java-concrete\n    end\n</code></pre>"},{"location":"references/editor-services/on-save/","title":"On-Save Handlers","text":"<p>The on-save handler (also known as the compiler strategy) is used to transform files when they are saved in an editor. In an IDE, when a new project is opened, the compiler strategy is also executed on each file in the project, as well as when files change in the background. In a command-line batch compiler setting, it is used to transform all files.</p> <p>The compiler strategy is configured in an ESV file with the <code>on save</code> key:</p> <pre><code>language\n\non save : $Strategy\n</code></pre> <p>The identifier after the colon refers to the Stratego strategy that performs the transformation. This strategy must have the exact same signature as the one for actions.</p> <p>For example:</p> <pre><code>language\n\non save : compile-file\n</code></pre>"},{"location":"references/editor-services/outline/","title":"Outline View","text":"<p>An outline is a summary of the structure of a file, shown in a separate view next to a textual editor. An outline is created by a Stratego strategy, but is configured in an ESV file under the <code>views</code> section:</p> <pre><code>views\n\n  outline view: $Strategy\n    expand to level: $Int\n</code></pre> <p>The Stratego strategy specified as <code>$Strategy</code> must have the following signature:</p> <pre><code>signature\nconstructors\n\nNode : Label * Children -&gt; Node\n\nrules\n\neditor-outline:\n(node, position, ast, path, project-path) -&gt; outline\n</code></pre> <p>Where the input is the default tuple used for builders, and the result is a list of <code>Node</code> terms, each carrying a label and a (possibly empty) list of child nodes.</p> <p>Preserve origins on the node's label to allow navigating to the corresponding code from the outline.</p> <p>For example:</p> <pre><code>views\n\n  outline view: editor-outline\n    expand to level: 3\n</code></pre> <p>This configures the <code>editor-outline</code> Stratego strategy to be used to create outlines, and that outline nodes should be expanded 3 levels deep by default.</p>"},{"location":"references/editor-services/parsing/","title":"Parsing","text":"<p>Parsing language files in an editor is configured in the <code>language</code> section of an ESV file. The syntax is as follows:</p> <pre><code>language\n\ntable         : $Path\n  start symbols : $Sorts\n\n  line comment  : $String\n  block comment : $String * $String\n  fences        : $Fences\n</code></pre> <p>For example:</p> <pre><code>language\n\ntable         : target/metaborg/sdf.tbl\n  start symbols : File\n\n  line comment  : \"//\"\nblock comment : \"/*\" * \"*/\"\nfences        : [ ] ( ) { }\n</code></pre>"},{"location":"references/editor-services/parsing/#parse-table","title":"Parse Table","text":"<p>The parse table of your language is set with the <code>table</code> key. By default, the parse table of an SDF specification is always produced at <code>target/metaborg/sdf.tbl</code>. It is only necessary to change this configuration when a custom parse table is used.</p>"},{"location":"references/editor-services/parsing/#start-symbols","title":"Start Symbols","text":"<p>The <code>start symbols</code> key determine which start symbols to use when an editor is opened. This must be a subset of the start symbols defined in the SDF3 specification of your language.</p> <p>Multiple start symbols can be set with a comma-separated list:</p> <pre><code>language\n\nstart symbols : Start, Program\n</code></pre>"},{"location":"references/editor-services/parsing/#comments","title":"Comments","text":"<p>The syntax for comments is:</p> <pre><code>language\n\nline comment  : $String\n  block comment : $String * $String\n</code></pre> <p>For example, Java comments are specified as:</p> <pre><code>language\n\nline comment  : \"//\"\nblock comment : \"/*\" * \"*/\"\n</code></pre> <p>The <code>line comment</code> key determines how single-line comments are created. It is used by editors to toggle the comment for a single line. For example, in Eclipse, pressing Ctrl+/ (Cmd+/ on macOS), respectively comments or uncomments the line. The <code>block comment</code> key determines how multi-line comments are created. It is used when a whole block needs to be commented or uncommented. A block comment is described by the two strings denoting the start and end symbols of the block comment respectively.</p>"},{"location":"references/editor-services/parsing/#fences","title":"Fences","text":"<p>Fences for bracket matching are set as follows:</p> <pre><code>language\n\nfences : $Fences\n</code></pre> <p>The <code>fences</code> key determines which symbols to use and match for bracket matching. A single fence is defined by a starting and closing symbol. Multiple fences can be set with a space-separated list. Fences are used to do bracket matching in text editors.</p> <p>For example, the default fences in a new Spoofax language project are:</p> <pre><code>language\n\nfences : [ ] ( ) { }\n</code></pre> <p>Multi-Character Fences</p> <p>Fences can contain multiple characters, but some implementations may not handle bracket matching with multiple fence characters. For example, Eclipse does not handle this case and ignores multi-character fences.</p>"},{"location":"references/editor-services/reference-resolution/","title":"Reference Resolution","text":"<p>Reference resolution takes an AST node containing a reference, and tries to resolve it to its definition. The resolution is performed by a Stratego strategy, but is configured in an ESV file under the <code>references</code> section:</p> <pre><code>references\n\n  reference _ : $Strategy\n</code></pre> <p>The identifier after the colon refers to the Stratego strategy that performs the resolution. The Stratego strategy takes an AST node, and either fails if it could not be resolved, or returns an AST node that has an origin location pointing to the definition site.</p> <p>For example:</p> <pre><code>references\n\n  reference _ : editor-resolve\n</code></pre>"},{"location":"references/editor-services/renaming/","title":"Rename Refactoring","text":"<p>Spoofax provides an automated rename refactoring as an editor service for every language developed with it that has the static semantics defined with Statix or NaBL2.</p>"},{"location":"references/editor-services/renaming/#strategy","title":"Strategy","text":"<p>Rename refactoring is enabled by default for new Spoofax language projects. This works by registering the <code>rename-action</code> strategy from the <code>statixruntime</code> library as an action in a menu. This strategy takes three parameters: a layout-preserving pretty-printing strategy (<code>construct-textual-change</code> by default), the editor analyze strategy (<code>editor-analyze</code> by default), and a strategy that should succeed when renaming in multi-file mode.</p> <p>The default rename refactoring strategy looks like this:</p> <pre><code>rules\n\nrename-menu-action = rename-action(construct-textual-change,\neditor-analyze, fail)\n</code></pre> <p>To enable multi-file mode, change the last argument to <code>id</code>:</p> <pre><code>rules\n\nrename-menu-action = rename-action(construct-textual-change,\neditor-analyze, id)\n</code></pre>"},{"location":"references/editor-services/renaming/#statix","title":"Statix","text":"<p>For the renaming to work correctly in all cases when using Statix, terms that represent a declaration of a program entity, such as a function or a variable, need to set the <code>@decl</code> property on the name of the entity. For example, when declaring a type:</p> <pre><code>declareType(scope, name, T) :-\n!type[name, T] in scope,\n@name.decl := name,\nquery type filter P* I* and { name' :- name' == name } in scope |-&gt; [_].\n</code></pre>"},{"location":"references/editor-services/renaming/#known-issues","title":"Known Issues","text":"<p>When a parse tree of a name is preceded by a term which is parsed from an empty string. The renaming algorithm will incorrectly select the preceding term to be renamed, and mostly fail accordingly. Sometimes, this issue can be circumvented by selecting the complete surrounding term. This issue is known to occur for:</p> <ul> <li>Statix predicate names.</li> </ul>"},{"location":"references/editor-services/renaming/#see-also","title":"See Also","text":"<ul> <li>How-To: Add Rename Refactoring to an Existing Project</li> </ul>"},{"location":"references/editor-services/stratego/","title":"Stratego","text":"<p>The Java JAR and CTree files that will be loaded into the Stratego runtime for your language can be configured with the <code>provider</code> key in an ESV file:</p> <pre><code>language\n\nprovider : $Path\n</code></pre> <p>The path is a path to a <code>.jar</code> or <code>.ctree</code> file, relative to the root of the project. For example:</p> <pre><code>language\n\nprovider : target/metaborg/stratego.ctree\n</code></pre> <p>The extension of the provider should match the format in the <code>metaborg.yaml</code> file of your language. Multiple files can be set by setting the key multiple times:</p> <pre><code>language\n\nprovider : target/metaborg/stratego.ctree\n  provider : target/custom1.jar\n  provider : target/custom2.ctree\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/","title":"Syntax Highlighting","text":"<p>Token-based syntax highlighting is configured in a <code>colorer</code> section of an ESV file. Such a section can contain style definitions and styling rules.</p>"},{"location":"references/editor-services/syntax-highlighting/#style-definitions","title":"Style Definitions","text":"<p>Style definitions bind an identifier to a style for later reuse, using the syntax:</p> <pre><code>  $ID = $Style\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/#styles","title":"Styles","text":"<p>A style specifies a combination of a foreground color, optional background color, and optional font style. Colors are specified as Red-Green-Blue values ranging from 0 (none) to 255 (full). The possible font attributes are:</p> Font attribute Description (none) Normal font. <code>bold</code> Bold font. <code>italic</code> Italic font. <code>bold italic</code> Bond and italic font. <code>italic bold</code> Same as <code>bold italic</code>. <p>For example, the following style definitions bind the <code>red</code>, <code>green</code>, and <code>blue</code> colors:</p> <pre><code>colorer\n\n  red   = 255 0 0\n  green = 0 255 0\n  blue  = 0 0 255\n</code></pre> <p>An optional background color can be set by adding another RGB value:</p> <pre><code>colorer\n\n  redWithGreenBackground = 255 0 0 0 255 0\n</code></pre> <p>The font attributes can be used to make the font bold or italic:</p> <pre><code>colorer\n\n  redWithBold   = 255 0 0 bold\n  redWithItalic = 255 0 0 italic\n  redWithGreenBackgroundWithBoldItalic = 255 0 0 0 255 0 bold italic\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/#style-rules","title":"Style Rules","text":"<p>Style rules assign a style to matched tokens with syntax:</p> <pre><code>$Matcher : $Style\n</code></pre> <p>Or assigns a previously defined style definition:</p> <pre><code>$Matcher : $Ref\n</code></pre> <p>The left hand side of style rules matches a token, whereas the right hand side assigns a style by referring to a previously defined style definition, or by directly assigning a style. For example, the following matches a token type and references a style definition:</p> <pre><code>colorer\n\n  operator : black\n</code></pre> <p>whereas the following matches a token with a sort and constructor, and directly assigns a style:</p> <pre><code>colorer\n\n  ClassBodyDec.MethodDec : 0 255 0\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/#matchers","title":"Matchers","text":"<p>There are several ways in which the matcher on the left-hand side of a style rule can be specified: by type, by sort, by constructor, or by sort and constructor.</p>"},{"location":"references/editor-services/syntax-highlighting/#match-by-sort-and-constructor","title":"Match by Sort and Constructor","text":"<p>The combination of a token sort and constructor can be matched by specifying the <code>$Sort.$Constructor</code>. For example:</p> <pre><code>colorer\n\n  ClassBodyDec.MethodDec : yellow\n  ClassBodyDec.FieldDec  : red\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/#match-by-constructor","title":"Match by Constructor","text":"<p>It is also possible to match constructors, regardless of their token sorts, using <code>_</code> in place of the sort name. For example:</p> <pre><code>colorer\n\n  _.Str     : blue\n  _.StrCong : blue\n  _.QStr    : blue\n  _.QDollar : blue\n  _.QBr     : gray\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/#match-by-sort","title":"Match by Sort","text":"<p>Additionally, it is possible to match any constructor for a specific sort. For this, just specify the name of the sort, <code>$Sort</code>. For example:</p> <pre><code>colorer\n\n  ID       : darkblue\n  TYPEID   : blue\n  JQTYPEID : blue\n  PQTYPEID : blue\n  FUNCID   : 153 51 0\n  JFUNCID  : 153 51 0\n  STRING   : 177 47 2\n</code></pre>"},{"location":"references/editor-services/syntax-highlighting/#match-by-type","title":"Match by Type","text":"<p>Finally, the following built-in token types can be matched on:</p> <ul> <li><code>identifier</code> \u2014 matches identifiers, found by lexical non-terminals without numbers;</li> <li><code>keyword</code> \u2014 matches keywords, found by terminals in the syntax definition;</li> <li><code>layout</code> \u2014 matches layout, such as whitespace and comments, found by layout definition;</li> <li><code>number</code> \u2014 matches numbers, found by lexical non-terminals with numbers;</li> <li><code>operator</code> \u2014 matches operations, found by terminals that contain just symbols (no characters);</li> <li><code>string</code> \u2014 matches strings, found by lexical non-terminals that include quotation marks;</li> <li><code>unknown</code> \u2014 matches tokens which the parser was unable to infer a type for.</li> <li><code>var</code></li> <li><code>error</code></li> </ul> <p>For example, the following code defines a simple highlighting with token types:</p> <pre><code>colorer\n\n  keyword    : 153 51 153\n  identifier : black\n  string     : 177 47 2\n  number     : 17 131 22\n  operator   : black\n  layout     : 63 127 95 italic\n</code></pre>"},{"location":"references/flowspec/","title":"Index","text":""},{"location":"references/flowspec/#flowspec","title":"FlowSpec","text":"<p>Programs that are syntactically well-formed are not necessarily valid programs. Programming languages typically impose additional context-sensitive requirements on programs that cannot be captured in a syntax definition. Languages use data and control flow to check certain extra properties that fall outside of names and type systems. The FlowSpec \u2018Flow Analysis Specification Language\u2019 supports the specification of rules to define the static control flow of a language, and data flow analysis over that control flow. FlowSpec supports flow-sensitive intra-procedural data flow analysis.</p>"},{"location":"references/flowspec/#control-flow-graphs","title":"Control Flow Graphs","text":"<p>Control-flow represents the execution order of a program. Depending on the input given to the program, or other things the program may observe of its execution environment (e.g. network communication, or a source of noise used to generate pseudo-random numbers), a program may execute a different trace of instructions. Since in general programs may not terminate at all, and humans are not very adapt at reasoning about possible infinities, we use a finite representation of possibly infinite program traces using control-flow graphs.</p> <p>Control-flow graphs are similarly finite as program text and are usually very similar, giving rise to a visual representation of the program. Loops in the program are represented as cycles in the control-flow graph, conditional code is represented by a split in control-flow which is merged again automatically after the conditional code.</p>"},{"location":"references/flowspec/#data-flow-analysis-over-control-flow-graphs","title":"Data Flow Analysis over Control Flow Graphs","text":"<p>Data-flow analysis propagates information either forward or backward along the control-flow graph. This can be information that approximates the data that is handled by the program, or the way in which the program interacts with memory, or something else altogether.</p> <p>Examples of data-flow analysis include constant analysis which checks when variables that are used in the program are guaranteed to have the same value regardless of the execution circumstances of the program, or live variables analysis which identifies if values in variables are actually observable by the program.</p>"},{"location":"references/flowspec/Stratego_API/","title":"Stratego API","text":""},{"location":"references/flowspec/Stratego_API/#setup","title":"Setup","text":"<p>Using the Stratego API requires a dependency on the FlowSpec Stratego code (source dependency), and an import of <code>flowspec/api</code>.</p> <p>Example. A Stratego module importing the FlowSpec API.</p> <pre><code>module example\n\nimports\n\nflowspec/api\n</code></pre>"},{"location":"references/flowspec/Stratego_API/#running-the-analysis","title":"Running the analysis","text":"<p>There are strategies to integrate FlowSpec analysis in the NaBL2 analysis, and strategies for doing both NaBL2 analysis and FlowSpec analysis on an AST.</p>"},{"location":"references/flowspec/Stratego_API/#integrated-into-nabl2-analysis","title":"Integrated into NaBL2 analysis","text":"<p>These can be used in the final phase of the NaBL2 analysis process using the Stratego hooks.</p> <pre><code>/**\n * Analyze the given AST with FlowSpec.\n * The FlowSpec analysis is added to given NaBL2 analysis result and returned.\n *\n * @param analysis:Analysis\n * @param propnames:String or List(String)\n * @type ast:Term -&gt; Analysis\n */\nflowspec-analyze(|analysis)\n\n/**\n * Analyze the given AST with FlowSpec, but only the given FlowSpec properties.\n * The FlowSpec analysis is added to given NaBL2 analysis result and returned.\n *\n * @param analysis:Analysis\n * @param propnames:String or List(String)\n * @type ast:Term -&gt; Analysis\n */\nflowspec-analyze(|analysis, propnames)\n</code></pre> <p>The analysis results are also usable at that point for generating editor messages. Integration with NaBL2 is done by giving the FlowSpec analysis result as the \u201ccustom final analysis result\u201d:</p> <pre><code>nabl2-custom-analysis-unit-hook:\n(resource, ast, custom-initial-result) -&gt; (resource, ast)\n\nnabl2-custom-analysis-final-hook(|a):\n(resource, custom-initial-result, custom-unit-results) -&gt; (errors, warnings, notes, custom-final-result)\nwith asts     := &lt;map(\\(ast-resource, ast) -&gt; &lt;nabl2--index-ast(|ast-resource)&gt; ast\\)&gt; custom-unit-results ; // workaround for https://yellowgrass.org/issue/NaBL2/54\ncustom-final-result := &lt;flowspec-analyze(|a)&gt; asts ;\nerrors   := ... ;\nwarnings := ... ;\nnotes    := ...\n</code></pre> <p>This propagates the AST of each unit from the unit phase, and analyzes all of them together in the final phase. The <code>custom-final-result</code> is returned so that NaBL2 preserves it for later usage. FlowSpec provides convenience functions that request the custom final result again later:</p>"},{"location":"references/flowspec/Stratego_API/#running-the-analysis-manually","title":"Running the analysis manually","text":"<p>Sometimes you need data-flow analysis between transformations which change the program. That means you need to run the analysis just before a transformation to have analysis results corresponding to the current program.</p> <p>The following strategies execute the analysis and help with consuming the resulting tuple.</p> <pre><code>/**\n * Analyze the given AST with NaBL2 and FlowSpec\n *\n * @param resource:String\n * @type ast:Term -&gt; (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage))\n */\nflowspec-analyze-ast(|resource)\n\n/**\n * Analyze the given AST with NaBL2 and FlowSpec.\n * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis.\n *\n * @param pre:Term -&gt; Term\n * @param post:Term -&gt; Term\n * @param resource:String\n * @type ast:Term -&gt; (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage))\n */\nflowspec-analyze-ast(pre,post|resource)\n\n/**\n * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties.\n *\n * @param resource:String\n * @param propnames:String or List(String)\n * @type ast:Term -&gt; (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage))\n */\nflowspec-analyze-ast(|resource, propname)\n\n/**\n * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties.\n * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis.\n *\n * @param pre:Term -&gt; Term\n * @param post:Term -&gt; Term\n * @param resource:String\n * @param propnames:String or List(String)\n * @type ast:Term -&gt; (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage))\n */\nflowspec-analyze-ast(pre,post|resource, propnames)\n\n/**\n * Take the analyze-ast 5-tuple output and return the result of applying the given strategy to the AST.\n * Note that the strategy takes the analysis object as a term argument.\n *\n * @param s(|Analysis): Term -&gt; Term\n * @type ast: (ast:Term, Analysis, errors:List(EditorMessage), warnings:List(EditorMessage), notes:List(EditorMessage)) -&gt; Term\n */\nflowspec-then(s)\n\n/**\n * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties.\n * Then return the result of applying the given strategy to the AST.\n * Note that the strategy takes the analysis object as a term argument.\n *\n * @param s(|Analysis): Term -&gt; Term\n * @param resource:String\n * @param propnames:String or List(String)\n * @type ast:Term -&gt; Term\n */\nflowspec-analyze-ast-then(s|resource, propnames)\n\n/**\n * Analyze the given AST with NaBL2 and FlowSpec, but only the given FlowSpec properties.\n * Transform the AST with pre before the FlowSpec analysis, and with post after the FlowSpec analysis.\n * Then return the result of applying the given strategy to the AST.\n * Note that the strategy takes the analysis object as a term argument.\n *\n * @param pre:Term -&gt; Term\n * @param post:Term -&gt; Term\n * @param s(|Analysis): Term -&gt; Term\n * @param resource:String\n * @param propnames:String or List(String)\n * @type ast:Term -&gt; Term\n */\nflowspec-analyze-ast-then(pre, post, s|resource, propnames)\n</code></pre>"},{"location":"references/flowspec/Stratego_API/#querying-analysis","title":"Querying analysis","text":"<p>The NaBL2 API defines several strategies to get an analysis term by resource name or from an AST node. This analysis term can then be passed to the querying strategies that give access to the data flow properties, if you hooked FlowSpec into the NaBL2 analysis process.</p> <p>The other way to get the analysis term is to execute the analysis with the flowspec-analyze-ast* variants.</p>"},{"location":"references/flowspec/Stratego_API/#control-flow-graph","title":"Control-flow graph","text":"<p>There are a number of strategies to get the control-flow graph nodes associated with an AST fragment, as well as control-flow graph navigation strategies and AST search strategies to get back to the AST from a control-flow graph node. Note that querying the control-flow graph is cheap but finding the way back from the control-flow graph to the AST is more expensive.</p> <pre><code>/**\n * Get the control flow graph node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-node(|a)\n\n/**\n * Get the control flow graph start node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-start-node(|a)\n\n/**\n * Get the control flow graph start node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-end-node(|a)\n\n/**\n * Get the control flow graph start node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-entry-node(|a)\n\n/**\n * Get the control flow graph start node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-exit-node(|a)\n\n/**\n * Get the control flow graph start node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-prev-nodes(|a)\n\n/**\n * Get the control flow graph start node associated with the given term.\n *\n * @param a : Analysis\n * @type term:Term -&gt; CFGNode\n */\nflowspec-get-cfg-next-nodes(|a)\n\n/**\n * Find AST node corresponding to the CFGNode back again\n *\n * @param ast : Term\n * @type node:CFGNode -&gt; Term\n */\nflowspec-cfg-node-ast(|ast)\n\n/**\n * Find AST node corresponding to the CFGNode back again\n *\n * @param ast : Term\n * @type pos:Position -&gt; Term\n */\nflowspec-pos-ast(|ast)\n\n/**\n * Find parent of AST node corresponding to the CFGNode back again by matching the parent with\n *  the parent argument and giving back the child that is likely to be a match to the CFG node.\n *\n * @param parent : Term -&gt; Term\n * @param ast : Term\n * @type node:CFGNode -&gt; Term\n */\nflowspec-cfg-node-ast(parent|ast)\n\n/**\n * Find parent of AST node corresponding to the CFGNode back again by matching the parent with\n *  the parent argument and giving back the child that is likely to be a match to the CFG node.\n *\n * @param parent : Term -&gt; Term\n * @param ast : Term\n * @type pos:Position -&gt; Term\n */\nflowspec-pos-ast(parent|ast)\n\n/**\n * Get the position of an AST node.\n *\n * @type Term -&gt; Position\n */\nflowspec-get-position\n</code></pre>"},{"location":"references/flowspec/Stratego_API/#data-flow-properties","title":"Data flow properties","text":"<p>FlowSpec properties can be read in two versions, pre and post. These indicate whether the effect of the cfg node has been applied yet. Whether or not it is applied depends on the direction of the analysis. pre for a forward analysis is without the effect of the node, but pre for a backward analysis includes the effect of the node.</p> <p>Note that each strategy can simply take the term that\u2019s associated with the control-flow graph node. But the control-flow graph node itself is also an accepted input.</p> <pre><code>/**\n * Get the property of the control flow graph node associated with\n * the given term. The value returned is the value of the property\n * _before_ the effect of the control flow graph node.\n *\n * @param a : Analysis\n * @param prop : String\n * @type term:Term -&gt; Term\n */\nflowspec-get-property-pre(|a, propname)\n\n/**\n * Get the property of the control flow graph node associated with\n * the given term. The value returned is the value of the property\n * _after_ the effect of the control flow graph node.\n *\n * @param a : Analysis\n * @param prop : String\n * @type term:Term -&gt; Term\n */\nflowspec-get-property-post(|a, propname)\n\n/**\n * Get the property of the control flow graph node associated with\n * the given term. The value returned is the value of the property\n * _after_ the effect of the control flow graph node. If no node\n * is found the exit control flow graph node of the AST node is\n * queried for its post-effect property value.\n *\n * @param a : Analysis\n * @param prop : String\n * @type term:Term -&gt; Term\n */\nflowspec-get-property-post-or-exit-post(|analysis-result, analysis-name)\n</code></pre>"},{"location":"references/flowspec/Stratego_API/#flowspec-data-helpers","title":"FlowSpec data helpers","text":"<p>FlowSpec sets and maps are passed back to Stratego as lists wrapped in Set and Map constructors. As a convenience, the most common operations are lifted and added to the flowspec API: <pre><code>/**\n * Check if a FlowSpec Set contains an element. Succeeds if the given strategy succeeds for at\n * least one element.\n *\n * @param s: Term -?&gt;\n * @type FlowSpecSet -?&gt; FlowSpecSet\n */\nflowspec-set-contains(s)\n\n/**\n * Look up elements in a FlowSpec Set of pairs. Returns the right elements of all pairs where\n * the given strategy succeeds on the left element.\n *\n * @param s: Term -?&gt;\n * @type FlowSpecSet -?&gt; List(Term)\n */\nflowspec-set-lookup(s)\n\n/**\n * Look up a key in a FlowSpec Map. Returns the element if the given key exists in the map.\n *\n * @param k: Term\n * @type FlowSpecMap -?&gt; Term\n */\nflowspec-map-lookup(|k)\n</code></pre></p>"},{"location":"references/flowspec/Stratego_API/#hover-text","title":"Hover text","text":"<p>For a hover implementation that displays name, type and FlowSpec properties use:</p> <pre><code>/**\n * Provides a strategy for a hover message with as much information as possible about name, type\n * (from NaBl2) and FlowSpec properties.\n */\nflowspec-editor-hover(language-pp)\n</code></pre>"},{"location":"references/flowspec/Stratego_API/#profiling-information","title":"Profiling information","text":"<pre><code>/**\n * If flowspec-debug-profile is extended to succeed, some timing information will be printed in\n * stderr when using flowspec-analyze*.\n */\nflowspec-debug-profile\n</code></pre>"},{"location":"references/flowspec/configuration/","title":"Configuration","text":"<p>We will show you how to prepare your project for use with FlowSpec, and write your first small specification.</p>"},{"location":"references/flowspec/configuration/#prepare-your-project","title":"Prepare your project","text":"<p>You can start using FlowSpec by creating a new project, or by modifying an existing project. See below for the steps for your case.</p>"},{"location":"references/flowspec/configuration/#start-a-new-project","title":"Start a new project","text":"<p>If you have not done this already, install Spoofax Eclipse, by following the installation instructions.</p> <p>Create a new project by selecting <code>New &gt; Project...</code> from the menu. Selecting <code>Spoofax &gt; Spoofax language project</code> from the list, and click <code>Next</code>. After filling in a project name, an identifier, name etc will be automatically suggested. Select <code>NaBL2</code> as the analysis type, FlowSpec builds on top of NaBL2\u2019s analysis infrastructure. Click <code>Finish</code> to create the project.</p> <p>Add the following dependencies in the metaborg.yaml file:</p> <pre><code>---\n# ...\ndependencies:\n  compile:\n  - org.metaborg:flowspec.lang:${metaborgVersion}\n  source:\n  - org.metaborg:flowspec.lang:${metaborgVersion}\n</code></pre> <p>Add menus to access the result of analysis, by adding the following import to editor/Main.esv.</p> <pre><code>module Main\n\nimports\n\n  flowspec/Menus\n</code></pre>"},{"location":"references/flowspec/configuration/#convert-an-existing-project","title":"Convert an existing project","text":"<p>If you have an existing project, and you want to start using FlowSpec, there are a few changes you need to make.</p> <p>First of all, make sure the <code>metaborg.yaml</code> file contains at least the following dependencies.</p> <pre><code>---\n# ...\ndependencies:\n  compile:\n  - org.metaborg:org.metaborg.meta.nabl2.lang:${metaborgVersion}\n  - org.metaborg:flowspec.lang:${metaborgVersion}\n  source:\n  - org.metaborg:org.metaborg.meta.nabl2.shared:${metaborgVersion}\n  - org.metaborg:org.metaborg.meta.nabl2.runtime:${metaborgVersion}\n  - org.metaborg:flowspec.lang:${metaborgVersion}\n</code></pre> <p>We will set things up, such that analysis rules will be grouped together in the directory <code>trans/analysis</code>. Create a file <code>trans/analysis/main.str</code> that contains the following.</p> <pre><code>module analysis/main\n\nimports\n\n  nabl2shared\n  nabl2runtime\n  analysis/-\n</code></pre> <p>Add the following lines to your main <code>trans/LANGUAGE.str</code>.</p> <pre><code>module LANGUAGE\n\nimports\n\n  analysis/main\n\nrules\n\n  editor-analyze = nabl2-analyze(desugar-pre)\n</code></pre> <p>If your language does not have a desugaring step, use <code>nabl2-analyze(id)</code> instead.</p> <p>Add an NaBL2 specification. The most minimal one is the following.</p> <pre><code>module analysis/minimal\n\nrules\n\ninit.\n\n[[ _ ]].\n</code></pre> <p>Running and integrating the FlowSpec analysis is explained on the Stratego API page.</p> <p>Finally, we will add reference resolution and menus to access the result of analysis, by adding the following lines to <code>editor/Main.esv</code>.</p> <p><pre><code>module Main\n\nimports\n\n  nabl2/References\n  nabl2/Menus\n  flowspec/Menus\n</code></pre> You can now continue to the example specification here, or directly to the language reference.</p>"},{"location":"references/flowspec/configuration/#inspecting-analysis-results","title":"Inspecting analysis results","text":"<p>You can debug your specification by inspecting the result of analysis.</p> <p>The result of analysis can be inspected, by selecting elements from the <code>Spoofax &gt; FlowSpec Analysis</code> the menu. For multi-file projects, use the <code>Project</code> results, or the <code>File</code> results for single-file projects. The result is given as a control-flow graph annotated with data-flow properties in the DOT format used by GraphViz. If you have GraphViz installed, you can set the <code>dot</code> executable in the settings of the graphviz editor to allow you to jump straight from Eclipse to the rendered graph.</p>"},{"location":"references/flowspec/references/","title":"References","text":""},{"location":"references/flowspec/references/#references","title":"References","text":""},{"location":"references/flowspec/structure/","title":"Structure","text":""},{"location":"references/flowspec/structure/#modules","title":"Modules","text":"<p>A module is defined by a single flowspec file. A module can contain several sections, for defining control-flow, data flow, types, and functions. Modules can import other modules.</p> <pre><code>module $module-id\n\nimports\n\n    $module-ref*\n\n$section*\n</code></pre>"},{"location":"references/flowspec/structure/#terms-and-patterns","title":"Terms and Patterns","text":"<p>FlowSpec defines various data types, including terms, tuples, sets, and maps. These can be constructed by the user, or introduced by matching on the AST.</p> <pre><code>term = ctor-id \"(\" {term \",\"}* \")\"\n     | \"(\" {term \",\"}* \")\"\n     | \"{\" {term \",\"}* \"}\"\n     | \"{\" term \"|\" {term \",\"}* \"}\"\n     | \"{\" {(term \"|-&gt;\" term) \",\"}* \"}\"\n     | \"{\" term \"|-&gt;\" term \"|\" {(term \"|-&gt;\" term) \",\"}* \"}\"\n</code></pre> <p>Examples of these terms can be found in the Expressions subsection.</p> <p>Control flow and data flow rules can use patterns to define which rules apply to which AST nodes.</p> <pre><code>pattern = ctor-id \"(\" {pattern \",\"}* \")\"\n  | \"(\" {pattern \",\"}* \")\"\n  | var-id \"@\" pattern\n  | \"_\"\n  | var-id\n</code></pre> <p>Example. The following shows an example of a pattern, matching a <code>VarDec</code> constructor with an <code>Int</code> child, binding some of the subterms. <pre><code>VarDec(n, _, num@Int(i))\n</code></pre></p>"},{"location":"references/flowspec/structure/#control-flow","title":"Control Flow","text":"<p>The control-flow section contains the rules that define the control-flow for the subject language.</p> <pre><code>control-flow rules\n\n    $control-flow-rule*\n</code></pre>"},{"location":"references/flowspec/structure/#control-flow-rules","title":"Control Flow Rules","text":"<p>A control-flow rule consists of a pattern and a corresponding list of control-flow chains.</p> <pre><code>control-flow-rule = \"root\"? pattern \"=\" {cfg-chain \",\"}+\n                  | \"node\" pattern\n\ncfg-chain = {cfg-chain-elem \"-&gt;\"}+\n\ncfg-chain-elem = \"entry\"\n               | \"exit\"\n               | variable\n               | \"node\" variable\n               | \"this\"\n</code></pre> <p>Example. Module that specifies how the control-flow for the <code>Add</code> AST node goes from the lhs, the rhs, and then to the <code>Add</code> itself. It also specifies that <code>Int</code> must have a node in the control-flow graph. <pre><code>module control\n\ncontrol-flow rules\n\n  node Int(_)\n  Add(l, r) = entry -&gt; l -&gt; r -&gt; this -&gt; exit\n</code></pre></p>"},{"location":"references/flowspec/structure/#root-rules","title":"Root Rules","text":"<p>A root of the control-flow defines the start and end nodes of a control-flow graph. You can have multiple control-flow graphs in the same AST, but not nested ones. Each control-flow graph has a unique start and end node. A root control-flow rule introduces the start and end node. In other control-flow rules these nodes can be referred to for abrupt termination.</p> <pre><code>cfg-chain-elem = ...\n               | \"start\"\n               | \"end\"\n</code></pre> <p>Example. Module that defines control-flow for a procedure, and the return statement that goes straight to the end of the procedure. <pre><code>module control\n\ncontrol-flow rules\n\n  root Procedure(args, _, body) = start -&gt; args -&gt; body -&gt; end\n  Return(_) = entry -&gt; this -&gt; end\n</code></pre></p>"},{"location":"references/flowspec/structure/#data-flow","title":"Data Flow","text":""},{"location":"references/flowspec/structure/#properties","title":"Properties","text":"<p>The data flow section contains definitions of the properties to compute, and the rules that define how these properties are computed.</p> <pre><code>properties\n\n  property-definition*\n</code></pre> <p>A property has a name, and a corresponding lattice type. The result after analysis will be a lattice of this type for each node in the control-flow graph.</p> <pre><code>property-definition = name \":\" lattice\n</code></pre> <p>Example. Lattice definition for a constant-value analysis. <pre><code>properties\n\n  values: Map[name, Value]\n</code></pre></p>"},{"location":"references/flowspec/structure/#rules","title":"Rules","text":"<p>The data flow rules specify how data should flow across the control-flow graph.</p> <pre><code>property rules\n\n  property-rule*\n</code></pre> <pre><code>property-rule = name \"(\" prop-pattern \")\" \"=\" expr\nprop-pattern = name \"-&gt;\" pattern\n             | pattern \"-&gt;\" name\n             | pattern \".\" \"start\"\n             | pattern \".\" \"end\"\n</code></pre> <p>Example. A simple specification for a constant-value analysis. <pre><code>property rules\n\n  values(_.end) = Map[string, Value].bottom\n  values(prev -&gt; VarDec(n, _, Int(i))) = { k |-&gt; v | (k |-&gt; v) &lt;- values(prev), k != n } \\/ {n |-&gt; Const(i)}\n  values(prev -&gt; VarDec(n, _, _))      = { k |-&gt; v | (k |-&gt; v) &lt;- values(prev), k != n } \\/ {n |-&gt; Top()}\n  values(prev -&gt; _) = values(prev)\n</code></pre></p>"},{"location":"references/flowspec/structure/#types","title":"Types","text":"<p>Algebraic datatypes can be defined for use within lattices definitions. Users can directly match these datatypes, or construct new values.</p> <pre><code>types\n\n  type-definition*\n</code></pre> <p>An algebraic datatype consists of a constructor and zero or more arguments. </p> <pre><code>name =\n  (\"|\" ctor-id \"(\" {type \",\"}* \")\")+\n</code></pre> <p>Example. The definition for an algebraic type <code>ConstProp</code> used in constant value analysis.</p> <pre><code>types\n\n  ConstProp =\n  | Top()\n  | Const(int)\n  | Bottom()\n</code></pre>"},{"location":"references/flowspec/structure/#lattices","title":"Lattices","text":"<p>Lattices are the main data type used in data-flow analysis, because of their desirable properties. Properties (the analysis results) must always be of type lattice. FlowSpec contains some builtin lattice types, but users can also specify their own.</p> <pre><code>lattices\n\n  lattice-definition*\n</code></pre> <p>Lattice definitions must include the following: the underlying datatype, a join operator (either least-upper bound or greatest-lower bound), a top, and a bottom.</p> <pre><code>name where\n  type = type\n  lub([name], name) = expr\n  top = expr\n  bottom = expr\n</code></pre> <p>Example. A lattice definition using the <code>ConstProp</code> above to define a <code>Value</code> type.</p> <pre><code>lattices\n  Value where\n    type = ConstProp\n    bottom = Bottom()\n    top = Top()\n    lub(l, r) = match (l, r) with\n      | (Top(), _) =&gt; Top()\n      | (_, Top()) =&gt; Top()\n      | (Const(i), Const(j)) =&gt; if i == j then Const(i) else Top()\n      | (_, Bottom()) =&gt; l\n      | (Bottom(), _) =&gt; r\n</code></pre>"},{"location":"references/flowspec/structure/#functions","title":"Functions","text":"<p>Functions make it possible to reuse functionality and avoid duplication of logic.</p> <pre><code>functions\n\n  function-definition*\n</code></pre> <pre><code>name([{(name \":\" type) \",\"}+]) =\n  expr\n</code></pre>"},{"location":"references/flowspec/structure/#expressions","title":"Expressions","text":""},{"location":"references/flowspec/structure/#integers","title":"Integers","text":"<p>Integer literals are written with an optional minus sign followed by one or more decimals.</p> <p>Supported integer operations are:</p> <ul> <li>Addition [<code>+</code>]</li> <li>Subtraction [<code>-</code>]</li> <li>Multiplication [<code>*</code>]</li> <li>Division [<code>/</code>]</li> <li>Modulo [<code>%</code>]</li> <li>Negate [<code>-</code>]</li> <li>Comparison [<code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>==</code>, <code>!=</code>]</li> </ul>"},{"location":"references/flowspec/structure/#booleans","title":"Booleans","text":"<p>Boolean literals true and false are available as well as the usual boolean operations:</p> <ul> <li>And [<code>&amp;&amp;</code>]</li> <li>Or [<code>||</code>]</li> <li>Not [<code>!</code>]</li> </ul>"},{"location":"references/flowspec/structure/#sets-and-maps","title":"Sets and Maps","text":"<p>Set and map literals are both denoted with curly braces. A set literal contains a comma-separated list of elements: <code>{elem1, elem2, elem3}</code>. A map literal contains a comma-separated list of bindings of the form key |-&gt; value: <code>{ key1 |-&gt; value1, key2 |-&gt; value2 }</code>.</p> <p>Operations on sets and maps include</p> <ul> <li>Union [<code>\\/</code>]</li> <li>Intersection [<code>/\\</code>]</li> <li>Set/map minus [<code>\\</code>]</li> <li>Containment/lookup [<code>in</code>]</li> </ul> <p>There are also comprehensions of the form <code>{ new | old &lt;- set, conditions }</code> or <code>{ newkey |-&gt; newvalue | oldkey |-&gt; oldvalue &lt;- map, condition }</code>, where new elements or bindings are gathered based on old ones from a set or map, as long as the boolean condition expressions hold. Such a condition expression may also be a match expression without a body for the arms. This is commonly used to filter maps or sets.</p> <p>Example. The following are some examples of sets and maps. <pre><code>// A map comprehension filtering the key n\n{ k |-&gt; v | (k |-&gt; v) &lt;- values(prev), k != n }\n\n// A map literal\n{n |-&gt; Top()}\n\n// A set comprehension filtering the value n\n{ k | k &lt;- live(prev), k != n }\n\n// A set literal\n{ n, \"b\", \"foo\" }\n</code></pre></p>"},{"location":"references/flowspec/structure/#match","title":"Match","text":"<p>Pattern matching can be done with a match expression: <code>match expr with | pattern1 =&gt; expr2 | pattern2 =&gt; expr2</code>, where expr are expressions and pattern are patterns. Terms and patterns are defined at the start of the reference.</p>"},{"location":"references/flowspec/structure/#variables-and-references","title":"Variables and References","text":"<p>Pattern matching can introduce variables. Other references include values in the lattice, such as <code>MaySet.bottom</code> or <code>MustSet.top</code>.</p>"},{"location":"references/flowspec/structure/#functions-and-lattice-operations","title":"Functions and Lattice Operations","text":"<p>User defined functions are invoked with <code>functionname(arg1, arg2)</code>. Lattice operations can be similarly invoked, requiring the type name: <code>MaySet.lub(s1, s2)</code>.</p>"},{"location":"references/flowspec/structure/#property-lookup","title":"Property Lookup","text":"<p>Property lookup is similar to a function call, although property lookup only ever has a single argument.</p> <p>Example. The following property rule performs a set comprehension over the results of a property lookup, <code>live(prev)</code>, where the property <code>live</code> has been declared in the <code>properties</code> section, and <code>next</code> is bound in the pattern. <pre><code>live(VarDec(n, _, _) -&gt; next) = { k | k &lt;- live(next), k != n }\n</code></pre></p>"},{"location":"references/flowspec/structure/#term-positions","title":"Term Positions","text":"<p>FlowSpec provides a builtin function that returns the position of a term: <code>position(term)</code>. This can be used to differentiate two terms from an AST that are otherwise equal.</p>"},{"location":"references/flowspec/structure/#lexical-grammar","title":"Lexical Grammar","text":""},{"location":"references/flowspec/structure/#identifiers","title":"Identifiers","text":"<p>Most identifiers in FlowSpec fall into one of two categories, which we will refer to as:</p> <pre><code>Lowercase identifiers, that start with a lowercase character, and must match the regular expression [a-z][a-zA-Z0-9]*.\nUppercase identifiers, that start with an uppercase character, and must match the regular expression [A-Z][a-zA-Z0-9]*.\n</code></pre>"},{"location":"references/flowspec/structure/#comments","title":"Comments","text":"<p>Comments in FlowSpec follow C-style comments:</p> <pre><code>// ... single line ... for single-line comments\n/* ... multiple lines ... */ for multi-line comments\n</code></pre> <p>Multi-line comments can be nested, and run until the end of the file when the closing */ is omitted.</p>"},{"location":"references/flowspec/testing/","title":"Testing","text":""},{"location":"references/flowspec/testing/#testing","title":"Testing","text":""},{"location":"references/pipelines/","title":"Pipelines for Interactive Environments","text":"<p>Pipelines for interactive Environments (PIE) is the build system for Spoofax 3. PIE consists of two parts: a Java framework, a Java runtime and the PIE Domain Specific Language (DSL). This reference documentation is for the PIE DSL and will only provide some high level information about the framework and runtime to provide context.</p> <p>PIE uses tasks to compose pipelines. Each task has 0 or more inputs and one output. Each task can depend on files or on other tasks. Tasks can be marked as explicitly observed to indicate that we want the output of these tasks to stay up to date. The PIE runtime executes tasks incrementally, which means that it only executes tasks that are no longer up to date and that are required for a task which is explicitly observed.</p> <p>Tasks can be written in Java, but this involves a lot of boilerplate. Tasks can also be written in the PIE DSL. The PIE DSL is specifically made for PIE, so it has little boilerplate. Tasks written in the PIE DSL are compiled to Java.</p>"},{"location":"references/pipelines/#the-pie-dsl","title":"The PIE DSL","text":"<p>PIE models a pipeline as tasks that call each other. The PIE DSL calls these tasks \"functions\", because each task has inputs and an output. A PIE DSL program consists of one or more files.</p>"},{"location":"references/pipelines/#file-structure","title":"File structure","text":"<pre><code>module fully:qualified:moduleName\n\nimport fully:qualified:name:of:another:module\nimport org:example:multipleDefs:{func1, func2 as other, aDataTypeAsWell}\nimport org:example:languages:{java, cpp, sql}:spoofax:{parse, analyze, compile}\n\ndata coolDataType = foreign java org.example.MyFirstJavaClass {\n    func aMethod(int) -&gt; bool\n}\n\nfunc greetWorld() -&gt; string = \"Hello world!\"\n</code></pre> <p>PIE DSL files contain a module statement, imports, and data and function definitions. The module statement declares the fully qualified name of the module. Imports are optional and import datatypes and function from other modules. They can import multiple functions or datatypes at the same time, and they can rename elements. Data and function definitions define functions and datatypes.</p>"},{"location":"references/pipelines/#directory-structure-and-module-system","title":"Directory structure and module system","text":"<p>PIE files have the extension <code>.pie</code>. Each PIE file forms a module. Modules can define functions and datatypes, and can import functions and datatypes from other modules. It is recommended to use the same name for the module as the path and filename, but this is not required. As such, the PIE DSL does not place any restrictions on paths and file names besides the standard restrictions for Spoofax languages.  The module system is described in Modules.</p>"},{"location":"references/pipelines/#types-and-data-definitions","title":"Types and data definitions","text":"<p>The PIE DSL is a statically typed language. There are a few built-in types, such as <code>int</code> and <code>path</code>. Built-in types use lowercase characters. Custom datatypes can currently only be imported from Java as foreign definitions. The types in the PIE DSL are described in Types. The PIE DSL also supports generic datatypes. These follow Java semantics. The semantics of generics can be found in Generics.</p>"},{"location":"references/pipelines/#function-definitions","title":"Function definitions","text":"<p>Functions express task definitions. Functions consist of a head and an implementation.</p> <pre><code>func $FuncHead = $FuncImpl\n\nfunc greet(name: string) -&gt; string = \"Hello ${name}!\"\nfunc doSomethingDifficult() -&gt; path = foreign org.example.DoSomethingDifficult\nfunc callJavaStaticFunction() -&gt; bool =\n  foreign java fully.qualified.java.ClassName#staticMethodName\nfunc createCustomType() -&gt; CustomType =\n  foreign java constructor org.example.CustomType\n</code></pre> <p>The function head describes the signature of the function: the name, the input parameter types and the output type. All functions can be called the same way regardless of their implementation. The function implementation describes the way a function is implemented. A function can be implemented in PIE by providing an expression, as can be seen with <code>greet</code> Expressions are described in Expressions. A function can also be implemented in Java. The three ways this can be done are shown in the example as well. A complete overview of functions is given in Functions.</p>"},{"location":"references/pipelines/#misc-information","title":"Misc information.","text":"<p>Java and C use the function called <code>main</code> with a certain signature as the entry point to the program. A PIE program does not have a set entry point. The entry point is whatever function is called from the PIE runtime.</p>"},{"location":"references/pipelines/expressions/","title":"Expressions","text":"<p>Function bodies in PIE DSL consist entirely of expressions. Every expression has a type and returns a value of that type, with the exception of <code>fail</code> and <code>return</code>.</p> <p>Expressions can use brackets to override the default priority rules, for example <code>a &amp;&amp; (b || c)</code>. Brackets have the following form: <code>($Exp)</code></p> <p>This section describes expressions in the PIE DSL. Expressions can use declared values. These are described in this section of the functions documentation.</p>"},{"location":"references/pipelines/expressions/#syntactic-priorities-disambiguation","title":"Syntactic priorities (disambiguation)","text":"<p>Nested expressions can be ambiguous, for example <code>! true &amp;&amp; false</code> could either <code>! (true &amp;&amp; false) // = true</code> or <code>(!true) &amp;&amp; false // = false</code>. To solve these ambiguities, each expression has a priority. Expressions with higher priories will be nested in expressions with lower priority. The example above is parsed as <code>(!true) &amp;&amp; false</code> because not has a higher priority than logical and. All expressions are left-associative, which means that if two expressions with the same priority are ambiguous, the leftmost expression will be nested in the rightmost expression. For example, <code>3 - 2 + 1</code> is equivalent to <code>(3 - 2) + 1</code>.</p> <p>The following list lists expressions in order of descending priority. Expressions on the same number have the same priority. If an expression is not listed, it cannot be ambiguous (e.g. Blocks and list literals)</p> <ol> <li>Not</li> <li>Make nullable, Make non-nullable</li> <li>Addition</li> <li>Compare for (in)equality</li> <li>Logical and</li> <li>Logical or</li> <li>list, walk</li> <li>requires, generates</li> <li>read, exists</li> <li>Function calls, Method calls, Create supplier, Task supplier</li> <li>Filters</li> <li>Tuple literal, List literal</li> <li>List comprehension</li> <li>Value declaration</li> <li>return, fail</li> <li>if-else</li> <li>if</li> </ol>"},{"location":"references/pipelines/expressions/#quick-overview","title":"Quick overview","text":"<p>The following table gives a quick overview of all expressions in the PIE DSL.</p> name syntax example description type Block <code>{$Exps}</code> <code>{val x = 4; x+7}</code> A sequence of expressions The type of the last expression Make nullable <code>$Exp?</code> <code>\"nullable string\"?</code> Makes the type <code>T</code> of an expression nullable (<code>T?</code>) When applied to an expression of type <code>T</code>, <code>T?</code> Make non-nullable <code>$Exp!</code> <code>input!</code> Makes the type <code>T?</code> of an expression non-nullable (<code>T</code>). Throws an exception if the value is null When applied to an expression of type <code>T?</code>, <code>T</code> Not <code>!$Exp</code> <code>!flag</code> Turns <code>false</code> to <code>true</code> and vice versa bool Compare for (in)equality <code>$Exp == $Exp</code> and <code>Exp != $Exp</code> <code>result == null</code>, <code>errors != []</code> Compares two values for (in)equality bool Logical or <code>$Exp || $Exp</code> <code>dryRun || input == null</code> Is <code>true</code> unless both the values are <code>false</code> bool Logical and <code>$Exp &amp;&amp; $Exp</code> <code>!dryRun &amp;&amp; input != null</code> Is <code>true</code> iff both values are <code>true</code> bool Addition <code>$Exp + $Exp</code> <code>x + y</code> Adds or concatenates two values Depends on the types of the expressions Value declaration <code>val $VALID TypeHint? = $Exp</code> <code>val num: int = 47</code> Declare a value by name The type of the declared value Value reference <code>$VALID</code> <code>x</code> Reference a value or parameter The type of the referenced value if <code>if ($Exp) $Exp</code> <code>if (input == null) fail \"Input is null\"</code> Evaluates the body if the condition evaluates to <code>true</code> unit if-else <code>if ($Exp) $Exp else $Exp</code> <code>if (name != null) name else default</code> Evaluates the first branch if the condition is <code>true</code>, and the second branch otherwise The least upper bound of the types of the branches List comprehension <code>[$Exp | $Binder &lt;- $Exp]</code> <code>[\"Key: $key; value: $value\" | (key, value) &lt;- pairs]</code> Evaluate the expression for each element in a list A list of the type of the expression Function calls <code>$ModuleList$FUNCID$TypeArgs($Exps)</code> <code>stdLib:okResult&lt;string&gt;(\"Hello world!\")</code> Call a function The return type of the function Method calls <code>$Exp.$FUNCID$TypeArgs($Exps)</code> <code>file.replaceExtension(\"pp.pie\")</code> Call a method The return type of the method Create supplier <code>supplier$TypeArgs($Exps)</code> <code>supplier(47)</code> Create a supplier A supplier of the provided type Task supplier <code>$ModuleList$FUNCID.supplier$TypeArgs($Exps)</code> <code>lang:java:parse.supplier(file)</code> Create a supplier from a function A supplier of the return type of the function requires <code>requires $Exp $FilterPart? $StamperPart?</code> <code>requires ./metaborg.yaml by hash</code> Declare that the current task depends on the provided path unit generates <code>generates $Exp $StamperPart?</code> <code>generates file by hash</code> Declare that the current task generates on the provided path unit list <code>list $Exp $FilterPart?</code> <code>list ./examples with extension \"pie\"</code> Lists the direct children of the given directory. Note: for list literals, see further down this table. A list of paths, i.e. <code>path*</code> walk <code>walk $Exp $FilterPart?</code> <code>walk ./examples with extension \"pie\"</code> Recursively get all descendants of the given directory A list of paths, i.e. <code>path*</code> exists <code>exists $Exp</code> <code>exists ./config.json</code> Check if a file exists bool read <code>read $Exp</code> <code>read ./config.json</code> Returns the file contents as a string, or null if the file does not exist A nullable string, i.e. <code>string?</code> return <code>return $Exp</code> <code>return false</code> Returns the provided value from the current function unit. Note: may get changed to bottom type fail <code>fail $Exp</code> <code>fail \"input cannot be null\"</code> Throws an ExecException with the provided string as message unit. Note: may get changed to bottom type Unit literal <code>unit</code> <code>unit</code> Literal expression of the only value of the unit type unit true <code>true</code> <code>true</code> Literal expression for the boolean value <code>true</code>. bool false <code>false</code> <code>false</code> Literal expression for the boolean value <code>false</code>. bool int literal <code>\"-\"? [0-9]+</code> <code>0</code>, <code>23</code>, <code>-4</code> A literal value of the int type int null <code>null</code> <code>null</code> Literal expression for the null value of nullable types. null type Tuple literal <code>($Exps)</code> <code>(1, \"one\", \"une\")</code> A literal value of a tuple type A tuple type of the types of the elements List literal <code>[$Exps]</code> <code>(1, 2, 3)</code> A literal value of a list type. For the keyword <code>list</code>, see earlier in this table. A list of the least upper bound of the types of the elements String literal <code>\"$StrParts\"</code> <code>\"Hello $name!\"</code> A literal value of the string type string Path literal <code>$PathStart$PathParts</code> <code>./src/test/resources</code> A literal value of the path type path <p>There is also a section on common lexical elements. This covers filters and stampers.</p>"},{"location":"references/pipelines/expressions/#block","title":"Block","text":"<p>Blocks are expressed as <code>{$Exps}</code>, where <code>$Exps</code> is a list of semi-colon separated expressions. Its type and value are those of the final expressions in the block. The final expression does not end with a semi-colon. For example: <pre><code>{\n  val name = read ./example/name.txt;\n  val greeting = read ./example/greeting.txt;\n  \"$greeting $name\"\n}\n</code></pre></p> <p>Empty blocks (blocks without any expression) are allowed, their type and value is <code>unit</code>.</p> <p>Blocks introduce their own scope. Expressions in the block are evaluated in that scope. Values declared in the block are not allowed to shadow values or parameters outside the block. This means that it is not allowed to declare a value with a name that already exists. Values declared before the block are still visible inside the block. Values declared inside the block are not visible after the block.</p>"},{"location":"references/pipelines/expressions/#make-nullable","title":"Make nullable","text":"<p>Make nullable is expressed as a question mark after an expression. As its name suggests, it makes a non-nullable expression nullable. The value remains unchanged, but the type of the expression is now nullable. Its syntax is <code>$Exp?</code>, for example <code>read ./name.txt == \"Bob\"?</code>.</p> <p>It is an error to use this expression on an expression that was nullable already.</p>"},{"location":"references/pipelines/expressions/#make-non-nullable","title":"Make non-nullable","text":"<p>Make non-nullable is expressed as an exclamation mark after an expression. As its name suggests, it makes a nullable expression non-nullable. The value remains unchanged, but the type of the expression is now non-nullable. Its syntax is <code>$Exp!</code>, for example <code>read file!</code>.</p> <p>It is an error to use this expression on an expression that was non-nullable already.</p>"},{"location":"references/pipelines/expressions/#not","title":"Not","text":"<p>Logical negation. It takes a boolean expression and returns the opposite boolean value. Its syntax is <code>!$Exp</code>, for example <code>if (!exists file) fail \"$file should exist</code>.</p>"},{"location":"references/pipelines/expressions/#compare-for-inequality","title":"Compare for (in)equality","text":"<p>Compare two expressions for equality or inequality. Two values are considered equal if they are both <code>null</code> or if the <code>equals</code> method in the backing Java class for the first value returns <code>true</code> when applied to the second value. Otherwise, they are considered in-equal. The syntax for equals is <code>$Exp == $Exp</code>, for example <code>x == null</code>. The syntax for in-equals is <code>$Exp != $Exp</code>, for example <code>x != null</code>.</p> <p>Expressions can only be compared if one is a non-strict subtype of the other. This provides protection against accidentally comparing two expressions that can never be equal.</p> Comparing <code>null</code> and empty lists <p>Expressions with nullable types can have equal values despite not being subtypes of each other, if they are both <code>null</code>. The same goes for list types with the empty list <code>[]</code>. In these cases, check for these specific values: <code>x == null &amp;&amp; y == null</code>.</p>"},{"location":"references/pipelines/expressions/#logical-or","title":"Logical or","text":"<p>Logical or. Takes two boolean expressions and returns <code>true</code> if either of them is <code>true</code> and <code>false</code> if both are <code>false</code>. This operator short-circuits if the first expression is <code>true</code>, in which case the second expression will not be evaluated. Its syntax is <code>$Exp || $Exp</code>, for example <code>exists file || default != null</code>.</p>"},{"location":"references/pipelines/expressions/#logical-and","title":"logical and","text":"<p>Logical and. Takes two boolean expressions and returns <code>true</code> if both of them are <code>true</code> and <code>false</code> if either of them is <code>false</code>. This operator short-circuits if the first expression is <code>false</code>, in which case the second expression will not be evaluated. Its syntax is <code>$Exp &amp;&amp; $Exp</code>, for example <code>configFile != null &amp;&amp; exists configFile</code>.</p>"},{"location":"references/pipelines/expressions/#addition","title":"Addition","text":"<p>The add operator is an overloaded in the PIE DSL. Its syntax is <code>$Exp + $Exp</code>.</p> <p>The type of adding two values depends on their static types. Adding two <code>int</code>s uses mathematical plus: <code>1 + 2 // result: 3</code>, and the result is an <code>int</code> as well.</p> <p>Adding any value to a <code>string</code> converts the value to a <code>string</code> and then concatenates the strings, resulting in a <code>string</code>: <code>\"The value is:\"  + x</code>.</p> String interpolation <p>It might be clearer to use string interpolation.</p> <p>Adding a <code>string</code> or a <code>path</code> to a relative <code>path</code> concatenates the values and results in a new <code>path</code>: <code>projectDir + ./src/test/resources/</code> Adding a <code>string</code> or a <code>path</code> to an absolute path results in a runtime error.</p> Path interpolation <p>It might be clearer to use path interpolation.</p> <p>Finally, adding a type <code>T2</code> to a list with type <code>T1*</code> has two cases</p> <ul> <li>If <code>T2</code> is a list as well both lists will be concatenated.   The element type of <code>T2</code> must be a subtype of <code>T1</code>.</li> </ul> Adding a list as an element <p>To add a list <code>list: T*</code> as an element to a list of lists <code>lists: T**</code>, wrap the list in another list: <code>lists + [list]</code></p> Empty lists <p>The PIE DSL keeps track of empty lists statically. This allows it to give a warning when concatenating an empty list: <code>[1, 2, 3] + []</code> will give a warning.</p> <ul> <li>All other cases will append the second item to the first list.   <code>T2</code> must be a (non-strict) subtype of <code>T1</code>.   The element type of the resulting list is <code>T1</code>, unless <code>T2</code> is the null type.   In that case, the element type of the resulting list is nullable as well.</li> </ul>"},{"location":"references/pipelines/expressions/#value-declaration","title":"Value declaration","text":"<p>Value declarations declare one or more named values. Expressions that are evaluated afterwards in the same scope or an inner scope can use the declared values by referencing them. For more information on values, see parameters and values.</p> <p>A basic value declaration declares a name with a value: <code>val x = 9</code>. It is possible to give a type hint with the name: <code>val y: int? = 8</code>. When a type hint is given, the type of the expression must be assignable to the type of the type hint. The type of the declared value is the provided type from the type hint, or the type of the expression if there is no type hint. A value declaration can also do tuple destructuring and assign its values to multiple variables at once: <code>val (name: string, times: int*) = getPerformance(id)</code>. Each name in a tuple destructuring can have a type hint. Tuple destructuring cannot be nested, so the following will not parse: <code>val (a, (b, c)) = (1, (2, 3))</code>.</p> Some examples of value declarations <pre><code>val firstName = \"Bob\"; // simple value declaration\nval age: int = 27; // with type hint\nval size: (int, int) = (800, 400); // assign tuple to single value.\nval (width, height) = size; // tuple destructuring\n// tuple destructuring with type hints\nval (name: string, in: path, out: path) = (\"expressions\", ./in/expressions.pie, ./out/expressions.java);\n// tuple destructuring with mixed type hints\nval (year, values: (string, bool)*) = (2020, []);\n</code></pre> <p>Value declarations have the following syntax: <code>val $Binder = $Exp</code>, where the binder can be either a single binder <code>$Bind</code> or tuple binder <code>($Binds)</code>, and binds can be only a name <code>$VALID</code> or a name with a type hint <code>$VALID: Type</code>.</p> <p>The type of a value declaration is the type of the variable(s) that it declares. It uses the type hint if available and the expression type otherwise. Single declarations have that single type, tuple declarations return a tuple of all the types that they declare.</p>"},{"location":"references/pipelines/expressions/#value-reference","title":"Value reference","text":"<p>Value references reference a declared value or parameter by name. The name must be declared beforehand in the current scope or an outer scope. The type and value of a value reference is the type and value of the referenced value. The syntax is <code>$VALID</code>, for example: <pre><code>func incrementInefficiently(x: int) -&gt; int = {\n    val y = 1;\n    val res = x + y; // reference parameter x and value y\n    res // reference value res\n}\n</code></pre></p>"},{"location":"references/pipelines/expressions/#if","title":"if","text":"<p>An if expression conditionally evaluates an expression. It takes two expressions. The first one is the condition and is of type boolean. The second one is the body and can have any type. Its syntax is <code>if ($Exp) $Exp</code>, for example <code>if (text == null) fail \"Could not read $file\"</code>. If the condition evaluates to <code>true</code>, the body is evaluated, otherwise not. The type of an <code>if</code> expression is the <code>unit</code> type. The condition and body are evaluated in their own scope, so value declarations in an <code>if</code> expression are not visible after the <code>if</code>. Because an if expression is evaluated in its own scope and always returns the same value, the only use for an <code>if</code> expression is if the body has side-effects.</p>"},{"location":"references/pipelines/expressions/#if-else","title":"if-else","text":"<p>Conditionally evaluates one of two expressions. It takes three expressions. The first one is the condition and is of type boolean. The second one is the true-branch and can have any type. The third one is the false-branch and can also have any type. Its syntax is <code>if ($Exp) $Exp else $Exp</code>, for example <code>if (name != null) name else default</code>. If the condition evaluates to <code>true</code>, the true-branch is evaluated, otherwise the false-branch is evaluated. The type of an if-else expression is the least upper bound of both branches. The condition and branches are evaluated in their own scope, so value declarations in an if-else expression are not visible after the expression.</p> Some examples of the least upper bound of different types <pre><code>val cat1: Cat = getCat(1);\nval cat2: Cat = getCat(2);\nval mammal: Mammal = getMammal();\nval animal: Animal = getAnimal();\nval dog: Dog = getDog();\nval fish: Fish = getFish();\nval animal1: Animal = getAnimal(1);\nval animal2: Animal = getAnimal(2);\nval catBox1: Box&lt;Cat&gt; = box(cat1);\nval catBox2: Box&lt;Cat&gt; = box(cat2);\nval anyBox1: Box&lt;_&gt; = box(animal1);\nval anyBox2: Box&lt;_&gt; = box(catBox2);\n\n// same type\nif (flag) \"hello\" else \"world\"  // type: string\nif (flag) 0 else 10             // type: int\nif (flag) cat1 else cat2        // type: Cat\nif (flag) animal1 else animal2  // type: Animal\nif (flag) catBox1 else catBox2  // type: Box&lt;Cat&gt;\nif (flag) anyBox1 else anyBox2  // type: Box&lt;_&gt;\n\n// subtypes\nif (flag) cat else mammal       // type: Mammal\nif (flag) catBox else anyBox    // type: Box&lt;_&gt;\n\n\n// different types\nif (flag) cat1 else dog         // type: Mammal\nif (flag) dog else cat2         // type: Mammal\nif (flag) cat2 else fish        // type: Animal\nif (flag) \"hello\" else 2        // type: top type\n</code></pre>"},{"location":"references/pipelines/expressions/#list-comprehension","title":"List comprehension","text":"<p>List comprehensions apply an expression to every element of a list and return a new list with the new elements. They are special syntax for mapping a list, which would not ordinarily be possible in the PIE DSL because there are no higher-order functions. They have the syntax <code>[$Exp | $Binder &lt;- $Exp]</code>, for example <code>[\"Key: $key; value: $value\" | (key, value) &lt;- pairs]</code> The last expression is the input list and must have type <code>T*</code> for some <code>T</code>. The binder defines names for the elements. It can either be a single binder to bind the complete element, or a tuple binder if the element is a tuple, see value declarations for more explanation The first expression can use the names defined by the binder. The type of that expression is some type <code>Q</code>. The type of the full list comprehension is a list of the type that was mapped to, i.e. <code>Q*</code>.</p> Empty lists <p>A list comprehension over an empty list simply returns a new empty list. A list comprehension will give a warning if the input list is statically known to be empty. List comprehensions over empty lists are compiled to an immediate empty list of the declared type because it is not known what the element type of the empty list is.</p>"},{"location":"references/pipelines/expressions/#function-calls","title":"Function calls","text":"<p>Function calls invoke a declared function. They have the syntax <code>$ModuleList$FUNCID$TypeArgs($Exps)</code>, for example <code>stdLib:okResult&lt;string&gt;(\"Hello world!\")</code>. The second element is the function name. This function name can either be qualified or left unqualified by the module list. If it is unqualified, the function name must be defined in the current module or be imported with a function import. If it is qualified, the function is looked up in that module. The number of type arguments must match the number of type parameters on the function declaration, and the type arguments must be within bounds for the type parameters. The expressions are the arguments to the function. They must match the number of parameters that the function declared and they must be subtypes of the parameters.</p> <p>The type of a call is the type of the declared function, where type parameters are replaced with their corresponding type arguments.</p> Return type is a generic parameter <pre><code>func id&lt;T&gt;(param: T) -&gt; T = param\nfunc test() -&gt; unit = {\n    id&lt;string&gt;(\"Hello world!\"); // type is string\n    id&lt;int&gt;(42);                // type is int\n    unit\n}\n</code></pre> Arguments can declare values <p>Value declarations in the arguments are legal and are visible after the call. Doing this is bad practice in almost all cases. Declare the value before the call instead. For example: <pre><code>// declares the value `x` with value 9\n// also passes 9 as argument to `test`\ntest(val x = 9);\nx // x is visible after the call.\n</code></pre> Better way: <pre><code>val x = 9; // declare before call\ntest(x); // refer to declared value\nx\n</code></pre></p>"},{"location":"references/pipelines/expressions/#method-calls","title":"Method calls","text":"<p>Method calls invoke a declared method. They have the syntax <code>$Exp.$FUNCID$TypeArgs($Exps)</code>, for example <code>file.replaceExtension(\"pp.pie\")</code>. The first element is an arbitrary expression. The second element is the method name. This method is looked up on the type of the first expression. The number of type arguments must match the number of type parameters on the method declaration, and the type arguments must be within bounds for the type parameters. The expressions are the arguments to the method. They must match the number of parameters that the method declared and they must be subtypes of the parameters.</p> <p>The type of a method call is the type of the declared method, where type parameters are replaced with their corresponding type arguments.</p> No methods on nullable types <p>There are no methods defined on nullable types. To access the methods of the inner type, cast the expression to non-nullable first: <pre><code>val maybe: Result&lt;string, _ : Exception&gt; = null;\nmaybe.unwrap(); // error: Cannot call method on nullable type\nmaybe!.unwrap(); // type checks, but will throw a run time exception\n\n// Better: handle null value before casting\nif (maybe == null) {\n    // handle null value here\n    \"Cannot get value, result is null\"\n} else {\n    maybe!.unwrap()\n}\n</code></pre></p> Return type is a generic parameter <pre><code>data Box&lt;T&gt; = foreign java org.example.methodCall.Box {\n    func get() -&gt; T\n}\nfunc test(box1: Box&lt;int&gt;, box2: Box&lt;bool&gt;) -&gt; unit = {\n    box1.get(); // type is int\n    box2.get(); // type is bool\n    unit\n}\n</code></pre> Expression and arguments can declare values <p>Value declarations in the expression or the arguments are legal and are visible after the call. Declarations in the expression are also visible to the expressions. Doing this is bad practice in almost all cases. Declare the value before the call instead. For example: <pre><code>// declares the value `name` and `msg`\n// also passes 9 as argument to `test`\n// Note: getName returns an stdLib:Result&lt;string, _ : Exception&gt;\n(val name = getName()).unwrapOrDefault(\n  // `name` is visible inside the arguments\n  val msg = \"Could not get name, exception: ${if (val ok = name.isOk())\n      \"No error\"\n    else\n      name.unwrapErr()\n    }\"\n);\n(name, ok, msg); // `name`, `ok` and `message` are visible after the call.\n</code></pre> Better way: <pre><code>val name = getName();\nval ok = name.isOk();\nval msg = if (ok)\n  \"Could not get name, exception: No error\"\nelse\n  \"Could not get name, exception: ${name.unwrapErr()}\"\n</code></pre></p>"},{"location":"references/pipelines/expressions/#create-supplier","title":"create supplier","text":"<p>A supplier for a value can be created with the <code>supplier</code> keyword. It has the syntax <code>supplier$TypeArgs($Exps)</code>, for example <code>supplier(47)</code> or <code>supplier&lt;string&gt;(\"Hello world!\")</code>. The type arguments can either be omitted or must be a single type argument. The expressions are the arguments for the supplier. There should be only one argument, the value that the supplier will supply. The type <code>T</code> for the supplier is the type argument if it was provided, or the type of the argument otherwise. In case a type argument is provided, the argument should be a subtype of that type argument. The type of a supplier creation expression is <code>supplier&lt;T&gt;</code>.</p> Supplier can be treated as a normal function <p>Creating a supplier is like a normal function call, but built into the language grammar for implementation reasons. This is the only function call where the type argument is derived at the moment.</p>"},{"location":"references/pipelines/expressions/#task-supplier","title":"task supplier","text":"<p>A task supplier expression creates a supplier from a function. A task supplier expression does not execute the task yet, but instead defers it until the supplier's <code>get</code> method is called. It has the syntax <code>$ModuleList$FUNCID.supplier$TypeArgs($Exps)</code>, for example <code>lang:java:parse.supplier(file)</code>. The second element is the function name. This function name can either be qualified or left unqualified by the module list. If it is unqualified, the function name must be defined in the current module or be imported with a function import. If it is qualified, the function is looked up in that module. The number of type arguments must match the number of type parameters on the function declaration, and the type arguments must be within bounds for the type parameters. The expressions are the arguments to the function. They must match the number of parameters that the function declared and they must be subtypes of the parameters.</p> <p>The type of a task supplier expression is <code>supplier&lt;T&gt;</code>, where <code>T</code> is the type of the declared function with the type parameters replaced with their corresponding type arguments.</p>"},{"location":"references/pipelines/expressions/#requires","title":"requires","text":"<p>A requires expression expresses that the current task depends on the given path. It has the syntax <code>requires $Exp $FilterPart? $StamperPart?</code>, for example <code>requires ./metaborg.yaml by hash</code> or <code>requires sampleDir with extension \"sdf3\"</code>. The expression is the path to depend on. The filter part is optional and adds a filter to filter out any paths that do not match the filter. It is described in the section on common lexical elements. The stamper part is also optional and provides a way to determine if a file or path is up-to-date. It is also described in the section on common lexical elements.</p> <p>The type and value of the expression is unit.</p> <p>Exceptions?</p> <p>What happens if there is another task that provides the path? Does it quietly schedule that task before this one, does it throw an error? What if that other task runs after this task?</p>"},{"location":"references/pipelines/expressions/#generates","title":"generates","text":"<p>Marks the given path as provided by the current task. It has the syntax <code>generates $Exp $StamperPart?</code>, for example <code>generates file by hash</code>. The expression is the path to depend on. The stamper part is optional and provides a way to determine if a file or path is up-to-date. It is described in the section on common lexical elements.</p> <p>The type and value of this expression is unit.</p> <p>Make file modifications before using this expression</p> <p>The contents or metadata of the file at the time that this expression is called may be cached and used for incrementality. Make all modifications to the file before using this expression.</p> <p>Exceptions?</p> <p>Can this mark a directory as provided or only a file? What happens when two tasks generate a file? What happens when this task declares it generates a file after another task has already used it? Can a task both require and provide a file? What happens if this task calls a task that provides a file and then this task also declares it generated that file?</p>"},{"location":"references/pipelines/expressions/#list","title":"list","text":"<p>Defining list literals</p> <p>This section is about listing children of a directory with the <code>list</code> keyword. To define a literal list value, see list literal.</p> <p>Lists direct children of the given directory. List expressions have the syntax <code>list $Exp $FilterPart?</code>, for example <code>list getProjectRootDir() + ./examples with extension \"pie\"</code>. The expression must have type path and refer to an existing directory. The filter part is optional and adds a filter to filter out any paths that do not match the filter. It is described in the section on common lexical elements.</p> <p>A list expression returns a list of the direct children of the given directory, and its type is <code>path*</code>.</p> <p>Declaring a dependency on the directory</p> <p>You will likely need to declare a dependency on the directory using requires. You may also need to declare dependencies on the individual files if you do not call a task which already does that.</p> Recursive listing <p>List only gets the direct children of the given directory. To recursively get all files and directories in a given directory, use walk.</p> <p>Todo</p> <p>What happens if the starting directory does not exist? What happens if it is not a directory?</p>"},{"location":"references/pipelines/expressions/#walk","title":"walk","text":"<p>Recursively gets descendants of the given directory. Walk expressions have the syntax <code>walk $Exp $FilterPart?</code>, for example <code>walk getProjectRootDir() + ./src/test/java with extension \"java\"</code>. The expression must have type path and refer to an existing directory. The filter part is optional and adds a filter to filter out any files that do not match the filter. It is described in the section on common lexical elements.</p> <p>A walk expression returns a list of all the files in the given directory and its descendants, and its type is <code>path*</code>.</p> <p>Declaring a dependency on the directory</p> <p>You will likely need to declare a dependency on the directory and all subdirectories using requires. You may also need to declare dependencies on the individual files if you do not call a task which already does that.</p> Getting only the direct descendants <p>Walk recursively gets all files in the given directory. To only get direct and directories in a given directory, use list.</p> <p>Todo</p> <p>What happens if the starting directory does not exist? What happens if it is not a directory? Does the filter also filter directories or only files? Should recursive directories automatically be declared required?</p>"},{"location":"references/pipelines/expressions/#exists","title":"exists","text":"<p>Checks if a file or folder exists. The syntax is <code>exists $Exp</code>, for example <code>exists ./config.json</code>. The expression is the path for which it should be checked if it exists. It returns a boolean indicating whether the file or path exists.</p>"},{"location":"references/pipelines/expressions/#read","title":"read","text":"<p>Reads the contents of the given file into a string. The syntax is <code>read $Exp</code>, for example <code>read pie.sdf3</code>. The expression is the file to be read, with type path. The file is read with the system default file encoding. It returns a string with the contents of the file.</p>"},{"location":"references/pipelines/expressions/#return","title":"Return","text":"<p>Returns from the current function with the provided value. Its syntax is <code>return $Exp</code>, for example <code>return true</code> or <code>return errResult&lt;FileNotFoundException&gt;(createFileNotFoundException(\"could not find $file\"))</code>. The expression is evaluated and its value returned. The type of the expression should be a subtype of the declared return type of the current function.</p> <p>The type of a return expression is unit.</p> Type may get changed to bottom type <p>The type of a return expression may be changed to the bottom type in the future. This would allow using a return expression as a branch in an if-else expression.</p>"},{"location":"references/pipelines/expressions/#fail","title":"fail","text":"<p>Throws an <code>ExecException</code> with the provided <code>string</code> as message. This exits the function, any code after this expression is not evaluated. Its syntax is <code>fail $Exp</code>, for example <code>fail \"Could not open $file, it does not exist\"</code> The expression is the message for the exception and must be of type string.</p> <p>The type of a fail expression is unit.</p> Type may get changed to bottom type <p>The type of a fail expression may be changed to the bottom type in the future. This would allow using a fail expression as a branch in an if-else expression.</p> consider using <code>Result&lt;T, E&gt;</code> <p>Fail throws an exception, which cannot be handled in the PIE DSL. We recommend using <code>Result&lt;T, E&gt;</code> from the PIE standard library instead.</p>"},{"location":"references/pipelines/expressions/#unit-literal","title":"Unit literal","text":"<p><code>unit</code> is a literal expression of the only value of the unit type.</p>"},{"location":"references/pipelines/expressions/#true","title":"True","text":"<p><code>true</code> is the literal expression for one of the two values of the boolean type.</p>"},{"location":"references/pipelines/expressions/#false","title":"False","text":"<p><code>false</code> is the literal expression for one of the two values of the boolean type.</p>"},{"location":"references/pipelines/expressions/#int-literal","title":"int literal","text":"<p>Int literals are a literal value of the int type. Their syntax is <code>\"-\"? [0-9]+</code>, for example <code>0</code>, <code>1</code>, <code>2</code>, <code>-1</code>, <code>47</code> and <code>-30774</code>. That is an optional dash (unary minus, <code>-</code>), followed by some digits. This syntax is lexical, meaning that there cannot be any layout between the sign or digits.</p> valid int values <p>Int literals represent literal values of the int type. As such, they must be valid values of the int type, i.e. in the range \\(-2^{31}\\) to \\(2^{31}-1\\), inclusive. This is currently not enforced, and breaking this constraint will lead to Java compile errors after compiling the PIE code.</p> <p><code>-0</code> is allowed and equal to <code>0</code>.</p> Examples <pre><code>// Valid integer literals:\n0\n1\n234\n2349273\n-4\n-237894\n-0 // same as 0\n0010 // same as 10\n\n// invalid integer literals\n- 12 // not allowed to have a space between the minus and the digits. Unary minus is not supported.\n1 024 // spaces between digits are not allowed\n2,048 // commas between digits are not allowed\n324.346 // periods between digits are not allowed. Floats do not exist in PIE, separators are not supported.\nDEADBEEF // letters are not allowed\n0b0101011110010 // binary notation is not supported\n0x234e9617ab7 // hexadecimal notation is not supported\nabd547 // this is not a hexadecimal value  but a value reference\nten // this is not an int literal but a value reference\n</code></pre>"},{"location":"references/pipelines/expressions/#null","title":"null","text":"<p><code>null</code> is the value that is added by making a type nullable. It is also a value of the top type.</p>"},{"location":"references/pipelines/expressions/#tuple-literal","title":"Tuple literal","text":"<p>Tuple literals express literal values of the tuple type. Their syntax is <code>($Exps)</code>, for example <code>(\"scala\", \"VF_SCALA\", walk (subjectScalaSrcDir + ./lib/scala.jar))</code>. The expressions are the elements of the tuple. There must be at least two elements. The type of a tuple literal is the tuple type of the types of the elements, so the literal <code>(1?, \"a string\", true)</code> has type <code>(int?, string, bool)</code>.</p> Tuples with less than two elements <p>It is not possible to express tuples with zero or a single element. Zero element tuples cannot be expressed by design. Their common use case as a unit type is covered by the unit literal instead. Single element tuples will be parsed as a bracketed expression instead.</p> Tuple literals from subtype elements <p>Tuple types cannot be assigned to each other in most cases, so the following is not possible: <pre><code>data Fruit = $DataImpl\ndata Apple : Fruit = $DataImpl\ndata Pear : Fruit = $DataImpl\n\nfunc getApple() -&gt; Apple = $FuncImpl\nfunc getPear() -&gt; Pear = $FuncImpl\n\n// type (Apple, Pear) cannot be assigned to (Fruit, Fruit)\nfunc example() -&gt; (Fruit, Fruit) = (getApple(), getPear())\n</code></pre></p> <p>To create such a tuple, assign the elements explicitly to the correct types first: <pre><code>func example() -&gt; (Fruit, Fruit) = {\n    val apple: Fruit = getApple();\n    val pear: Fruit = getPear();\n    (apple, pear)\n}\n</code></pre></p>"},{"location":"references/pipelines/expressions/#list-literal","title":"List literal","text":"<p>List keyword</p> <p>This section is about defining list literals. For information on the <code>list</code> keyword, see list expressions, which list the children of a directory.</p> <p>Define a literal list value. The syntax is <code>[$Exps]</code>, for example <code>[1, 2, 3]</code>, or <code>[apple, banana, pear]</code>. The expressions are the elements of the list. The least upper bound of the types of the expressions is the list element type <code>T</code>. The type of the list literal is a list of <code>T</code>, i.e. <code>T*</code>. The list element type must not be the top type.</p> Empty list literals may lead to Java errors <p>The empty list literal <code>[]</code> has a special type for implementation reasons. It compiles to a list with the bottom type. As such, the generated Java code may have compile errors.</p>"},{"location":"references/pipelines/expressions/#string-literal","title":"String literal","text":"<p>Define a literal value of type string. The syntax is <code>\"$StrParts\"</code>, where <code>$StrParts</code> are parts of the string. String parts are lexical, which means that there cannot be any layout between them (layout between string parts will be part of the string). The possible string parts are:</p> <ul> <li>A sequence of characters excluding <code>$</code>, <code>\"</code>, <code>\\</code> and newlines, for example <code>A sequence of characters = 123!?</code>. This expresses that exact sequence of characters.</li> <li><code>$</code> followed by the name of a value or parameter, for example <code>$dir</code>. This converts the value to a string. It is an error to use an undefined name.</li> <li><code>${$Exp}</code>, for example <code>${1 + 2}</code>. This evaluates the expression and converts the resulting value into a string.</li> <li><code>\\$</code>. This represents the literal character <code>$</code>.</li> <li><code>\\</code> followed by another character. This represents a character according to Java semantics. For example, <code>\\n</code> is a newline character, <code>\\\\</code> is a single backslash, and <code>\\r</code> is a carriage return character. In particular, <code>\\\"</code> represents the literal character <code>\"</code>, and does not end the string literal.</li> </ul> <p>All of the string parts are concatenated into a single string value without separating characters between them.</p>"},{"location":"references/pipelines/expressions/#path-literal","title":"path literal","text":"<p>Define a literal value of type path. The syntax is <code>$PathStart$PathParts</code>, for example <code>/home/alice/very-important-documents</code> or <code>./src/test/resources/</code>. <code>$PathStart</code> is either <code>/</code> for absolute paths or <code>./</code> for relative paths.<code>$PathParts</code> are parts of the path. Path start and path parts are lexical, which means that there cannot be any layout between them (layout between path parts will result in parse errors). The possible path parts are:</p> <ul> <li>A sequence of characters excluding <code>$</code>, <code>\"</code>, <code>\\</code> and layout, for example <code>path/to/the/goods</code>. This expresses that exact sequence of characters.</li> <li><code>$</code> followed by the name of a value or parameter, for example <code>$rootDir</code>. The value must be of type path. It is an error to use an undefined name.</li> <li><code>${$Exp}</code>, for example <code>${getProjectDir()}</code>. This evaluates the expression. The resulting value must be of type path.</li> <li><code>\\$</code>. This represents the literal character <code>$</code>.</li> <li><code>\\</code> followed by another character. This represents a character according to Java semantics. For example, <code>\\\\</code> is a single backslash.</li> </ul> <p>The path start and all of the path parts are concatenated into a single path value without separating characters between them.</p> Path validity and existence (is not checked) <p>The validity or existence of path literals is not checked. This means that a path literal like <code>.////.</code> is allowed, even though it would be invalid for most file systems. To check if a path exists, use exists.</p>"},{"location":"references/pipelines/expressions/#common-lexical-elements","title":"Common lexical elements","text":"<p>This section describes common lexical elements that are used by multiple expressions.</p>"},{"location":"references/pipelines/expressions/#filter-and-filterpart","title":"Filter and FilterPart","text":"<p>Filters are used expressions that read directories from the filesystem, so requires, list and walk. They are used to keep certain paths and ignore all other paths based on the name and the extension. They have the syntax <code>with $Filter</code>, for example <code>with extension \"str\"</code> or <code>with patterns [\"test-res\", \"result\", \"generated\"]</code> The possible filters are listed in the table below.</p> name expression description Regex <code>regex $Exp</code> Keeps files if they match the provided regular expression. The expression must be a string representing a regular expression. Todo: Figure out what exactly it matches on (full path, name, includes extension?), regex flavor (Java, some other kind?) Pattern <code>pattern $Exp</code> Keeps files if the name contains the provided string. The expression must be a string. TODO: I assume that this only needs to match part of the name and does not include the extension Patterns <code>patterns $Exp</code> Keeps files if the name contains any of the provided strings. The expression must be a list of strings. TODO: I assume that this only needs to match part of the name and does not include the extension Extension <code>extension $Exp</code> Keeps files if the file extension matches the provided string. The extension must match the string exactly, so <code>pie</code> is different from <code>PIE</code> and <code>PIE-simple</code>. The string should not include the period (<code>.</code>) separating the filename and the file extension. The expression must be a string. TODO: I assume that it needs to be an exact match. Can it match <code>pp.pie</code>? Extensions <code>extensions $Exp</code> Keeps files if the file extension matches any of the provided strings. The extension must match one of the strings exactly, so <code>pie</code> is different from <code>PIE</code> and <code>PIE-simple</code>. The strings should not include the period (<code>.</code>) separating the filename and the file extension. The expression must be a list of strings. TODO: I assume that it needs to be an exact match. Can it match <code>pp.pie</code>? <p>Todo</p> <p>Find exact semantics for the filters. Can they handle directories or do they only work on files? See also todos in the table.</p> Multiple filters <p>It is not allowed to use multiple filters. If you need multiple filters, encode your requirements in a regex filter instead.</p>"},{"location":"references/pipelines/expressions/#stamper-stamperpart-and-stamperkind","title":"Stamper, StamperPart and StamperKind","text":"<p>A Stamper specifies how it is determined whether a path is up-to-date when executing incrementally. They are used by requires and generates. They use the syntax <code>by $StamperKind</code>, where the stamper kind can be <code>hash</code> or <code>modified</code>.</p> <p>Stamping <code>by hash</code> will calculate the md5 hash of a file and assume that the file is up to date if the hash matches the cached hash. Stamping <code>by modified</code> will check the modification time, and assumes it is up-to-date when that time is at or before the cached time.</p> Checking the full file contents <p>There is currently no way in the PIE DSL to specify that the full file contents should match for a file to be considered up-to-date. If you need this, write the task in Java or use <code>read file</code>.</p> <p>Todo</p> <p>Does it work for directories or only files? Does the hash calculate md5 hash or another hash? What happens when a file is generated <code>by modified</code> but required <code>by hash</code>? What is the default modifier?</p>"},{"location":"references/pipelines/functions/","title":"Functions","text":"<p>This section describes functions in the PIE DSL.</p> <p>Note</p> <p>A task is a function with some special semantics in regards to runtime behavior. The PIE DSL does not differentiate between functions and tasks. In the DSL, both are called functions.</p> <p>Todo</p> <p>Write documentation</p>"},{"location":"references/pipelines/functions/#name","title":"Name","text":"<p>Todo</p> <p>describe legal function names, functions must be unique within a module (including function imports)</p>"},{"location":"references/pipelines/functions/#foreign-java-functions","title":"Foreign java functions","text":""},{"location":"references/pipelines/functions/#type-parameters","title":"Type parameters","text":""},{"location":"references/pipelines/functions/#parameters-and-values","title":"Parameters and values","text":"<p>Todo</p> <p>describe how values and parameters behave</p>"},{"location":"references/pipelines/functions/#return-type","title":"Return type","text":"<p>Todo</p> <p>describe the return value</p>"},{"location":"references/pipelines/functions/#function-invocations","title":"Function invocations","text":"<p>Todo</p> <p>describe function invocations</p>"},{"location":"references/pipelines/generics/","title":"Generics","text":"<p>This section describes generics in the PIE DSL. In a nutshell, it just follows the Java semantics.</p> <p>Todo</p> <p>Write documentation</p>"},{"location":"references/pipelines/limitations/","title":"Known bugs and limitations","text":"<p>This page lists the known bugs and limitations of the PIE DSL, and workarounds if they exist. If you have an issue that is not listed here, please check if it is listed on our Github page, and if not, open a new issue there: https://github.com/metaborg/pie/issues.</p> <p>Missing section: how to troubleshoot</p>"},{"location":"references/pipelines/limitations/#compiler-generates-invalid-code-for-void-return-types","title":"Compiler generates invalid code for void return types","text":"<p>The Java type <code>void</code> does not exist in the PIE DSL. Instead, it uses <code>unit</code> to signify that the return type does not hold a useful value. Right now, the compiler will generate incorrect code for <code>void</code> functions, which results in Java compile errors in the generated code. There is no specific workaround for this, but the standard workarounds for unsupported Java functions should work. In the future, the compiler will support functions that are declared to have a <code>unit</code> return type in PIE but which have a <code>void</code> return type in Java.</p>"},{"location":"references/pipelines/limitations/#java-reserved-words","title":"Java reserved words","text":"<p>Using Java keywords (and PIE keywords) is allowed in the PIE DSL as long as the use is not ambiguous. However, the compiler does not generate correct code for those keywords, which means that the generated Java code does not compile. To avoid this issue, do not use Java reserved words.</p>"},{"location":"references/pipelines/limitations/#standard-workarounds-for-unsupported-java-features","title":"Standard workarounds for unsupported Java features","text":"<p>The PIE DSL has less features than Java by design. This sometimes means that Java elements cannot be used as is in the PIE DSL. This sections lists some standard workarounds for these issues.</p>"},{"location":"references/pipelines/limitations/#standard-workarounds-for-unsupported-java-functions","title":"Standard workarounds for unsupported Java functions","text":"<p>This section provides workarounds for calling Java functions that are not supported by the PIE DSL.</p> <p>Missing section: standard workarounds for unsupported Java functions</p> <p>In summary, the workarounds are:</p> <ol> <li>Write a wrapper function</li> <li>Implement the task in Java. (Do not call the function from the PIE DSL, but call it from Java instead)</li> </ol>"},{"location":"references/pipelines/limitations/#standard-workarounds-for-unsupported-java-data-types","title":"Standard workarounds for unsupported Java data types","text":"<p>Missing section: standard workarounds for unsupported Java data types</p>"},{"location":"references/pipelines/modules/","title":"Module system","text":"<p>This section describes the module system of the PIE DSL.</p> <p>Todo</p> <p>document the module system</p>"},{"location":"references/pipelines/modules/#imports","title":"Imports","text":""},{"location":"references/pipelines/modules/#function-imports","title":"Function imports","text":""},{"location":"references/pipelines/modules/#qualified-calls","title":"Qualified calls","text":""},{"location":"references/pipelines/types/","title":"Types","text":"<p>This page explains the type system of the PIE DSL and lists all the built-in types.</p>"},{"location":"references/pipelines/types/#the-type-system","title":"The type system","text":"<p>A type system checks for type errors. PIE DSL uses a static type system, so type errors are found before compilation. The PIE DSL supports subtypes, generics and methods on types.</p>"},{"location":"references/pipelines/types/#nullability","title":"Nullability","text":"<p>PIE DSL keeps explicit track of nullability, so an expression cannot be null unless the type of the expression is nullable.</p> <p>Todo</p> <p>Fully document nullability.</p>"},{"location":"references/pipelines/types/#super-types-and-subtypes","title":"Super types and subtypes","text":"<p>When a type <code>X</code> is a subtype of type <code>Y</code>, you can use an expression with type <code>X</code> wherever an expression with type <code>Y</code> is expected. When <code>X</code> is a subtype of <code>Y</code>, <code>Y</code> is the super type of <code>X</code> For example, the method <code>cutFruit(fruit: Fruit) -&gt; Piece*</code> expects a <code>Fruit</code>. If an <code>Apple</code> is declared to be a subtype of <code>Fruit</code>, we can pass an <code>Apple</code>: <code>cutFruit(getApple())</code></p> <p>Subtypes are transitive, which means that if <code>A</code> is a subtype of <code>B</code>, and <code>B</code> is a subtype of <code>C</code>, then <code>A</code> is a subtype of <code>C</code>, even if that is not explicitly declared.</p> <p>The PIE DSL allows declaring exactly one super type.</p> <p>The top type is a super type of everything. As such, any expression can be assigned to the top type.</p> <p>The bottom type is a subtype of everything. As such, an expression with the bottom type can be assigned to everything.</p>"},{"location":"references/pipelines/types/#generics","title":"Generics","text":"<p>Generics refer to making a type or a function generic over types, that is, add type parameters to the type or function. You likely already know about these, lists are an example of parameterized types. It's not just any list, it's a list of <code>some type here</code>.</p> <p>Every data type in the PIE DSL is generic. When declaring a datatype in a data definition, there is a list of generic parameters: <code>data Box&lt;T&gt; = $DataImpl</code>. When referring to a type, there is a list of generic parameters: <code>val box: Box&lt;string&gt; = $Exp</code>. These lists can be empty: <code>data Apple&lt;&gt; = $DataImpl</code>. This makes the term \"generic\" a bit meaningless, but <code>Apple</code> is still considered generic for the purposes of the semantics. That is to say, <code>Apple</code> is treated as a generic type that just happens to have zero generic parameters, in the same way that <code>Box</code> happens to have one generic parameter and <code>Foo&lt;A, B, C&gt;</code> happens to have three.</p> Omitting type parameter and argument lists <p>Type parameter/argument list can sometimes be omitted. Parameter lists can be omitted if they are empty: <code>data Apple = $DataImpl</code>, <code>func notGeneric(string) -&gt; unit = $FuncImpl</code>. Type argument lists can be omitted for empty lists and for calls to the built-in <code>supplier</code> function. For example, <code>Apple</code>, <code>notGeneric(\"regular argument\")</code>.</p> <p>A type declares zero or more generic parameters. These can be used in methods of that type to parameterize the method.</p> <p>A function or method can also declare generic parameters to be used in that function or method.</p> PIE does not derive bounds <p>Unlike Java, the PIE DSL does not derive bounds for datatypes based on super types. The following would be possible in Java but will not work in the PIE DSL: <pre><code>data CustomAnimalSet&lt;A : Animal&gt; = $DataImpl\ndata OrderedAnimalSet&lt;T&gt; : CustomAnimalSet&lt;T&gt; = $DataImpl\n// error on `T` in `CustomAnimalSet&lt;T&gt;`: `T` is not within upper bound `Animal`\n// Solution: declare the bound on the subtype as well\ndata OrderedAnimalSet2&lt;T : Animal&gt; : CustomAnimalSet&lt;T&gt; = $DataImpl\n</code></pre></p> <p>Todo</p> <p>Explain generics</p>"},{"location":"references/pipelines/types/#methods-and-overriding","title":"Methods and overriding","text":"<p>Every type can have methods. For now, the only data types are <code>foreign java</code> datatypes, so methods follow Java semantics for overriding.</p> <p>Todo</p> <p>Explain overriding.</p>"},{"location":"references/pipelines/types/#built-in-types","title":"Built-in types","text":"<p>The PIE DSL has several built-in types. This section explains all of them.</p> Datatype equality with equal Java class <p>PIE DSL does not consider types equivalent when their backing Java class is equal. This means that a built-in type and a custom datatype backed by the same class cannot be used interchangeably.</p> <p>The following table gives a quick overview of the built-in types, click on the name to go to the documentation.</p> name syntax description values methods backing Java class unit <code>unit</code> Unit type, only has a single value. Use as return type for methods without a meaningful return value <code>unit</code> - <code>mb.pie.api.None</code> bool <code>bool</code> Booleans. Used as flags and for conditions in <code>if</code> and <code>if-else</code>. <code>true</code>, <code>false</code> - <code>java.lang.Boolean</code> int <code>int</code> Integers. Range from \\(-2^{31}\\) to \\(2^{31}-1\\), inclusive. -2147483648, ... -1, 0, 1, 2, 3, ... 2147483647 - <code>java.lang.Integer</code> path <code>path</code> Paths on the file system. Might not exist. E.g. <code>./src/test/resources/test1.txt</code>, <code>/home/users/me/programming</code> - <code>mb.resource.fs.FSPath</code> null type - Type of the literal <code>null</code>. Subtype of every nullable type. <code>null</code> - - top - The top type is the super type of all other types. every value is an instance of <code>top</code> - <code>java.lang.Object</code> bottom - The bottom type is a subtype of all other types. It has no values by definition. An expression of type bottom will never return normally. No values - - Nullable types <code>$Type?</code>, e.g. <code>string?</code> Makes a type nullable. All values of the original type and <code>null</code> All methods of the original type Original backing class Lists <code>$Type*</code>, e.g. <code>int*</code> A list. Unknown amount of elements, all with the same type. <code>[]</code>, <code>[e1]</code>, <code>[e1, e2]</code>, <code>[e1, e2, e3]</code>, where <code>e1</code>, <code>e2</code> and <code>e3</code> are valid elements of the list element type. - <code>java.util.ArrayList</code> Tuples <code>($Types)</code> A tuple of elements. Known amount of elements, can be different types. elements of the inner types, e.g. <code>(e1, e2)</code> is a value of <code>(T1, T2)</code> if <code>e1</code> and <code>e2</code> are values of <code>T1</code> and <code>T2</code> respectively - <code>mb.pie.TupleX</code>, where <code>X</code> is the number of elements. supplier <code>supplier&lt;$Type&gt;</code> A supplier of a value. Useful for performance in certain situations. Can be created using <code>supplier($Exp)</code> or <code>$FUNCID.supplier&lt;$TypeArgs&gt;($Exps)</code> <code>func get&lt;&gt;() -&gt; T</code> for <code>supplier&lt;T&gt;</code> <code>mb.pie.api.Supplier</code> Function types - The type of a function. Functions cannot be used as values, but their type can be seen by hovering over the name - - - Wildcards <code>_$UpperBound$LowerBound</code> Represent a set of types. Can only be used as type argument. Instances of types in the type set - Backed by the Java wildcard: <code>?</code> Custom datatypes <code>$TYPEID</code> A type defined in a pie file with. Instances of the type, ultimately obtained from <code>foreign java</code> functions The methods that are declared on the type itself, and the methods of its super types The declared backing class"},{"location":"references/pipelines/types/#unit","title":"unit","text":"<p><code>unit</code> is a type with only a single value: <code>unit</code>. It is meant to be used as return value for functions that have no meaningful return value, for example functions that operate via side effects like writing to a file. It is backed by <code>mb.pie.api.None</code>.</p>"},{"location":"references/pipelines/types/#bool","title":"bool","text":"<p><code>bool</code> represents booleans and as such has two values: <code>true</code> and <code>false</code>. Booleans are used as flags and as conditions for <code>if</code> and <code>if-else</code>. <code>bool</code> is backed by <code>java.lang.Boolean</code>.</p>"},{"location":"references/pipelines/types/#int","title":"int","text":"<p><code>int</code> represents integers. It is backed by <code>java.lang.Integer</code>, and as such has a range of \\(-2^{31}\\) to \\(2^{31}-1\\), inclusive.</p>"},{"location":"references/pipelines/types/#string","title":"string","text":"<p><code>string</code> represents strings. Strings have many built-in methods which have yet to be added to the implementation. It is backed by java <code>String</code>.</p>"},{"location":"references/pipelines/types/#path","title":"path","text":"<p><code>path</code> represents a path to a file or directory in the file system. The directory or file need not exist. Paths can be relative or absolute. Paths have many built-in methods which have yet to be added to the implementation. Paths are backed by <code>mb.resource.fs.FSPath</code></p>"},{"location":"references/pipelines/types/#null-type","title":"null type","text":"<p>The null type cannot be expressed in the PIE DSL, meaning that there is no way to specify it as the type of something. Its only value is <code>null</code>. The null type is a subtype of every nullable type.</p>"},{"location":"references/pipelines/types/#top","title":"top","text":"<p>The top type is a super type of every other type. It cannot be specified as a type. It is backed by <code>java.lang.Object</code></p>"},{"location":"references/pipelines/types/#bottom","title":"bottom","text":"<p>The bottom type is a subtype of every other type. It cannot be specified as a type. The bottom type has no values, and as such an expression with bottom type will never return normally to the function it is defined in. It is the element type of empty lists, and in the future also of <code>return</code> and <code>fail</code> expressions. This type is not backed by any java class.</p> Compiling bottom type <p>Code that has the bottom type will fail to compile. Remove the code that has bottom type to resolve this.</p>"},{"location":"references/pipelines/types/#nullable-types","title":"Nullable types","text":"<p>Nullable types are represented with a question mark after the type. For example, a nullable <code>int</code> is <code>int?</code>. A nullable type <code>X?</code> represents a value that could either be a regular value <code>X</code> or \"missing\", represented with the expression <code>null</code>. A nullable type <code>X?</code> is a super type of both <code>X</code> and the null type. It is an error to make a nullable type nullable again, so <code>X??</code> is not allowed. Java types are always nullable, so the nullable type <code>X?</code> is backed by Java type <code>X</code>.</p>"},{"location":"references/pipelines/types/#lists","title":"Lists","text":"<p>Lists are represented with an asterisk behind the type. For example, a list of <code>path</code> is <code>path*</code>. Lists of <code>X</code> can contain any element that could be assigned to <code>X</code>. Lists do not have subtypes besides the bottom type. This means that <code>Apple*</code> is not a subtype of <code>Fruit*</code>. Lists do not have methods yet. Lists are backed by Java <code>java.util.ArrayList</code>.</p> Empty lists <p>The PIE DSL type system keeps track of empty lists for implementation reasons. Because it is doing this anyway, it gives warnings when doing certain non-sensical things such as appending an empty list to another list or list comprehension over empty lists.</p>"},{"location":"references/pipelines/types/#tuples","title":"Tuples","text":"<p>Tuple types represent a combination of multiple types. They are specified as the types between parentheses. For example, <code>(string, int*)</code> represents a pair of a <code>string</code> and a list of <code>int</code>s. Tuple types differ from lists because lists have a variable amount of elements of a single type, while tuples have a set number of elements with heterogenous types. Tuple types can be deconstructed to get their values: <pre><code>val pair: (string, int*) = (\"Alice\", [9, 4, 6, 7]);\nval (name: string, grades: int*) = pair;\n</code></pre> Tuples are backed by Java classes <code>mb.pie.TupleX</code>, where <code>X</code> is a number representing the amount of elements, e.g. <code>Tuple2</code> for a pair. This is because Java is not generic in the amount of generic elements.</p> Limits on tuple sizes <p>While the PIE DSL language does not specify a limit on the amount of elements in a tuple, the backing Java <code>TupleX</code> classes only go up to 10. If you run into this limit, use a foreign data type backed by a custom Java class instead.</p>"},{"location":"references/pipelines/types/#supplier","title":"supplier","text":"<p><code>supplier&lt;T&gt;</code> represents a supplier of a value of type <code>T</code>. Suppliers represent a value, either by being created with a value or by deferring a task that returns the value. Suppliers have a single method <code>get&lt;&gt;() -&gt; T</code>, which returns the value of the supplier, either by returning the value if it already existed or by calling the task that the supplier supplies.</p> <p>The main use case for suppliers is as input types for tasks. If the supplier is faster to check for consistency than the value it supplies, the runtime performance is improved. As an example, consider <pre><code>func readFile() -&gt; string = read ./bundled.java\n\nfunc parse1(program: string) -&gt; IStrategoTerm =\n  mb:lang:java:parse(program)\nfunc parse2(program: supplier&lt;string&gt;) -&gt; IStrategoTerm =\n  mb:lang:java:parse(program.get&lt;&gt;())\n\nfunc parseBoth() -&gt; unit = {\n    parse1(readFile());\n    parse2(readfile.supplier());\n    unit\n}\n</code></pre> Both <code>parse1</code> and <code>parse2</code> need to read the file <code>./bundled.java</code>, strip of any whitespace, and then parse it with <code>mb:lang:java:parse</code> on the initial build. If we modify <code>./bundled.java</code> before the second build, <code>readFile</code> is now outdated and will need to read again. To check if the input for <code>parse1</code> is in the cache, the runtime needs to check the contents of the entire file against any cached values to see if it matches. To check if the input for <code>parse2</code> is in the cache, the runtime only checks if the supplier is in the cache. The supplier is a <code>TaskSupplier</code>, which is in the cache if its task is not outdated. The runtime only has to make a few calls to determine that the input for <code>parse2</code> is not cached.</p> <p>Suppliers are backed by <code>mb.pie.api.Supplier</code>.</p>"},{"location":"references/pipelines/types/#function-types","title":"Function types","text":"<p>Function types are visible when hovering over a function name. They follow the pattern <code>func($Params) -&gt; $Type</code>. For example, <code>func(int, string) -&gt; bool</code> is a function that takes an int and a string and returns a boolean. Function types cannot be specified in PIE DSL, and they can also not be the type of a variable. Because function types cannot be the type of a variable, they are not backed by a Java class.</p>"},{"location":"references/pipelines/types/#wildcards","title":"Wildcards","text":"<p>Wildcards represent a set of types by using an upper or lower bound. They use the following syntax. The wildcard itself is represented by an underscore: <code>_</code> The upper bound is specified by a colon followed by a type: <code>: $Type</code> The lower bound is specified with a dash, colon and then a type: <code>-: $Type</code> If a the upper bound is omitted, it is implicitly the top type. If the lower bound is omitted, it is implicitly the bottom type. A wildcard cannot have both an upper and a lower bound.</p> <p>Here are some examples of wildcards and what they mean: <pre><code>_ // unbounded wildcard (bounds are implicitly the top and bottom type)\n_ : Fruit // upper bounded wildcard. Matches Fruit, Apple, Pear\n_ : path:to:module:Vegetable // qualified upper bound\n_ -: Fruit // lower bounded wildcard. Matches Fruit, Food, top type\n\n_ : Fruit -: Apple // both upper and lower bounded, gives an error\n\n_ : Iterable : Comparable // _not_ a type with multiple upper bounds, parsed as\n_ : Iterable:Comparable   // a single qualified upper bound.\n\n_ -: Apple : Fruit // _not_ a lower bound and then upper bound, parsed as\n_ -: Apple:Fruit   // a qualified lower bound\n</code></pre></p> <p>Wildcards can only be used as type arguments or as arguments to built-in types. They are useful when we want to allow any of the type arguments within the bounds. For example, <code>func buildZoo(Animal*) -&gt; Zoo</code> will only take a list with type <code>Animal*</code>, but not a list with type <code>Mammal*</code>, even though a zoo of just mammals can be pretty cool already. To allow any list of animals, we use a wildcard: <code>func buildZoo((_ : Animal)*) -&gt; Zoo</code> This <code>buildZoo</code> will take <code>Animal*</code>, <code>Mammal*</code>, <code>Bird*</code>, <code>Insect*</code> and even <code>Chicken*</code>.</p> <p>Wildcards are translated to Java wildcards.</p>"},{"location":"references/pipelines/types/#custom-datatypes","title":"Custom datatypes","text":"<p>Custom datatypes are definitions using the <code>data</code> keyword. They look like this: <pre><code>$Modifiers data $TYPEID&lt;$GenericParameters&gt; : $SuperType = $DataImpl\n\n$Modifier = \"transient\"\n$DataImpl = foreign java $QID {\n    $FuncHeads\n}\n</code></pre></p> <p>Modifiers change the semantics of a datatype. The only modifier right now is <code>transient</code>. This modifier signifies to the PIE runtime that the datatype cannot be cached. It is an error to repeat modifiers, i.e. <code>transient transient data Foo = $DataImpl</code> is not allowed.</p> <p>The name can be any name that not already a built-in type. The convention is to use PascalCase, meaning that every first letter of a word is a capital letter. Names start with a letter or underscore, and can contain letters, numbers, a dash (<code>-</code>) and underscores (<code>_</code>).</p> <p>The list of generic parameters can be omitted. This is syntactic sugar for an empty list, so <code>Foo</code> is the same as <code>Foo&lt;&gt;</code>. For an explanation of generics in the PIE DSL, see generics</p> <p>The super type specifies the super type of this data type. The super type can be omitted, for example <code>data Foo = $DataImpl</code>. If the super type is omitted, the top type implicitly becomes the super type. See the section about super types and subtypes earlier on this page for an explanation of super types.</p> <p>The only implementation right now is <code>foreign java</code>. This implementation is a Java class. It looks like this <pre><code>foreign java $QID {\n    $FuncHeads\n}\n</code></pre> The <code>$QID</code> specifies the qualified name of the backing Java class. <code>$FuncHeads</code> is a newline separated list of function headers. These are declarations of the non-static methods of the class. Not all non-static methods of the class need to be declared here. Static methods of the class can be declared as <code>foreign java</code> functions outside this data definition.</p> Separate your imports <p>Define foreign java datatypes in a separate module and import them into your main module to keep your main module cleaner.</p>"},{"location":"references/statix/","title":"Statix","text":"<p>Statix is a Meta-language for the Specification of Static Semantics. Statix specifications are organised in modules. In Statix, programs, types and all other data are represented using terms. Type-checking a program is performed by solving a set of constraints over terms. In addition to these built-in constraints, specification writers can define their own constraints.</p> <p>Type-checking is closely related to, and strongly intertwined with, name resolution. For that reason, Statix has built-in support for modelling name binding patterns in the form of scope graphs. During type-checking, names can be resolved using queries.</p> <p>When transforming programs using in Stratego, Statix specifications can be executed, and the results accesssed using the Stratego API for Statix.</p> <p>Statix has a special test format, which can be used for isolating issues in a specification, or in the Statix ecosystem.</p> <p>Tip</p> <p>Readers with little or no familiarity with Statix are recommended to read the Language Concepts section first.</p>"},{"location":"references/statix/#sources","title":"Sources","text":"<p>The sources of the different Statix components can be found at:</p> <ul> <li>https://github.com/metaborg/nabl/tree/master/statix.lang: The Statix Language</li> <li>https://github.com/metaborg/nabl/tree/master/statix.runtime: The Statix Runtime</li> <li>https://github.com/metaborg/nabl/tree/master/statix.solver: The Statix Solver</li> </ul>"},{"location":"references/statix/basic-constraints/","title":"Basic Constraints","text":"<p>As mentioned in the Language Concepts section, the core idea of Statix is to see a type-checking problem as a constraint solving problem. Therefore, it is crucial to be able to express constraints in a specification.</p> <p>In this section, we discuss all constraints that are not related to scope graphs. These constraints are explained in-depth in the sections on Scope Graph Construction and Queries.</p>"},{"location":"references/statix/basic-constraints/#true","title":"True","text":"<pre><code>true\n</code></pre> <p>The <code>true</code> constraint is the constraint that is trivially satisfied.</p>"},{"location":"references/statix/basic-constraints/#false","title":"False","text":"<pre><code>false $Message?\n</code></pre> <p>The <code>false</code> constraint is the constraint that will always fail. Just as all other constraints that can fail, it is possible to add a message.</p>"},{"location":"references/statix/basic-constraints/#conjunction","title":"Conjunction","text":"<pre><code>$Constraint,\n$Constraint\n</code></pre> <p>A conjunction of constraints is satisfied when both conjuncts are satisfied. Note that the solving order of the conjuncts is undefined.</p>"},{"location":"references/statix/basic-constraints/#equality","title":"Equality","text":"<pre><code>$Term == $Term $Message?\n</code></pre> <p>Asserts that two terms are equal. When necessary, this constraint infers values for free variables in the terms. Statically, both terms should have the same type.</p>"},{"location":"references/statix/basic-constraints/#disequality","title":"Disequality","text":"<pre><code>$Term != $Term $Message?\n</code></pre> <p>Asserts that two terms are not equal. Statically, both terms should have the same type.</p> <p>Statix treats free variables as different from each other, and as different from concrete terms. Therefore, when any of both terms is not ground (i.e. contains free variables), the constraint will not fail.</p>"},{"location":"references/statix/basic-constraints/#exists","title":"Exists","text":"<pre><code>{ $Var* }\n$Constraint\n</code></pre> <p>An exists constraint introduces new existentially quantified variables in the scope of its subconstraint. The names of the variables in an exists constraint should be unique (i.e. <code>{x x} true</code> is not allowed), but are allowed to shadow outer variables.</p>"},{"location":"references/statix/basic-constraints/#try","title":"Try","text":"<pre><code>try { $Constraint } $Message?\n</code></pre> <p>The <code>try</code> constraint validates whether the outer context implies that the inner constraint holds. That is: any model for the outer context (all other constraints than <code>$Constraint</code>) is also a (not necessarily minimal) model for <code>$Constraint</code>.</p> <p>In order to implement these semantics, the <code>$Constraint</code> is handled differently than regular constraints in two ways.</p> <ol> <li>The <code>$Constraint</code> is not allowed to refine the outer context. Therefore,    equality constraints will not infer values for variable that were introduced    outside the <code>try</code>. Likewise, scopes can not be instantiated, nor edges/declarations    added to scopes from outside the <code>try</code>. This behavior also implies that values    constructed within a <code>try</code> construct will never escape the <code>try</code> context.</li> <li>Disequalities in <code>$Constraint</code> that involve free variables cause the <code>try</code>    to fail, because appearently the disequality does not hold for all models of    the outer context.</li> </ol> <p>Todo</p> <p>Explain the design choices for <code>try</code> in a background section.</p>"},{"location":"references/statix/basic-constraints/#ast-identifiers","title":"AST Identifiers","text":"<pre><code>astId($Term, $Term)\n</code></pre> <p>The <code>astId</code> constraint asserts that its second argument is the term index of the first argument. The type of the first argument may be anything, but the type of the second argument is <code>astId</code>.</p> <p>Tip</p> <p>Often, using an <code>astId</code> term will read more natural.</p>"},{"location":"references/statix/basic-constraints/#ast-property","title":"AST Property","text":"<pre><code>@$Term.$Prop $Op $Term\n</code></pre> <p>Statix allows to set properties on AST nodes. These properties can be used to communicate typing results to the outside world, for example to be used in a transformation. For more information on reading these properties, please refer to the Stratego API documentation.</p> <p>The first term is the term (usually an AST node) on which the property is set.</p> <p>Next <code>$Prop</code> specifies which property is set. This property can be any string of the form <code>[a-zA-Z] [a-zA-Z0-9\\_]*</code>. It is not required to declare properties.</p> <p>There are two special properties: <code>ref</code> and <code>type</code>. <code>ref</code> properties are set on (syntactic) variable references, and point to the term they are referencing. The Spoofax reference resolution service uses these properties to offer reference resolution in the editor. The <code>type</code> property contains the type of a term. This type is shown when hovering over a term in an editor.</p> <p>The <code>$Op</code> specifies the operator with which a property is set. There are two possible operators:</p> <ul> <li><code>:=</code>: The assignment operator. This operator requires a property to have only   a single unique value (although, since Spoofax 2.5.17, that value may be set   multiple times).</li> <li><code>+=</code>: The bag insertion operator. Properties using this operator can be set   multiple times, and will be aggregated in the eventual property value.</li> </ul> <p>Note that using both operators for a single property on a particular node will result in a failed constraint. However, it is allowed to use different operators for a property, as long as the terms on which these operators are used are different.</p> <p>Finally, the last <code>$Term</code> denotes the value of the property.</p> <p>Warning</p> <p>Failing property constraints are ignored (i.e., no error for them is reported).</p>"},{"location":"references/statix/basic-constraints/#arithmetic-constraints","title":"Arithmetic Constraints","text":"<pre><code>$Term $Op $ArithExp $Message?\n</code></pre> <p>Statix supports several arithmetic constraints. These constraints consist of a term, an operator and an arithmetic expression. The <code>$Term</code> should have type <code>int</code>, while the <code>$ArithExp</code> is syntactically guaranteed to have type <code>int</code>, given that all variable references have type <code>int</code>.</p> <p>At the <code>$Op</code> position, several comparison operators can be used:</p> <ul> <li><code>#=</code> asserts that both terms are equal</li> <li><code>#\\\\=</code> asserts that both terms are not equal</li> <li><code>#&gt;=</code> asserts that the left term is equal or bigger that the left term</li> <li><code>#=&lt;</code> asserts that the left term is equal or smaller that the left term</li> <li><code>#&gt;</code> asserts that the left term is strictly bigger that the left term</li> <li><code>#&lt;</code> asserts that the left term is strictly smaller that the left term</li> </ul> <p>Arithmetic expressions can be integer literals, variables and bracketed arithmetic expressions. Variables in an arithmetic expression must have type <code>int</code>. Additionally, the following arithmetic operations can be used:</p> <ul> <li><code>$ArithExp + $ArithExp</code>: computes integer addition</li> <li><code>$ArithExp - $ArithExp</code>: computes integer subtraction</li> <li><code>$ArithExp * $ArithExp</code>: computes integer multiplication</li> <li><code>min($ArithExp, $ArithExp)</code>: computes the minimum of both arguments</li> <li><code>max($ArithExp, $ArithExp)</code>: computes the maximum of both arguments</li> <li><code>$ArithExp div $ArithExp</code>: computes the integer divisor (i.e. rounded down   regular division).</li> <li><code>$ArithExp mod $ArithExp</code>: computes the modulus of its arguments.</li> </ul> <p>Unlike other constraints, arithmetic constraint do no inference of values in the <code>$ArithExp</code>. Hence, having any free variables in this expression will cause the constraint to fail.</p> <p>Separate Arithmetic Expression Syntax</p> <p>As discussed, Statix has a special syntactic category for arithmetic expressions. Therefore, arithmetic expressions cannot be used at regular term positions. Instead, arithmetic expressions can be embedded in terms using the Arithmetic Expressions term syntax.</p> Java Integers <p>Arithmetic Expressions are implemented using standard Java integers, and hence have the same size limitations.</p>"},{"location":"references/statix/basic-constraints/#messages","title":"Messages","text":"<pre><code>| $Severity $MessageBody $Position?\n</code></pre> <p>Constraints that might possibly fail can be provided with a customized message. Such message carry three parameters.</p> <p>First, the <code>$Severity</code> indicates the severity of a message. It may be either <code>error</code>, <code>warning</code> or <code>note</code>. Note however that warnings and notes can only be issued for failing <code>try</code> constraints.</p> <p>Second, the error message string is provided. This message string may be a regular string literal or a template literal. Template literals look as follows:</p> <pre><code>$[$ContentPart*]\n</code></pre> <p>Content parts are either message string literals or interpolated terms. The escaping rules for string literals in templates are slightly different than for regular string literals. Message string literals can contain any character, where square brackets and backslashes must be escaped with a backslash. Just as regular string literals, tabs, newlines and carriage returns can be encoded with <code>\\t</code>, <code>\\n</code> and <code>\\r</code>, respectively.</p> <p>Terms can be inserted in a message template by surrounding them with (unescaped) square brackets: <code>[$Term]</code>. The term may have any type, but must be well-formed according to the regular typing rules for terms.</p> <p>Bug</p> <p>Using functional predicates inside message templates will cause an exception when loading the specification.</p> <p>Thirdly, a position can be assigned to the message:</p> <pre><code>@ $Var\n</code></pre> <p>Here, the <code>$Var</code> is assumed to be an AST node. When the constraint on which this message is placed fails, the message will be shown inline at the AST node pointed to by this variable.</p> <p>When no message position is provided, or the assigned position is invalid, Statix will scan the the arguments to user-defined constraints on the call trace that led to the failed constraint from left to right for an AST argument, and put the message on the first valid node found. When no AST node could be found (for example when the project constraint fails), the error is positioned at the project resource.</p> <p>Warning</p> <p>Messages on projects are often overlooked by users. Hence it is recommended that project constraints are designed in a way they can never fail.</p> <p>When message is provided for a failed constraint, Statix will scan the call trace for constraints that have a message provided, and use the message it encounters. If no message is found, a rendering of the failed constraint is used as a message.</p>"},{"location":"references/statix/concepts/","title":"Language Concepts","text":"<p>In this section, a brief description of the main concepts of the Statix language is provided.</p>"},{"location":"references/statix/concepts/#terms","title":"Terms","text":"<p>The data model that underlies all Statix specifications is algebraic data. Besides several built-in primitives, such as integer and string literals, users can build composite terms using term constructors, tuples and lists. Statix is a sorted logic, in the sense that all runtime data should adhere to a multi-sorted signature.</p>"},{"location":"references/statix/concepts/#constraints","title":"Constraints","text":"<p>Key to the Statix design philosophy is to view a type-checking problem as a constraint problem. When solving the constraint problem, a minimal model is inferred from the constraints. This model represents a principal typing for the original program. In order to express such constraint problems, a versatile set of built-in constraints is provided by the Statix language. For more information on constraints, see the Basic Constraints section.</p>"},{"location":"references/statix/concepts/#rules","title":"Rules","text":"<p>Besides using built-in constraints, users can define their own constraints using constraint handling rules. Rules consist of a head and a body. The head specifies the arguments to the constraint, and (optionally) a guard, which indicates when to apply the rule. The body is a regular constraint, which, when proven, asserts that the constraint holds. More detailed information about user-defined constraints can be found in the Rules section.</p>"},{"location":"references/statix/concepts/#scope-graphs","title":"Scope Graphs","text":"<p>Since Statix is especially designed for type-checking, and type-checking is heavily intertwined with name binding, special support for name binding is integrated in the language. Name binding is modelled using scope graphs, in which scopes are represented as nodes, visibility is modelled using labelled edges between nodes, and declarations using special terminal nodes that are associated with a particular datum. References are modelled using scope graph queries. For more information on scope graph construction and querying, see sections Scope Graph Constraints and Queries, respectively.</p>"},{"location":"references/statix/modules/","title":"Modules","text":"<p>A Statix Specification is organised as a collection of modules. Each module corresponds to a file with a <code>.stx</code> extension.</p>"},{"location":"references/statix/modules/#module-structure","title":"Module Structure","text":"<p>The structure of a Statix module looks as follows:</p> <pre><code>module $ModuleName\n\n$Section*\n</code></pre> <p>Each module declares its name, and subsequently contains a number of sections. The module name should coincide with the relative path of the module with respect to the closest source root.</p> <p>Todo</p> <p>Link to documentation on source roots.</p>"},{"location":"references/statix/modules/#imports","title":"Imports","text":"<p>In an <code>imports</code> section, definitions from other modules can be brought in scope.</p> <pre><code>imports\n\n$ModuleName*\n</code></pre> <p>Modules can only be imported with their fully qualified name. That is, for each <code>$ModuleName</code> in an <code>imports</code> section, a module with exactly the same name must exist.</p> <p>Imports of sorts, constructors and predicates are transitive, while imports of labels and relations are non-transitive. Furthermore, overloading by type, shadowing of top-level definitions, and duplicate imports of definitions are not allowed.</p>"},{"location":"references/statix/modules/#signatures","title":"Signatures","text":"<p>In a <code>signature</code> section, type definitions are located.</p> <pre><code>signature\n\n$Signature*\n</code></pre> <p>Examples of signatures are: sort and constructor declarations or label and relation declarations. Each of these will be explained in the appropriate subsection.</p>"},{"location":"references/statix/modules/#rules","title":"Rules","text":"<p>In a <code>rules</code> section, the rules of a specification are defined. For more information on rules, see the Rules section.</p> <pre><code>rules\n\n$RuleDeclaration*\n</code></pre>"},{"location":"references/statix/queries/","title":"Queries","text":"<p>Scope Graphs, as introduced in the previous section can be queried. Scope graph queries always start in a particular scope, and traverse the scope graph in order to find declarations under a particular relation. The syntax for queries is as follows:</p> <pre><code>query $QueryTarget\nfilter $LabelRE and $DataWF\nmin $LabelOrder* and $DataLeq\nin $Scope |-&gt; $Result\n</code></pre> <p>The <code>$Scope</code> parameter is a term with type <code>scope</code>. In this scope, the query starts. All other query arguments are explained in the following subsections.</p>"},{"location":"references/statix/queries/#query-targets","title":"Query Targets","text":"<p>The query target is the 'thing' that is looked for in the query. This can be one of:</p> <ul> <li><code>$Relation</code>: A relation identifier. In this case, the query will return data   that is declared under that relation.</li> <li><code>()</code>: the end of path query target. In this case, the query will return all   paths that match the appropriate filters.</li> </ul> <code>()</code> as relation <p>The <code>()</code> query target can be thought of as a regular relation if one assumes <code>#1 |-()-&gt; #1</code> to exist for every scope <code>#1</code> in the scope graph.</p>"},{"location":"references/statix/queries/#filters","title":"Filters","text":"<p>Query results can be filtered using two different filters. First, a regular expression on labels (<code>$LabelRE</code>) defines a filter on the paths that the query resolution algorithm will explore. This regular expression can be build from the following components:</p> <ul> <li><code>$Label</code>: Matches paths that travers a single edge with the label <code>$Label</code>.   Requires the label to be declared in a <code>signature</code> section, as explained in   the section on edges.</li> <li><code>e</code>: epsilon. Matches the empty path. Queries using this filter will only return   declarations in the scope where the query started.</li> <li><code>0</code>: empty set. Matches no path.</li> <li><code>$LabelRE $LabelRE</code>: concatenation. Matches paths that can be split in two   segments <code>p1</code> and <code>p2</code>, such that <code>p1</code> matches the first regular expression,   and <code>p2</code> matches the second.</li> <li><code>$LabelRE | $LabelRE</code>: disjunction. Matches paths that match either the first   or the second regular expression.</li> <li><code>$LabelRE &amp; $LabelRE</code>: conjunction. Matches paths that match both the first   and the second regular expression.</li> <li><code>~$LabelRE</code>: negation. Matches all paths that do not match the inner   regular expression.</li> <li><code>$LabelRE*</code>: closure. Matches paths that can be split into zero or more   segments that each match the inner regular expression.</li> <li><code>$LabelRE+</code>: one or more. Matches paths that can be split into one or more   segments that each match the inner regular expression. Equivalent to   <code>$LabelRE $LabelRE*</code></li> <li><code>$LabelRE?</code>: zero or one. Matches paths that are matched by the inner regular   expression, or empty paths. Equivalent to <code>$LabelRE | e</code>.</li> </ul> <p>Additionally, regular expression can be grouped by brackets.</p> <p>Second, data well-formedness filters (<code>$DataWF</code>) can be applied. These filters restrict which datums are included in the query result. They are expressed as anonymous lambda rules:</p> <pre><code>{ $Pattern :- $Constraint }\n</code></pre> <p>This rule is instantiated for every declaration that is reachable according to the path well-formedness expression. When the instantiated body constraint holds, the declaration is included in the query answer.</p> Lambda Instantiation <p>Lambda constraint instantiation is similar to rule instantiation. For more information on rule instantiation, see the section about rule definitions.</p> Entailment semantics <p>Data well-formedness conditions are treated as entailment/implied conditions. Hence, they are not allowed to extend or refine the outer context. For more information on this evaluation mode, see the documentation of the <code>try</code> construct.</p> <p>The type of the predicate that is expected depends on the kind of relation that is used. For predicative relations, all arguments in the relation are provided to the data well-formedness constraint. However, for functional relations, the 'output value' (i.e. the value that the relation maps to) is not provided to the filter.</p> <p>When multiple arguments are provided to a data-wellformedness predicate (when there are multiple 'input' arguments to the queried relation), these arguments must be wrapped in a tuple.</p> <p>When the end-of-path query target <code>()</code> is used, the data-wellformedness constraint expects a single scope as argument.</p> Example of filters <p>A simple query for variables illustrates both filters. Suppose the relation <code>var</code> is in scope with type <code>string -&gt; TYPE</code>. Then a rule (with type ascriptions) that looks up a variable definition can be defined as follows. <pre><code>resolveVar(s : scope, name : string) = R :-\nquery var\nfilter P* I?\n       and { name' : string :- name' == name }\nin s |-&gt; R.\n</code></pre> In this example, the path well-formedness expression <code>P* I?</code> indicates that any number of <code>P</code> edges may be traversed, and then, optionally, a single <code>I</code> edge. This resolution policy excludes e.g. transitive imports, and the traversal of <code>P</code> edges in an imported module.</p> <p>The anonymous data well-formedness condition states that a declaration with name <code>name'</code> may only be included in the query result if <code>name'</code> is equal to <code>name</code> from the enclosing scope. Suppose that <code>resolveVar</code> is instantiated for <code>name |-&gt; \"x\"</code>, and declarations with name <code>\"x\"</code> and <code>\"y\"</code> are in scope. Now the anonymous inner rule is instantiated for both <code>\"x\"</code> and <code>\"y\"</code>. For <code>\"x\"</code>, the constraint <code>\"x\" == \"x\"</code> is generated, which can be solved successfully. For <code>\"y\"</code> however, the constraint <code>\"y\" == \"x\"</code> is generated, which cannot be solved successfully. Hence, only the declaration for <code>\"x\"</code> is included in the eventual query answer.</p> <p>There are three shorthands for common data well-formedness predicates:</p> <ul> <li><code>true</code>, which is equivalent to <code>{ _ :- true }</code>. This shorthand   will thus include all encountered declaration in the query result.</li> <li><code>false</code>, which is equivalent to <code>{ _ :- false }</code>. This shorthand   will include no declarations in the query answer.</li> <li><code>eq($Term)</code>, is equivalent to <code>{ x :- x == $Term }</code> and hence will include   all declarations that are equal to <code>$Term</code>.</li> </ul> <p>Syntactically, the query filter can be omitted entirely, or the data well-formedness predicate can be omitted, even if a path filter is provided. By default, the path filter is <code>~0</code>, meaning that every path is considered valid, and the data well-formedness predicate is <code>true</code>, meaning that every datum will be returned in the query answer.</p>"},{"location":"references/statix/queries/#shadowing","title":"Shadowing","text":"<p>For many languages, name resolution involves dealing with shadowing correctly. In Statix queries, it is possible to encode shadowing policies using label orders and data comparison predicates. A declaration shadows another declaration iff its path is 'smaller than' the other path by a prefix order defined over a label comparison relation, and when the declaration data is smaller than or equal to the data of the other declaration according to a data comparison predicate.</p> <p>Label orders (<code>$LabelOrder</code>) are expressed as less-than relations on labels.</p> <pre><code>$Label &lt; $Label\n</code></pre> <p>Here, a label is either a declared label symbol, or <code>$</code>, which denotes the 'end-of-path' label. This label can be used to express orders on path length. For example, <code>$ &lt; P</code> expresses that paths with fewer <code>P</code> labels are preferred over paths with more <code>P</code> labels.</p> <p>Strict Partial Order</p> <p>Label orders must be strict partial orders. That is, they are implicitly transitive, but may not be reflexive or symmetric. Label order specifications that are not strict partial orders will be rejected at specification loading time.</p> Prefix order <p>Note that the label order is a prefix order, not a lexicographical full-path order. That is, paths that diverged by traversing different edges with the same label are not ordered by this relation.</p> <p>In addition to a label ordering relation, a data comparison predicate (<code>$DataLeq</code>) can be provided. This predicate can be written as follows:</p> <pre><code>{ $Pattern, $Pattern :- $Constraint }\n</code></pre> <p>This constraint indicates that the left argument is smaller than the right argument, given that the constraint can be satisfied.</p> <p>The types of each patterns is similar to the type of the data-wellformedness predicate. When the queried relation is predicative (i.e. has no 'output'), the pattern is a tuple containing arguments of the declaration that is compared. If the queried relation is functional, a tuple with only the 'input' arguments must be provided. When there is only one declaration argument, the tuple may be omitted.</p> <p>There are several shorthands available for the data comparison constraint:</p> <ul> <li><code>true</code> is equivalent to <code>{ _, _ :- true }</code>, and hence ensures that declarations   are shadowed based on the label order only.</li> <li><code>false</code> is equivalent to <code>{ _, _ :- false }</code>, and hence ensures that no   shadowing is applied, even when paths can be ordered using the label order.</li> <li><code>$ConstraintName</code> is equivalent to <code>{ d1, d2 :- $ConstraintName(d1, d2) }</code>,   which means that <code>d1</code> shadows <code>d2</code> when <code>$ConstraintName(d1, d2)</code> can be   satisfied.</li> <li><code>{ $Pattern, $Pattern }</code> is equivalent to <code>{ $Pattern, $Pattern :- true }</code>,   which means that the first argument shadows the second if they match the   patterns.</li> </ul> Non-linear Patterns <p>The data comparison shorthand is mostly used with non-linear patterns. For example, to encode that declarations with equal names shadow each other, the data comparison shorthand <code>{ x, x }</code> can be used. When using this pattern however, please ensure that variable names are fresh, because the behavior of shadowing names is planned to change in the future.</p> Partial Order <p>Data comparison functions orders must be (non-strict) partial orders. That is, they are implicitly transitive and reflexive, but may not be symmetric. However, this is not validated for tractability reasons. Therefore, for any predicate that is not a partial order (other than <code>true</code>), shadowing behavior is undefined.</p> <p>Syntactically, the shadowing parameters can be omitted altogether, or the data comparison predicate can be omitted, even when an label order is specified. The default value of the label order is an empty relation, while the default value of the data comparison predicate is <code>true</code>. On the one hand, this ensures that no shadowing is applied when no shadowing parameters are provided. On the other hand, when a label order, but no data comparison predicate is provided, all declarations shadow each other based on a path comparison only.</p> <p>Operationally, the label order and the data comparison constraints are applied conjunctively. For any declaration <code>d</code> and <code>d'</code>, if the path to <code>d</code> is smaller than the path to <code>d'</code> according to the label order, and the application of the data comparison constraint to <code>d, d'</code> can be satisfied, <code>d'</code> will be excluded from the query answer.</p>"},{"location":"references/statix/queries/#result-pattern","title":"Result Pattern","text":"<p>When the query resolution is completed, the query result will be unified with the <code>$Result</code> term. This term is a list that contains path-datum entries. Therefore, the type of this term is <code>list((path * R))</code>, where <code>R</code> is a tuple type with the argument types of the relation that is queried. In case the relation is functional, the 'output' type is included in the result. When the relation is unary, the tuple is omitted. When the query target is <code>()</code>, <code>R</code> is the <code>scope</code> type.</p> <p>For the syntactic structure of the paths, please refer to the section on path terms. Semantically, for any query answer pair <code>(p, d)</code>, the path <code>p</code> represents the path followed from the scope in which the query started to the scope in which the declaration of <code>d</code> was found.</p> Top-level Destination scope <p>Since path terms are left-recursive, have the source scope at the left side, and the destination scope (i.e. the scope in which the paired datum was declared) on the right, it turns out that the target scope is in the third argument of the top-level constructor. This is convenient, since it allows to access the target scope without destructuring the whole path. (Direct access to the source scope is not really important, since it is already available as an argument to the query constraint). On the other side, it is sometimes perceived as not completely intuitive to have the target scope in the top level constructor.</p> <p>When multiple results are returned by the query, Statix has no guarantees on the order of their appearence in the list.</p>"},{"location":"references/statix/queries/#query-sugar","title":"Query Sugar","text":"<p>Warning</p> <p>Since Spoofax 2.5.15, the query sugar constructs are deprecated.</p>"},{"location":"references/statix/rules/","title":"Rules","text":"<p>User-defined constraints and their rules make up the main part of a Statix specification. In this section, we describe the definition and usage of user-defined constraints and their rules.</p>"},{"location":"references/statix/rules/#constraint-definitions","title":"Constraint Definitions","text":"<p>In order to define a custom constraint, its type must be declared first. A constraint can be declared in a <code>rules</code> section, or in a <code>constraints</code>  subsection of a <code>signature</code> section.</p> <p>A constraint is declared by specifying its name and argument type. For more information on types, please refer to the Terms section. Note that the name of the constraint must be unique within a specification.</p> <pre><code>$ConstraintName : {$Type \"*\"}*\n</code></pre> <p>Terminology</p> <p>In this reference manual, we consistently use the term 'constraint declaration' for the introduction of new user-defined constraints. However, in practise, these are sometimes also referred to as 'predicate' or just simply 'constraint'.</p> <p>When a constraint declaration is provided this way, it can be used as a constraint by providing concrete arguments, separated by comma's.</p> <pre><code>$ConstraintName({$Term \",\"}*) $Message?\n</code></pre> <p>The sorts of the argument terms should be equal to the sorts in the constraint declaration.</p>"},{"location":"references/statix/rules/#rule-definitions","title":"Rule Definitions","text":"<p>When solving a user-defined constraint, a rule for that constraint is unfolded in order to infer a model satisfying the constraint.</p> <pre><code>[$RuleName]$ConstraintName({$Pattern \",\"}*) :- $Constraint.\n</code></pre> <p>The part before the turnstile (<code>:-</code>) is often referred to as the head of the rule, while the <code>$Constraint</code> after the turnstile is denoted as body. When applying a rule, each head pattern (which is just a term) will be matched with its corresponding actual argument.</p> <p>Statically, the sorts of the terms in <code>$Patterns</code> are type-checked based on the constraint declaration. Any variables in patterns are implicitly introduced in the scope of the rule. Patterns can be non-linear. That is, a variable may occur multiple times in a pattern. Operationally, the subterms at these positions are then required to be structurally equal.</p> <p>Note that multiple rules for a single constraint can, and often will, be provided. For each constraint, the rule that is used for simplification is determined by the guard of the rule. This guard is derived from the head pattern: a rule can only be applied when the constraint arguments match the patterns.</p> <p>During constraint solving, Statix will try at most one rule for each constraint. The appropriate rule is selected by applying the following heuristics in order: 1. Rules with a smaller domain are preferred over rules with a larger domain. 2. When pairwise comparing rules, the rule for which, in left-to-right order, a    more specific pattern is encountered first is preferred over the other. For all cases where these heuristics do not decide which rule to use for a constraint, compile time \"Overlapping patterns\" errors will be emitted.</p> <p>The <code>$RuleName</code> is just a name that can be used for documentation purposes. It cannot be referenced from any position in the specification, and may be omitted altogether.</p>"},{"location":"references/statix/rules/#axiom-rules","title":"Axiom rules","text":"<p>In some cases, a constraint trivially holds for particular inputs. For such constraints, an axiom rule can be specified.</p> <pre><code>[$RuleName]$ConstraintName({$Pattern \",\"}*).\n</code></pre> <p>This rule is similar to a regular rule, but lacks a body. When applying such a rule, no new constraints are introduced, reflecting the fact that the constraint trivially holds for these arguments.</p>"},{"location":"references/statix/rules/#functional-rules","title":"Functional Rules","text":"<p>Some user-defined constraints can be thought of more naturally as a function: a constraint where a particular term is inferred by the constraint, rather than validated. Statix allows to write constraints in a functional idiom as follows:</p> <p>First, a constraint declaration for such 'functional constraints' must be provided as follows:</p> <pre><code>$ConstraintName : {$Type \"*\"}* -&gt; $Type\n</code></pre> <p>In addition to the regular list of input sorts, a sort for the output term is provided to the constraint declaration.</p> <p>Rule definitions for a functional constraint look as follows:</p> <pre><code>[$RuleName]$ConstraintName({$Pattern \",\"}*) = $Term :- $Constraint.\n</code></pre> <p>Compared to predicative rule definitions as introduced earlier in this section, an additional term after an equality-sign is appended to the rule head. This term denotes the output term (the term inferred by the rule).</p> <p>A functional constraint can be used in a term position, as opposed to a constraint position for predicative rules. Otherwise, their syntax is the same.</p> <pre><code>$ConstraintName({$Term \",\"}*)\n</code></pre> <p>Semantically, the output term of applying the constraint is substituted at the position of the application of the functional predicate.</p> <p>Terminology: Functional vs. Predicative</p> <p>When we want to make the distinction between these two forms of constraints explicit, we usually refer to either groups with 'predicative constraint declarations' and 'predicative constraints', versus 'functional constraint declarations' and 'functional constraints', respectively.</p> <p>Normalization</p> <p>Every specification with functional predicates is normalized to a form with only regular predicates. To show the normal form of a specification in Eclipse, use the Spoofax \u2023 Syntax \u2023 Format normalized AST menu action.</p>"},{"location":"references/statix/rules/#mapping-rules","title":"Mapping rules","text":"<p>Another common pattern in Statix is defining a predicate that instantiates a predicate for all elements in a list. Statix allows derive such mapping rules using the <code>maps</code> keyword as follows:</p> <pre><code>$MappingConstraintName maps $MappedConstraintName({$Lift \",\"}*)\n</code></pre> <p>A lift specifier (<code>$Lift</code>) can be one of the following:</p> <ul> <li><code>*</code>: The identity lift. This lift specifier indicates that this argument is   passed to the mapped constraint unchanged.</li> <li><code>list(*)</code>: The list lift: This lift specifier indicates that the mapped   constraint will be instantiated for each element in the list at that argument   position. Each constraint defined with <code>maps</code>, must contain at least one list   lift. Otherwise, the mapping would be a no-op.</li> <li><code>({$Lift \",\"}+)</code>: The tuple lift: This lift specifier indicates that arguments   are extracted from a tuple. For each tuple argument, a corresponding lifting   is applied afterwards.</li> </ul> <p>The type of <code>$MappingConstraintName</code> is inferred by inverse application of the lift specifiers to the type of <code>$MappedConstraintName</code>. Therefore, no explicit declaration of the type of the mapping constraint is required.</p> <p>Similar to predicative constraints, functional mapping constraints can be derived:</p> <pre><code>$MappingConstraintName maps $MappedConstraintName({$Lift \",\"}) = $Lift\n</code></pre> <p>In addition to lift specifiers of the input arguments, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred terms from the mapped constraints are aggregated and returned by the mapping constraint.</p> <p>Example. A common example where mapping rules are used is when type-checking a list of declarations. A specification snippet for that could look as follows:</p> <pre><code>rules\n\ndeclOk: scope * Decl\ndeclsOk maps declOk(*, list(*))\n\n// rules for declOk\n</code></pre> <p>In this snippet, the <code>declsOk</code> constraint instantiates <code>declOk</code> for each declaration in a list of declaration. Its inferred type is  <code>scope * list(Decl)</code>.</p> <p>When mapping functional constraints, a lift specifier for the inferred term must be provided as well. This lift specifier indicates how the inferred values of the mapped constraint are returned by the mapping constraint.</p> <p>When using multiple list lifts in the input, the resulting constraint will zip the arguments. This implicitly requires the input lists to be of equal length. The creation of a cartesian product can be achieved by repeated application of the <code>maps</code> construct for each argument.</p> <p>Normalization</p> <p>Similar to functional constraints, constraints derived using the <code>maps</code> construct are normalized to regular predicative constraints. This normalization can be inspected using the Spoofax \u2023 Syntax \u2023 Format normalized AST menu  action.</p>"},{"location":"references/statix/rules/#injections-of-namespaces-and-relations","title":"Injections of Namespaces and Relations","text":"<p>For convenience, it is possible to declare namespaces, namespace queries (both deprecated) and relations in a <code>rules</code> section as well.</p> <pre><code>rules\n\nnamespace Var: string\nresolve Var\nfilter P* I*\n\n  relations\nvar: string -&gt; TYPE\n</code></pre>"},{"location":"references/statix/scope-graphs/","title":"Scope Graph Constraints","text":"<p>One of the core concepts of Statix is modelling name binding structures using scope graphs. Scope graphs consist of three different components, summarized in the following table.</p> Component Description Textual Notation Graphical notation Scope Region in a program with uniform behavior wrt. name resolution. Represented as nodes in a graph. <code>#1</code> Circular node Edge Directed edges with upper-case labels model reachability between scopes. <code>#1 -L-&gt; #2</code> Labeled arrow Declaration Declarations associate data terms with a particular scope under a particular relation. <code>#1 |-r-&gt; d</code> Labeled block arrow <p>Using these components, and leveraging the fact that scopes are regular terms, many name-binding patterns can be modelled. In the remainder of this section, we will explain how scope graph constraints can be expressed in the Statix language.</p>"},{"location":"references/statix/scope-graphs/#scopes","title":"Scopes","text":"<p>First, scopes can be created using the <code>new</code> keyword:</p> <pre><code>new $Var+\n</code></pre> <p>For each var in the list of variables provided to the new constraint, a fresh scope is generated, and bound to that particular variable. Note that the <code>$Var</code>s are not introduced by this constraints, but rather have to be introduced earlier in a rule head or using an existential constraint.</p> <p>Statix guarantees that each scope has a unique identity. Scopes that are generated by different <code>new</code> constraints can never be equal under the equality constraint.</p>"},{"location":"references/statix/scope-graphs/#edges","title":"Edges","text":"<p>The existence of edges in a scope graph can be asserted using edge assertion constraints:</p> <pre><code>$Term -$Label-&gt; $Term\n</code></pre> <p>This constraint ensures that an edge from the first term argument to the last argument (which must have type <code>scope</code>) with a label <code>$Label</code> exists.</p> Edge Assertions not Idempotent <p>Edge constraints are not idempotent. That is, repeated edge assertions will result in multiple equivalent edges in a scope graph. However, because query results have set semantics, and edges have structural identity, declarations reached via such a duplicated edge will not be duplicated in a query answer.</p> <p>For example (assuming familiarity with queries and tests), the constraint: <pre><code>{R s1 s2}\nnew s1 s2,\ns1 -P-&gt; s2,\ns1 -P-&gt; s2,\nquery () filter P in s1 |-&gt; R\n</code></pre> will give the following (slightly simplified) result: <pre><code>substitution\nR |-&gt; [(PathStep(PathEmpty(#s1), P, #s2), #s2)]\n\nanalysis\nscope graph\n#s1 {\nedges {\nP : #s2\n#s2\n}\n}\n</code></pre> In this result, the <code>P</code> edge is duplicated in the scope graph, but there is still only a single query result.</p> <p>It is required to declare edge labels in a <code>signature</code> section:</p> <pre><code>signature\n\nname-resolution\nlabels\n$Label+\n</code></pre> <p>Label are just uppercase identifiers. They must adhere to the following regular expression: <code>[A-Z] [A-Za-z0-9\\_]</code>. It is not allowed to shadow label names, nor may modules import equivalent label names from different modules.</p>"},{"location":"references/statix/scope-graphs/#declarations","title":"Declarations","text":"<p>Declarations in a scope graph can be asserted as follows:</p> <pre><code>!$Relation[$Term*] in $Scope\n</code></pre> <p>This constraint asserts that the terms inside the square brackets are associated with scope <code>$Scope</code> under relation <code>$Relation</code>.</p> <p>Regarding the static semantics of this constraint, <code>$Scope</code> is a term which should have type <code>scope</code>. Additionally, the term arguments must adhere to the signature of the relation. The signature of a relation must be provided in a <code>signature</code> section:</p> <pre><code>signature\n\nrelations\n$Relation : {$Type \"*\"}*\n</code></pre> <p>Just as rules, relations can alternatively be declared in a functional style:</p> <pre><code>$Relation : {$Type \"*\"}* -&gt; $Type\n</code></pre> <p>The style of declaration is importand when doing queries, but asserting declarations is similar for both types of relations. When asserting a declaration for a functional relation, the terms that the relation maps to should be provided as the last term in the square brackets.</p> <p>Instead of in a <code>signature</code> section, relations can be declared in a <code>rules</code> section as well.</p> <p>It is allowed to have multiple declaration assertions for a single relation in the same scope, even when the data of the different relations are equivalent. In the latter case, multiple equivalent declarations will be inserted in the scope graph.</p>"},{"location":"references/statix/scope-graphs/#permission-to-extend","title":"Permission to Extend","text":"<p>In order to make query execution sound, Statix statically limits to which scopes new edges or declarations may be added (adding a edge or declaration is often called extending). Scope extension is only allowed in the following cases:</p> <ol> <li>Scopes that are freshly instantiated in a rule using <code>new</code> constraints may be    extended by that rule, and any user-defined constraint that is instantiated    by that rule.</li> <li>Scopes that are passed as direct argument to a rule may be extended by that    rule, given that the scope may be extended by rule that instantiated that    constraint. This property is validated at the instantiation site.</li> <li>Uninstantiated scope variables that are passed directly to a user-defined    constraint in which they are instantiated may be extended by the outer    constraint as well. However, this does not hold for input/output values of    functional rules</li> </ol> <p>These rules prevent extension of scopes that are obtained by pattern matching/ deconstruction.</p>"},{"location":"references/statix/scope-graphs/#namespaces-and-occurrences","title":"Namespaces and Occurrences","text":"<p>Warning</p> <p>Since Spoofax 2.5.15, namespaces and occurrences are deprecated.</p>"},{"location":"references/statix/stratego-api/","title":"Stratego API","text":"<p>The Statix solver can be called from a Stratego Transformation using the API in the Statix Runtime project. After analysis is executed, the analysis result can be queried using other strategies. In this section, we provide an overview of the availble strategies.</p> <p>The public API of the Statix runtime is available here. This API strongly depends on the Spoofax constraint analysis library, which is available in the Spoofax Meta Library.</p>"},{"location":"references/statix/stratego-api/#single-file-analysis","title":"Single-File Analysis","text":"<pre><code>stx-editor-analyze(pre, post|spec-name, init-constraint)\n</code></pre> <p>Type: <code>AnalysisAction -&gt; AnalysisResult</code>.</p> <p>Applies single-file analysis with the specification provided in the arguments. Since this strategy only performs single-file analysis, the current term should always have <code>AnalyzeSingle</code> as top-level constructor. The term and strategy arguments are explained in the following table:</p> Argument Type Default Description <code>pre</code> <code>AST -&gt; AST</code> <code>id</code> Transformation to apply before analyzing. This transformation receives the 'parsed AST'. <code>post</code> <code>AST -&gt; AST</code> <code>id</code> Transformation to apply before analyzing. This transformation receives the result of applying <code>pre</code> to the 'parsed AST', and yields the 'analyzed AST'. <code>spec-name</code> <code>String</code> The full path to the root module of the specification. <code>init-constraint</code> <code>String</code> The name of the constraint that should be applied to the pre-transformed AST. This may be a fully qualified name in the form <code>$Module!$ConstraintName</code>, or just a <code>$ConstraintName</code>. In the latter case, the name will be qualified with the <code>spec-name</code> argument. This constraint should have the (Statix) type <code>: Start</code> <p>The <code>post</code> and <code>pre</code> arguments may be omitted (in that order).</p> <p>Note that this strategy will return no results for <code>Cached</code> terms in the analysis action.</p>"},{"location":"references/statix/stratego-api/#single-file-elaboration","title":"Single-File Elaboration","text":"<pre><code>stx-editor-elaborate(pre, post|spec-name, init-constraint)\n</code></pre> <p>Todo</p> <p>Find out what this is?</p>"},{"location":"references/statix/stratego-api/#multi-file-analysis","title":"Multi-File Analysis","text":"<pre><code>stx-editor-analyze(pre, post|spec-name, project-constraint, file-constraint)\n</code></pre> <p>Type: <code>AnalysisAction -&gt; AnalysisResult</code>.</p> <p>Applies multi-file analysis with the specification provided in the arguments. Since this strategy only performs multi-file analysis, the current term should always have <code>AnalyzeMulti</code> as top-level constructor. This strategy chooses the solver based on the <code>metaborg.yaml</code> configuration of the project and the language. The term and strategy arguments are explained in the following table:</p> Argument Type Description <code>pre</code> <code>AST -&gt; AST</code> Transformation to apply before analyzing. This transformation receives the 'parsed AST'. <code>post</code> <code>AST -&gt; AST</code> Transformation to apply before analyzing. This transformation receives the result of applying <code>pre</code> to the 'parsed AST', and yields the 'analyzed AST'. <code>spec-name</code> <code>String</code> The full path to the root module of the specification. <code>project-constraint</code> <code>String</code> The name of the constraint that should be applied to the global scope once. This may be a fully qualified name in the form <code>$Module!$ConstraintName</code>, or just a <code>$ConstraintName</code>. In the latter case, the name will be qualified with the <code>spec-name</code> argument. This constraint should have the (Statix) type <code>: scope</code> <code>file-constraint</code> <code>String</code> The name of the constraint that should be applied to the pre-transformed AST of each file in the project. This may be a fully qualified name in the form <code>$Module!$ConstraintName</code>, or just a <code>$ConstraintName</code>. In the latter case, the name will be qualified with the <code>spec-name</code> argument. This constraint should have the (Statix) type <code>: scope * Start</code>"},{"location":"references/statix/stratego-api/#concurrent-analysis","title":"Concurrent Analysis","text":"<pre><code>stx-editor-analyze(pre, group, post|spec-name, project-constraint, group-constraint, file-constraint)\n</code></pre> <p>Type: <code>AnalysisAction -&gt; AnalysisResult</code>.</p> <p>Applies concurrent multi-file analysis with the specification provided in the arguments. Since this strategy only performs multi-file analysis, the current term should always have <code>AnalyzeMulti</code> as top-level constructor. This strategy chooses the solver based on the <code>metaborg.yaml</code> configuration of the project and the language, but fails with a fatal error if the concurrent solver is not enabled on this project. The term and strategy arguments are explained in the following table:</p> Argument Type Description <code>pre</code> <code>AST -&gt; AST</code> Transformation to apply before analyzing. This transformation receives the 'parsed AST'. <code>group</code> <code>(Resource * AST) -&gt; List(String)</code> Strategy that decides in which group a resource is analyzed. Should return a list with the identifiers of the groups in which the resource should be analyzed. <code>post</code> <code>AST -&gt; AST</code> Transformation to apply before analyzing. This transformation receives the result of applying <code>pre</code> to the 'parsed AST', and yields the 'analyzed AST'. <code>spec-name</code> <code>String</code> The full path to the root module of the specification. <code>project-constraint</code> <code>String</code> The name of the constraint that should be applied to the global scope once. This may be a fully qualified name in the form <code>$Module!$ConstraintName</code>, or just a <code>$ConstraintName</code>. In the latter case, the name will be qualified with the <code>spec-name</code> argument. This constraint should have the (Statix) type <code>: scope</code> <code>group-constraint</code> <code>String</code> The name of the constraint that should be applied to the each group. This may be a fully qualified name in the form <code>$Module!$ConstraintName</code>, or just a <code>$ConstraintName</code>. In the latter case, the name will be qualified with the <code>spec-name</code> argument. This constraint should have the (Statix) type <code>: scope * string * scope</code> <code>file-constraint</code> <code>String</code> The name of the constraint that should be applied to the pre-transformed AST of each file in the project. This may be a fully qualified name in the form <code>$Module!$ConstraintName</code>, or just a <code>$ConstraintName</code>. In the latter case, the name will be qualified with the <code>spec-name</code> argument. This constraint should have the (Statix) type <code>: scope * Start</code>"},{"location":"references/statix/stratego-api/#constraint-evaluation","title":"Constraint Evaluation","text":"<pre><code>stx-evaluate(|spec-name, constraint)\n</code></pre> <p>Type: <code>List(Term) -&gt; Term</code></p> <p>Evaluates a functional constraint. The terms in the current term are passed as argument to the constraint, and the result term is the output term of the constraint.</p> Argument Type Description <code>spec-name</code> <code>String</code> The full path to the root module of the specification. <code>constraint</code> <code>String</code> The name of the constraint that should be applied to the term arguments."},{"location":"references/statix/stratego-api/#reading-analysis-results","title":"Reading Analysis Results","text":"<p>The Statix API provides several strategies to query properties from the analysis. These strategies are dicussed in the following sections.</p> <p>First of all, the analysis result can be obtained by the following strategy:</p> <pre><code>stx-get-ast-analysis\n</code></pre> <p>Type: <code>Term -&gt; Analysis</code></p> <p>The <code>stx-get-ast-analysis</code> returns the Analysis object for an AST. This object can later be used to query the scope graph and AST properties set by the Statix specification.</p> <p>Note that the passed AST should be an analyzed AST. For Spoofax 2 use cases, this means that this strategy can only be used in builders without the <code>(source)</code> annotation.</p> <p>The returned values will be interpreted relative to the unifier of the analysis. That is, it will be instantiated as much as possible. When a property value contains free variables, those will occur in the property as <code>nabl2.Var: String * String -&gt; Term</code> terms.</p>"},{"location":"references/statix/stratego-api/#properties","title":"Properties","text":"<p>AST properties can be extracted from the analysis result using the following strategy:</p> <pre><code>stx-get-ast-property(|a, name)\n</code></pre> <p>Type: <code>Term -&gt; Term or list(Term)</code>.</p> Argument Type Description <code>a</code> <code>Analysis</code> Analysis object for the given AST node. <code>name</code> <code>String</code> The name of the property that is queried. <p>Given an AST node, this strategy will return the property value. For singleton properties (<code>:=</code> operator), the property value is returned. For bag properties (<code>+=</code> operator), a list with all assigned values is returned. It fails if no property with the given name is set. Therefore, for bag properties the resulting list will never be empty.</p> <p>Example 1. Consider a Statix specification that contains a <code>@t.prop := val</code> constraint. Using <code>&lt;stx-get-ast-property(|a, \"prop\")&gt; t</code> will then return <code>val</code></p> <p>Example 2. Consider a Statix specification that contains <code>@t.prop += val1, @t.prop += val2</code> constraints. Using <code>&lt;stx-get-ast-property(|a, \"prop\")&gt; t</code> will then return <code>[val1, val2]</code>.</p> <p>As the <code>type</code> and <code>ref</code> properties have special meanings in the Spoofax context, there are special strategies to retrieve those: <pre><code>stx-get-ast-type(|a)\n\nstx-get-ast-ref(|a)\n</code></pre> which both have the same type constraints as <code>stx-get-ast-property</code></p> <p><code>type</code> and <code>ref</code> properties</p> <p>Using the generic <code>stx-get-ast-property</code> to retrieve <code>type</code> or <code>ref</code> properties will not work. I.e., <code>stx-get-ast-property(|a, \"type\")&gt; t</code> will fail, even if there was an <code>@t.type := T</code> constraint.</p>"},{"location":"references/statix/stratego-api/#scope-graph","title":"Scope Graph","text":"<p>Declarations in a scope graph can be retrieved using the following strategies:</p> <pre><code>stx-get-scopegraph-data(|a, rel)\n\nstx-get-scopegraph-edges(|a, lbl)\n</code></pre> Argument Type Description <code>a</code> <code>Analysis</code> Analysis object for the given AST node. <code>rel</code> <code>String</code> Fully qualified name of the relation that is queried. <code>lbl</code> <code>String</code> Fully qualified name of the label that is traversed. <p>The <code>stx-get-scopegraph-data</code> strategy, which has type <code>Scope -&gt; [Term]</code> retrieves all data declared under relation <code>rel</code> in the input term scope. The data is returned in a (possible empty) list that contains tuples holding the data of each relevant declaration.</p> <p>Example. Consider a Statix specification that gives rise to a <code>new s, !var[\"x\", INT()] in s, !var[\"y\", BOOL()] in s</code> constraint. Now, applying <code>&lt;stx-get-scopegraph-data(|a, \"statics/Main!var\")&gt; s</code> will return <code>[(\"x\", INT()), (\"y\", BOOL())]</code>.</p> <p>Note that a fully qualified name should be passed to the <code>rel</code> argument. Fully qualified names are created by prefixing a relation name with the module in which it is declared, separated by a <code>!</code>. For example, <code>\"statics/Main!var\"</code> is the fully qualified name of the relation <code>var</code> declared in module <code>statix/Main</code>. The Spoofax 2 Console will emit warnings when an invalid label is used, and suggest available names.</p> <p>The returned values will be interpreted relative to the unifier of the analysis. That is, it will be instantiated as much as possible. When a property value contains free variables, those will occur in the property as <code>nabl2.Var: String * String -&gt; Term</code> terms.</p> <p>The <code>stx-get-scopegraph-edges</code> strategy, which has type <code>Scope -&gt; [Scope]</code> traverses all edges with the <code>lbl</code> label. All target scopes are returned in the output list.</p> <p>Example. Consider a Statix specification that gives rise to a <code>new s s1 s2, s -L-&gt; s1, s -L-&gt; s2</code> constraint. Now, applying <code>&lt;stx-get-scopegraph-edges(|a, \"statics/Main!L\")&gt; s</code> will return <code>[s1, s2]</code>.</p> <p>Similar to the <code>stx-get-scopegraph-edges</code> strategy, the label should be fully qualified, and the result may contain free variables.</p> Retrieving a scope <p>Both strategies discussed in this section take a scope as input. However, it seemed that no way to obtain a reference to a scope was introduced. In fact, scope references should be made available using AST properties. For example, the <code>new s, @t.scope := x</code> makes scope <code>s</code> available using the <code>stx-get-ast-property(|a, \"scope\") t</code> transformation.</p>"},{"location":"references/statix/stratego-api/#analysis-results","title":"Analysis Results","text":"<pre><code>stx-analysis-has-errors = stx--analysis-has-errors\n</code></pre> <p>Type: <code>Analysis -&gt; Analysis</code></p> <p>Fails if the current term has no errors, succeeds otherwise.</p>"},{"location":"references/statix/terms/","title":"Terms","text":"<p>In Statix, data is represented using terms. This data can be a program, a typing annotation, or anything else that the specification defines. Terms are built from atoms and composites, such as constructors, tuples and lists. Additionally, Statix allows to inline several constraint results in terms.</p> <p>In this section, we explain the various types of terms that Statix supports, and, when appropriate, how their types should be declared.</p> <p>Terminology: Sort vs. Type</p> <p>Throughout this reference manual, we use the term 'sort' for syntactic categories, and 'type' for all other types (such as lists, tuples, scopes, etc.). However, in practice, these terms are both used in both meanings.</p>"},{"location":"references/statix/terms/#numerals","title":"Numerals","text":"<p>Numeric literals are literals of the form <code>[0-9]+</code>. Negative literals are not supported directly. All integer literals have the built-in type <code>int</code>.</p>"},{"location":"references/statix/terms/#strings","title":"Strings","text":"<p>String literals are arbitrary, single-line sequences of characters enclosed in double quotes. String literals may not contain unescaped backslashes, double quotes, or tabs. Double quotes and backslashes can be used in a string literal by prefixing them with another backslashes (<code>\\\"</code> and <code>\\\\</code>, respectively), while tabs, newlines and carriage returns can be encoded using respectively <code>\\t</code>, <code>\\n</code> and <code>\\r</code>. Otherwise, no escaping is required. String literals have the built-in type <code>string</code>.</p>"},{"location":"references/statix/terms/#identifiers","title":"Identifiers","text":"<p>Variables are identifiers of values of the following form: <code>[a-zA-Z] [a-zA-Z0-9\\_]* [\\']*</code>.</p> <p>With respect to type-checking, variables can be handled in two ways. When a variable occurs in the head of a rule, it is implicitly brought into scope with the type inferred from the rule type. Otherwise, it is required that the variable is introduced earlier, with the correct type. Apart from introduction in rule heads, variables can be introduced by existential constraints. In that case, the type of the variable is derived from its usage. Rule patterns may be non-linear (containing multiple occurrences of a variable), variables in an existential must be unique. That is, the constraint <code>{x x} ...</code>  will give a type error. Shadowing variables is allowed, but discouraged by a warning.</p> Substitution and Unification <p>Although the Statix language does not distinguish between variables in rule heads and existentials, the solver treats those quite differently. On rule application, occurrences of variables from rule heads in the body of the rule are substituted by the actual arguments. For example, in a specification containing the rule <code>rule(x) :- x == ().</code>, simplifying the constraint <code>rule(())</code> will result in the residual constraint <code>() == ()</code>, which trivially holds. However, when simplifying the constraint <code>{x} x == ()</code>, simplifying will generate a fresh unification variable (say <code>?x-1</code>), and substitute that in the constraint, yielding <code>?x-1 == ()</code>. Solving that will create a new mapping <code>?x-1 |-&gt; ()</code> in the unifier of the solver result. ```</p>"},{"location":"references/statix/terms/#wildcards","title":"Wildcards","text":"<p>Wildcards are represented as <code>_</code>, and denote variables without identity. Every occurrence of a wildcard is interpreted as a new variable. Because wildcards cannot reference each other, it is not required that the types of multiple wildcard occurrences coincide.</p>"},{"location":"references/statix/terms/#composite-terms","title":"Composite terms","text":"<p>Composite terms can be build using constructor applications:</p> <pre><code>$ConsId({$Term \",\"}*)\n</code></pre> <p>Here a term with constructor <code>$ConsId</code> and some term arguments is built.</p> <p>Composite terms must adhere to a signature. A signature describes which term compositions are valid, and must be declared in a <code>signature</code> section:</p> <pre><code>signature\nsorts $SortID*\n\n  constructors\n$ConsId : {$Type \"*\"}+ -&gt; $SortID\n$ConsId : $SortID\n</code></pre> <p>First, the syntactic categories (which closely correspond to type identifiers in other languages) must be declared in a <code>sorts</code> subsection. Then, the constructor symbols can be declared in a <code>constructors</code> section. For each constructor, the types of the arguments and its sort should be provided. For nullary constructors (constructors without arguments), the arrow preceding the sort should be omitted.</p> <p>When a composite term is built, it is validated that all arguments match the type declaration from the signature. The type of the whole composite term is equal to the sort of the constructor.</p>"},{"location":"references/statix/terms/#tuples","title":"Tuples","text":"<p>A built-in composite data construction is tuples:</p> <pre><code>({$Term \",\"}*)\n</code></pre> <p>Tuples have a statically fixed length, but the types of the arguments may differ. The type of the tuple expression is just the product of its arguments.</p> <p>The arity of a tuple may be anything except one, because unary tuples cause syntactic ambiguities with bracketed expressions.</p>"},{"location":"references/statix/terms/#lists","title":"Lists","text":"<p>Another built-in composite data construction is lists:</p> <pre><code>[{$Term \",\"}*]\n</code></pre> <p>Lists are created by comma-separating terms, enclosing them in square brackets. All terms should have the same type. Given that the type of the terms is <code>T</code>, the type of the list expression will be <code>list(T)</code>.</p> <p>Alternatively, lists can have a variable tail:</p> <pre><code>[{$Term \",\"}* | $Term]\n</code></pre> <p>In this syntax, the tail of the list is another term. This term should have type <code>list(T)</code>, where <code>T</code> is again the type of the first terms.</p>"},{"location":"references/statix/terms/#name-ascription","title":"Name Ascription","text":"<p>It is possible to assign names to terms by prefixing the term with a variable name:</p> <pre><code>$Var@$Term\n</code></pre> <p>Note that this does not introduce a new variable with name <code>$Var</code> (except in a rule head, where all variables are introduced implicitly), but rather requires that a variable with corresponding name and type is already introduced.</p> Ascribe and Equality <p>In terms of equality constraints, the ascribe is equal to <code>$Var == $Term</code>. It is used to prevent the duplication of <code>$Term</code>.</p>"},{"location":"references/statix/terms/#type-ascription","title":"Type Ascription","text":"<p>Statix allows to add inline type annotations to terms as follows:</p> <pre><code>$Term : $Type\n</code></pre> <p>The type-checker will validate that the term actually has the specified type, but the runtime behavior in not influenced by these ascriptions.</p> <p>Complete Inference</p> <p>In general, the Statix type-checker should be able to infer all types. However, in case of a type error being reported at an incorrect position, these type ascriptions can help tracing the cause of the error.</p>"},{"location":"references/statix/terms/#arithmetic-operations","title":"Arithmetic operations","text":"<p>Arithmetic expressions can be inserted in terms as follows:</p> <pre><code>#( $ArithExp )\n</code></pre> <p>Here, the type of the expression is <code>int</code>. For more information on arithmetic expressions, see Arithmetic Constraints</p> Normalization <p>In terms of existential constraints, inline arithmetic expressions have behavior equal to <code>{v} v #= $ArithExp</code>, where <code>v</code> is used at the position of the arithmetic expression. So, for example, <code>{T} T == CONS(#(21 * 2))</code> is equal to <code>{T v} v #= 21 * 2, T == CONS(v)</code>.</p>"},{"location":"references/statix/terms/#ast-identifier","title":"AST Identifier","text":"<p>In Spoofax, all terms in an AST are assigned a unique identifier (the term index) before analysis. This term identifier can be isolated as follows:</p> <pre><code>astId($Term)\n</code></pre> <p>Here, the type of <code>$Term</code> can be anything, and the type of the whole term will be <code>astId</code>. AST Identifiers are used to assign properties.</p>"},{"location":"references/statix/terms/#new","title":"New","text":"<p>Statix allows inline creation of scopes:</p> <pre><code>new\n</code></pre> <p>Statically, the <code>new</code> term has type <code>scope</code>. At runtime, this creates a fresh scope, and inserts that at the position of the <code>new</code> term.</p> Normalization <p>In terms of existential constraints, the inline <code>new</code> operator has behavior equal to <code>{s} new s</code>, where <code>s</code> is used at the position of the <code>new</code> term. So, for example, <code>{T} T == CLASS(new)</code> is equal to <code>{T s} new s, T == CLASS(s)</code>.</p>"},{"location":"references/statix/terms/#paths","title":"Paths","text":"<p>Part of a query result is the path from the resolved datum back to the scope where the query started. In order to represent paths, Statix has two built-in constructors:</p> <ul> <li><code>_PathEmpty</code>: Unary constructor that carries a single scope. This constructor   has type <code>scope -&gt; path</code>.</li> <li><code>_PathStep</code>: Ternary constructor that represents a traversed edge in a path.   This constructor has type <code>path * label * scope -&gt; path</code>.</li> </ul> <p>Label Constraints</p> <p>Although the labels in a <code>_PathStep</code> can be bound to a variable, and hence be compared with and included in other terms, no inspection, matching or comparison with label definitions is supported.</p>"},{"location":"references/statix/terms/#occurrences","title":"Occurrences","text":"<p>Warning</p> <p>Since Spoofax 2.5.15, namespaces and occurrences are deprecated.</p> <p>Statix has built-in support for namespaces. A term embedded in a particular namespace is called an <code>occurrence</code>. Occurrences can be written as follows:</p> <pre><code>$NamespaceId{ $SpaceTerms }\n$NamespaceId{ $SpaceTerms @$OccurrenceId }\n</code></pre> <p>In this structure template, <code>$SpaceTerms</code> means a list of terms, separated by spaces. The occurrence identifier can be any term. In case the term has an AST identifier, that value will be used as the identity of the occurrence.</p> <p>Alternatively, the occurrence identifier can be left out:</p> <pre><code>$NamespaceId{ $SpaceTerms }\n</code></pre> <p>The default occurrence identifier is <code>-</code>, which means that the occurrence has no identifier. The type of an occurrence literal is <code>occurrence</code>. For more information about namespaces, see the Queries section.</p>"},{"location":"references/statix/terms/#declaration-match","title":"Declaration Match","text":"<p>Statix allows to query the current scope for declarations of a particular form:</p> <pre><code>?$RelationId[{$Term \",\"}] in $Scope\n</code></pre> <p>When using this expression, a functional relation <code>$RelationId</code> must be declared. The terms arguments must correspond to the argument of the relation, and the type of the term is the output type of the relation.</p> <p>For more information on querying the scope graph, see the Queries section.</p> Declaration Match as Query <p>In terms of regular queries, the declaration match is equal to a query with filter <code>e</code>, expecting a single output. E.g. <code>T == ?var[\"x\"] in s</code> is equal to <code>query var filter e and { x' :- x' == \"x\" } in s |-&gt; [(_, (_, T))]</code>.</p>"},{"location":"references/statix/tests/","title":"Tests","text":"<p>Statix has its own test format. These tests can help to debug your specification and isolate issues. In this section, we explain the format and the output of such tests.</p>"},{"location":"references/statix/tests/#test-format","title":"Test Format","text":"<p>Statix tests should reside in <code>*.stxtest</code> files, and look as follows:</p> <pre><code>resolve $Constraint\n\n$Section*\n</code></pre> <p>At the top level, the <code>resolve</code> keyword indicates this is a test file. After this keyword, the constraint that should be solved when executing the test is provided. Finally, any section that can be found in a regular module can be added to a test.</p> <p>A test can be executed using the traditional or the concurrent solver with the <code>Spoofax &gt; Evaluate &gt; Evaluate Test</code> or <code>Spoofax &gt; Evaluate &gt; Evaluate Test (Concurrent)</code> menu, respectively.</p>"},{"location":"references/statix/tests/#test-output","title":"Test Output","text":"<p>When a test is executed, a <code>.stxresult</code> file with the test result will open. This file contains three sections.</p> <p>First, under the <code>substitution</code> header, a mapping from the top-level existentially quantified variables to their values is provided. Due to the normalization Statix applies, there are sometimes additional entries for wildcards and return values of functional predicates.</p> <p>Secondly, under <code>analysis</code> and <code>scope graph</code>, the scope graph that models the test constraint is shown. A scope graph consists of a list of scope terms, which look as follows</p> <pre><code>$ScopeName {\nrelations {\n$RelationID : $Term+\n  }\nedges {\n$LabelID: $Scope+\n  }\n}\n</code></pre> <p>That is, for each label and relation for which entries exists in a scope, a list of associated scopes/data is shown.</p> <p>Empty Scopes</p> <p>Note that no entry for an empty scope will be present.</p> <p>Finally, under the <code>errors</code>, <code>warnings</code> and <code>notes</code> headers, the appropriate messages of these types are shown. The message value is equal to the top line of a regular Statix message, but no traces are displayed. Terms in templates are formatted three levels deep.</p>"},{"location":"references/stratego/","title":"Stratego","text":"<p>The Stratego language caters for the definition of program transformations.</p> <p>Transformations operate on the abstract syntax trees of programs. Abstract syntax trees are represented by means of first-order terms.</p> <p>A program is structured as a collection of modules, which may import each other.</p> <p>Transformations are defined by means of named rewrite rules. Rules may explicitly invoke rules. Alternatively, rules may be invoked by strategies that define how to combine rules into a more complex transformation using strategy combinators. Context-sensitive transformations can be expressed using dynamic rewrite rules.</p> <p>Starting with Stratego 2, terms and transformation strategies are (gradually) typed.</p>"},{"location":"references/stratego/#placeholder-convention","title":"Placeholder Convention","text":"<p>In this reference manual we use placeholders to indicate the syntactic structure of language constructs. For example, a rewrite rule has the form</p> <pre><code>$Label :\n$Term -&gt; $Term\n</code></pre> <p>in which the <code>$Label</code> is the name of the rule, the first <code>$Term</code> the left-hand side, and the second the right-hand side of the rule. This convention should give an indication of the formal structure of a construct, without going down to the precise details of the syntax definition. As a side effect, the schema also shows the preferred indentation of language constructs where that is applicable.</p>"},{"location":"references/stratego/#not-in-reference-manual","title":"Not in Reference Manual","text":""},{"location":"references/stratego/#concrete-syntax","title":"Concrete Syntax","text":"<p>By using the concrete syntax of a language, transformations can be expressed in the native syntax of the language under transformation, rather than using abstract syntax.</p>"},{"location":"references/stratego/#library","title":"Library","text":"<p>The Stratego standard library is a collection of modules that are available with each Stratego program and on which the runtime library relies.</p> <p>Find automatically generated documentation at the following sites:</p> <ul> <li>http://releases.strategoxt.org/docs/api/libstratego-lib/stable/docs/</li> <li>https://stratego.martijndwars.nl/</li> </ul>"},{"location":"references/stratego/#source","title":"Source","text":"<p>The sources of the Stratego implementation can be found at</p> <ul> <li> <p>https://github.com/metaborg/stratego: The Stratego language implementation</p> </li> <li> <p>https://github.com/metaborg/strategoxt: The Stratego/XT ecosystem</p> </li> </ul>"},{"location":"references/stratego/dynamic-rules/","title":"Dynamic Rules","text":"<p>Plain rewrite rules are context-free, i.e. do not take their context into account. Context-sensitive transformations can be defined by passing context information using additional arguments to rules and strategies. Alternatively, Stratego provides linguistic support to dynamically define rewrite rules based on context information1.</p>"},{"location":"references/stratego/dynamic-rules/#defining-dynamic-rules","title":"Defining Dynamic Rules","text":"<pre><code>rules( $Id : $Rule ... )\n</code></pre> <p>A dynamic rule definition is a regular (conditional) rewrite rule that is defined as part of a strategy rather than at top-level.</p> <p>The difference is that any variables that are bound in the context of the rule, take their binding from the context, rather then being universally quantified. Thus, a dynamic rule instance can be thought of as having the context variables replaced by the corresponding terms from the context.</p> <p>Example. The following strategy <code>DefineInlineCall</code> defines the dynamic rule <code>InlineCall</code>:</p> <pre><code>DefineInlineCall =\n?FunDef(f, args, e)\n; rules(\nInlineCall :\nCall(f, es) -&gt; Let(dec*, e)\nwhere &lt;zip(\\(x, e) -&gt; VarDec(x, e)\\)&gt; (args, es) =&gt; dec*\n    )\n</code></pre> <p>The variables <code>f</code>, <code>args</code>, and <code>e</code> in the dynamic rule are bound in context, while the variables <code>es</code> and <code>dec*</code> are universally quantified. The variables <code>x</code> and <code>e</code> in the embedded lambda rule are local to that rule. Thus, the application</p> <pre><code>&lt;DefineInlineCall&gt;\nFunDef(\"inc\", [\"x\"], Add(Var(\"x\"), Int(\"1\")))\n</code></pre> <p>can be thought of to give rise to the definition</p> <pre><code>InlineCall :\nCall(\"inc\", es) -&gt; Let(dec*, Add(Var(\"x\"), Int(\"1\")))\nwhere &lt;zip(\\(x, e) -&gt; VarDec(x, e)\\)&gt; ([\"x\"], es) =&gt; dec*\n</code></pre>"},{"location":"references/stratego/dynamic-rules/#invoking-dynamic-rules","title":"Invoking Dynamic Rules","text":"<p>When <code>$Id</code> is defined as a dynamic rule it can be invoke like a regular rule or strategies. The invocation only succeeds when applied to a term that coincide with the left-hand side pattern variables bindings inherited from the context.</p> <p>Thus, in the example above <code>InlineCall</code> can be called to invoke a previously defined dynamic rule. For example, the following are calls to <code>DefineInlineCall</code> and <code>InlineCall</code></p> <pre><code>&lt;DefineInlineCall&gt;\nFunDef(\"inc\", [\"x\"], Add(Var(\"x\"), Int(\"1\")))\n\n&lt;InlineCall&gt;\nCall(\"inc\", [Mul(Var(\"y\"), Int(\"3\"))]) =&gt;\nLet([VarDec(\"x\", Mul(Var(\"y\"), Int(\"3\")))],\nAdd(Var(\"x\"), Int(\"1\")))\n\n&lt;InlineCall&gt;\nCall(\"foo\", []) // fails\n</code></pre> <p>Note that the application to <code>Call(\"foo\", [])</code> fails since it does not match the dynamically defined rule.</p>"},{"location":"references/stratego/dynamic-rules/#parameterized-dynamic-rules","title":"Parameterized Dynamic Rules","text":"<p>Dynamic rules can be parameterized like regular rewrite rules and strategies.</p>"},{"location":"references/stratego/dynamic-rules/#multiple-definitions","title":"Multiple Definitions","text":"<p>Dynamic rules can be defined for multiple contexts simultaneously.</p> <p>For example, the following applications of <code>DefineInlineCall</code></p> <pre><code>&lt;DefineInlineCall&gt;\nFunDef(\"inc\", [\"x\"], Add(Var(\"x\"), Int(\"1\")))\n\n&lt;DefineInlineCall&gt;\nFunDef(\"twice\", [\"y\"], Mul(Var(\"x\"), Int(\"2\")))\n</code></pre> <p>can be thought of defining multiple top-level rewrite rules</p> <pre><code>InlineCall :\nCall(\"inc\", es) -&gt; Let(dec*, Add(Var(\"x\"), Int(\"1\")))\nwhere &lt;zip(\\(x, e) -&gt; VarDec(x, e)\\)&gt; ([\"x\"], es) =&gt; dec*\n\nInlineCall :\nCall(\"twice\", es) -&gt; Let(dec*, Mul(Var(\"y\"), Int(\"2\")))\nwhere &lt;zip(\\(x, e) -&gt; VarDec(x, e)\\)&gt; ([\"y\"], es) =&gt; dec*\n</code></pre>"},{"location":"references/stratego/dynamic-rules/#overriding-dynamic-rules","title":"Overriding Dynamic Rules","text":"<p>A definition of a dynamic rule with the same left-hand side as a previous definition, overrides that previous definition.</p> <p>Thus, if after the applications of <code>DefineInlineCall</code> above, we apply</p> <pre><code>&lt;DefineInlineCall&gt;\nFunDef(\"twice\", [\"z\"], Add(Var(\"z\"), Var(\"z\")))\n</code></pre> <p>Then the dynamic rule for <code>twice</code> above is undefined, and instead the rule</p> <pre><code>InlineCall :\nCall(\"twice\", es) -&gt; Let(dec*, Add(Var(\"z\"), Var(\"z\")))\nwhere &lt;zip(\\(x, e) -&gt; VarDec(x, e)\\)&gt; ([\"z\"], es) =&gt; dec*\n</code></pre> <p>is added to the collection of rules.</p>"},{"location":"references/stratego/dynamic-rules/#dynamic-rule-scope","title":"Dynamic Rule Scope","text":"<p>It is possible to limit the scope in which dynamic rule definitions are available. The dynamic rule scope <code>{| $Id ... : $Strategy |}</code> limits the availability of dynamic rules named <code>$Id ..</code> defined within the brackets to that scope. After exiting the scope, the state of the dynamic rule definitions before the scope is restored.</p> <p>For example, the following strategy defines inlining rules that are only available during the visit of the body of the <code>Let</code>:</p> <pre><code>  inline :\nLet(dec1*, e1) -&gt; Let(dec2*, e2)\nwith &lt;inline&gt; dec1* =&gt; dec2*\n    with {| InlineCall\n: &lt;map(try(DefineInlineCall))&gt; dec2*\n          ; &lt;inline&gt; e1 =&gt; e2\n|}\n</code></pre> <p>Application of this strategy to the program term</p> <pre><code>Let([FunDef(\"inc\", [..], ..)\n, FunDef(\"twice\", [..], ..)]\n, Add(\nLet([FunDef(\"twice\", [..], [..])]\n, Call(\"twice\", [..])) // inline second def of twice\n, Call(\"twice\", [..]) // inline first def of twice\n)\n)\n</code></pre> <p>will result in locally overriding the first dynamic rule for <code>\"twice\"</code>, but undoing that override at the end of the dynamic rule scope, such that it is available again at the second call to <code>\"twice\"</code>.</p> <p>While dynamic rule scopes can deal with lexical scope systems, the preferred way to deal with scope in programming languages is to perform name (and type) analysis using the Statix meta-language and perform a uniquify transformation to guarantee unique names.</p>"},{"location":"references/stratego/dynamic-rules/#multiple-right-hand-sides","title":"Multiple Right-Hand Sides","text":"<p>In order to collect multiple ways to rewrite a term use <code>rules( $Id :+ $Rule)</code>.</p> <p>For example, the following is a small API for for emitting nodes in a control-flow graph consisting of blocks.  </p> <pre><code>add-cfg-node  :: CBlock -&gt; CBlock\nall-cfg-nodes :: List(CBlock) -&gt; List(CBlock)\n\nadd-cfg-node =\n?block\n; rules( CFGNode :+ _ -&gt; block )\n\nall-cfg-nodes =\n&lt;bagof-CFGNode &lt;+ ![]&gt;()\n</code></pre> <p>The <code>bagof-$Id</code> strategy is generated automatically and produces all right-hand sides corresponding to a left-hand side.</p>"},{"location":"references/stratego/dynamic-rules/#other-dynamic-rule-extensions","title":"Other Dynamic Rule Extensions","text":"<p>The papers by Olmos and Visser2 and Bravenboer et. al1 describe more advanced features of dynamic rules, primarily inspired by data-flow transformations. For defining data-flow analyses, Spoofax now provides the FlowSpec meta-language.</p>"},{"location":"references/stratego/dynamic-rules/#references","title":"References","text":"<ol> <li> <p>Martin Bravenboer, Arthur van Dam, Karina Olmos, and Eelco Visser. Program transformation with scoped dynamic rewrite rules. Fundamenta Informaticae, 69(1-2):123\u2013178, 2006. URL: https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06.\u00a0\u21a9\u21a9</p> </li> <li> <p>Karina Olmos and Eelco Visser. Composing source-to-source data-flow transformations with rewriting strategies and dependent dynamic rewrite rules. In Rastislav Bod\u00edk, editor, Compiler Construction, 14th International Conference, CC 2005, Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2005, Edinburgh, UK, April 4-8, 2005, Proceedings, volume 3443 of Lecture Notes in Computer Science, 204\u2013220. Springer, 2005. URL: https://doi.org/10.1007/978-3-540-31985-6_14, doi:10.1007/978-3-540-31985-6_14.\u00a0\u21a9</p> </li> </ol>"},{"location":"references/stratego/lexical/","title":"Lexical","text":""},{"location":"references/stratego/lexical/#identifiers","title":"Identifiers","text":"<p>Identifiers used as names of constructors and transformations have the form</p> <pre><code>ID = [a-zA-Z][a-zA-Z0-9\\-\\_]*\n</code></pre> <p>In particular, hyphens can be part of identifiers.</p> <p>Identifiers cannot be followed by identifiers or keywords without intervening whitespace.</p>"},{"location":"references/stratego/lexical/#reserved-words","title":"Reserved Words","text":"<p>Todo</p> <p>provide list of reserved words</p>"},{"location":"references/stratego/lexical/#module-names","title":"Module Names","text":"<p>Module names can be sequences of identifiers separated by <code>/</code>.</p>"},{"location":"references/stratego/lexical/#integers","title":"Integers","text":"<pre><code>INT = [0-9]+\n</code></pre> <p>Check</p> <p>syntax of integers</p>"},{"location":"references/stratego/lexical/#whitespace","title":"Whitespace","text":"<p>Spaces, tabs, and newlines are whitespace and can occur between any two tokens.</p>"},{"location":"references/stratego/lexical/#comments","title":"Comments","text":"<p>Comments follow the C/Java tradition. That is, the language supports single line comments after <code>//</code></p> <pre><code>// a single line comment\n</code></pre> <p>and multi-line comments between <code>/*</code> and <code>*/</code></p> <pre><code>/*\n  a multi-line comment\n  can be spread over multiple\n  lines\n */\n</code></pre> <p>Comments can occur anywhere.</p> <p>Multi-line comments cannot be nested currently.</p> <p>Todo</p> <p>but this should be changed so that multi-line comments can be nested</p>"},{"location":"references/stratego/modules/","title":"Modules","text":"<p>A Stratego program is organized as a collection of modules, which are imported from a main module.</p>"},{"location":"references/stratego/modules/#module-structure","title":"Module Structure","text":"<pre><code>module $ModuleName\n$Imports*\n$Section*\n</code></pre> <p>A module starts with a module header followed by a list of <code>imports</code>. The name of a module in the header and imports should correspond to the file name, relative to a 'root' directory.</p> <p>The rest of a module consists of <code>signature</code>, <code>rules</code>, and <code>strategies</code> sections, in any order, and possibly repeated.</p>"},{"location":"references/stratego/modules/#file-name-and-file-extension","title":"File Name and File Extension","text":"<p>A module coincides with the file it resides in. It is not possible to define more than one module in a file, which precludes nested modules. The name of a module coincides with the file name, which should be fully qualified relative to a root directory.</p> <p>A Stratego is a file with the extension <code>.str2</code> for Stratego 2. Modules for the Stratego 1 version of the language have extension <code>.str</code>. The file extension does not feature in the module names used in the language.</p> <p>The following is example module header:</p> <pre><code>module compilation/translation\nimports desugaring/desugar\n</code></pre>"},{"location":"references/stratego/modules/#module-names","title":"Module Names","text":"<p>Module names can be hierarchical. For example, consider the following directory structure</p> <p><pre><code>- trans\n  - compilation\n    - optimization.str2\n    - translation.str2\n  - desugaring\n    - desugar.str2\n</code></pre> A declaration of or reference to a module uses its fully qualified name, with <code>/</code> to indicate the directory structure, relative to a 'root' directory.</p> <p>For example, if <code>trans</code> is declared as a root, then the module names for the modules above are</p> <pre><code>- compilation/optimization\n- compilation/translation\n- desugaring/desugar\n</code></pre>"},{"location":"references/stratego/modules/#imports","title":"Imports","text":"<pre><code>imports $ModuleName+\n</code></pre> <p>A module should import all other modules from which it uses definitions. Imports are non-transitive and may be mutually recursive.</p> <p>Modules can extend rule and strategy definitions from other modules. This allows the modular extension of a language.</p> <p>When imported, all definitions in a module are visible. There are currently no mechanisms for hiding definitions.</p> <p>An <code>imports</code> can list multiple modules. The form</p> <pre><code>imports A B\n</code></pre> <p>is equivalent to</p> <pre><code>imports A\nimports B\n</code></pre>"},{"location":"references/stratego/modules/#signatures","title":"Signatures","text":"<p>A signature section introduces sorts, constructors, and overlays.</p> <pre><code>signature\nsorts $Sort*\n  constructors\n$ConstructorDef*\n  overlays\n$OverlayDef*\n</code></pre>"},{"location":"references/stratego/modules/#rules-and-strategies","title":"Rules and Strategies","text":"<p>Rule definitions and strategy definitions introduce named transformations.</p> <pre><code>rules\n$RuleDef*\n</code></pre> <pre><code>strategies  $StrategyDef*\n</code></pre> <p>The <code>rules</code> and <code>strategies</code> section headers are indicative only; rule and strategy definitions can actually be mixed.</p>"},{"location":"references/stratego/modules/#libraries","title":"Libraries","text":"<p>A Stratego library is a closed collection of modules. A library can be pre-compiled since client programs may not extend its definitions. A library is used by importing a collection of external definitions of the signatures of constructors and transformations it defines. Even if definitions in a library are not included in a libraries external definition, they cannot be redefined, as that produces link errors.</p>"},{"location":"references/stratego/modules/#source-inclusion","title":"Source Inclusion","text":"<p>Todo</p>"},{"location":"references/stratego/modules/#concrete-syntax","title":"Concrete Syntax","text":"<p>When using concrete syntax in a module, a <code>.meta</code> file accompanying the module indicates the parse table to use.</p>"},{"location":"references/stratego/rewrite-rules/","title":"Rewrite Rules","text":"<pre><code>$Id($StrategyArg, ... | $TermArg, ...) :\n$Term -&gt; $Term\n$Condition*\n</code></pre> <p>A rewrite rule has a name, zero or more strategy arguments, zero or more term arguments, a left-hand side term pattern, a right-hand side term pattern, and zero or more conditions.</p> <p>A rewrite rule application <code>$Id($StrategExp, ... | $Term)</code> to a subject term binds the strategy and term arguments and matches the term pattern in the left-hand side to the term. If the pattern match succeeds, the conditions are applied in turn to the subject term, accumulating bindings to term variables. When all conditions succeed, the right-hand side term pattern is instantiated with the accumulated variable bindings.</p> <p>When the pattern match to the left-hand side or one of the conditions fails, the rule fails.</p>"},{"location":"references/stratego/rewrite-rules/#where-condition","title":"Where Condition","text":"<pre><code>where $StrategyExp\n</code></pre> <p>A <code>where</code> condition performs a strategy expression in the context of the rule arguments, the left-hand side bindings, and the previous conditions, possibly binding term variables.</p> <p>If the strategy expression fails, the enclosing rule fails. Failure of a <code>where</code> clause is expected. The strategy expression is expected to be discriminating and only succeed in those cases that the rule should be applied.</p>"},{"location":"references/stratego/rewrite-rules/#with-condition","title":"With Condition","text":"<pre><code>with $StrategyExp\n</code></pre> <p>A <code>with</code> condition performs a strategy expression in the context of the rule arguments, the left-hand side bindings, and the previous conditions, possibly binding term variables.</p> <p>A <code>with</code> condition expresses the expectation that the strategy expression succeeds in all cases. When a <code>with</code> condition fails, this is an indication of a programming error, and the enclosing rule throws a fatal exception, and the program terminates with a stack trace.</p>"},{"location":"references/stratego/rewrite-rules/#simple-rewrite-rules","title":"Simple Rewrite Rules","text":"<pre><code>$Id:\n$Term -&gt; $Term\n$Condition*\n</code></pre> <p>A simple (unparameterized) rewrite rule consists of a name that identifies the rule, a left-hand side term pattern, a right-hand side term pattern, and zero or more conditions.</p> <p>Example</p> <pre><code>DeMorgan :\nNot(And(e1, e2)) -&gt; Or(Not(e1), Not(e2))\n</code></pre>"},{"location":"references/stratego/rewrite-rules/#rules-with-the-same-name","title":"Rules with the Same Name","text":"<p>Multiple rewrite rules may have the same name. When a (simple) rewrite rule fails to apply to a term, the next rule with the same name is tried.</p> <p>For examples, the following rules define desugarings of expressions.</p> <pre><code>rules desugar-exp :: Exp -&gt; Exp\n\ndesugar-exp :\nSeq([], e) -&gt; e\n\ndesugar-exp :\nSeq([e], Unit()) -&gt; e\n\ndesugar-exp :\nSeq([e1, e2 | e*], e3) -&gt; Seq([e1], Seq([e2 | e*], e3))\n\ndesugar-exp :\nSeq([Seq(e1*, e1) | e2*], e2) -&gt; Seq([e1*, e1 | e2*], e2)\n\ndesugar-exp :\nLet(dec*, [e1, e2 | e*]) -&gt; Let(dec*, [Seq([e1, e2 | e*], Unit())])\n</code></pre> <p>When one rule fails to apply, the next rule is tried. When the left-hand sides are non-overlapping, the order of the rules does not matter. In case of overlap, the rules are tried in textual order. When overlapping rules are defined in separate modules, the order is undefined.</p> <p>Note</p> <p>Consider specificity ordering in the future.</p>"},{"location":"references/stratego/rewrite-rules/#parameterized-rewrite-rules","title":"Parameterized Rewrite Rules","text":"<p>Rewrite rules can be parameterized with transformation strategies and with terms.</p> <p>Example. The following rules define reversal of a list with an accumulator:</p> <pre><code>rules\nreverse :: List(a) -&gt; List(a)\nreverse : xs -&gt; &lt;reverse-acc(|[])&gt; xs\n\nreverse-acc(|List(a)) :: List(a) -&gt; List(a)\nreverse-acc(|xs) : [] -&gt; xs\nreverse-acc(|xs) : [y | ys] -&gt; &lt;reverse-acc(|[y | xs])&gt; ys\n</code></pre> <p>When leaving out the term parameters, the bar can be left out</p> <pre><code>$Id($StrategyArg) :\n$Term -&gt; $Term\n$Condition*\n</code></pre> <p>Example. The <code>map(s)</code> strategy applies transformation <code>s</code> to each element of a list:</p> <pre><code>map(a -&gt; b) :: List(a) -&gt; List(b)\nmap(s) : [] -&gt; []\nmap(s) : [hd | tl] -&gt; [&lt;s&gt;hd | &lt;map(s)&gt; tl]\n</code></pre> <p>Note</p> <p>In the absence of a type system, the distinction between strategy arguments and term arguments was made based on the syntactic distinction. In a future version of the language, this syntactic distinction may no longer be necessary based on types.</p>"},{"location":"references/stratego/rewrite-rules/#desugaring","title":"Desugaring","text":"<p>A conditional rewrite rule can be desugared to a strategy definition using basic strategy combinators.</p> <p>A simple rewrite rule succeeds if the match of the left-hand side succeeds. Sometimes it is useful to place additional requirements on the application of a rule, or to compute some value for use in the right-hand side of the rule. This can be achieved with conditional rewrite rules.</p> <p>A conditional rule <code>L: p1 -&gt; p2</code> where <code>s</code> is a simple rule extended with an additional computation <code>s</code> which should succeed in order for the rule to apply. The condition can be used to test properties of terms in the left-hand side, or to compute terms to be used in the right-hand side. The latter is done by binding such new terms to variables used in the right-hand side.</p> <p>For example, the <code>EvalPlus</code> rule in the following session uses a condition to compute the sum of <code>i</code> and <code>j</code>:</p> <pre><code>EvalPlus:\nPlus(Int(i),Int(j)) -&gt; Int(k)\nwhere !(i,j); addS; ?k\n\n&lt;EvalPlus&gt;\nPlus(Int(\"14\"),Int(\"3\")) =&gt; Int(\"17\")\n</code></pre> <p>A conditional rule can be desugared similarly to an unconditional rule. That is, a conditional rule of the form</p> <pre><code>L : p1 -&gt; p2 where s\n</code></pre> <p>is syntactic sugar for</p> <pre><code>L = ?p1; where(s); !p2\n</code></pre> <p>Thus, after the match with <code>p1</code> succeeds the strategy <code>s</code> is applied to the subject term. Only if the application of <code>s</code> succeeds, is the right-hand side <code>p2</code> built. Note that since <code>s</code> is applied within a where, the build <code>!p2</code> is applied to the original subject term; only variable bindings computed within <code>s</code> can be used in <code>p2</code>.</p> <p>As an example, consider the following constant folding rule, which reduces an addition of two integer constants to the constant obtained by computing the addition.</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k) where !(i,j); addS; ?k\n</code></pre> <p>The addition is computed by applying the primitive strategy addS to the pair of integers <code>(i,j)</code> and matching the result against the variable <code>k</code>, which is then used in the right-hand side. This rule is desugared to</p> <pre><code>EvalPlus =\n?Add(Int(i),Int(j)); where(!(i,j); addS; ?k); !Int(k)\n</code></pre>"},{"location":"references/stratego/strategy-combinators/","title":"Strategy Combinators","text":"<p>A strategy expression combines the application of rules using strategy combinators. We first provide a concise overview of (the syntax of) all combinators. After that, we provide a more detailed description of each combinator.</p> <p>Sequential Combinators</p> <ul> <li><code>id</code>   : identity</li> <li><code>fail</code> : failure</li> <li><code>s1 ; s2</code> : sequential composition</li> <li><code>s1 &lt;+ s2</code> : left choice</li> <li><code>s1 &lt; s2 + s3</code> : guarded left choice</li> <li><code>if s1 then s2 else s3</code> : if-then-else</li> <li><code>switch ... end</code> : switch</li> <li><code>s1 + s2</code> : non-deterministic choice</li> <li><code>rec x(s)</code> : fixpoint recursion</li> </ul> <p>Term Combinators</p> <ul> <li><code>!p</code> : build</li> <li><code>?p</code> : match</li> <li><code>{x, ... : s}</code> : term variable scope</li> </ul> <p>Strategy Sugar</p> <ul> <li><code>(p1 -&gt; p2)</code> : anonymous rewrite rule</li> <li><code>where(s)</code> : where</li> <li><code>with(s)</code> : with</li> <li><code>\\ p1 -&gt; p2 where s \\</code> : lamba rules</li> <li><code>&lt;s&gt; p</code> : apply</li> <li><code>s =&gt; p</code> : match</li> <li><code>&lt;s&gt; p1 =&gt; p2</code> : apply and match</li> <li><code>p1 := p2</code> : assign</li> </ul> <p>Term Sugar</p> <ul> <li><code>&lt;s&gt; p</code> : apply in build</li> <li><code>!p[&lt;s&gt;]</code> : term wrap</li> <li><code>?p[&lt;s&gt;]</code> : term project</li> </ul> <p>Traversal Combinators</p> <ul> <li><code>c(s1, ..., sn)</code> : congruence</li> <li><code>(s1, ..., sn)</code> : tuple congruence</li> <li><code>[s1, ..., sn]</code> : list congruence</li> <li><code>[s1, ..., sn | s]</code> : list congruence</li> <li><code>all(s)</code> : all</li> <li><code>one(s)</code> : one</li> <li><code>some(s)</code> : some</li> </ul> <p>Generic Term (De)Construction</p> <ul> <li><code>c#(ts)</code> : generic term (de)construction</li> </ul>"},{"location":"references/stratego/strategy-combinators/#sequential-combinators","title":"Sequential Combinators","text":""},{"location":"references/stratego/strategy-combinators/#identity-and-failure","title":"Identity and Failure","text":"<pre><code>id\nfail\n</code></pre> <p>The identity strategy <code>id</code> always succeeds and behaves as the identity function on terms. The failure strategy <code>fail</code> always fails. The operations have no side effects.</p>"},{"location":"references/stratego/strategy-combinators/#sequential-composition","title":"Sequential Composition","text":"<pre><code>$StrategyExp; $StrategyExp\n</code></pre> <p>The sequential composition <code>s1 ; s2</code> of the strategies <code>s1</code> and <code>s2</code> first applies the strategy <code>s1</code> to the subject term and then <code>s2</code> to the result of that first application. The strategy fails if either <code>s1</code> or <code>s2</code> fails.</p> <p>Properties. Sequential composition is associative. Identity is a left and right unit for sequential composition; since <code>id</code> always succeeds and leaves the term alone, it has no additional effect to the strategy that it is composed with. Failure is a left zero for sequential composition; since <code>fail</code> always fails the next strategy will never be reached. This leads to the following equations:</p> <pre><code>(s1; s2) ; s3 = s1; (s2; s3)\n\nid; s = s\n\ns; id = s\n\nfail; s = fail\n</code></pre> <p>However, not for all strategies <code>s</code> we have that failure is a right zero for sequential composition:</p> <pre><code>s ; fail = fail   // is not a law\n</code></pre> <p>Although the composition <code>s; fail</code> will always fail, the execution of <code>s</code> may have side effects that are not performed by <code>fail</code>. For example, consider printing a term in <code>s</code>.</p> <p>Example. Consider the following rewrite rules.</p> <pre><code>A : P(Z(),x) -&gt; x\nB : P(S(x),y) -&gt; P(x,S(y))\n</code></pre> <p>The following applications shows the effect of first applying <code>B</code> and then <code>A</code>:</p> <pre><code>&lt;B&gt; !P(S(Z()), Z()) =&gt; P(S(Z),Z)\n\n&lt;A&gt; P(Z,S(Z)) =&gt; S(Z)\n</code></pre> <p>Using the sequential composition of the two rules, this effect can be achieved \u2018in one step\u2019:</p> <pre><code>&lt;B; A&gt; !P(S(Z()),Z()) =&gt; S(Z)\n</code></pre> <p>The following application shows that the application of a composition fails if the second strategy in the composition fails to apply to the result of the first:</p> <pre><code>&lt;B; B&gt; !P(S(Z()),Z()) // fails\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#left-choice","title":"Left Choice","text":"<pre><code>$StrategyExp &lt;+ $StrategyExp\n</code></pre> <p>The left choice or deterministic choice <code>s1 &lt;+ s2</code> tries to apply <code>s1</code> and <code>s2</code> in that order. That is, it first tries to apply <code>s1</code>, and if that succeeds the choice succeeds. However, if the application of <code>s1</code> fails, <code>s2</code> is applied to the original term.</p> <p>Properties. Left choice is associative. Identity is a left zero for left choice; since id always succeeds, the alternative strategy will never be tried. Failure is a left and right unit for left choice; since fail always fails, the choice will always backtrack to the alternative strategy, and use of fail as alternative strategy is pointless.</p> <pre><code>(s1 &lt;+ s2) &lt;+ s3 = s1 &lt;+ (s2 &lt;+ s3)\n\nid &lt;+ s  = id\n\nfail &lt;+ s = s\n\ns &lt;+ fail = s\n</code></pre> <p>However, identity is not a right zero for left choice. That is, not for all strategies s we have that</p> <pre><code>s &lt;+ id =  s    // is not a law\n</code></pre> <p>The expression <code>s &lt;+ id</code> always succeeds, even (especially) in the case that <code>s</code> fails, in which case the right-hand side of the equation fails of course.</p> <p>Local Backtracking. The left choice combinator is a local backtracking combinator. That is, the choice is committed once the left-hand side strategy has succeeded, even if the continuation strategy fails. This is expressed by the fact that the property</p> <pre><code>(s1 &lt;+ s2); s3 = (s1; s3) &lt;+ (s2; s3)    // is not a law\n</code></pre> <p>does not hold for all <code>s1</code>, <code>s2</code>, and <code>s3</code>. The difference is illustrated by the following applications:</p> <pre><code>&lt;(B &lt;+ id); B&gt; P(S(Z),Z) // fails\n\n&lt;(B; B) &lt;+ (id; B)&gt; P(S(Z()),Z()) =&gt; P(Z,S(Z))\n</code></pre> <p>In the application of <code>(B &lt;+ id); B</code>, the first application of <code>B</code> succeeds after which the choice is committed. The subsequent application of <code>B</code> then fails. This is equivalent to first applying <code>(B &lt;+ id)</code> and then applying <code>B</code> to the result. The application of <code>(B; B) &lt;+ (id; B)</code>, however, is successful; the application of <code>B; B</code> fails, after which the choice backtracks to <code>id; B</code>, which succeeds.</p> <p>Example. The typical use of left choice is to create a composite strategy trying one from several possible transformations. If the strategies that are composed are mutually exclusive, that is, don\u2019t succeed for the same terms, their sum is a transformation that (deterministically) covers a larger set of terms. For example, consider the following two rewrite rules:</p> <pre><code>PlusAssoc : Plus(Plus(e1, e2), e3) -&gt; Plus(e1, Plus(e2, e3))\nPlusZero  : Plus(Int(\"0\"), e) -&gt; e\n</code></pre> <p>These rules are mutually exclusive, since there is no term that matches the left-hand sides of both rules. Combining the rules with left choice into <code>PlusAssoc &lt;+ PlusZero</code> creates a strategy that transforms terms matching both rules as illustrated by the following applications:</p> <pre><code>&lt;PlusAssoc&gt;\nPlus(Int(\"0\"),Int(\"3\")) // fails\n\n&lt;PlusAssoc &lt;+ PlusZero&gt;\nPlus(Int(\"0\"),Int(\"3\")) =&gt; Int(\"3\")\n\n&lt;PlusZero&gt;\nPlus(Plus(Var(\"x\"),Int(\"42\")),Int(\"3\")) // fails\n\n&lt;PlusAssoc &lt;+ PlusZero&gt;\nPlus(Plus(Var(\"x\"),Int(\"42\")),Int(\"3\")) =&gt;\nPlus(Var(\"x\"),Plus(Int(\"42\"),Int(\"3\")))\n</code></pre> <p>Example. An application of <code>&lt;+</code> in combination with <code>id</code> is the reflexive closure of a strategy <code>s</code>:</p> <pre><code>try(s) = s &lt;+ id\n</code></pre> <p>The user-defined strategy combinator try tries to apply its argument strategy <code>s</code>, but if that fails, just succeeds using <code>id</code>.</p>"},{"location":"references/stratego/strategy-combinators/#guarded-left-choice","title":"Guarded Left Choice","text":"<pre><code>$StrategyExp &lt; $StrategyExp + $StrategyExp\n</code></pre> <p>With the guarded left choice operator <code>s1 &lt; s2 + s3</code>, if <code>s1</code> succeeds <code>s2</code> is applied, else <code>s3</code> is applied. If <code>s2</code> fails, the complete expression fails; no backtracking to <code>s3</code> takes place.</p> <p>Properties. This combinator is a generalization of the left choice combinator <code>&lt;+</code>.</p> <pre><code>s1 &lt;+ s2 = s1 &lt; id + s2\n</code></pre> <p>The following laws make clear that the \u2018branches\u2019 of the choice are selected by the success or failure of the guard:</p> <pre><code>id &lt; s2 + s3  = s2\n\nfail &lt; s2 + s3 = s3\n</code></pre> <p>If the right branch always fails, the construct reduces to the sequential composition of the guard and the left branch.</p> <pre><code>s1 &lt; s2 + fail = s1; s2\n</code></pre> <p>Guarded choice is not associative:</p> <pre><code>(s1 &lt; s2 + s3) &lt; s4 + s5 = s1 &lt; s2 + (s3 &lt; s4 + s5)    // not a law\n</code></pre> <p>To see why consider the possible traces of these expressions. For example, when <code>s1</code> and <code>s2</code> succeed subsequently, the left-hand side expression calls <code>s4</code>, while the right-hand side expression does not.</p> <p>However, sequential composition distributes over guarded choice from left and right:</p> <pre><code>(s1 &lt; s2 + s3); s4 = s1 &lt; (s2; s4) + (s3; s4)\n\ns0; (s1 &lt; s2 + s3) = (s0; s1) &lt; s2 + s3\n</code></pre> <p>Examples. The guarded left choice operator is most useful for the implementation of higher-level control-flow strategies. For example, the negation <code>not(s)</code> of a strategy <code>s</code>, succeeds if <code>s</code> fails, and fails when it succeeds:</p> <pre><code>not(s) = s &lt; fail + id\n</code></pre> <p>Since failure discards the effect of a (successful) transformation, this has the effect of testing whether <code>s</code> succeeds. So we have the following laws for not:</p> <pre><code>not(id) = fail\nnot(fail) = id\n</code></pre> <p>However, side effects performed by <code>s</code> are not undone, of course. Therefore, the following equation does not hold:</p> <pre><code>not(not(s)) = s   // not a law\n</code></pre> <p>Another example of the use of guarded choice is the restore-always combinator:</p> <pre><code>restore-always(s, r) = s &lt; r + (r; fail)\n</code></pre> <p>It applies a \u2018restore\u2019 strategy <code>r</code> after applying a strategy <code>s</code>, even if <code>s</code> fails, and preserves the success/failure behavior of <code>s</code>. Since <code>fail</code> discards the transformation effect of <code>r</code>, this is mostly useful for ensuring that some side-effecting operation is done (or undone) after applying <code>s</code>.</p>"},{"location":"references/stratego/strategy-combinators/#if-then-else","title":"If-then-else","text":"<pre><code>if $StrategyExp\nthen\n$StrategyExp\nelse\n$StrategyExp\nend\n</code></pre> <p>The <code>if s1 then s2 else s3 end</code> construct is like the traditional construct since both branches apply to the original term. The condition strategy is only used to test if it succeeds or fails, but its transformation effect is undone. However, the condition strategy <code>s1</code> is still applied to the subject term. The <code>if s1 then s2 end</code> strategy is similar; if the condition fails, the strategy succeeds.</p> <p>The if-then-else-end strategy is just syntactic sugar for a combination of guarded choice and the where combinator:</p> <pre><code>    if s1 then s2 else s3 end\n==&gt; // transforms to\nwhere(s1) &lt; s2 + s3\n</code></pre> <p>The strategy <code>where(s)</code> succeeds if <code>s</code> succeeds, but returns the original subject term.</p> <p>Properties. The following laws show that the branches are selected by success or failure of the condition:</p> <pre><code>if id   then s2 else s3 end  =  s2\n\nif fail then s2 else s3 end  =  s3\n</code></pre> <p>The if-then-end strategy is an abbreviation for the if-then-else-end with the identity strategy as right branch:</p> <pre><code>if s1 then s2 end  =  where(s1) &lt; s2 + id\n</code></pre> <p>Examples. The inclusive or <code>or(s1, s2)</code> succeeds if one of the strategies <code>s1</code> or <code>s2</code> succeeds, but guarantees that both are applied, in the order <code>s1</code> first, then <code>s2</code>:</p> <pre><code>or(s1, s2) =\nif s1 then try(where(s2)) else where(s2) end\n</code></pre> <p>This ensures that any side effects are always performed, in contrast to <code>s1 &lt;\\+ s2</code>, where <code>s2</code> is only executed if <code>s1</code> fails. (Thus, left choice implements a short circuit Boolean or.)</p> <p>Similarly, the following <code>and(s1, s2)</code> combinator is the non-short circuit version of Boolean conjunction:</p> <pre><code>and(s1, s2) =\nif s1 then where(s2) else where(s2); fail end\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#switch","title":"Switch","text":"<pre><code>switch s0\ncase s1 : s1'\n  case s2 : s2'\n  ...\n  otherwise : sdef\nend\n</code></pre> <p>The switch construct is an n-ary branching construct similar to its counter parts in other programming languages. It is defined in terms of guarded choice.</p> <p>The <code>switch</code> first applies the <code>s0</code> strategy to the current term <code>t</code> resulting in a term <code>t'</code>. Then it tries the cases in turn applying each <code>si</code> to <code>t'</code>. As soon as this succeeds the corresponding case is selected and <code>si'</code> is applied to the <code>t</code>, the term to which the switch was applied. If none of the cases applies, the default strategy <code>sdef</code> from the <code>otherwise</code> is applied.</p> <p>The <code>switch</code> construct is syntactic sugar for a nested if-then-else:</p> <pre><code>{x : where(s0 =&gt; x);\nif &lt;s1&gt; x\nthen s1'\n    else if &lt;s2&gt; x\nthen s2'\n        else if ...\n            then ...\n            else sdef\nend\nend\nend}\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#non-deterministic-choice","title":"Non-Deterministic Choice","text":"<pre><code>$StrategyExp + $StrategyExp\n</code></pre> <p>The non-deterministic choice operator <code>s1 + s2</code> chooses one of the two strategies <code>s1</code> or <code>s2</code> to apply, such that the one it chooses succeeds. If both strategies fail, then the choice fails as well. Operationally the choice operator first tries one strategy, and, if that fails, tries the other. The order in which this is done is undefined, i.e., arbitrarily chosen by the compiler or runtime system.</p> <p>The <code>+</code> combinator is used to model modular composition of rewrite rules and strategies with the same name, but in different modules. Multiple definitions with the same name in different modules, are merged into a single definition with that name, where the bodies are composed with <code>+</code>. The following transformation illustrates this:</p> <pre><code>module A\nf = s1\nmodule B   f = s2  module main\nimports A B\n=&gt;\nf = s2 + s1\n</code></pre> <p>This transformation is somewhat simplified; the complete transformation needs to take care of local variables and parameters.</p> <p>While the <code>+</code> combinator is used internally by the compiler for this purpose, programmers are advised not to use this combinator, but rather use the left choice combinator <code>&lt;+</code> to avoid surprises.</p> <p>Note. In the past, the <code>+</code> combinator was also used to compose definitions with the same name within a module. This has been replaced by interpreting such compositions with the textual order of the definitions. The following transformation illustrates this:</p> <pre><code>module A\nf = s1\nf = s2\n=&gt;\nf = s1 &lt;+ s2\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#fixpoint-recursion","title":"Fixpoint Recursion","text":"<pre><code>rec $Id($StrategyExp)\n</code></pre> <p>The fixpoint operator <code>rec x(s)</code>, which recurses on applications of <code>x</code> within <code>s</code>.</p> <p>The rec operator allows the definition of an unnamed strategy expression to be recursive. For example, in the definition</p> <pre><code>g(s) = foo; rec x(... x ...); bar\n</code></pre> <p>the strategy between foo and bar is a recursive strategy that does not recurse to <code>g(s)</code>.</p> <p>Alternative. Originally, the <code>rec</code> operator was the only way to define recursive strategies. Currently, a recursive definition is a normal strategy definition with a recursive call in its body.</p> <pre><code>f(s) = ... f(s) ...\n</code></pre> <p>The <code>rec</code> operator is still in the language in the first place because it is widely used in many existing programs, and in the second place because it can be a concise expression of a recursive strategy, since call parameters are not included in the call. Furthermore, all free variables remain in scope.</p> <p>Example. The <code>repeat</code> strategy applies a transformation <code>s</code> until it fails. It is defined as a recursive definition using <code>try</code> as follows:</p> <pre><code>try(s)    = s &lt;+ id\nrepeat(s) = try(s; repeat(s))\n</code></pre> <p>An equivalent definition using <code>rec</code> is:</p> <pre><code>repeat(s) = rec x(try(s; x))\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#term-combinators","title":"Term Combinators","text":""},{"location":"references/stratego/strategy-combinators/#building-terms","title":"Building Terms","text":"<pre><code>!$Term\n</code></pre> <p>The build operation <code>!p</code> replaces the subject term with the instantiation of the pattern <code>p</code> using the bindings from the environment to the variables occurring in <code>p</code>.</p> <p>Example. The strategy <code>!Or(And(x, z), And(y, z))</code> replaces the subject term with the instantiation of <code>Or(And(x, z), And(y, z))</code> using bindings to variables <code>x</code>, <code>y</code> and <code>z</code>.</p> <pre><code>!Int(\"10\") =&gt; Int(\"10\")\n!Plus(Var(\"a\"), Int(\"10\")) =&gt; Plus(Var(\"a\"), Int(\"10\"))\n</code></pre> <p>It is possible to build terms with variables. A pattern is a term with meta-variables. The current term is replaced by an instantiation of pattern <code>p</code>.</p> <p>Example. In a context where <code>e</code> is bound to <code>Var(\"b\")</code></p> <pre><code>!Plus(Var(\"a\"),e) =&gt; Plus(Var(\"a\"),Var(\"b\"))\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#matching-terms","title":"Matching Terms","text":"<pre><code>?$Term\n</code></pre> <p>The match operation <code>?t</code> matches the subject term against the term <code>t</code>.</p> <pre><code>&lt;?Plus(Var(\"a\"),Int(\"3\"))&gt; Plus(Var(\"a\"),Int(\"3\")) // succeeds\n&lt;?Plus(Int(\"3\"),Var(\"b\"))&gt; Plus(Var(\"a\"),Int(\"3\")) // fails\n</code></pre> <p>Matching against a term pattern with variables binds those variables to (parts of) the current term. The match strategy <code>?x</code> compares the current term (<code>t</code>) to variable <code>x</code>. It binds variable <code>x</code> to term <code>t</code> in the environment. A variable can only be bound once, or to the same term.</p> <pre><code>&lt;?e&gt; Plus(Var(\"a\"), Int(\"3\")) // binds e to Plus(Var(\"a\"),Int(\"3\"))\n&lt;?e&gt; !Int(\"17\")               // fails\n</code></pre> <p>The general case is matching against an arbitrary term pattern. The match strategy <code>?p</code> compares the current term to a pattern <code>p</code>. It will add bindings for the variables in pattern p to the environment. The wildcard <code>_</code> in a match will match any term.</p> <pre><code>&lt;?Plus(e,_)&gt;Plus(Var(\"a\"),Int(\"3\")) // e is bound to Var(\"a\")\n</code></pre> <p>Patterns may be non-linear. Multiple occurrences of the same variable can occur and each occurrence has to match the same term.</p> <pre><code>&lt;?Plus(e,e)&gt; Plus(Var(\"a\"),Int(\"3\")) // fails\n&lt;?Plus(e,e)&gt;!Plus(Var(\"a\"),Var(\"a\")) // e is bound to Var(\"a\")\n</code></pre> <p>Example. Non-linear pattern matching is a way to test equality of terms. Indeed the equality predicates from the Stratego Library are defined using non-linear pattern matching:</p> <pre><code>equal = ?(x, x)\nequal(|x) = ?x\n</code></pre> <p>The equal strategy tests whether the current term is a a pair of the same terms. The <code>equal(|x)</code> strategy tests whether the current term is equal to the argument term.</p> <pre><code>&lt;equal&gt;(\"a\", \"a\")               // succeeds\n&lt;equal&gt;(\"a\", \"b\")               // fails\n&lt;equal(|Foo(Baz()))&gt; Foo(Bar()) // fails\n&lt;equal(|Foo(Bar()))&gt; Foo(Bar()) // succeeds\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#term-variable-scope","title":"Term Variable Scope","text":"<pre><code>{$Id, ... : $StrategyExp}\n</code></pre> <p>Once a variable is bound it cannot be rebound to a different term. Thus, when we have applied an anonymous rule once, its variables are bound and the next time it is applied it only succeeds for the same term. For example, in the next session the second application of the rule fails, because <code>e2</code> is bound to <code>Int(\"3\")</code> and does not match with <code>Var(\"b\")</code>.</p> <pre><code>&lt;?Plus(e1, e2)! Plus(e2, e1))&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Int(\"3\"), Var(\"a\"))\n// e1 is bound to Var(\"a\")\n// e2 is bound to Int(\"3\")\n\n&lt;?Plus(e1, e2)! Plus(e2, e1)&gt;\nPlus(Var(\"a\"), Var(\"b\")) // fails\n</code></pre> <p>To use a variable name more than once Stratego provides term variable scope. A scope <code>{x1,...,xn : s}</code> locally undefines the variables <code>xi</code>. That is, the binding to a variable <code>xi</code> outside the scope is not visible inside it, nor is the binding to <code>xi</code> inside the scope visible outside it. For example, to continue the session above, if we wrap the anonymous swap rule in a scope for its variables, it can be applied multiple times.</p> <pre><code>&lt;{e3,e4 : ?Plus(e3,e4); !Plus(e4,e3)}&gt;\nPlus(Var(\"a\"),Int(\"3\")) =&gt; Plus(Var(\"a\"),Int(\"3\"))\n// e3 is not bound to a term\n\n&lt;{e3,e4 : ?Plus(e3,e4); !Plus(e4,e3)}&gt;\nPlus(Var(\"a\"),Var(\"b\")) =&gt; Plus(Var(\"b\"),Var(\"a\"))\n</code></pre> <p>Of course we can name such a scoped rule using a strategy definition, and then invoke it by its name:</p> <pre><code>SwapArgs =\n{e1,e2 : ?Plus(e1,e2); !Plus(e2,e1)}\n\n&lt;SwapArgs&gt;\nPlus(Var(\"a\"),Int(\"3\")) =&gt; Plus(Int(\"3\"),Var(\"a\"))\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#implicit-variable-scope","title":"Implicit Variable Scope","text":"<p>When using match and build directly in a strategy definition, rather than in the form of a rule, the definition contains free variables. Strictly speaking such variables should be declared using a scope, that is one should write</p> <pre><code>SwapArgs = {e1,e2 : ?Plus(e1,e2); !Plus(e2,e1)}\n</code></pre> <p>However, since declaring all variables at the top of a definition is distracting and does not add much to the definition, such a scope declaration can be left out. Thus, one can write</p> <pre><code>SwapArgs = (Plus(e1,e2) -&gt; Plus(e2,e1))\n</code></pre> <p>instead. The scope is automatically inserted by the compiler. This implies that there is no global scope for term variables. Of course, variables in inner scopes should be declared where necessary. In particular, note that variable scope is not inserted for strategy definitions in a let binding, such as</p> <pre><code>let SwapArgs = ?Plus(e1,e2); Plus(e2,e1) in ... end\n</code></pre> <p>While the variables are bound in the enclosing definition, they are not restricted to <code>SwapArgs</code> in this case, since in a let one typically wants to use bindings to variables in the enclosing code.</p>"},{"location":"references/stratego/strategy-combinators/#combining-match-and-build","title":"Combining Match and Build","text":"<p>Match and build are first-class citizens in Stratego, which means that they can be used and combined just like any other strategy expressions. In particular, we can implement rewrite rules using these operations, since a rewrite rule is basically a match followed by a build. For example, consider the following combination of match and build:</p> <pre><code>&lt;?Plus(e1, e2); !Plus(e2, e1)&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Int(\"3\"), Var(\"a\"))\n</code></pre> <p>This combination first recognizes a term, binds variables to the pattern in the match, and then replaces the current term with the instantiation of the build pattern. Note that the variable bindings are propagated from the match to the build.</p> <p>Stratego provides syntactic sugar for various combinations of match and build.</p>"},{"location":"references/stratego/strategy-combinators/#anonymous-rewrite-rule","title":"Anonymous Rewrite Rule","text":"<pre><code>($Pattern -&gt; $Pattern)\n</code></pre> <p>An anonymous rewrite rule <code>(p1 -&gt; p2)</code> transforms a term matching <code>p1</code> into an instantiation of <code>p2</code>. Such a rule is equivalent to the sequence <code>?p1; !p2</code>.</p> <pre><code>&lt;(Plus(e1, e2) -&gt; Plus(e2, e1))&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt;\nPlus(Int(\"3\"), Var(\"a\"))\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#where","title":"Where","text":"<pre><code>where($StrategyExp)\n</code></pre> <p>The <code>where(s)</code> combinator applies <code>s</code> to the current term, but restores that term afterwards. Any bindings to variables are kept, however.</p> <p>The <code>where(s)</code> construct is syntactic sugar for <code>{x: ?x; s; !x}</code> with <code>x</code> a fresh variable not occurring in <code>s</code>. Thus, the current subject term is saved by binding it to a new variable <code>x</code>, then the strategy <code>s</code> is applied, and finally, the original term is restored by building <code>x</code>.</p> <p>Example</p> <pre><code>&lt;where(?Plus(Int(i), Int(j)); &lt;addS&gt;(i,j) =&gt; k)&gt;\nPlus(Int(\"14\"),Int(\"3\")) =&gt; Plus(Int(\"14\"),Int(\"3\"))\n// i is bound to \"14\"\n// k is bound to \"17\"\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#with","title":"With","text":"<pre><code>with(s)\n</code></pre> <p>The strategy <code>with(s)</code> applies <code>s</code> on the current subject term and then restores the current subject term. In other words, <code>s</code> is executed solely for its side effects, such as binding variables. In this respect, with is like <code>where</code>. However, <code>with(s)</code> differs in a key way: if the strategy <code>s</code> fails, Stratego stops with an error, reporting the strategy that failed.</p>"},{"location":"references/stratego/strategy-combinators/#lambda-rules","title":"Lambda Rules","text":"<pre><code>\\ $Term -&gt; $Term where $Condition \\\n</code></pre> <p>A lambda rule of the form <code>\\ p1 -&gt; p2 where s \\</code> is an anonymous rewrite rule for which the variables in the left-hand side <code>p1</code> are local to the rule, that is, it is equivalent to an expression of the form</p> <pre><code>{x1,...,xn : (p1 -&gt; p2 where s)}\n</code></pre> <p>with <code>x1</code>,\u2026,<code>xn</code> the variables of <code>p1</code>. This means that any variables used in <code>s</code> and <code>p2</code> that do not occur in <code>p1</code> are bound in the context of the rule.</p> <p>Example.</p> <pre><code>&lt;map(\\ (x, y) -&gt; x \\ )&gt; [(1,2),(3,4),(5,6)] =&gt; [1,3,5]\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#apply-and-match","title":"Apply and Match","text":"<pre><code>$StrategyExp =&gt; $Term\n&lt;$StrategyExp&gt; $Term\n&lt;$StrategyExp&gt; $Term =&gt; $Term\n</code></pre> <p>The operation <code>&lt;s&gt; p</code> captures the notion of applying a strategy to a term, i.e., the scenario <code>!p; s</code>. The operation <code>s =&gt; p</code> capture the notion of applying a strategy to the current subject term and then matching the result against the pattern <code>p</code>, i.e., <code>s; ?p</code>. The combined operation <code>&lt;s&gt; p1 =&gt; p2</code> thus captures the notion of applying a strategy to a term <code>p1</code> and matching the result against <code>p2</code>, i.e, <code>!p1; s; ?p2</code>.</p> <p>Example. The conditional rewrite rule</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwhere !(i,j); addS; ?k\n</code></pre> <p>can be reformulated as</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwhere &lt;addS&gt;(i,j) =&gt; k\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#assignment","title":"Assignment","text":"<pre><code>$Term := $Term\n</code></pre> <p>The strategy <code>p1 := p2</code> builds <code>p2</code> and matches the result against <code>p1</code>, i.e. it is equivalent to <code>!p2; ?p1</code>. The strategy is often combined with strategy application into <code>p1 := &lt;s&gt;p2</code>, which is equivalent to <code>&lt;s&gt;p2 =&gt; p1</code> (but more familiar to an audience with an imperative mindset).</p> <p>For example, consider the following rewrite rule</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwith k := &lt;addS&gt;(i,j)\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#applying-strategies-in-build","title":"Applying Strategies in Build","text":"<pre><code>&lt;$StrategyExp&gt; $Term   // in build pattern\n</code></pre> <p>In a build pattern, the application <code>&lt;s&gt;t</code> applies the strategy <code>s</code> to the term <code>t</code>, returning the resulting term.</p> <p>Example. The constant folding rule</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(k)\nwhere &lt;addS&gt;(i,j) =&gt; k\n</code></pre> <p>can be simplified by directly applying the addition in the right-hand side:</p> <pre><code>EvalPlus :\nAdd(Int(i),Int(j)) -&gt; Int(&lt;addS&gt;(i,j))\n</code></pre> <p>Example. The following definition of the <code>map(s)</code> strategy applies a strategy to each term in a list:</p> <pre><code>map(s) : [] -&gt; []\nmap(s) : [x | xs] -&gt; [&lt;s&gt; x | &lt;map(s)&gt; xs]\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#term-wrap","title":"Term Wrap","text":"<pre><code>&lt;$StrategyExp&gt;    // in build pattern\n</code></pre> <p>A term wrap is a build strategy <code>!p[&lt;s&gt;]</code> containing one or more strategy applications <code>&lt;s&gt;</code> that are not applied to a term. When executing the the build operation, each occurrence of such a strategy application <code>&lt;s&gt;</code> is replaced with the term resulting from applying <code>s</code> to the current subject term, i.e., the one that is being replaced by the build.</p> <p>Motivation. One often write rules of the form <code>x -&gt; Foo(Bar(x))</code>, i.e. wrapping a term pattern around the current term. Using rule syntax this is quite verbose. The syntactic abstraction of term wraps, allows the concise specification of such little transformations as <code>!Foo(Bar(&lt;id&gt;))</code>.</p> <p>Example. The following applications illustrate some uses of term wraps:</p> <pre><code>&lt;!(&lt;id&gt;,&lt;id&gt;)&gt; 3 =&gt; (3,3)\n\n&lt;(&lt;Fst; inc&gt;,&lt;Snd&gt;)&gt; (3,3) =&gt; (4,3)\n\n&lt;!Call(&lt;id&gt;, [])&gt; \"foobar\" =&gt; Call(\"foobar\", [])\n\nmod2 = &lt;mod&gt;(&lt;id&gt;,2)\n\n&lt;mod2&gt; 6 =&gt; 0\n</code></pre> <p>Desugaring. Term wraps are implemented by translation to a combination of match and build expressions. Thus, a term wrap <code>!p[&lt;s&gt;]</code> is translated to a strategy expression</p> <pre><code>{x: where(s =&gt; x); !p[x]}\n</code></pre> <p>where <code>x</code> is a fresh variable not occurring in <code>s</code>. In other words, the strategy <code>s</code> is applied to the current subject term, i.e., the term to which the build is applied.</p> <p>As an example, the term wrap <code>!Foo(Bar(&lt;id&gt;))</code> is desugared to the strategy</p> <pre><code>{x: where(id =&gt; x); !Foo(Bar(x))}\n</code></pre> <p>which after simplification is equivalent to <code>{x: ?x; !Foo(Bar(x))}</code>, i.e., exactly the original lambda rule <code>\\x -&gt; Foo(Bar(x))\\</code>.</p>"},{"location":"references/stratego/strategy-combinators/#term-project","title":"Term Project","text":"<pre><code>&lt;$StrategyExp&gt;   // in match pattern\n</code></pre> <p>Term projections are the match dual of term wraps. Term projections can be used to project a subterm from a term pattern.</p> <p>Examples. For example, the expression <code>?And(&lt;id&gt;,x)</code> matches terms of the form <code>And(t1,t2)</code> and reduces them to the first subterm <code>t1</code>. Another example is the strategy</p> <pre><code>map(?FunDec(&lt;id&gt;,_,_))\n</code></pre> <p>which reduces a list of function declarations to a list of the names of the functions, i.e., the first arguments of the <code>FunDec</code> constructor. Here are some more examples:</p> <pre><code>&lt;?[_|&lt;id&gt;]&gt; [1,2,3] =&gt; [2,3]\n\n&lt;?Call(&lt;id&gt;, [])&gt; Call(\"foobar\", []) =&gt;  \"foobar\"\n</code></pre> <p>Term projections can also be used to apply additional constraints to subterms in a match pattern. For example, <code>?Call(x, &lt;?args; length =&gt; 3&gt;)</code> matches only with function calls with three arguments.</p> <p>Desugaring. A match expression <code>?p[&lt;s&gt;]</code> is desugared as</p> <pre><code>{x: ?p[x]; &lt;s&gt; x}\n</code></pre> <p>That is, after the pattern <code>p[x]</code> matches, it is reduced to the subterm bound to <code>x</code> to which s is applied. The result is also the result of the projection. When multiple projects are used within a match the outcome is undefined, i.e., the order in which the projects will be performed can not be counted on.</p>"},{"location":"references/stratego/strategy-combinators/#traversal-combinators","title":"Traversal Combinators","text":"<p>Traversal combinators apply strategies to direct subterms of a term and can be combined with other combinators to define full term traversal strategies.</p>"},{"location":"references/stratego/strategy-combinators/#congruence-operators","title":"Congruence Operators","text":"<pre><code>$Constructor($StrategyExp, ..., $StrategyExp)\n</code></pre> <p>A congruence operator applies a strategy to each direct subterm of a specific constructor. For each n-ary constructor <code>c</code> declared in a signature, there is a corresponding congruence operator <code>c(s1 , ..., sn)</code>, which applies to terms of the form <code>c(t1 , ..., tn)</code> by applying the argument strategies to the corresponding argument terms. A congruence fails if the application of one the argument strategies fails or if constructor of the operator and that of the term do not match.</p> <p>Example. Consider the following signature of expressions:</p> <pre><code>module expressions\nsignature\nsorts Exp\nconstructors\nPlus  : Exp * Exp -&gt; Exp\nTimes : Exp * Exp -&gt; Exp\n</code></pre> <p>The following applications apply the congruence operators <code>Plus</code> and <code>Times</code> to a term:</p> <pre><code>&lt;Plus(!Var(\"a\"), id)&gt;\nPlus(Int(\"14\"),Int(\"3\")) =&gt;\nPlus(Var(\"a\"),Int(\"3\"))\n\n&lt;Times(id, !Int(\"42\"))&gt;\nPlus(Var(\"a\"),Int(\"3\")) // fails\n</code></pre> <p>The first application shows how a congruence transforms a specific subterm, that is the strategy applied can be different for each subterm. The second application shows that a congruence only succeeds for terms constructed with the same constructor.</p>"},{"location":"references/stratego/strategy-combinators/#tuple-and-list-congruences","title":"Tuple and List Congruences","text":"<pre><code>[$StrategExp, ..., $StrategyExp]\n[$StrategExp, ..., $StrategyExp | $StrategyExp]\n($StrategExp, ..., $StrategyExp)\n</code></pre> <p>Congruences can also be applied to tuples, <code>(s1,s2,...,sn)</code>, and lists, <code>[s1,s2,...,sn]</code>.</p> <p>Example. The definition of a <code>map(s)</code> strategy using list congruences:</p> <pre><code>map(s) = [] &lt;+ [s | map(s)]\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#visiting-all-subterms","title":"Visiting All Subterms","text":"<pre><code>all($StrategyExp)\n</code></pre> <p>The <code>all(s)</code> strategy transforms a constructor application by applying the parameter strategy <code>s</code> to each direct subterm. An application of <code>all(s)</code> fails if the application to one of the subterms fails.</p> <p>The following example shows how all (1) applies to any term, and (2) applies its argument strategy uniformly to all direct subterms.</p> <pre><code>&lt;all(!Var(\"a\"))&gt;\nPlus(Int(\"14\"), Int(\"3\")) =&gt; Plus(Var(\"a\"), Var(\"a\"))\n\n&lt;all(!Var(\"z\"))&gt;\nTimes(Var(\"b\"), Int(\"3\")) =&gt; Times(Var(\"z\"), Var(\"z\"))\n</code></pre> <p>Example. The <code>bottomup(s)</code> is defined as</p> <pre><code>bottomup(s) = all(bottomup(s)); s\n</code></pre> <p>and defines a full traversal over the subject term.</p>"},{"location":"references/stratego/strategy-combinators/#visiting-one-subterm","title":"Visiting One Subterm","text":"<pre><code>one($StrategyExp)\n</code></pre> <p>The <code>one(s)</code> strategy transforms a constructor application by applying the parameter strategy <code>s</code> to exactly one direct subterm. An application of <code>one(s)</code> fails if the application to all of the subterms fails.</p> <p>The following applications illustrate the behavior of the combinator:</p> <pre><code>&lt;one(!Var(\"a\"))&gt;\nPlus(Int(\"14\"), Int(\"3\")) =&gt; Plus(Var(\"a\"), Int(\"3\"))\n\n&lt;one(\\ Int(x) -&gt; Int(&lt;addS&gt;(x,\"1\")) \\ )&gt;\nPlus(Var(\"a\"), Int(\"3\")) =&gt; Plus(Var(\"a\"), Int(\"4\"))\n\n&lt;one(?Plus(_,_))&gt;\nPlus(Var(\"a\"), Int(\"4\")) // fails\n</code></pre> <p>Example. A frequently used application of <code>one</code> is the <code>oncetd(s)</code> traversal, which performs a left to right depth first search/transformation that stops as soon as s has been successfully applied.</p> <pre><code>oncetd(s) = s &lt;+ one(oncetd(s))\n</code></pre> <p>Thus, <code>s</code> is first applied to the root of the subject term. If that fails, its direct subterms are searched one by one (from left to right), with a recursive call to <code>oncetd(s)</code>.</p> <p>An application of <code>oncetd</code> is the <code>contains(|t)</code> strategy, which checks whether the subject term contains a subterm that is equal to t.</p> <pre><code>contains(|t) = oncetd(?t)\n</code></pre> <p>Through the depth first search of <code>oncetd</code>, either an occurrence of <code>t</code> is found, or all subterms are verified to be unequal to <code>t</code>.</p>"},{"location":"references/stratego/strategy-combinators/#visiting-some-subterms","title":"Visiting Some Subterms","text":"<pre><code>some($StrategyExp)\n</code></pre> <p>The <code>some(s)</code> strategy transforms a constructor application by applying the parameter strategy <code>s</code> to as many direct subterms as possible and at least one. An application of <code>some(s)</code> fails if the application to all of the subterms fails.</p> <p>Some one-pass traversals based on some:</p> <pre><code>sometd(s) = s &lt;+ some(sometd(s))\nsomebu(s) = some(somebu(s)) &lt;+ s\n</code></pre> <p>A fixed-point traversal with some:</p> <pre><code>reduce-par(s) = repeat(rec x(some(x) + s))\n</code></pre>"},{"location":"references/stratego/strategy-combinators/#generic-term-deconstruction","title":"Generic Term Deconstruction","text":"<pre><code>$Term#($Term)   // in a match pattern\n</code></pre> <p>The term pattern expression <code>c#(ts)</code> used in a match pattern succeeds when applied to a constructor application and matches the constructor name (as a string) to <code>c</code> and the list of term arguments to <code>ts</code>.</p>"},{"location":"references/stratego/strategy-combinators/#generic-term-construction","title":"Generic Term Construction","text":"<pre><code>$Term#($Term)   // in a build pattern\n</code></pre> <p>The term pattern expression <code>c#(ts)</code> used in a build pattern succeeds when <code>c</code> constructs a string and <code>ts</code> constructs a list of terms. It then builds the corresponding constructor application <code>c(ts)</code>.</p>"},{"location":"references/stratego/strategy-combinators/#references","title":"References","text":"<p>Rather than defining rewrite rules and high-level strategies as primitives of the language, Stratego provides strategy combinators as basic building blocks from which these can defined1. Thus, Stratego consists of a core language2 and a 'sugar' language defined by reduction to the core language.</p> <p>Warning</p> <p>While it useful to understand the constructs defined in this section, their use should be avoided in favour of the higher-level language constructs, such as rewrite rules, where possible.</p> <ol> <li> <p>Eelco Visser, Zine-El-Abidine Benaissa, and Andrew P. Tolmach. Building program optimizers with rewriting strategies. In Matthias Felleisen, Paul Hudak, and Christian Queinnec, editors, Proceedings of the third ACM SIGPLAN international conference on Functional programming, 13\u201326. Baltimore, Maryland, United States, 1998. ACM. URL: http://doi.acm.org/10.1145/289423.289425, doi:10.1145/289423.289425.\u00a0\u21a9</p> </li> <li> <p>Eelco Visser and Zine-El-Abidine Benaissa. A core language for rewriting. Electronic Notes in Theoretical Computer Science, 15:422\u2013441, 1998. URL: http://dx.doi.org/10.1016/S1571-0661(05)80027-1, doi:10.1016/S1571-0661(05)80027-1.\u00a0\u21a9</p> </li> </ol>"},{"location":"references/stratego/strategy-definitions/","title":"Strategy Definitions","text":"<pre><code>$Id($StrategyArg, ... | $TermArg, ...) =\n$StrategyExp\n</code></pre> <p>A strategy definition gives a name to a strategy expression, has zero or more strategy arguments, and zero or more term arguments.</p>"},{"location":"references/stratego/strategy-definitions/#simple-definitions","title":"Simple Definitions","text":"<p>A simple strategy definition gave a name to a strategy expression.</p> <pre><code>$Id = s\n</code></pre> <p>For example, the following definition defines <code>desugar</code> as an application of the <code>innermost</code> strategy to the rewrite rule(s) <code>desugar-exp</code>.</p> <pre><code>strategies\ndesugar :: Module -&gt; Module\ndesugar = innermost(desugar-exp)\n</code></pre>"},{"location":"references/stratego/strategy-definitions/#parameterized-definitions","title":"Parameterized Definitions","text":"<p>Just like rewrite rules, strategy definitions can be parameterized with strategies and terms.</p> <pre><code>$Id($StrategyArg, ... | $TermArg, ...) :: $Type -&gt; $Type\n$Id(s1, ... | t1, ...) = s\n</code></pre> <p>When a strategy has no term arguments, the bar can be left out:</p> <pre><code>$Id($StrategyArg, ... ) :: $Type -&gt; $Type\n$Id(s1, ...) = s\n</code></pre> <p>Simple strategy definitions are the special case in which a strategy does not have strategy and term arguments.</p> <p>For example, the following definition defines <code>topdown(s)</code> in terms of sequential composition and generic traversal:</p> <pre><code>topdown(TP) :: TP\ntopdown(s) = s; all(topdown(s))\n</code></pre>"},{"location":"references/stratego/strategy-definitions/#extending-definitions","title":"Extending Definitions","text":"<p>Just like rewrite rules, strategy definitions can have multiple definitions. In case a strategy expression fails to apply, the next definition is applied. When definitions are in the same module, definitions are applied in the textual order they are defined in. When definitions are defined in separate modules, the order is undefined.</p>"},{"location":"references/stratego/strategy-definitions/#external-definitions","title":"External Definitions","text":"<p>external definitions</p> <p>libraries</p> <p>Todo</p> <p>finish this section on external definitions</p>"},{"location":"references/stratego/strategy-definitions/#local-definitions","title":"Local Definitions","text":"<p>Todo</p> <p>finish this section on local definitions</p>"},{"location":"references/stratego/terms/","title":"Terms","text":"<p>Stratego programs transform terms.</p> <p>For example, the code <code>4 + f(5 * x)</code> might be represented in a term as:</p> <pre><code>Plus(Int(\"4\"), Call(\"f\", [Mul(Int(\"5\"), Var(\"x\"))]))\n</code></pre>"},{"location":"references/stratego/terms/#term-forms","title":"Term Forms","text":"<p>Terms are constructed from the following forms.</p>"},{"location":"references/stratego/terms/#integer","title":"Integer","text":"<pre><code>$Digit+\n</code></pre> <p>An integer constant, that is a list of decimal digits, is an ATerm.</p> <p>Examples: <code>1</code>, <code>12343</code>.</p>"},{"location":"references/stratego/terms/#string","title":"String","text":"<pre><code>\"$Char*\"\n</code></pre> <p>A string constant, that is a list of characters between double quotes is an ATerm. Special characters such as double quotes and newlines should be escaped using a backslash. The backslash character itself should be escaped as well.</p> <p>Examples: <code>\"foobar\"</code>, <code>\"string with quotes\\\"\"</code>, <code>\"escaped escape character\\\\ and a newline\\n\"</code>.</p>"},{"location":"references/stratego/terms/#string-templates","title":"String Templates","text":"<pre><code>$[$TemplateChar*]\n</code></pre> <p>Multiline strings can be constructed using string templates.</p> <pre><code>$[if [code1] then\n[code2]]\n</code></pre> <p>The indentation will be computed relative to the start of the template.</p> <p>String templates can also include escapes to term expressions producing strings or integers.</p> <p>For example, the string above includes escapes to include <code>code1</code> and <code>code2</code> and the following error message</p> <pre><code>$[error: variable [x] is not defined]\n</code></pre> <p>includes the name of the variable <code>x</code>.</p>"},{"location":"references/stratego/terms/#constructor-application","title":"Constructor application","text":"<pre><code>$Constructor($Term,...,$Term)\n</code></pre> <p>A constructor is an identifier, that is an alphanumeric string starting with a letter, or a double quoted string.</p> <p>A constructor application <code>c(t1,...,tn)</code> creates a term by applying a constructor to a sequence of zero or more terms.</p> <p>For example, the term <code>Plus(Int(\"4\"),Var(\"x\"))</code>uses the constructors <code>Plus</code>, <code>Int</code>, and <code>Var</code> to create a nested term from the strings <code>\"4\"</code> and <code>\"x\"</code>.</p> <p>The parentheses are needed even when a constructor has no subterms, in order to avoid ambiguity with variables. Thus, <code>True()</code> is a constructor application, but <code>True</code> is a variable.</p>"},{"location":"references/stratego/terms/#list","title":"List","text":"<pre><code>[$Term, ..., $Term]\n</code></pre> <p>A list is a term of the form <code>[t1,...,tn]</code>, that is a list of zero or more terms between square brackets. While all applications of a specific constructor typically have the same number of subterms, lists can have a variable number of subterms. The elements of a list are typically of the same type, while the subterms of a constructor application can vary in type.</p> <p>Example: The second argument of the call to <code>\"f\"</code> in the term <code>Call(\"f\",[Int(\"5\"),Var(\"x\")])</code> is a list of expressions.</p>"},{"location":"references/stratego/terms/#tuple","title":"Tuple","text":"<pre><code>($Term, ..., $Term)\n</code></pre> <p>A tuple <code>(t1,...,tn)</code> is a constructor application without a constructor.</p> <p>Example: <code>(Var(\"x\"), Type(\"int\"))</code></p>"},{"location":"references/stratego/terms/#annotation","title":"Annotation","text":"<pre><code>$PreTerm{$Term, ..., $Term}\n</code></pre> <p>Any of the term forms above can be annotated with a list of terms.  </p> <p>Example: <code>Lt(Var(\"n\"),Int(\"1\")){Type(\"bool\")}</code>.</p> <p>Only 'preterms', i.e. terms without annotations, can be annotated. The form <code>Var(\"a\"){Type(\"bool\")}{Value(3)}</code> is syntactically incorrect.</p>"},{"location":"references/stratego/terms/#term-patterns","title":"Term Patterns","text":"<p>A term pattern, is a term extended with variables.</p> <p>In the term pattern</p> <pre><code>Plus(e, Int(\"0\"))\n</code></pre> <p>the identifier <code>e</code> is a variable that stands for any term.</p>"},{"location":"references/stratego/terms/#linear-vs-non-linear","title":"Linear vs Non-Linear","text":"<p>A pattern is linear if each variable occurs at most once, non-linear otherwise. The non-linear pattern</p> <pre><code>Plus(e, e)\n</code></pre> <p>stands for a <code>Plus</code> term with identical arguments.</p> <p>A term pattern without variables (aka term) is ground.</p>"},{"location":"references/stratego/terms/#substitution","title":"Substitution","text":"<p>Substitution is the process of applying a map from variables to terms to a term pattern, replacing occurrence of variables in the domain of the map with the corresponding terms in the co-domain of the map.</p> <p>Substitution is also the name for the mapping of variables to terms.</p>"},{"location":"references/stratego/terms/#pattern-matching","title":"Pattern Matching","text":"<p>Pattern matching is the process of matching a ground term against a term pattern.</p> <p>A term <code>t</code> matches a term pattern <code>p</code> iff there is a substitution <code>S</code> such that applying the substitution to the pattern <code>S(p)</code> yields the term <code>t</code>.</p>"},{"location":"references/stratego/terms/#persistent-representation","title":"Persistent Representation","text":"<p>The term format described above is used in Stratego programs to denote terms, but is also used to exchange terms between programs. Thus, the internal format and the external format exactly coincide. Of course, internally a Stratego program uses a data-structure in memory with pointers rather than manipulating a textual representation of terms. But this is completely hidden from the Stratego programmer.</p> <p>Todo</p> <p>API for reading, writing terms?</p>"},{"location":"references/stratego/terms/#namespaces","title":"Namespaces","text":"<p>Currently, the constructors of terms live in a global namespace. In the future, we want to support qualified names.</p>"},{"location":"references/stratego/terms/#references","title":"References","text":"<p>Terms in Stratego are inspired by terms in the Annotated Term Format, or ATerms for short1. The ATerm format provides a set of constructs for representing trees, comparable to XML or abstract data types in functional programming languages.</p> <ol> <li> <p>Mark G. J. van den Brand, H. A. de Jong, Paul Klint, and Pieter A. Olivier. Efficient annotated terms. Software: Practice and Experience, 30(3):259\u2013291, 2000.\u00a0\u21a9</p> </li> </ol>"},{"location":"references/stratego/troubleshooting/","title":"Stratego Troubleshooting","text":""},{"location":"references/stratego/troubleshooting/#unsupportedclassversionerror-interopregisterer","title":"UnsupportedClassVersionError: InteropRegisterer","text":"<p>In Eclipse, if you get this error:</p> <pre><code>Caused by: java.lang.UnsupportedClassVersionError:\nMyLanguage/strategies/InteropRegisterer has been compiled by a more recent\nversion of the Java Runtime (class file version 55.0), this version of the\nJava Runtime only recognizes class file versions up to 52.0\n</code></pre> <p>It is caused by Eclipse internally compiling using the wrong Java version. Go to the Eclipse Preferences (Cmd+, on  macOS), Java \u2023 Compiler and set the Compiler Compliance Level to <code>1.8</code> (which corresponds to class file version 52.0).</p>"},{"location":"references/stratego/types/","title":"Types","text":"<p>Terms provide a generic, untyped format to represent tree-structured data. Stratego transformations can transform such data, but require at least that the arities of term constructors that are used in rules are declared.</p> <p>Starting with Stratego 2, the types of terms and term transformations may be declared and checked in more detail1.</p>"},{"location":"references/stratego/types/#signatures","title":"Signatures","text":"<pre><code>signature\n$SigSection*\n</code></pre> <p>A signature declares the shape of well-formed terms using sort declarations, constructor declarations, and overlays.</p>"},{"location":"references/stratego/types/#sorts","title":"Sorts","text":"<pre><code>sorts $Sort*\n</code></pre> <p>A sort is determined by an identifier and optionally has arguments.</p> <p>A sort (or type) identifies a collection of well-formed terms.</p> <p>Convention: Sort identifiers start with a capital letter.</p>"},{"location":"references/stratego/types/#constructors","title":"Constructors","text":"<pre><code>constructors\n$ConstructorDecl\n</code></pre> <p>A constructor declaration has the form</p> <pre><code>$Constructor : $Sort * ... * $Sort -&gt; Decl\n</code></pre> <p>and declares a constructor name, the sorts of the argument terms, and the sort of the constructed term.</p> <p>Convention: Constructor identifiers start with a capital letter.</p> <p>Example: The constructor declaration</p> <pre><code>Assign : ID * Exp -&gt; Stmt\n</code></pre> <p>defines the constructor <code>Assign</code> with input sorts <code>ID</code> and <code>Exp</code> and output sort <code>Stmt</code>. Thus, if <code>x</code> and <code>e</code> are terms of sort <code>ID</code> and <code>Exp</code>, respectively, then <code>Assign(x, e)</code> is a term of sort <code>Stmt</code>.</p> <p>When the list of argument sorts is empty the arrow can be omitted:</p> <pre><code>$Constructor : Decl\n</code></pre> <p>Example: The constructor declaration</p> <pre><code>True : Bool\n</code></pre> <p>defines that <code>True()</code> is a term of sort <code>Bool</code>. Note that the parentheses are required. The term <code>True</code> is a variable.</p> <p>The Stratego1 compiler only checks the arity of constructor applications against the signature. The Stratego2 compiler uses signature definitions to type check code if it has been given a type signature.</p>"},{"location":"references/stratego/types/#injections","title":"Injections","text":"<p>An injection is a constructor without name and with a single argument.</p> <pre><code>  : $Sort -&gt; $Sort\n</code></pre> <p>Injections include an entire type as a subtype of another type without cluttering the tree structure.</p>"},{"location":"references/stratego/types/#list-type","title":"List Type","text":"<pre><code>List($Sort)\n</code></pre> <p>The type constructor <code>List(_)</code> is for typing homogenous lists.</p> <p>Exmample. The type <code>List(Exp)</code> represents lists of expressions <code>Exp</code>.</p>"},{"location":"references/stratego/types/#polymorphic-types","title":"Polymorphic Types","text":"<p>Stratego2 supports user-defined polymorphic types. That is, sorts can have parameters.</p> <p>For example, the following signature defines the type of priority queues, polymorphic in the carrier type, in which the priority is determined by the length of the list.</p> <pre><code>signature\nsorts PrioQ(*)\nconstructors\nNilQ  : PrioQ(a)\nConsQ : a * int * List(a) * PrioQ(a) -&gt; PrioQ(a)\n</code></pre>"},{"location":"references/stratego/types/#tuple-type","title":"Tuple Type","text":"<pre><code>($TermType * ... * $TermType)\n</code></pre> <p>Tuple terms can be typed in strategy types. Currently, tuple types cannot be used in term signatures.</p>"},{"location":"references/stratego/types/#overlays","title":"Overlays","text":"<pre><code>overlays\n$OverlayDef\n</code></pre> <p>An overlay defines a term abbreviation. An overlay definition has the form</p> <pre><code>  $Constructor($ID, ..., $ID) = $Term\n</code></pre> <p>and defines that applications of the constructor should be expanded to the term.</p>"},{"location":"references/stratego/types/#transformation-types","title":"Transformation Types","text":"<pre><code>$Id($StrategyType, ... | $TermType, ...) :: $TermType -&gt; $TermType\n</code></pre> <p>A transformation type defines the signature of a transformation with name <code>$Id</code> with the types of its strategy arguments and term arguments, the type of the 'current term' to which the transformation is applied, and the type of the term that is returned, if the transformation succeeds. Transformation types are declared in <code>rules</code> or <code>strategies</code> sections.</p> <pre><code>$Id($StrategyType, ...) :: $TermType -&gt; $TermType\n</code></pre> <p>When a transformation only has strategy parameters, the bar can be left out.</p> <pre><code>$Id :: $TermType -&gt; $TermType\n</code></pre> <p>When a transformation also has no strategy parameters, the parentheses can be left out as well.</p>"},{"location":"references/stratego/types/#strategy-type","title":"Strategy Type","text":"<pre><code>$TermType -&gt; $TermType\n</code></pre> <p>The type of a transformation/strategy argument is an arrow from a term type to a term type.</p> <p>Note that transformation strategies cannot be reified as terms.</p>"},{"location":"references/stratego/types/#type-dynamic","title":"Type Dynamic","text":"<pre><code>?\n</code></pre> <p>Type dynamic, written <code>?</code>, represents the unknown type.</p> <p>Stratego2 is a gradually typed language in order to facilitate the migration from (mostly) untyped Stratego1 code to typed Stratego2 code. Furthermore, some patterns in Stratego cannot be typed statically.</p> <p>When used as a strategy type <code>?</code> represents <code>? -&gt; ?</code>.</p>"},{"location":"references/stratego/types/#type-casts","title":"Type Casts","text":"<pre><code>///syntax of casts\n</code></pre> <p>Todo</p> <p>syntactic form</p> <p>Gradual type systems allow a term with the dynamic type to be used in any place where a static type is required. Stratego2 will insert a type cast at such a point to check at run time that the term is type-correct. This way, a Stratego program halts execution in predictable places when a run time type error occurs. There can be no run time type errors in fully statically typed code either, only at the boundary between dynamically and statically typed code.</p>"},{"location":"references/stratego/types/#type-preserving","title":"Type Preserving","text":"<pre><code>TP\n</code></pre> <p>A type preserving transformation transforms any type to itself (or fails).</p> <p>In signatures, a type preserving transformation is indicated with <code>TP</code>.</p> <p>Example. The type declaration</p> <pre><code>topdown(s : TP) :: TP\n</code></pre> <p>declares that the <code>topdown</code> strategy is type preserving if its argument strategy is.</p> <p>The type-checking for a type preserving transformation is very strict. It should be in terms of other type preserving transformations, or match the input term to a specific type and return a term from that specific type.</p>"},{"location":"references/stratego/types/#is-type","title":"Is Type","text":"<pre><code>is($Sort)\n</code></pre> <p>Given the definition of a term sort <code>S</code>, the <code>is(S)</code> strategy checks whether a term is of sort <code>S</code> and fails if that is not the case.</p> <p>Example. The strategy <code>&lt;is(Exp)&gt;t</code> checks that term <code>t</code> conforms to the signature of sort <code>Exp</code>.</p> <p>The <code>is(S)</code> strategy uses the same mechanism as type casts for checking a term type at run time.</p>"},{"location":"references/stratego/types/#references","title":"References","text":"<ol> <li> <p>Jeff Smits and Eelco Visser. Gradually typing strategies. In Ralf L\u00e4mmel, Laurence Tratt, and Juan de Lara, editors, Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2020, Virtual Event, USA, November 16-17, 2020, 1\u201315. ACM, 2020. URL: https://doi.org/10.1145/3426425.3426928, doi:10.1145/3426425.3426928.\u00a0\u21a9</p> </li> </ol>"},{"location":"references/syntax/","title":"SDF3","text":"<p>SDF3 is the meta-language in Spoofax for syntax definition.</p> <p>A syntax definition is structured as a collection of modules, which may import each other.</p> <p>Symbols are the building blocks of productions. Productions are defined for lexical, context-free, or kernel syntax.</p> <p>Start symbols indicate the entry point of a syntax definition.</p> <p>SDF3 automatically generates a pretty-printer for template-based productions.</p> <p>Grammars can be disambiguated by means of rejects, priorities, associativity, and restrictions.</p> <p>SDF3 provides additional constructs for the definition of layout-sensitivite languages.</p> <p>Permissive grammars are automatically generated for error-recovery parsing. Handwritten recovery rules can be added to tweak recovery behavior.</p> <p>Several aspects related to syntax definition and parsing can be configured in the <code>metaborg.yaml.</code> file.</p>"},{"location":"references/syntax/#source","title":"Source","text":"<p>The sources of the SDF3 implementation can be found at</p> <ul> <li>https://github.com/metaborg/sdf/tree/master/org.metaborg.meta.lang.template: The SDF3 language implementation (SDF3 was called TemplateLang before and it has not been renamed everywhere yet)</li> </ul>"},{"location":"references/syntax/configuration/","title":"Configuration","text":"<p>When using SDF3 inside Spoofax, several configuration options are relevant. They allow using the new parser generator, specifying the shape of completion placeholders, or disable SDF altogether. These options should be specified in the <code>metaborg.yaml</code> file.</p> <p>For example, to disable SDF for the current project, use:</p> <pre><code>language:\nsdf:\nenabled: false\n</code></pre> <p>SDF3 allows generating placeholders for code completion. The default \"shape\" of placeholders is <code>$Symbol</code>. However, it is possible to tweak this shape using the configuration below (the configuration for suffix is optional):</p> <pre><code>language:\nsdf:\nplaceholder:\nprefix: \"$\"\nsuffix: \"$\"\n</code></pre> <p>Currently, the path to the parse table is specified in the <code>Syntax.esv</code> file, commonly as <code>table: target/metaborg/sdf.tbl</code>. When the ESV file does not contain this entry, it is also possible to specify the path to the parse table in the <code>metaborg.yaml</code> file. This is useful when testing an external parse table, or using a parse table different from the one being generated in the project. In the example below, the table is loaded from the path <code>tables/sdf.tbl</code>. The same can be applied to the parse table used for code completion.</p> <pre><code>language:\nsdf:\nparse-table: \"tables/sdf.tbl\"\ncompletion-parse-table: \"tables/sdf-completions.tbl\"\n</code></pre> <p>In a Spoofax project, it is also possible to use SDF2 instead of SDF3. This enables SDF2 tools such as the SDF2 parenthesizer, signature generator, etc. For example:</p> <pre><code>language:\nsdf:\nversion: sdf2\n</code></pre> <p>By default SDF3 compilation works by generating SDF2 files, and depending on the SDF2 toolchain. However, a new (and experimental) parse table generator can be selected by writing:</p> <pre><code>language:\nsdf:\nsdf2table: java\n</code></pre> <p>This configuration disables the SDF2 generation, and may cause problems when defining grammars to use concrete syntax, since this feature is not supported yet by SDF3. However, the <code>java</code> parse table generator supports Unicode, whereas SDF2 generation does not. Furthermore, <code>dynamic</code> can be used instead of <code>java</code>, to enable lazy parse table generation, where the parse table is generated while the program is parsed.</p> <p>A namespaced grammar can be generated automatically from an SDF3 grammar. This namespacing is done by adding the language name to all module names and sort names. The generated grammar is put in <code>src-gen/syntax</code>.</p> <p>The configuration to enable this is:</p> <pre><code>language:\nsdf:\ngenerate-namespaced: true\n</code></pre> <p>Note that namespacing doesn't not handle imports of grammar files from other projects very well. </p>"},{"location":"references/syntax/configuration/#jsglr-version","title":"JSGLR version","text":"<p>An experimental new version of the SGLR parser implementation is available: JSGLR2. It supports parsing, imploding and syntax highlighting.</p> <p>Error reporting, recovery and completions are currently not supported. It can be enabled with:</p> <pre><code>   language:\nsdf:\njsglr-version: v2\n</code></pre> <p>There are some extensions of JSGLR2 available. To use them, change the <code>jsglr-version</code> by replacing <code>v2</code> with one of the following:</p> <ul> <li><code>data-dependent</code>:       Data-dependent JSGLR2 solves deep priority conflicts using data-dependent parsing, which does not require duplicating the grammar productions.</li> <li><code>incremental</code>:          Incremental JSGLR2 reuses previous parse results to speed up parsing.</li> <li><code>layout-sensitive</code>:     Layout-sensitive JSGLR2, see Layout Sensitivity.</li> <li><code>recovery</code>:             JSGLR2 with recovery tries to recover from parse errors. This extension is experimental.</li> <li><code>recovery-incremental</code>: Incremental JSGLR2 with recovery. This extension is experimental.</li> </ul>"},{"location":"references/syntax/configuration/#jsglr2-logging","title":"JSGLR2 logging","text":"<p>Logging is available for JSGLR2. It can be enabled with:</p> <pre><code>language:\nsdf:\njsglr2-logging: all\n</code></pre> <p>Since logging all parsing events is quite verbose, several other scopes are available in addition to the <code>all</code> option:</p> <ul> <li><code>none</code>: Log nothing (default).</li> <li><code>minimal</code>: Only log the start and end of a parse, including a measurement of total parse time (including imploding and tokenization).</li> <li><code>parsing</code>: Log all standard parsing events (such as stack and parse forest operations, action execution, etc.) but no variant-specific events (e.g. related to recovery).</li> <li><code>recovery</code>: Log the recovery iterations and the recovery productions that are applied.</li> </ul>"},{"location":"references/syntax/context-free-syntax/","title":"Context-Free Syntax","text":"<p>The context-free syntax describes the more high-level syntactic structure of sentences in a language. A context-free syntax contains a list of productions. Elements of the right-hand side of a context-free production are pre-processed in a normalization step before parser generation that adds the <code>LAYOUT?</code> symbol between any two symbols.</p> <p>Context-free syntax has the form:</p> <pre><code>context-free syntax\n\n  $Production*\n</code></pre> <p>An example production rule:</p> <pre><code>context-free syntax\n\n  Block.Block = \"{\" Statement* \"}\"\n</code></pre> <p>SDF3 automatically allows for layout to be present between the symbols of a rule. This means that a fragment such as:</p> <pre><code>{\n\n}\n</code></pre> <p>will still be recognized as a block (assuming that the newline and line-feed characters are defined as layout).</p>"},{"location":"references/syntax/disambiguation/","title":"Disambiguation","text":"<p>The semantics of SDF3 can be seen as two-staged. First, the grammar generates all possible derivations. Second, the disambiguation constructs remove a number of derivations that are not valid. Note that SDF3 actually performs some disambiguation both when generating the parse table as during parsing.</p>"},{"location":"references/syntax/disambiguation/#rejections","title":"Rejections","text":"<p>Rejections filter derivations. The semantics of a rejection is that the set of valid derivations for the left-hand side of the production will not contain the construction described on the right-hand side. In other words, the language defined by the sort on the left-hand side has become smaller, removing all the constructions generated by the rule on the right-hand side. Disambiguation by <code>reject</code> occurs at parse time (mostly).</p> <p>A rule can be marked as rejected by using the attribute <code>{reject}</code> after the rule:</p> <pre><code>$Sort = ... {reject}\n</code></pre> <p>The <code>{reject}</code> attribute works well for lexical rejections, especially keyword reservation in the form of productions like:</p> <pre><code>ID = \"keyword\" {reject}\n</code></pre>"},{"location":"references/syntax/disambiguation/#preferences","title":"Preferences","text":"<p>The preferences mechanism is another disambiguation filter that provides a post parse filter to parse forests. The attributes <code>prefer</code> and <code>avoid</code> are the only disambiguation constructs that compare alternative derivations after parsing.</p> <p>Warning</p> <p><code>prefer</code> and <code>avoid</code> are deprecated and will be removed in a future version of Spoofax.</p> <p>The following definition assumes that derivations are represented using parse forests with \"packaged ambiguity nodes\". This means that whenever in a derivation there is a choice for several sub-derivations, at that point a special choice node (ambiguity constructor) is placed with all alternatives as children. We assume here that the ambiguity constructor is always placed at the location where a choice is needed, and not higher (i.e. a minimal parse forest representation). The preference mechanism compares the top nodes of each alternative:</p> <ul> <li>All alternative derivations that have <code>avoid</code> at the top node will be removed, but only if other alternatives derivations are there that do not have <code>avoid</code> at the top node.</li> <li>If there are derivations that have <code>prefer</code> at the top node, all other derivations that do not have <code>prefer</code> at the top node will be removed.</li> </ul> <p>The preference attribute can be used to handle the case when two productions can parse the same input. Here is an example:</p> <pre><code>Exp.FunctionApp = &lt;&lt;Expr&gt; &lt;Expr*&gt;&gt;\nExp.Constructor = &lt;&lt;ID&gt; &lt;Expr&gt;&gt;  {prefer}\n</code></pre>"},{"location":"references/syntax/disambiguation/#priorities","title":"Priorities","text":"<p>Priorities are one of SDF3's most often used disambiguation constructs. A priority section defines the relative priorities between productions. Priorities are a powerful disambiguation construct because it occurs at parse generation time. The idea behind the semantics of priorities is that productions with a higher priority \"bind stronger\" than productions with a lower priority. The essence of the priority disambiguation construct is that certain parse trees are removed from the \"forest\" (the set of all possible parse trees that can be derived from a segment of code). The basic priority syntax looks like this:</p> <pre><code>context-free priorities\n\n    $ProductionRef &gt;  $ProductionRef\n</code></pre> <p>Where <code>$ProductionRef&gt;</code> can either be <code>$Sort.$Constructor</code> or the entire production itself.</p> <p>Several priorities in a priority grammar are separated by commas. If more productions have the same priority they may be grouped between curly braces on each side of the <code>&gt;</code> sign.</p> <pre><code>context-free priorities\n\n    {$ProductionRef $ProductionRef}\n                &gt;  $ProductionRef,\n    $ProductionRef\n                &gt;  $ProductionRef\n</code></pre> <p>By default, the priority relation is automatically transitively closed (i.e. if A &gt; B and B &gt; C then A &gt; C). To specify a non-transitive priority relation it is necessary to include a dot before the &gt; sign (<code>.&gt;</code>).</p> <p>SDF3 provides safe disambiguation, meaning that priority relations only remove ambiguous derivations. Furthermore, SDF3 also allows tree filtering by means of indexed priorities such as:</p> <pre><code>context-free priorities\n\n    $ProductionRef $Index &gt;  $ProductionRef\n</code></pre> <p>where the symbol at position <code>$Index</code> (starting with 0) in the first production should not derive the second production.</p> <p>An example defining priorities for the addition, subtraction and multiplication operators is listed below. Because addition and subtraction have the same priority, the are grouped together between brackets.</p> <pre><code>context-free priorities\n\n    {Exp.Times} &gt;\n    {Exp.Plus Exp.Minus}\n</code></pre>"},{"location":"references/syntax/disambiguation/#associativity","title":"Associativity","text":"<p>Like with priorities, the essence of the associativity attribute is that certain parse trees are removed from the \"forest\".</p> <ul> <li>The <code>left</code> associativity attribute on a production P filters all occurrences of P as a direct child of P in the right-most argument. This implies that <code>left</code> is only effective on productions that are recursive on the right (as in <code>A B C -&gt; C</code>).</li> <li>The <code>right</code> associativity attribute on a production P filters all occurrences of P as a direct child of P in the left-most argument. This implies that <code>right</code> is only effective on productions that are recursive on the left ( as in <code>C A B -&gt; C</code>).</li> <li>The <code>non-assoc</code> associativity attribute on a production P filters all occurrences of P as a direct child of P in any argument. This implement that <code>non-assoc</code> is only effective if a production is indeed recursive (as in <code>A C B -&gt; C</code>).</li> <li>The <code>assoc</code> attribute means the same as <code>left</code></li> </ul> <p>Associativity declarations occur in two places in SDF3. The first is as production attributes. The second is as associativity declarations in priority groups.</p> <p>An example on how to mention associativity as a production attribute is given below:</p> <pre><code>Exp.Plus = &lt;&lt;Exp&gt; + &lt;Exp&gt;&gt; {left}\n</code></pre> <p>In priority groups, the associativity has the same semantics as the associativity attributes, except that the filter refers to more nested productions instead of a recursive nesting of one production. The group associativity attribute works pairwise and commutative on all combinations of productions in the group. If there is only one element in the group the attribute is reflexive, otherwise it is not reflexive.</p> <pre><code>context-free priorities\n\n    {left: Exp.Times} &gt;\n    {left: Exp.Plus Exp.Minus}\n</code></pre>"},{"location":"references/syntax/disambiguation/#restrictions","title":"Restrictions","text":"<p>The notion of restrictions enables the formulation of lexical disambiguation strategies. Examples are \"shift before reduce\" and \"longest match\". A restriction filters applications of productions for certain non-terminals if the following character (lookahead) is in a certain class. The result is that specific symbols may not be followed by a character from a given character class. A lookahead may consist of more than one character class (multiple lookahead). Restrictions come in two flavors:</p> <ul> <li>lexical restrictions that apply to lexical non-terminals</li> <li>context-free restrictions that apply to context-free non-terminals.</li> </ul> <p>The general form of a restriction is:</p> <pre><code>    $Symbol+ -/- $Lookahead\n</code></pre> <p>The semantics of a restriction is to remove all derivations that produce a certain <code>$Symbol</code>. The condition for this removal is that the derivation tree for that symbol is followed immediately by something that matches the lookahead declaration. Note that to be able to check this condition, one must look past derivations that produce the empty language, until the characters to the right of the filtered symbol are found. Also, for finding multiple lookahead matches, one must ignore nullable sub-trees that may occur in the middle of the matched lookahead.</p> <p>In case of lexical restrictions <code>$Symbol</code> may be either a literal or sort. In case of context-free restrictions only a sort or symbol is allowed. The restriction operator <code>-/-</code> should be read as may not be followed by. Before the restriction operator <code>-/-</code> a list of symbols is given for which the restriction holds.</p> <p>As an example, the following restriction rule implements the \u201clongest match\u201d policy: an identifier can not be followed by an alpha-numeric character.</p> <pre><code>    ID -/- [a-zA-Z0-9\\_]\n</code></pre>"},{"location":"references/syntax/kernel-syntax/","title":"Kernel Syntax","text":"<p>The rules from context-free and lexical syntax are translated into kernel syntax by the SDF3 normalizer. When writing kernel syntax, one has more control over the layout between symbols of a production.</p> <p>As part of normalization, among other things, SDF3 renames each symbol in the lexical syntax to include the suffix <code>-LEX</code> and each symbol in the context-free syntax to include the suffix <code>-CF</code>.</p> <p>For example, the two productions</p> <pre><code>lexical syntax\n\n    BinaryConst = [0-1]+\n\ncontext-free syntax\n\n  Block.Block = \"{\" Statement* \"}\"\n</code></pre> <p>written in kernel syntax look like</p> <pre><code>syntax\n\n    Block-CF.Block  = \"{\" LAYOUT?-CF Statement*-CF LAYOUT?-CF \"}\"\n    BinaryConst-LEX = [0-1]+\n</code></pre> <p>Literals and character classes are lexical by definition, thus they do not need any suffix. Note that each symbol in kernel syntax is uniquely identified by its full name including <code>-CF</code> and <code>-LEX</code>. That is, two symbols named <code>Block-CF</code> and <code>Block</code> are different, if both occur in kernel syntax. However, <code>Block-CF</code> is the same symbol as <code>Block</code> if the latter appears in a context-free syntax section.</p> <p>As mentioned before, layout can only occur in between symbols if explicitly specified.</p> <p>For example, the production</p> <pre><code>syntax\n\n    Block-CF.Block  = \"{\" Statement*-CF LAYOUT?-CF \"}\"\n</code></pre> <p>does not allow layout to occur in between the opening bracket and the list of statements.</p> <p>This means that a fragment such as:</p> <pre><code>    {\n      x = 1;\n    }\n</code></pre> <p>would not be recognized as a block.</p>"},{"location":"references/syntax/layout-sensitivity/","title":"Layout Sensitivity","text":"<p>SDF3 supports definition of layout sensitive syntax by means of low-level layout constraints and high-level layout declarations.</p> <p>Note</p> <p>If you want to use layout constraints or layout declarations, you should specify the <code>jsglr-version: layout-sensitive</code> parameter for SDF3, see configuration.</p>"},{"location":"references/syntax/layout-sensitivity/#layout-constraints","title":"Layout Constraints","text":"<p>While we haven't covered layout constraints in this documentation, the paper of Erdweg et al.1 describes the concepts.</p>"},{"location":"references/syntax/layout-sensitivity/#layout-declarations","title":"Layout Declarations","text":"<p>In the paper of Erdweg et al.1, the authors describe layout constraints in terms of restrictions involving the position of the subtree involved in the constraint (<code>0</code>, <code>1</code>, ...), token selectors (<code>first</code>, <code>left</code>, <code>last</code> and <code>right</code>), and position selectors as lines and columns (<code>line</code> and <code>col</code>).</p> <p>This mechanism allows writing layout constraints to express alignment, offside and indentation rules, but writing such constraints is rather cumbersome and error prone. Alternatively, one may write layout constraints using layout declarations, which are more declarative specifications and abstract over lines, columns and token selectors as the original layout constraints from the Erdweg et al. paper1.</p>"},{"location":"references/syntax/layout-sensitivity/#tree-selectors","title":"Tree selectors","text":"<p>To specify which trees should be subject to a layout constraint, one may use: tree positions, SDF3 labeled non-terminals, or unique literals that occurs in the production. For example:</p> <pre><code>context-free syntax\n\n    Stmt.IfElse = \"if\" Exp \"then\" Stmts \"else\" else:Stmts  {layout(\n        indent \"if\" 3, else &amp;&amp;\n        align 3 else &amp;&amp;\n        align \"if\" \"else\"\n    )}\n</code></pre> <p>In the layout constraint for the production above, <code>else</code> refers to the tree for the labeled non-terminal <code>else:Stmts</code>, <code>\"if\"</code> refers to the tree corresponding to the <code>\"if\"</code> literal and the number 3 correspond to the tree at position 3 in the parse tree (starting at 0, ignoring trees for <code>LAYOUT?</code>).</p>"},{"location":"references/syntax/layout-sensitivity/#align","title":"<code>align</code>","text":"<p>The layout constraint <code>layout(align x y1, ..., yn)</code> specifies that the trees indicated by the tree selectors <code>yi</code> should be aligned with the tree indicated by the tree selector <code>x</code>, i.e., all these trees should start in the same column. For example, if we consider the production above, the following program is correct according to the <code>align</code> constraints:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 0\nelse\n\u00b7\u00b7y = 1\n</code></pre> <p>Whereas, the following program is incorrect because neither the if and else keyword align (<code>align \"if\" \"else\"</code>), nor the statements in the branches (<code>align 3 else</code>):</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 0\n\u00b7else\n\u00b7\u00b7\u00b7y = 1\n</code></pre>"},{"location":"references/syntax/layout-sensitivity/#align-list","title":"<code>align-list</code>","text":"<p>The constraint <code>align-list</code> can be used to indicate that all subtrees within a list should be aligned. That is, a constraint <code>layout(align-list x)</code>, where <code>x</code> is a tree selector for a list subtree, can be used to enforce such constraint. For example, consider the following production and its layout constraint:</p> <pre><code>context-free syntax\n\n    Stmt.If = \"if\" Exp \"then\" then:Stmt*  {layout(\n        align-list then\n    )}\n</code></pre> <p>This constraint indicates that statements inside the list should be aligned. Therefore, the following program is correct according to this constraint:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 0\n\u00b7\u00b7y = 4\n\u00b7\u00b7z = 2\n</code></pre> <p>And the following program is invalid, as the second statement is misaligned:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 0\n\u00b7\u00b7\u00b7y = 4\n    \u00b7\u00b7z = 2\n</code></pre>"},{"location":"references/syntax/layout-sensitivity/#offside","title":"<code>offside</code>","text":"<p>The offside rule is very common in layout-sensitive languages. It states that all lines after the first one should be further to the right compared to the first line. For a description of how the offside rule can be modelled with layout constraints, refer to Erdweg et al.1. An example of a declarative specification of the offside rule can be seen in the production below:</p> <pre><code>context-free syntax\n\n    Stmt.Assign = &lt;&lt;ID&gt; = &lt;Exp&gt;&gt; {layout(offside 3)}\n</code></pre> <p>The layout constraint specifies that when the expression in the statement spams multiple lines, all following lines should be indented with respect to the column where the expression started. For example, the following program is valid according to this constraint:</p> <pre><code>x = 4 * 10\n\u00b7\u00b7\u00b7\u00b7\u00b7+ 2\n</code></pre> <p>However, the following program is not valid, as the second line of the expression starts at the same column as the first line:</p> <pre><code>x = 4 * 10\n\u00b7\u00b7\u00b7\u00b7+ 2\n</code></pre> <p>Note that if the expression is written on a single line, the constraint is also verified. That is, the following program successfully parses:</p> <pre><code>    x = 4 * 10 + 2\n</code></pre> <p>It is also possible to use the offside relation on different trees. For example, consider the constraint in the following production:</p> <pre><code>context-free syntax\n\n    Stmt.If = \"if\" Exp \"then\" then:Stmt*  {layout(\n        offside \"if\" then\n    )}\n</code></pre> <p>This constraint states that all lines (except the first) of the statements in the <code>then</code> branch should be indented with respect to the <code>if</code> literal. Thus, the following program is invalid according to this layout constraint, because the statement <code>x = 2</code> should be indented with relation to the topmost <code>if</code>.</p> <pre><code>    if x &lt; 0 then\n    \u00b7\u00b7if y &lt; 0 then\n    x = 2\n</code></pre> <p>In general, an <code>offside</code> constraint involving more than a single tree is combined with <code>indent</code> constraint to enforce that the column of the first and all subsequent lines should be indented.</p>"},{"location":"references/syntax/layout-sensitivity/#indent","title":"<code>indent</code>","text":"<p>An indent constraint indicates that the column of the first line of a certain tree should be further to the right with respect to another tree. For example, consider the following production:</p> <pre><code>context-free syntax\n\n    Stmt.If = \"if\" Exp \"then\" then:Stmt*  {layout(\n        indent \"if\" then\n    )}\n</code></pre> <p>This constraint indicates that the first line of the list of statements should be indented with respect to the <code>if</code> literal. Thus, according to this constraint the following program is valid:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 2\n</code></pre> <p>Note that if the list of statements in the then branch spams multiple lines, the constraint does not apply to its subsequent lines. For example, consider the following program:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 2 + 10\n* 4\ny = 3\n</code></pre> <p>This program is still valid, since the column of the first line of the first assignment is indented with respect to the if literal. To indicate that the first and all subsequent lines should be indented, an offside constraint should also be included.</p> <pre><code>context-free syntax\n\n    Stmt.If = \"if\" Exp \"then\" then:Stmt*  {layout(\n        indent \"if\" then &amp;&amp;\n        offside \"if\" then\n    )}\n</code></pre> <p>With this constraint, the remainder of the expression <code>* 4</code> should also be further to the right compared to the \"if\" literal. The following program is correct according to these two constraints, since the second line of the first assignment and the second assignment are also indented with respect to the <code>if</code> literal:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x = 2 + 10\n\u00b7* 4\n\u00b7y = 3\n</code></pre>"},{"location":"references/syntax/layout-sensitivity/#newline-indent","title":"<code>newline-indent</code>","text":"<p>The newline-indent constraint indicates that a certain tree should both be located on a new line, as well as further to the right with respect to another tree.</p> <p>For example, consider the following production:</p> <pre><code>context-free syntax\n\n    Exp.If = \"if\" Exp \"then\" then:Exp \"else\" Exp  {layout(\n        newline-indent \"if\" then\n    )}\n</code></pre> <p>This constraint indicates that the \"then\" branch of the if-then-else expression needs to be on a new line and indented with respect to the \"if\" keyword. Thus, according to this constraint the following program is valid:</p> <pre><code>if x &lt; 0 then\n\u00b7\u00b7x + 2 else x * 2\n</code></pre> <p>The newline-indent constraint does not require that the expression is located on the immediate next line, but rather that it is located below the reference tree. Consequently, the following is also allowed:</p> <pre><code>if x &lt; 0 then\n\n\n\u00b7\u00b7x + 2\nelse x * 2\n</code></pre> <p>Note that the newline-indent constraint is relative to the first character in the reference tree. That means that, given the following syntax:</p> <pre><code>context-free syntax\n    Example.Example = a:FooBar b:Baz {layout(newline-indent a b)}\n    FooBar.FooBar = &lt;foo bar&gt;\n    Baz.Baz = &lt;baz&gt;\n</code></pre> <p>The following syntax is valid, despite <code>bar</code> being indented further than <code>baz</code>:</p> <pre><code>foo\n\u00b7\u00b7\u00b7\u00b7bar\n\u00b7\u00b7baz\n</code></pre>"},{"location":"references/syntax/layout-sensitivity/#single-line","title":"<code>single-line</code>","text":"<p>The single-line constraints indicates that the entirety of the given subtrees must be located on the same line. For example, consider the following production:</p> <pre><code>context-free syntax\n    Exp.If = \"if\" Exp \":\" then:Exp \"else\" Exp {layout(\n        single-line \"if\" \":\"\n    )}\n</code></pre> <p>This enforces that both the <code>if</code> and <code>:</code> tokens need to be on the same line. As a result, the condition expression also needs to be contained on the same line. Thus, the following program is valid for the given constraints:</p> <pre><code>if x &lt; 3:\n  x + 2 else x * 2\n</code></pre> <p>Note that the entirety of the referenced tree needs to be on the same line. Consider the following syntax:</p> <pre><code>context-free syntax\n    Example.Example = a:Baz b:FooBar {layout(single-line a b)}\n    FooBar.FooBar = &lt;foo bar&gt;\n    Baz.Baz = &lt;baz&gt;\n</code></pre> <p>With this definition, the following program is invalid, despite <code>baz</code> and the start of <code>foo bar</code> being on the same line:</p> <pre><code>baz foo\n  bar\n</code></pre> <p>Using the <code>single-line</code> constraint without any parameters will add a constraint that the entire production needs to be on a single line. This can be useful as a shorthand when your grammar requires that the entirety of a production is on the same line:</p> <pre><code>context-free syntax\n    Exp.Add = &lt;&lt;Exp&gt; + &lt;Exp&gt;&gt; {layout(single-line)}\n    // is equivalent to\n    Exp.Add = &lt;&lt;a:Exp&gt; + &lt;b:Exp&gt;&gt; {layout(single-line a b)}\n</code></pre> <p>Finally, all these layout declarations can be ignored by the parser and used only when generating the pretty-printer. To do that, prefix the constraint with <code>pp-</code> writing, for example, <code>pp-offside</code> or <code>pp-align</code>.</p> <ol> <li> <p>Sebastian Erdweg, Tillmann Rendel, Christian K\u00e4stner, and Klaus Ostermann. Layout-sensitive generalized parsing. In Krzysztof Czarnecki and G\u00f6rel Hedin, editors, Software Language Engineering, 5th International Conference, SLE 2012, Dresden, Germany, September 26-28, 2012, Revised Selected Papers, volume 7745 of Lecture Notes in Computer Science, 244\u2013263. Springer, 2012. doi:10.1007/978-3-642-36089-3\\_14.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"references/syntax/lexical-syntax/","title":"Lexical Syntax","text":"<p>The lexical syntax usually describes the low level structure of programs (often referred to as lexical tokens). However, in SDF3, the token concept is not really relevant, since only character classes are terminals. The lexical syntax sections in SDF3 are simply a convenient notation for the low level syntax of a language. The <code>LAYOUT</code> symbol should also be defined in a lexical syntax section.</p> <p>A lexical syntax consists of a list of productions.</p> <p>Lexical syntax is described as follows:</p> <pre><code>lexical syntax\n\n    $Production*\n</code></pre> <p>An example of a production in lexical syntax:</p> <pre><code>lexical syntax\n\n    BinaryConst = [0-1]+\n</code></pre>"},{"location":"references/syntax/modules/","title":"Modules","text":"<p>An SDF3 specification consists of a number of module declarations. Each module defines sections and may import other modules.</p>"},{"location":"references/syntax/modules/#imports","title":"Imports","text":"<p>Modules may import other modules for reuse or separation of concerns. A module may extend the definition of a non-terminal in another module. A module may compose the definition of a language by importing the parts of the language. The structure of a module is as follows:</p> <pre><code>module $ModuleName\n\n$ImportSection*\n\n$Section*\n</code></pre> <p>The <code>module</code> keyword is followed by the module name, then a series of imports can be made, followed by sections that contain the actual definition of the syntax. An import section is structured as follows:</p> <pre><code>imports $ModuleName*\n</code></pre> <p>Note that SDF3 does not support parameterized modules.</p>"},{"location":"references/syntax/modules/#sections","title":"Sections","text":"<p>An SDF3 module may constitute of zero or more sections. All sections contribute to the final grammar that defines a language:</p> <ul> <li><code>sorts</code>, <code>lexical sorts</code>, <code>context-free sorts</code> (see Symbols#Sorts)</li> <li><code>lexical syntax</code> (see Lexical Syntax)</li> <li><code>context-free syntax</code> (see Context-Free Syntax)</li> <li><code>syntax</code> (see Kernel Syntax)</li> <li><code>lexical start-symbols</code>, <code>context-free start-symbols</code>, <code>start-symbols</code> (see Start Symbols)</li> <li><code>context-free priorities</code>, <code>priorities</code> (see Disambiguation)</li> <li><code>template options</code> (see Templates)</li> </ul>"},{"location":"references/syntax/productions/","title":"Productions","text":"<p>The basic building block of syntax sections is the production. The left-hand side of a regular production rule can be either just a symbol or a symbol followed by <code>.</code> and a constructor name. The right-hand side consists of zero or more symbols. Both sides are separated by <code>=</code>:</p> <pre><code>$Symbol              = $Symbol*\n$Symbol.$Constructor = $Symbol*\n</code></pre> <p>A production is read as the definition. The symbol on the left-hand side is defined by the right-hand side of the production.</p> <p>Productions are used to describe lexical, context-free, and kernel syntax. Productions may also occur in priority sections, but might also be referred to by its <code>$Symbol.$Constructor</code>. All productions with the same symbol together define the alternatives for that symbol.</p>"},{"location":"references/syntax/productions/#attributes","title":"Attributes","text":"<p>The definition of productions may be followed by attributes that define additional (syntactic or semantic) properties of that production. The attributes are written between curly brackets after the right-hand side of a production. If a production has more than one attribute they are separated by commas. Attributes have thus the following form:</p> <pre><code>$Sort              = $Symbol* { $Attribute1, $Attribute2, ...}\n$Sort.$Constructor = $Symbol* { $Attribute1, $Attribute2, ...}\n</code></pre> <p>The following syntax-related attributes exist:</p> <ul> <li><code>bracket</code> is an important attribute in combination with priorities. The parenthesizer tool uses the <code>bracket</code> attribute to find productions to add to a parse tree before pretty printing (when the tree violates priority constraints). Note that most of these tools demand the production with a <code>bracket</code> attribute to have the shape: <code>X = \"(\" X \")\" {bracket}</code> with any kind of bracket syntax but the <code>X</code> being the same symbol on the left-hand side and the right-hand side. The connection with priorities and associativity is that when a non-terminal is disambiguated using either of them, a production rule with the <code>bracket</code> attribute is probably also needed.</li> <li><code>reject</code> is a disambiguation construct that implements language difference. It is used for keyword reservation. See Disambiguation#Rejections.</li> <li><code>left</code>, <code>right</code>, <code>non-assoc</code>, <code>assoc</code> are disambiguation constructs used to define the associativity of productions. See Disambiguation#Associativity.</li> <li><code>prefer</code> and <code>avoid</code> are deprecated disambiguation constructs to define preference of one derivation over others. See Disambiguation#Preferences.</li> </ul>"},{"location":"references/syntax/recovery/","title":"Recovery","text":"<p>SDF3 automatically generates permissive grammars for supporting error-recovery parsing1. The permissive grammars contain recovery productions that can be used to recover from syntactic errors. The recovery productions are either deletions or insertions. Deletions can skip over an erroneous part of the input. Insertions recover from a missing part of the input, e.g. a missing closing bracket.</p> <p>Handwritten recovery rules can be added to tweak the automatically generated permissive grammar by using the <code>recover</code> attribute. For example, the following insertion enables recovery for missing <code>if</code> literals:</p> <pre><code>lexical syntax\n\n  \"if\" =  {recover}\n</code></pre> <p>The empty right-hand side makes sure that, in recovery mode, the <code>if</code> literal can be parsed even when it is not present in the input.</p> <ol> <li> <p>Maartje de Jonge, Lennart C. L. Kats, Eelco Visser, and Emma S\u00f6derberg. Natural and flexible error recovery for generated modular language environments. ACM Transactions on Programming Languages and Systems, 34(4):15, 2012. URL: http://doi.acm.org/10.1145/2400676.2400678, doi:10.1145/2400676.2400678.\u00a0\u21a9</p> </li> </ol>"},{"location":"references/syntax/start-symbols/","title":"Start Symbols","text":"<p>The lexical or context-free start symbols sections explicitly define the symbols which will serve as start symbols when parsing terms. If no start symbols are defined it is not possible to recognize terms. This has the effect that input sentences corresponding to these symbols can be parsed. So, if we want to recognize boolean terms we have to define explicitly the sort <code>Boolean</code> as a start symbol in the module <code>Booleans</code>. Any symbol and also lists, optionals, etc., can serve as a start-symbol. A definition of lexical start symbols looks like:</p> <pre><code>lexical start-symbols\n\n    $Symbol*\n</code></pre> <p>While context-free start symbols are defined as:</p> <pre><code>context-free start-symbols\n\n    $Symbol*\n</code></pre> <p>SDF3 also supports kernel start-symbols:</p> <pre><code>start-symbols\n\n    $Symbol*\n</code></pre> <p>In contrast to lexical and kernel start-symbols, context-free start symbols can be surrounded by optional layout. A lexical start-symbol should have been defined by a production in the lexical syntax; a context-free symbol should have been defined in the context-free syntax. Both symbols can also be defined in kernel syntax using the suffix <code>-LEX</code> or <code>-CF</code>.</p>"},{"location":"references/syntax/symbols/","title":"Symbols","text":"<p>The building block of SDF3 productions is a symbol. SDF3 symbols can be compared to terminals and non-terminals in other grammar formalisms. The elementary symbols are character classes, literals, and sorts.</p> <p>Intrinsically, only character classes are real terminal symbols. All other symbols represent non-terminals. SDF3 also support symbols that capture BNF-like notation such as lists, optionals, alternatives, and sequences. Note that these symbols are also non-terminals, and are just shorthands for common structures present in context-free grammars.</p>"},{"location":"references/syntax/symbols/#character-classes","title":"Character classes","text":"<p>Character classes occur only in lexical syntax and are enclosed by <code>[</code> and <code>]</code>. A character class consists of a list of zero or more characters (which stand for themselves) such as <code>[x]</code> to represent the character <code>x</code>,  or character ranges, as an abbreviation for all the characters in the range such as <code>[0-9]</code> representing <code>0</code>, <code>1</code>, ..., <code>9</code>. A valid range consists of <code>[c1-c2]</code>, where the character <code>c2</code> has a higher ASCII code than <code>c1</code>. Note that nested character classes can also be concatenated within the same character class symbol, for example <code>[c1c2-c3c4-c5]</code> includes the characters <code>c1</code> and the ranges <code>c2-c3</code>, <code>c4-c5</code>.  In this case, the nested character classes do not need to be ordered, as SDF3 orders them when performing a normalization step.</p>"},{"location":"references/syntax/symbols/#escaping","title":"Escaping","text":"<p>SDF3 uses a backslash (<code>\\</code>) as a escape for the quotingof special characters. One should use <code>\\c</code> whenever <code>c</code> is not a digit or a letter in a character class.</p>"},{"location":"references/syntax/symbols/#unicode","title":"Unicode","text":"<p>Arbitrary Unicode code points can be included in a character class by writing an escaped integer, which is particularly useful for representing characters outside the printable ASCII range. The integer can be a binary, octal, decimal, or hexadecimal number, for example: <code>\\0b101010</code>, <code>\\052</code>, <code>\\42</code>, and <code>\\0x2A</code> all represent the code point 42, or the <code>'*'</code> character.</p>"},{"location":"references/syntax/symbols/#special-ascii-characters","title":"Special ASCII Characters","text":"<p>Additionally, special ASCII characters are represented by:</p> <ul> <li><code>\\t</code> : horizontal tabulation</li> <li><code>\\n</code> : newline character</li> <li><code>\\v</code> : vertical tabulation</li> <li><code>\\f</code> : form feed</li> <li><code>\\r</code> : carriage return</li> </ul>"},{"location":"references/syntax/symbols/#operators","title":"Operators","text":"<p>SDF3 provides the following operators for character classes:</p> <ul> <li>(complement) <code>~</code> : Accepts all the characters that are not in the original class.</li> <li>(difference) <code>/</code> : Accepts all the characters in the first class unless they are in a second class.</li> <li>(union) <code>\\/</code> : Accepts all the characters in either character classes.</li> <li>(intersection) <code>/\\</code> : Accepts all the characters that are accepted by both character classes.</li> </ul> <p>Note that the first operator is unary and the other ones are left associative binary operators. Furthermore, such operators are not applicable to other symbols in general.</p>"},{"location":"references/syntax/symbols/#literals","title":"Literals","text":"<p>A literal symbol defines a fixed length word. This usually corresponds to a terminal symbol in ordinary context-free grammars, for example <code>\"true\"</code> or <code>\"+\"</code>. Literals must always be quoted and consist of (possibly escaped) ASCII characters.</p> <p>As literals are also regular non-terminals, SDF3 automatically generates productions for them in terms of terminal symbols.</p> <pre><code>\"definition\" = [d][e][f][i][n][i][t][i][o][n]\n</code></pre> <p>Note that the production above defines a case-sensitive implementation of the defined literal. Case-insensitive literals are defined using single-quoted strings as in <code>'true'</code> or <code>'else'</code>. SDF3 generates a different production for case-insensitive literals as</p> <pre><code>'definition' = [dD][eE][fF][iI][nN][iI][tT][iI][oO][nN]\n</code></pre> <p>The literal above accepts case-insensitive inputs such as <code>definition</code>, <code>DEFINITION</code>, <code>DeFiNiTiOn</code> or <code>defINITION</code>.</p>"},{"location":"references/syntax/symbols/#sorts","title":"Sorts","text":"<p>A sort corresponds to a plain non-terminal, e.g. <code>Statement</code> or <code>Exp</code>. Sort names start with a capital letter and may be followed by letters, digits, hyphens, or underscores. Note that unlike SDF2, SDF3 does not support parameterized sorts (yet!).</p> <p>Sorts are declared by listing their name in the appropriate sorts section, which have the following forms.</p> <p>For context-free sorts:</p> <pre><code>context-free sorts\n\n    $Sort*\n</code></pre> <p>For lexical sorts:</p> <pre><code>lexical sorts\n\n    $Sort*\n</code></pre> <p>SDF3 also supports kernel sorts:</p> <pre><code>sorts\n\n    $Sort*\n</code></pre> <p>Note</p> <p>Kernel sorts should be suffixed with <code>-CF</code> or <code>-LEX</code>, depending on whether they are context-free sorts or lexical sorts. When a sort in a <code>sorts</code> block does not have a suffix, it is treated as a context-free sort.</p> <p>Writing a sort in these sections only indicates that a sort has been declared, even if it does not have any explicit production visible.</p>"},{"location":"references/syntax/symbols/#optionals","title":"Optionals","text":"<p>SDF3 provides a shorthand for describing zero or exactly one occurrence of a sort by appending the sort with <code>?</code>.</p> <p>For example, the sort <code>Extends?</code> can be parsed as <code>Extends</code> or without consuming any input. Internally, SDF3 generates the following productions after normalizing the grammar::</p> <pre><code>Extends?.None =\nExtends?.Some = Extends\n</code></pre> <p>Note that using <code>?</code> adds the constructors <code>None</code> and <code>Some</code> to the final abstract syntax tree.</p>"},{"location":"references/syntax/symbols/#lists","title":"Lists","text":"<p>Lists symbols as the name says, indicate that a symbol should occur several times. In this way, it is also possible to construct flat structures to represent them. SDF3 provides support for two types of lists, with and without separators. Furthermore, it is also possible to indicate whether a list can be empty (<code>*</code>) or should have at least one element (<code>+</code>). For example, a list <code>Statement*</code> indicates zero or more <code>Statement</code>, whereas a list with separator <code>{ID \",\"}+</code> indicates one or more <code>ID</code> separated by <code>,</code>. Note that SDF3 only supports literal symbols as separators.</p> <p>Again, SDF3 generates the following productions to represent lists, when normalizing the grammar:</p> <pre><code>Statement* =\nStatement* = Statement+\nStatement+ = Statement+ Statement\nStatement+ = Statement\n\n{ID \",\"}* =\n{ID \",\"}* = {ID \",\"}+\n{ID \",\"}+ = {ID \",\"}+ \",\" {ID \",\"}\n{ID \",\"}+ = {ID \",\"}\n</code></pre> <p>When parsing a context-free list, SDF3 produces a flattened list as an AST node such as <code>[Statement, ..., Statement]</code> or <code>[ID, ..., ID]</code>. Note that because the separator is a literal, it does not appear in the AST.</p>"},{"location":"references/syntax/symbols/#alternative","title":"Alternative","text":"<p>Alternative symbols express the choice between two symbols, for example, <code>ID | INT</code>. That is, the symbol <code>ID | INT</code> can be parsed as either <code>ID</code> or <code>INT</code>. For that reason, SDF3 normalizes alternatives by generating the following productions:</p> <pre><code>ID | INT = ID\nID | INT = INT\n</code></pre> <p>Note that SDF3 only allow alternative symbols to occur in lexical syntax. Furthermore, note that the alternative operator is right associative and binds stronger than any operator. That is, <code>ID \",\" | ID \";\"</code> expresses <code>ID (\",\" | ID) \";\"</code>. To express <code>(ID \",\") | (ID \";\")</code>, we can use a sequence symbol.</p>"},{"location":"references/syntax/symbols/#sequence","title":"Sequence","text":"<p>A sequence operator allows grouping of two or more symbols. Sequences are useful when combined with other symbols such, lists or optionals, for example <code>(\"e\" [0-9]+)?</code>. Like alternative symbols, sequences can only occur in lexical syntax. A sequence symbol is normalized as:</p> <pre><code>(\"e\" [0-9]+) = \"e\" [0-9]+\n</code></pre>"},{"location":"references/syntax/symbols/#labeled-symbols","title":"Labeled symbols","text":"<p>SDF3 supports decorating symbols with labels, such as <code>myList:{elem:Stmt \";\"}*</code>. The labels can be used for layout constraints/declarations or by other tools that use SDF3 grammars as input.</p>"},{"location":"references/syntax/symbols/#layout","title":"<code>LAYOUT</code>","text":"<p>The <code>LAYOUT</code> symbol is a reserved sort name. It is used to indicate the whitespace that can appear in between context-free symbols. The user must define the symbol <code>LAYOUT</code> such as:</p> <pre><code>LAYOUT = [\\ \\t\\n]\n</code></pre> <p>Note that the production above should be defined in the lexical syntax.</p>"},{"location":"references/syntax/templates/","title":"Templates","text":"<p>Templates are a major change in SDF3 when comparing to SDF2. They are essential when aiming to generate a nice pretty printer or generate proper syntactic code completion templates. When generating such artifacts, a general production simply introduces a whitespace in between symbols.</p> <p>For example, when writing a grammar rule</p> <pre><code>Statement.If = \"if\" \"(\" Exp \")\" Exp \"else\" Exp\n</code></pre> <p>and pretty printing a valid program, we would get the text in a single line separated by spaces, as:</p> <p></p> <p>Furthermore, code completion would consider the same indentation when inserting code snippets.</p> <p>However, when using template productions such as</p> <pre><code>Statement.If = &lt;\n  if ($Exp)\n    $Exp\n  else\n    $Exp\n</code></pre> <p>We would get the following program:</p> <p></p> <p>Again, code completion would also consider this indentation for proposals.</p> <p>That is, in template productions, the surrounding layout is used to nicely pretty print programs and its code completion suggestions.</p>"},{"location":"references/syntax/templates/#template-productions","title":"Template Productions","text":"<p>Template productions are an alternative way of defining productions. Similarly, they consist of a left-hand side and a right-hand side separated by <code>=</code>. The left-hand side is the same as for productive rules. The right-hand side is a template delimited by <code>&lt;</code> and <code>&gt;</code>. The template can contain zero or more symbols:</p> <pre><code>$Sort              = &lt; $Symbol* &gt;\n$Sort.$Constructor = &lt; $Symbol* &gt;\n</code></pre> <p>Alternatively, square brackets can be used to delimit a template:</p> <pre><code>$Sort              = [ $Symbol* ]\n$Sort.$Constructor = [ $Symbol* ]\n</code></pre> <p>The symbols in a template can either be placeholders or literal strings. It is worth noting that:</p> <ul> <li>placeholders need to be enclosed within the same delimiters (either <code>&lt;...&gt;</code> or <code>[...]</code>) as the template;</li> <li>literal strings need not not be enclosed within quotation marks;</li> <li>literal strings are tokenized on space characters (whitespace, tab);</li> <li>additionally, literal strings are tokenized on boundaries between characters from the set given by the tokenize option, see the <code>tokenize</code> template option;</li> <li>placeholders translate literally. If a separator containing any layout characters is given, the placeholder maps to a list with separator that strips the layout.</li> </ul> <p>An example of a template rule:</p> <pre><code>Exp.Addition = &lt; $Exp + $Exp &gt;\n</code></pre> <p>Here, the <code>+</code> symbol is a literal string and <code>$Exp</code> is a placeholder for sort <code>Exp</code>.</p> <p>Placeholders are of the form:</p> <ul> <li><code>$Sort?</code>: optional placeholder</li> <li><code>$Sort*</code>: repetition (0...n)</li> <li><code>$Sort+</code>: repetition (1...n)</li> <li><code>&lt;{$Sort \",\"}*&gt;</code>: repetition with separator</li> </ul>"},{"location":"references/syntax/templates/#case-insensitive-literals","title":"Case-insensitive Literals","text":"<p>As we showed before, SDF3 allows defining case-insensitive literals as single-quoted strings in regular productions. For example:</p> <pre><code>Exp.If = 'if' \"(\" Exp \")\" Exp 'else' Exp\n</code></pre> <p>accepts case-insensitive keywords for <code>if</code> and <code>else</code> such as <code>if</code>, <code>IF</code>, <code>If</code>, <code>else</code>, <code>ELSE</code> or <code>ELsE</code>. However, to generate case-insensitive literals from template productions, it is necessary to add annotate these productions as case-insensitive. For example, a template production:</p> <pre><code>Exp.If = &lt;\n  if($Exp)\n    $Exp\n  else\n    $Exp\n&gt; {case-insensitive}\n</code></pre> <p>accepts the same input as the regular production mentioned before.</p> <p>Moreover, lexical symbols can also be annotated as case-insensitive to parse as such. The constructed abstract syntax tree contains lower-case symbols, but the original term is preserved via origin-tracking. For example:</p> <pre><code>    ID = [a-zA-z][a-zA-Z0-9]* {case-insensitive}\n</code></pre> <p>can parse <code>foo</code>, <code>Foo</code>, <code>FOo</code>, <code>fOo</code>, <code>foO</code>, <code>fOO</code> or <code>FOO</code>. Whichever option generates a node <code>\"foo\"</code> in the abstract syntax tree. By consulting the origin information on this node, it is possible to know which term was used as input to the parser.</p>"},{"location":"references/syntax/templates/#template-options","title":"Template options","text":"<p>Template options are options that are applied to the current file. A template options section is structured as follows:</p> <pre><code>template options\n\n    $TemplateOption*\n</code></pre> <p>Multiple template option sections are not supported. If multiple template option sections are specified, the last one is used.</p> <p>There are three kinds of template options.</p>"},{"location":"references/syntax/templates/#keyword","title":"<code>keyword</code>","text":"<p>Convenient way for setting up lexical follow restrictions for keywords. See the section on follow restrictions for more information. The structure of the keyword option is as follows:</p> <pre><code>keyword -/- $Pattern\n</code></pre> <p>This will add a follow restriction on the pattern for each keyword in the language. Keywords are automatically detected, any terminal that ends with an alphanumeric character is considered a keyword.</p> <p>Multiple keyword options are not supported. If multiple keyword options are specified, the last one is used.</p> <p>Note that this only sets up follow restrictions, rejection of keywords as identifiers still needs to be written manually.</p>"},{"location":"references/syntax/templates/#tokenize","title":"<code>tokenize</code>","text":"<p>Specifies which characters may have layout around them. The structure of a tokenize option is as follows:</p> <pre><code>    tokenize : \"$Character*\"\n</code></pre> <p>Consider the following grammar specification:</p> <pre><code>template options\n\n    tokenize : \"(\"\n\ncontext-free syntax\n\n    Exp.Call = &lt;&lt;ID&gt;();&gt;\n</code></pre> <p>Because layout is allowed around the <code>(</code> and <code>)</code> characters, there may be layout between <code>()</code> and <code>;</code> in the template rule. If no tokenize option is specified, it defaults to the default value of <code>()</code>.</p> <p>Multiple tokenize options are not supported. If multiple tokenize options are specified, the last one is used.</p>"},{"location":"references/syntax/templates/#reject","title":"<code>reject</code>","text":"<p>Convenient way for setting up reject rules for keywords. See the section on rejections for more information. The structure of the reject option is as follows:</p> <pre><code>Symbol = keyword {attrs}\n</code></pre> <p>where <code>Symbol</code> is the symbol to generate the rules for. Note that <code>attrs</code> can be include any attribute, but by using <code>reject</code>, reject rules such as <code>ID = \"true\" {reject}</code> are generated for all keywords that appear in the templates.</p> <p>Multiple reject template options are not supported. If multiple reject template options are specified, the last one is used.</p>"},{"location":"references/testing/","title":"SPT: Spoofax Testing Language","text":"<p>The SPoofax Testing language (SPT) allows language developers to test their language in a declarative way. It offers a language to express test cases for any textual language that you want to test, and a framework for executing those tests on language implementations created with Spoofax.</p> <p>We will first describe the syntax and semantics of the SPT language. Then, we will discuss how you can execute your SPT test cases, and finally we conclude with an overview of the architecture of the SPT framework.</p> <p>In this section we will describe the syntax and semantics of SPT.</p> <p>If you want to write your own tests you can follow along as the different concepts are explained. We suggest using the Spoofax Eclipse plugins, as they contain an editor for SPT files. In an Eclipse with Spoofax installed, simply create a new file with the extension <code>.spt</code> and follow along to create your first SPT test suite.</p>"},{"location":"references/testing/running-tests/","title":"Running SPT Tests","text":"<p>SPT tests can be run different ways. Each one corresponds to a different use case of SPT. In the end, they all use the common core SPT Java API for extracting and executing tests.</p> <p>We will now briefly discuss the different ways to run an SPT test suite based on the use case. If you are new to SPT, the Interactive Test Design use case will be the one for you.</p>"},{"location":"references/testing/running-tests/#interactive-test-design","title":"Interactive Test Design","text":"<p>SPT was originally designed for this use case. Its goal was to lower the threshold of writing tests for your language, by allowing you to concisely declare test inputs and outputs, offering editor services for the fragments that you write, and providing you with real time in-editor feedback on whether your test fails or passes.</p> <p>For this use case you would be using Eclipse with the Spoofax plugin. When you open a test suite in the Eclipse editor, all failing test cases will have error markers on them. By turning the test results into message markers inside the editor, we can provide you with a detailed location on where it went wrong. Especially for parsing or analysis errors. However, to keep the error message readable, they can not contain full stack traces, which you might need to debug transformation or Stratego run tests. It is also impractical to check all your test suites this way if you have many of them in your project.</p> <p>To solve this, we have created a JUnit style test runner in Eclipse. It is available through the <code>Spoofax (meta)</code> menu bar entry, and offers two ways to run tests.</p> <p>The first one is called <code>Run tests of SPT files</code>. If you click this, it will check if you currently have an SPT file that is open and, if so, launch the test runner to run all tests in this file. This mode can be useful if one of your tests is failing and you would like to see a more detailed error message.</p> <p>The second entry is called <code>Run all selected tests</code>. It will check what you selected in the package or project explorer. If you selected any SPT files, directories, or projects, it will scan all of the selected locations and run all of the SPT files it found within those selections. This method is useful for running regression tests.</p> <p>The user interface of the test runner consists of 3 parts. The first part is the progress bar, which is followed by two numbers that indicate the progress of your current test runs. This part is displayed at the top of the runner. The second part is the overview of all the test suites and their test cases which are part of this test run. This part is displayed in the bottom left. The final part is a console window, which contains more detailed error messages about the test suite or test case you selected in the second part. This part is displayed in the bottom right:</p> <p></p> <p>The test runner will start displaying any test suites and test cases within those test suites as soon as it discovers them. Then, after they are all loaded, they will be executed one by one, and the progress bar at the top will increase. As long as the progress bar remains green, no tests failed yet. As soon as a single test fails, the progress bar will turn red to indicate so.</p> <p>The numbers next to the progress bar also indicate the progress. For example, <code>5 / 7</code> means 5 tests passed already out of a total of 7 tests. This can mean that either 2 tests failed, or some tests have not been executed yet. Which case applies can be determined by looking at the progress bar.</p> <p>Any SPT files that fail can't be parsed or from which we can't extract test cases for some other reason, will be included in the list on the bottom left side, along with the test suites that did manage to get extracted. The ones that did not extract properly will be displayed in red, as opposed to the default black color for test suites. By selecting a red test suite, the extraction errors will be displayed in the console on the bottom right. Any test suite can be double clicked to open the corresponding file in Eclipse. Test suites that got extracted succesfully can be expanded if they contained any test cases. This will show all the test cases of that suite as child elements of the test suite in the bottom left view.</p> <p>Test cases are displayed in the default black color if they have not been executed yet. Test cases that have finished will have their duration appended to their name. Failed test cases are displayed in red, and passing test cases are displayed in green. A red test case can be selected, doing so will show the messages about the test failure, including the exceptions that caused them (e.g. a <code>StrategoRuntimeException</code> with a stacktrace) in the console on the bottom right. Double clicking a test case will open the corresponding SPT file and jump to the location of the test case.</p> <p>When a test case fails, the test suite that contained the failing test case will be appended with the number of failed tests in that test suite so far.</p>"},{"location":"references/testing/running-tests/#run-using-the-command-line-runner","title":"Run using the Command Line Runner","text":"<p>At https://github.com/metaborg/spt/tree/master/org.metaborg.spt.cmd there is a project that creates an executable jar with which you can run all the test suites in a given directory. It is more of a proof of concept and an example of how to use our core SPT Java API than a full fledged test runner.</p> <p>For those interested in giving it a try:</p> <ol> <li> <p>Obtaining the test runner jar:</p> <pre><code>bash\n$ git clone https://github.com/metaborg/spt.git\n$ cd spt/org.metaborg.spt.cmd\n$ mvn package\n$ ls target/org.metaborg.spt.cmd*\n  target/org.metaborg.spt.cmd-2.0.0-SNAPSHOT.jar\n</code></pre> <p>This jar is the executable jar that contains the test runner. Next up, we want to run the tests for our language. To do so, we need:</p> <ol> <li>the directory with tests to run (e.g., <code>path/to/test/project</code>)</li> <li>the language under test (e.g. <code>path/to/MiniJava/project</code>)</li> <li>the SPT language, to be able to extract the tests from the specification</li> <li>(Optionally) the Stratego language if we want to be able to execute the <code>run</code> or <code>transform</code> expectations</li> </ol> </li> <li> <p>You should already have your tests and your language project, so next up is the SPT language.     This is in the same repo as the command line runner:</p> <pre><code>cd spt/org.metaborg.meta.lang.spt\nmvn verify\n</code></pre> </li> <li> <p>If you want to use the <code>run</code> and <code>transform</code> expectations, you also need the Stratego language:</p> <pre><code>$ git clone https://github.com/metaborg/stratego.git\n$ cd stratego/org.metaborg.meta.lang.stratego\n$ mvn verify\n</code></pre> </li> <li> <p>Now we can run the tests:</p> <pre><code>$ java -jar spt/org.metaborg.spt.cmd/target/org.metaborg.spt.cmd-2.0.0-SNAPSHOT.jar -h\nUsage: &lt;main class&gt; [options]\n  Options:\n    --help, -h\n       Shows usage help\n       Default: false\n    --lang, -ol\n       Location of any other language that should be loaded\n       Default: []\n  * --lut, -l\n       Location of the language under test\n  * --spt, -s\n       Location of the SPT language\n    --start-symbol, -start\n       Start Symbol for these tests\n  * --tests, -t\n     Location of test files\n$ java -jar spt/org.metaborg.spt.cmd/target/org.metaborg.spt.cmd-2.0.0-SNAPSHOT.jar\n   --lut /path/to/MiniJava/project\n   --tests /path/to/test/project\n   --spt spt/org.metaborg.meta.lang.spt\n   --lang stratego/org.metaborg.meta.lang.stratego\n</code></pre> </li> </ol>"},{"location":"references/testing/running-tests/#run-using-the-spt-framework","title":"Run using the SPT Framework","text":"<p>The SPT framework at https://github.com/metaborg/spt offers a Java API to run SPT test suites. The framework is split between the generic part (<code>org.metaborg.mbt.core</code> - MetaBorg Testing (MBT)) and the Spoofax specific part (<code>org.metaborg.spt.core</code> SPoofax Testing (SPT)).</p> <p>The first step in running tests is to extract them from an SPT test suite. <code>org.metaborg.mbt.core</code> provides a Java object model to represent SPT test cases. To extract test cases from a test suite to the Java model, you can use the <code>ITestCaseExtractor</code>. You can either implement this for your own version of the SPT language, or use our SPT language (<code>org.metaborg.meta.lang.spt</code>) and our extractor (<code>ISpoofaxTestCaseExtractor</code>).</p> <p>Now that you have the tests in Java objects, you can execute them with the <code>ITestCaseRunner</code>. If the language you are testing is not integrated with Metaborg Core, you will either have to do so and subclass the <code>TestCaseRunner</code>, or make your own implementation for the <code>ITestCaseRunner</code>. If your language under test is integrated with Metaborg Core (this is the case for all languages created with Spoofax), you can use our <code>ISpoofaxTestCaseRunner</code>.</p> <p>For an example on how to use dependency injection to obtain the correct classes and extract and run SPT tests using the Java API, see the <code>TestRunner</code> class at (https://github.com/metaborg/spt/tree/master/org.metaborg.spt.core).</p>"},{"location":"references/testing/running-tests/#run-using-maven","title":"Run using Maven","text":"<p>For regression testing and continuous integration, it can be useful to be able to execute tests from a maven build. To do so, create a pom.xml file in your test project with the following content:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project\nxsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\nxmlns=\"http://maven.apache.org/POM/4.0.0\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n&gt;\n&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n&lt;groupId&gt;your.group.id&lt;/groupId&gt;\n&lt;artifactId&gt;your.test.project.name&lt;/artifactId&gt;\n&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n&lt;packaging&gt;spoofax-test&lt;/packaging&gt;\n\n&lt;parent&gt;\n&lt;groupId&gt;org.metaborg&lt;/groupId&gt;\n&lt;artifactId&gt;parent.language&lt;/artifactId&gt;\n&lt;version&gt;2.1.0-SNAPSHOT&lt;/version&gt;\n&lt;/parent&gt;\n\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;your.group.id&lt;/groupId&gt;\n&lt;artifactId&gt;your.language.under.test.id&lt;/artifactId&gt;\n&lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;\n&lt;type&gt;spoofax-language&lt;/type&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;org.metaborg&lt;/groupId&gt;\n&lt;artifactId&gt;org.metaborg.meta.lang.spt&lt;/artifactId&gt;\n&lt;version&gt;${metaborg-version}&lt;/version&gt;\n&lt;type&gt;spoofax-language&lt;/type&gt;\n&lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n\n&lt;build&gt;\n&lt;plugins&gt;\n&lt;plugin&gt;\n&lt;groupId&gt;org.metaborg&lt;/groupId&gt;\n&lt;artifactId&gt;spoofax-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;${metaborg-version}&lt;/version&gt;\n&lt;configuration&gt;\n&lt;languageUnderTest&gt;your.group.id:your.language.under.test.id:1.0.0-SNAPSHOT&lt;/languageUnderTest&gt;\n&lt;/configuration&gt;\n&lt;/plugin&gt;\n&lt;/plugins&gt;\n&lt;/build&gt;\n&lt;/project&gt;\n</code></pre> <p>You should now be able to execute the tests with <code>mvn verify</code>.</p>"},{"location":"references/testing/test-expectations/","title":"Test Expectations","text":"<p>Test expectations allow you to specify which component of the language under test should be tested, and what the expected output of the test will be.</p> <p>We have already seen the <code>parse succeeds</code> expectation in action, and briefly mentioned that a test case without any test expectations is the same as a test case with a <code>parse succeeds</code> expectation. We will now list the syntax and semantics of all the currently supported test expectations:</p>"},{"location":"references/testing/test-expectations/#parse-expectations","title":"Parse Expectations","text":"<p>Parse expectations can be used to test the syntax of your language. They indicate that the input fragment of the test case should be parsed and allow you to specify what you expect the result to be. As parsing is the preliminary step to all other language components (e.g., analysis and transformations) they are treated differently from other expectations. If no parse expectation is present on a test case, even if another expectation (e.g. an analysis expectation) is present, a <code>parse succeeds</code> expectation will be added to the test case.</p> <code>Expectation.ParseSucceeds = &lt;parse succeeds&gt;</code> Parse the fragment and expect the parsing to succeed, with no parse errors and no ambiguities. <code>Expectation.ParseFails = &lt;parse fails&gt;</code> Parse the fragment and expect the parsing to fail, with at least one parse error. <code>Expectation.ParseAmbiguous = &lt;parse ambiguous&gt;</code> Parse the fragment and expect the parsing to succeed with one or more ambiguities. <code>Expectation.ParseToAterm = &lt;parse to &lt;ATerm&gt;&gt;</code> <p>Parse the fragment, expect parsing to succeed, and compare it to the given ATerm AST. When using test fixtures, the ATerm should only be the AST of the fragment of the test, not of the entire test fixture. Please note that if you want to specify a List in the <code>ATerm</code>, the square brackets of the list may interfere with the markers of a fragment. Therefore, to specify a list as the expected output, prepend it with the keyword <code>!ATerm</code>. For example:</p> <pre><code>parse to !ATerm [\"5\"]\n</code></pre> <code>Expectation.ParseToFragment = &lt;parse to &lt;Language?&gt; &lt;OpenMarker&gt; &lt;Fragment&gt; &lt;CloseMarker&gt;]]&gt;</code> <p>Parse the fragment, expect parsing to succeed, and compare it to the result of parsing the given <code>Fragment</code> with the given <code>Language</code>. When the <code>Language</code> is omitted the language under test will be used to parse the given fragment. When using test fixtures, only the test's input fragment will be combined with the test fixture. The fragment in this expectation (i.e., the output fragment) will not be combined with it, even if the language under test is used to parse it. To counteract this, the entire AST (including the nodes from the fixture) will be compared to the expectation's fragment's AST.</p> <p>This expectation can be useful to test disambiguations, or to test your language against a reference implementation. An example test case for disambiguation in MiniJava would be: <pre><code>module disambiguation\nlanguage MiniJava\nstart symbol Exp\n\ntest plus is left associative [[\n  1 + 2 + 3\n]] parse to [[\n  (1 + 2) + 3\n]]\n</code></pre></p>"},{"location":"references/testing/test-expectations/#analysis-expectations","title":"Analysis Expectations","text":"<p>Analysis expectations specify that the analyzer should be tested. We will first discuss the most generic analysis expectations: the message expectations. These expectations can be used to test the entire static semantic analysis process. Then we will look at test expectations that are more specific: the name analysis expectations.</p>"},{"location":"references/testing/test-expectations/#analysis-message-expectations","title":"Analysis Message Expectations","text":"<p>Analysis message expectations will cause the input fragment to be parsed and analyzed (e.g., name and type analysis and static error checking). Finally, the resulting messages (i.e. errors, warnings, or notes) will be compared to the expectation. Note that messages of the expected type are not allowed to appear in the test fixture, if one is present. This is to prevent test from succeeding, when a message that would make it fail appears in an unexpected location. Only the messages within the test's fragment will be compared to the expectation.</p> <code>Expectation.MessageExpectation = &lt;&lt;Operator?&gt; &lt;INT&gt; &lt;Severity&gt;&gt;</code> These expectations will check if the number of messages of the given severity generated by the analysis matches the given number. Any other messages (of different severity or located in the test fixture) will be ignored by this expectation. <p>The optional operator can be used to losen the strictness of the check. For example the expectation <code>&gt; 2 errors</code> allows any number of errors bigger than 2. If no operator is specified, it will default to <code>=</code>. The allowed operators are <code>=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>.</p> <p>The allowed message severities are: <code>error</code> or <code>errors</code> for error messages, <code>warning</code> or <code>warnings</code> for warning messages, and <code>note</code> or <code>notes</code> for note messages. Please note that error messages in this expectation refer only to analysis errors (not parse errors). Also when you are testing for warnings, for example, any analysis messages of different severity (including errors) will not cause the test to fail. For example, the following test will succeed, regardless of the blatant type error, because we only test for warnings:</p> <pre><code>module test-for-warnings\nlanguage MiniJava\n\nfixture [[\n  class Main {\n    public static void main(String[] args) {\n      System.out.println([[...]]);\n    }\n  }\n]]\n\ntest no warnings [[1 + new A()]] 0 warnings\n</code></pre> <p>These analysis message expectations may be followed by the <code>at</code> keyword and a list of one or more comma separated references to selections of the test's fragment: <code>#&lt;INT&gt;, #&lt;INT&gt;, #&lt;INT&gt;, ...</code>. As this is the first time we encounter references to selections, let's look at an example:</p> <pre><code>module error-locations\nlanguage MiniJava\n\ntest duplicate classes [[\n  class Main {\n    public static void main(String[] args) {\n      System.out.println(42);\n    }\n  }\n  class [[A]]{}\n  class [[A]]{}\n]] 2 errors at #1, #2\n</code></pre> <p>This test will cause SPT to check if the specified messages appeared at the location of the given selection references. The selections are the classnames <code>A</code> that are selected by wrapping them in an open and close marker. Selections are referenced by the order in which they appear, starting at 1, from left to right and top to bottom.</p> <p>It is allowed to give less selection references than the number of expected messages. In this case SPT assumes you don't care about the location of the other messages. If the same selection is referenced more than once, multiple messages will be expected at that location. mFor example <code>3 errors at #1,#1</code> expects 3 errors, 2 of which should be at the location of selection number 1. The other error may be anywhere within the test fragment.</p> <code>Expectation.MessageContent = &lt;&lt;Severity&gt; like &lt;STRING&gt;&gt;</code> <p>This expectation specifies that there should be at least 1 message of the given severity that contains the given String. For example <code>error like \"duplicate class name\"</code> expects there to be at least 1 error in the fragment whose message contains <code>duplicate class name</code>.</p> <p>This expectation can also be followed by the <code>at</code> keyword, and a single selection reference, to indicate where you expect the message with the given content.</p> <code>Expectation.AnalysisSucceeds = &lt;analysis succeeds&gt;</code> This expectation is syntactic sugar for <code>0 errors</code>. <code>Expectation.AnalysisFails = &lt;analysis fails&gt;</code> This expectation is syntactic sugar for <code>&gt; 0 errors</code>."},{"location":"references/testing/test-expectations/#name-analysis-expectations","title":"Name Analysis Expectations","text":"<p>Name analysis expectations will check if use sites can be resolved and, if required, if they resolve to the correct definition. The fragment will be parsed and analyzed, but any number and severity of analysis messages are allowed.</p> <code>Expectation.Resolve = &lt;resolve #&lt;INT&gt;&gt;</code> Try to resolve the AST node at the given selection. Expect it to successfully resolve to any definition site. <code>Expectation.ResolveTo = &lt;resolve #&lt;INT&gt; to #&lt;INT&gt;&gt;</code> Try to resolve the AST node at the first given selection. Expect it to successfully resolve to the location marked by the second given selection. <p>Note that selections can only occur in the test's fragment, not in the test fixture. So name analysis can only be tested within a test's fragment.</p>"},{"location":"references/testing/test-expectations/#transformation-expectations","title":"Transformation Expectations","text":"<p>A transformation transforms an AST to another AST. The idea within Spoofax is that a transformation has a name, and can be nested within a structure of menu's. Furthermore, it can have additional information about whether it transforms the raw AST (i.e. the parse result) or the analyzed AST (i.e. the result of desugaring and analysis). In languages created with Spoofax, transformations are Stratego strategies that are registered in the <code>Menus.esv</code> file.</p> <p>Transformation expectations will first look up a given transformation using the name under which it was registered. Note that, for Spoofax languages, this is not necessarily the name of the Stratego strategy, but the name under which it is registered in the <code>Menus.esv</code> file. If this name is not unique, the menu structure can be used to look up the proper transformation.</p> <p>Once the transformation is found, SPT will determine if it requires the raw AST, or the analyzed AST. If the raw AST is required, it will only parse the fragment. If the analyzed AST is required, it will also analyze the parse result. However, analysis is allowed to produce any number and severity of messages. Then, SPT will run the transformation on the entire AST, including the nodes from the test fixture, if there was one.</p> <code>Expectation.Transform = &lt;transform &lt;STRING&gt;&gt;</code> The <code>STRING</code> should be delimited by double quotes and contain the name of the transformation. If the name is not unique, the menu structure can be included as well, seperated by <code>-&gt;</code>. For example: <code>transform \"Menu name -&gt; transformation name\" to Some(Result())</code>. As long as the transformation returns a result, this expectation passes. <code>Expectation.TransformToAterm = &lt;transform &lt;STRING&gt; to &lt;ATerm&gt;&gt;</code> Same as <code>Transform</code>, but the result of the transformation is compared to the given AST. <code>Expectation.TransformToFragment = &lt;transform &lt;STRING&gt; to &lt;Language?&gt; &lt;OpenMarker&gt; &lt;Fragment&gt; &lt;CloseMarker&gt;&gt;</code> Does the same as <code>TransformToAterm</code>, but compares the result of the transformation to the AST of the given fragment. If the applied transformation required the raw AST, the given fragment will only be parsed with the given language. If no language is given, the language under test will be used. If the applied transformation required an analyzed AST, the given fragment will be parsed and analyzed."},{"location":"references/testing/test-expectations/#run-stratego-expectations","title":"Run Stratego Expectations","text":"<p>These test expectations are really only applicable to languages that use Stratego strategies in their implementation. They will parse and analyze the fragment and run a given Stratego strategy (with no arguments) and compare its output to the expectation.</p> <code>Expectation.Run = &lt;run &lt;STRATEGY&gt;&gt;</code> This expectation will lookup the given strategy name and run it on the AST node in the test's fragment. If the fragment contains multiple nodes (e.g., it's a list of Statements but some Statements were in the test fixture) the strategy will be run on each of these nodes. Either until it completes successfully, or until it failed on all these nodes. Note that it wil not be executed on the nodes in the test fixture, if there was one. <code>Expectation.RunWithArgs = &lt;run &lt;STRATEGY&gt;(|&lt;TermArgs&gt;)&gt;</code> <p>This expectation will run a strategy that expects term arguments. String literals, integer literals and selection references are permitted as term arguments.:</p> <pre><code>test rename variable without type [[\n  let\n    var msg := \"Hello World\"\n  in\n    print([[msg]])\n  end\n]] run rename(|#1, \"message\", 0) to [[\n  let\n    var message := \"Hello World\"\n  in\n    print(message)\n  end\n]]\n</code></pre> <code>Expectation.RunFails = &lt;run &lt;STRATEGY&gt; fails&gt;</code> This expectation checks if the given strategy fails. <code>Expectation.RunOn = &lt;run &lt;STRATEGY&gt; on #&lt;INT&gt;&gt;</code> This expectation does the same as <code>Run</code>, except it runs the strategy on the nodes at the given selection instead of the nodes of the test's fragment. <code>Expectation.RunToAterm = &lt;run &lt;STRATEGY&gt; to &lt;ATerm&gt;&gt;</code> <code>shorty</code> <code>Expectation.RunToAtermOn = &lt;run &lt;STRATEGY&gt; on #&lt;INT&gt; to &lt;ATerm&gt;&gt;</code> These expectations are similar to the first two, but they require the result of running the strategy to match the given AST. <code>Expectation.RunToFragment = &lt;run &lt;STRATEGY&gt; to &lt;Language?&gt; &lt;OpenMarker&gt; &lt;Fragment&gt; &lt;CloseMarker&gt;&gt;</code> <code>Expectation.RunToFragmentOn = &lt;run &lt;STRATEGY&gt; on #&lt;INT&gt; to &lt;Language?&gt; &lt;OpenMarker&gt; &lt;Fragment&gt; &lt;CloseMarker&gt;&gt;</code> These expectations are similar to the first two, but they require the result of running the strategy to match the result of analyzing the given fragment with the given language. If no language is given, the language under test is used."},{"location":"references/testing/test-expectations/#origin-location-expectations","title":"Origin Location Expectations","text":"<code>Expectation.HasOrigins = &lt;has origin locations&gt;</code> This expectation parses and analyzes the fragment. It then checks if all AST nodes in the test's fragment (except for Lists in Spoofax) have a source region (an origin) associated with them. It does not check the AST nodes in the test fixture. <p>When using Spoofax, there are some strategies that will break the origin information when used. This can lead to desugarings that create AST nodes without origin information, which can cause problems when trying to create messages at their location and with other services. This expectation can be used to check that your analysis is origin preserving.</p>"},{"location":"references/testing/test-suites/","title":"Test suites","text":"<p>Test cases in SPT are grouped in test suites (or modules). Each SPT file contains exactly 1 test suite.</p> <p>Test suites allow you to group together the test cases that test similar aspects of your language, making it easier to organize your tests. They also allow you to reduce the size of your test cases by using configuration options like headers and test fixtures that apply to all test cases in the test suite. We will describe those later on.</p> <p>The syntax for a test suite is as follows:</p> <pre><code>TestSuite = &lt;\nmodule &lt;MODULENAME&gt;\n&lt;Header?&gt;\n&lt;TestFixture?&gt;\n&lt;TestCase*&gt;\n&gt;\n</code></pre> <p>The modulename must start with a letter and can be followed by any number of letters, digits, underscores, and dashes.</p> <p>If you are following along, you can create your first SPT test suite. Just create a file with the extension <code>.spt</code> and paste the following:</p> <pre><code>module my-first-test-suite\n\nlanguage MyLanguageName\n</code></pre> <p>Be sure to replace <code>MyLanguageName</code> with the name of the language you want to test. Also, feel free to use a more descriptive module name if you like.</p>"},{"location":"references/testing/test-suites/#headers","title":"Headers","text":"<p>Headers are a configuration option for all test cases in a test suite. The most important header is the language header. If you are following along with the example, you have already used it to specify which language you wanted to test. All test cases in the test suite will be ran against the language you specify with the language header. This language will be called the language under test (LUT):</p> <pre><code>Header.Language = &lt;language &lt;LANGNAME&gt;&gt;\n</code></pre> <p>For now, there is only one other header: the start symbol header. This optional header allows you to specify a nonterminal from your grammar from which the test cases will be parsed. Don't worry if that doesn't make any sense yet. We will look at an example later:</p> <pre><code>Header.StartSymbol = &lt;start symbol &lt;ID&gt;&gt;\n</code></pre> <p>Where the <code>ID</code> must start with a letter, and can be followed by any number of letters or digits.</p> <p>As our example test suite already contains the language header, we will move on to writing our first test.</p>"},{"location":"references/testing/test-suites/#test-cases","title":"Test Cases","text":"<p>Test cases are the most important parts of SPT. Each test case is a behaviorial test, or black-box test, for your language. A behavioral test consists of a component that should be tested, an initial state for that component, input for that component, and the expected output after running the component on the input.</p> <p>First, let's look at the input of a test case. As we are testing languages, the input of a test case is always a program written in the language under test. Such a program written in the language under test is called a fragment, and it is embedded in the SPT test suite. In the future, we want to offer all editor services of your language under test (e.g., syntax highlighting) while you are writing such a fragment. However, for now this is not yet supported.</p> <p>The component that should be tested and the expected output are captured in test expectations. We will discuss those in a later section.</p> <p>Finally, the initial state of the test case can be specified in a test fixture, analogous to the JUnit <code>setUp</code> and <code>tearDown</code> methods. These fixtures will also be discussed in a later section.</p> <p>The syntax of test case is as follows:</p> <pre><code>TestCase = &lt;\n  test &lt;Description&gt; &lt;OpenMarker&gt;\n    &lt;Fragment&gt;\n  &lt;CloseMarker&gt;\n  &lt;Expectation*&gt;\n&gt;\n</code></pre> <p>Where <code>Description</code> is the name of the test and can contain any character that is not a newline or <code>[</code>. The <code>OpenMarker</code> marks the start of the fragment and can be one of <code>[[</code>, <code>[[[</code>, or <code>[[[[</code>. The <code>CloseMarker</code> marks the end of the fragment and should be the counter part of the <code>OpenMarker</code>, so either <code>]]</code>, <code>]]]</code>, or <code>]]]]</code>.</p> <p>The <code>Fragment</code> is a piece of text written in the language under test, about which we want to reason in our test case. It may contain any sequence of characters that are not open- or closing markers. For example, if the <code>[[[</code> and <code>]]]</code> markers are used, the fragment may contain at most 2 consecutive open or closing square brackets. If the <code>[[[[</code> and <code>]]]]</code> markers are used, the fragment may contain at most 3 consecutive open or closing square brackets.</p> <p>Parts of the fragment may be selected, by surrounding the text with the same open- and closing markers that were used to delimit the fragment. These selections can later be referred to in the test expectations to allow more precise reasoning about the fragment.</p> <p>We will discuss selections and expectations later, but note that not supplying any test expectation is equivalent to supplying only a <code>parse succeeds</code> expectation, indicating that the fragment is expected to be valid syntax and parsing it with the language under test is expected to succeed without errors.</p> <p>If you are following along with your own test suite, let's create our first test case. I will be using a simplified version of Java (called MiniJava) as my language under test, but it shouldn't be too hard to write a simple test for your own language. We will be writing a MiniJava program with valid syntax and test that it does indeed parse. The input for our test case will simply be a main class in MiniJava. The component that we will be testing is the parser, and the expected output is a successful parse result:</p> <pre><code>module simple-parse-tests\n\nlanguage MiniJava\n\ntest check if this simple program parses sucessfully [[\n  class Main {\n    public static void main(String[] args) {\n      System.out.println(42);\n    }\n  }\n]] parse succeeds\n</code></pre> <p>Change the language header to refer to the name of your language and change the fragment to be a valid specification in your language, and you should have your first working test case. Try messing up the syntax of your fragment and an error message should be displayed to indicate that the test failed, as the fragment failed to be parsed correctly. These error messages can be displayed directly inside the fragment you wrote, to make it easier for you to spot why the test failed. This is the power of SPT fragments!</p> <p>Now that we know the basic structure of a test, we can already see how the start symbol header can be used to decrease the size of our test:</p> <pre><code>module statement-parse-tests\n\nlanguage MiniJava\nstart symbol Statement\n\ntest check if a printline is a valid statement [[\n  System.out.println(42);\n]]\n</code></pre> <p>Note how the fragment is now no longer a proper MiniJava program. The test still passes, as the fragment is now parsed starting from the <code>Statement</code> nonterminal. Note that this only works if <code>Statement</code> is exported as a start symbol in the MiniJava language. These start symbols are a way of indicating what the initial state of the component under test should be. In this case, it influences the state of the parser and only allows it to successfully parse statements.</p> <p>Before we move on to discuss the set of all supported test expectations, we will first look at another way to influence the initial state and reduce the size of our test cases: test fixtures.</p>"},{"location":"references/testing/test-suites/#test-fixtures","title":"Test Fixtures","text":"<p>A test fixture offers a template for all test cases in the test suite. Using test fixtures, you can factor out common boilerplate from your tests and write it only once.</p> <p>The syntax for a test fixture is as follows:</p> <pre><code>TestFixture = &lt;\n  fixture &lt;OpenMarker&gt;\n    &lt;StringPart&gt;\n    &lt;OpenMarker&gt; ... &lt;CloseMarker&gt;\n    &lt;StringPart&gt;\n  &lt;CloseMarker&gt;\n&gt;\n</code></pre> <p>Where the <code>OpenMarker</code> is one of <code>[[</code>, <code>[[[</code>, or <code>[[[[</code>, and the <code>CloseMarker</code> is one of <code>]]</code>, <code>]]]</code>, or <code>]]]]</code>. The <code>StringPart</code> can contain any sequence of characters that is not an open- or closing marker, just like a fragment from a test. However, unlike a fragment of a test, it can not contain selections.</p> <p>For each test case, the fragment of the test will be inserted into the fixture at the marked location (<code>&lt;OpenMarker&gt; ... &lt;CloseMarker&gt;</code>), before the test expectations will be evaluated.</p> <p>We can now use a test fixture to test the syntax of statements in MiniJava without the use of the start symbol header:</p> <pre><code>module statements-parse-test\n\nlanguage MiniJava\n\nfixture [[\n  class Main {\n    public static void main(String[] args) {\n      [[...]]\n    }\n  }\n]]\n\ntest check if printing an integer is allowed [[\n  System.out.println(42);\n]]\n\ntest check if printing a String is allowed [[\n  System.out.println(\"42\");\n]]\n</code></pre> <p>Note that test fixtures offer a fully language implementation agnostic way of factoring out boiler plate code, whereas the start symbol header requires knowledge of the non terminals of the language implementation.</p>"},{"location":"release/develop/","title":"Development Releases","text":"<p>Use the development releases of Spoofax only if you want to be on the cutting-edge of Spoofax development.</p> <p>Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the From Source installation:</p> Eclipse Bundle with JRE (recommended) <p>Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform:</p> <p>+ macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit)</p> <p>Installation instructions.</p> Eclipse Bundle <p>Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform:</p> <p>macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit)</p> <p>Installation instructions.</p> Eclipse Plugin <p>Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site:</p> <pre><code>https://buildfarm.metaborg.org/job/metaborg/job/spoofax-releng/job/master/lastSuccessfulBuild/artifact/dist/spoofax/eclipse/site/\n</code></pre> <p>Installation instructions.</p> From Source <p>Use Git to clone the Spoofax Github repository:</p> HTTPS <pre><code>git clone https://github.com/metaborg/spoofax-releng.git\n</code></pre> HTTPS <pre><code>git clone git@github.com:metaborg/spoofax-releng.git\n</code></pre> GitHub CLI <pre><code>gh repo clone metaborg/spoofax-releng\n</code></pre> <p>Installation instructions.</p>"},{"location":"release/stable/","title":"Stable Releases","text":"<p>This page lists the latest stable release of Spoofax: version 2.5.18 released on 14-11-2022.</p> <p>Choose the Eclipse Bundle installation (recommended), the Eclipse Plugin installation, or the Homebrew installation ( macOS only):</p> Eclipse Bundle with JRE (recommended) <p>Download an Eclipse instance with an embedded Java Runtime Environment (JRE) and the latest Spoofax plugin pre-installed for your platform:</p> <p>+ macOS Intel (64-bit) + Linux x64 (64-bit) + Windows x64 (64-bit) + Windows x86 (32-bit)</p> <p>Installation instructions.</p> Eclipse Bundle <p>Download an Eclipse instance (without JRE) and the latest Spoofax plugin pre-installed for your platform:</p> <p>macOS Intel (64-bit) Linux x64 (64-bit) Windows x64 (64-bit) Windows x86 (32-bit)</p> <p>Installation instructions.</p> Eclipse Plugin <p>Perform a manual installation of the Spoofax plugin in Eclipse 3.5 or newer through the update site:</p> <pre><code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.18/org.metaborg.spoofax.eclipse.updatesite-2.5.18-assembly.zip-unzip/\n</code></pre> <p>Installation instructions.</p> Homebrew <p>On macOS Spoofax can be installed easily using Homebrew.</p> <p>Install the latest release of Spoofax Eclipse as follows:</p> <pre><code>brew tap metaborg/metaborg\nbrew install --cask spoofax\n</code></pre> <p>The optional command-line tools are installed with:</p> <pre><code>brew install strategoxt\n</code></pre> <p>Upgrading the Spoofax cask is not recommended</p> <p>Upgrading the Spoofax cask using <code>brew cask upgrade --greedy</code> will lose all manually installed plugins. It is recommended to use Eclipse update sites to keep Spoofax up-to-date.</p>"},{"location":"release/migrate/2.0.0/","title":"Spoofax 2.0.0 Migration Guide","text":"<p>This migration guide describes the differences between Spoofax 1.5 and 2.0 and describes the steps to convert a Spoofax 1.5 project to Spoofax 2.0 project.</p> <p>To gather the required knowledge for migrating a language project, go through the documentation in the following order:</p> <ol> <li>Spoofax 2.0 Release Notes, for a general overview of the changes in Spoofax 2.0.</li> <li>This document, for the concrete differences and steps to convert your Spoofax project.</li> </ol>"},{"location":"release/migrate/2.0.0/#differences","title":"Differences","text":""},{"location":"release/migrate/2.0.0/#concepts","title":"Concepts","text":"<p>Spoofax 2.0 introduces several new concepts and terminology.</p> <p>A language specification is the specification of a language using meta-languages.</p> <p>A language specification project specifies a language component. When the specification is compiled, the result is a component which can be loaded into Spoofax. A language component has specifications and implementations for parts of a language, such as its parser, pretty-printer, analysis, transformations, editor services, etc.</p> <p>A component contributes these parts to a language implementation. Multiple components can contribute to the same language implementation, and components can contribute to multiple language implementations. In the most simple case, a single component contributes all parts of the language to a single implementation.</p> <p>Language components can depend on other language components to depend on parts of a language. Currently, there are two kinds of dependencies: compile and source dependencies.</p> <p>A compile dependency on a language component is used to compile source files of that language component. For example, a compile dependency on NaBL will ensure that all .nab files are compiled into .str files.</p> <p>A source dependency is used to depend on source files of a language component. Source dependencies are used to depend on libraries, for example to depend on a Stratego library for name and type analysis. They are also used to compose multiple language components into a single language component, for example to do language extension.</p> <p>A language is the more abstract notion of a language, which has multiple language implementations. For example, the Java language has the JDK7 and JDK8 implementations, which each have front-end and back-end components.</p> <p>An end-user project is a project with programs of an end-user language, in contrast to a language specification project which has programs of meta-languages. For example, a Java project is a Java end-user project, whereas the JDK project is a language specification project.</p>"},{"location":"release/migrate/2.0.0/#project-structure","title":"Project structure","text":"<p>The project structure of language specification projects has significantly changed. The biggest change is that these projects are no longer Eclipse (plugin) projects, so that they can be used outside of the Eclipse platform as well. Ant build files have also been removed since we do not use Ant to build projects any more. Many ESV files have been deprecated, and all generated ESV files in the editor directory have been removed.</p> <p>The following files and directories are no longer part of the project structure:</p> <ul> <li>Ant build: .externalToolBuilders, build.generated.xml, build.main.xml</li> <li>Eclipse plugin: plugin.xml, META-INF</li> <li>Eclipse project: .settings, .classpath, .project, build.properties</li> <li>Refactoring: lib/refactor-common.generated.str</li> <li>Deprecated ESV files: editor/langname-Completions.esv, editor/langname-Folding.esv, editor/langname-Outliner.str, editor/langname-Refactorings.esv</li> <li>Generated ESV files: editor/langname-*.generated.esv, editor/langname-Outliner.generated.str</li> <li>The RTG and signatures files are no longer generated for SDF3 projects, since SDF3 generates its own signatures.</li> <li>The generated box pp files are no longer generated, and box pp files are no longer converted into pp.af files.</li> </ul> <p>The following files and directories have been moved:</p> <ul> <li>ESV<ul> <li>Main ESV file must be at editor/Main.esv. If it does not exist, no packed ESV file will be generated.</li> <li>Packed ESV file: target/metaborg/editor.esv.af</li> </ul> </li> <li>SDF<ul> <li>Definition: src-gen/syntax/[LanguageName].def</li> <li>Permissive definition: src-gen/syntax/[LanguageName]-permissive.def</li> <li>Parenthesizer: src-gen/pp/[LanguageName]-parenthesize.str</li> <li>Parse table: target/metaborg/sdf.tbl</li> </ul> </li> <li>Stratego<ul> <li>'editor-common.generated' file: src-gen/stratego/metaborg.str</li> <li>Ctree: target/metaborg/stratego.ctree</li> <li>Generated Java files: src-gen/stratego-java</li> <li>JAR: target/metaborg/stratego.jar</li> <li>Java strategies: src/main/strategies</li> <li>Java strategies JAR: target/metaborg/stratego-javastrat.jar</li> <li>Build cache: target/stratego-cache</li> </ul> </li> <li>DynSem<ul> <li>Manual Java: src/main/ds</li> <li>Generated Java: src-gen/ds-java</li> </ul> </li> </ul> <p>The following generated files and directories still exist, but should not be published to source control any more:</p> <ul> <li>lib/editor-common.generated.str or stratego/metaborg.str</li> <li>src-gen</li> </ul> <p>When importing a language specification project into Eclipse or IntelliJ, several platform-specific files will be generated. These files should not be published to source control to keep projects as platform-agnostic as possible.</p>"},{"location":"release/migrate/2.0.0/#eclipse","title":"Eclipse","text":""},{"location":"release/migrate/2.0.0/#importing","title":"Importing","text":"<p>To import a language specification project into Eclipse, use Import... \u2023 Maven \u2023 Existing Maven Projects. We use Maven to set up the correct Java dependencies, which is why there is no special 'Existing Spoofax Projects' importer.</p>"},{"location":"release/migrate/2.0.0/#builds","title":"Builds","text":"<p>Eclipse has the concept of incremental project builders, which incrementally parse, analyze, and compile files inside a project. An example of such a project builder is the Eclipse JDT builder which incrementally builds Java files. Spoofax 1.5  did not use this functionality, but the new Eclipse plugin in Spoofax 2.0 does.</p> <p>The project builder for Spoofax parses, analyses, executes transformations, and shows all error markers, for all language files (Stratego files, SDF3 files, files of your language, etc.) in the project. If the project is opened for the first time, a full build will occur, building all language files. When changes occur in the project, an incremental build occurs, building only changed files.</p> <p>The commands under the Project menu in Eclipse now also affect Spoofax projects. Executing Project \u2023 Build... (or pressing Ctrl/Cmd+Alt+B) will build the project.</p> <p>Executing Project \u2023 Clean... will delete the .cache directory, reset the index and task engine, remove all error markers, and reanalyze and rebuild all files in the project. This makes the Reset and Reanalyze builder unnecessary, since this is now properly integrated with Eclipse.</p> <p>Automatic building can also be turned off by disabling Project \u2023 Build Automatically. Builds will then only occur if Project \u2023 Build Project is executed or if Ctrl/Cmd+Alt+B is pressed.</p> <p>Furthermore, the language specification build is no longer written in Ant, but in Java using the Pluto incremental build system.</p>"},{"location":"release/migrate/2.0.0/#natures","title":"Natures","text":"<p>The Spoofax language specification project builder is not enabled by default, to enable it a 'Spoofax meta nature' must be added to the project. A nature in Eclipse is a project tag which enables functionality for that project. To add the Spoofax nature to a project, right click the project, and choose Spoofax (meta) \u2023 Add Spoofax meta nature. When importing a language specification, this nature is automatically added.</p> <p>For end-user projects, right click the project, and choose Spoofax \u2023 Add Spoofax nature to add a nature for end-user projects.</p> <p>Editors will parse and analyze files regardless of there being a Spoofax nature, but the on-save handler will not be called.</p>"},{"location":"release/migrate/2.0.0/#builders","title":"Builders","text":"<p>Builders for the open editor are now located in the Spoofax main menu instead of buttons on the tool bar. Builders wait for the analyzed AST if needed, so the issue where builders are sometimes not executed on the analyzed AST should be solved now.</p> <p>Builders can also be executed on a set of files by selecting the files in the project or package explorer, right clicking the files, selecting the language name from the menu, and then selecting a builder.</p>"},{"location":"release/migrate/2.0.0/#cancellation","title":"Cancellation","text":"<p>Editor updates can now be cancelled by clicking the red stop button in the progress view. If the progress view is not visible, you can open it by choosing Window \u2023 Show View \u2023 Progress. If the editor update is not responsive (it is looping for example), the thread running the editor update will be killed after a while.</p> <p>Killing a thread during analysis may leave the index and task engine in an inconsistent state. If this happens, clean the project using Project \u2023 Clean... to force a full build, which makes the state consistent again. Killing a thread is not very well supported in Java and may break Eclipse or even the JVM, which then requires a restart.</p> <p>Project builds and transformations can also be cancelled in the progress view.</p>"},{"location":"release/migrate/2.0.0/#console-logging","title":"Console logging","text":"<p>Console logging in the new plugin is more prominent so that we can diagnose problems more easily. If the console is not visible, you can open it by choosing Window \u2023 Show View \u2023 Console. The console does not automatically pop-up when there is a message any more, so it can also be hidden by just closing it.</p> <p>All warning and error messages are also sent to Eclipse's error log. The error log can sometimes contain more information about exceptions and stack traces in errors. If the error log is not visible, you can open it by choosing Window \u2023 Show View \u2023 Error Log.</p>"},{"location":"release/migrate/2.0.0/#manually-loadingunloading-a-language","title":"Manually loading/unloading a language","text":"<p>A language can be manually loaded or reloaded by right clicking a project and choosing Spoofax (meta) \u2023 Load language, and unloaded with Spoofax (meta) \u2023 Unload language.</p>"},{"location":"release/migrate/2.0.0/#external-dependencies","title":"External dependencies","text":"<p>The new plugin does not depend on a modified version of IMP, making it possible to install the Rascal plugin alongside the Spoofax plugin. All other external dependencies are limited to the Spoofax plugin, which should prevent conflicts with other Eclipse plugins.</p>"},{"location":"release/migrate/2.0.0/#converting-a-project","title":"Converting a project","text":"<p>If your project is simple (e.g. it only has syntax and a few transformations), the easiest way to convert your project is to create a new Spoofax language specification project, and to copy your files into that project.</p> <p>Otherwise, Spoofax 2.0 supports converting an old Spoofax project into a new Spoofax project, but some conversions need to be done manually.</p> <p>Warning</p> <p>Converting a Spoofax project is a destructive operation, some files will be deleted, replaced, or changed. Make a backup of your projects before doing any conversions!</p>"},{"location":"release/migrate/2.0.0/#automatic-conversion","title":"Automatic conversion","text":"<p>First, import your existing Spoofax project into Eclipse using File \u2023 Import... \u2023 Existing Projects into Workspace. Right click the project, and choose Spoofax (meta) \u2023 Upgrade language project. A wizard screen will pop up where you have to fill in some details about your language.</p> <p>If a packed.esv file was found, Spoofax will try to fill in some fields for you. If not, all fields need to be filled in manually. The id and name of your language can be found in the main ESV file. For group id, use a Maven identifier for your organization (e.g. org.metaborg), and as version: 1.0.0-SNAPSHOT.</p> <p>Warning</p> <p>Make sure that the id and name fields match exactly with the fields in your ESV file, otherwise the conversion will go wrong.</p> <p>Press finish to convert the language project.</p>"},{"location":"release/migrate/2.0.0/#manual-conversion","title":"Manual conversion","text":"<p>Unfortunately, not all required conversions can be done automatically. Do the following conversions manually.</p>"},{"location":"release/migrate/2.0.0/#project-configuration","title":"Project configuration","text":"<p>Most of the project configuration is now in the metaborg.yaml file. The manual page on configuration lists all configuration options.</p> <ul> <li>Add/remove compile and source dependencies as needed.</li> <li>Add build configuration, such as Stratego compiler arguments, SDF compiler arguments, external def files, and external JAR files.</li> </ul>"},{"location":"release/migrate/2.0.0/#imports","title":"Imports","text":"<p>In Stratego, SDF2, SDF3, NaBL, and TS files:</p> <ul> <li>Remove <code>src-gen</code>, <code>lib</code>, and <code>trans</code>, from module names and imports. These paths are now on the source path of the SDF and Stratego compilers.</li> </ul> <p>In Stratego, NaBL, and TS files:</p> <ul> <li>Instead of importing <code>lib/editor-common.generated</code>, import <code>stratego/metaborg</code>.</li> <li>Instead of importing <code>include/&lt;langname&gt;-parenthesize</code>, import <code>pp/&lt;langname&gt;-parenthesize</code>.</li> <li>If you're using SDF3:<ul> <li>Instead of importing the signatures from <code>include/&lt;langname&gt;</code>, import them from <code>signatures/&lt;langname&gt;-sig</code>. These signatures are spread over multiple files, import all the required files to fix errors, since the Stratego editor does not handle transitive imports. You can also use the wildcard import <code>signatures/-</code> to import all signature files, if your syntax definition is not spread over multiple directories.</li> </ul> </li> <li>If you're using SDF2 or an external definition file:</li> <li>Instead of importing the signatures from <code>include/&lt;langname&gt;</code>, import th  em from <code>signatures/&lt;langname&gt;</code>.</li> </ul>"},{"location":"release/migrate/2.0.0/#sdf","title":"SDF","text":"<p>If you are still using SDF2 instead of SDF3, add the following setting to the metaborg.yaml file:</p> <pre><code>language:\nsdf:\nversion: sdf2\n</code></pre>"},{"location":"release/migrate/2.0.0/#nabl-and-ts","title":"NaBL and TS","text":"<p>If you\u2019re using a NaBL/TS based analysis, perform the following changes:</p> <ul> <li>NaBL files are now generated into src-gen/names, fix imports to NaBL files, delete old generated NaBL files.</li> <li>TS files are now generated into src-gen/types, fix imports to TS files, delete old generated TS files.</li> <li>The <code>editor-analyze</code> calls have been changed. Remove <code>analysis-single-default-interface</code>, <code>analysis-multiple-default-interface</code>, and <code>editor-analyze</code>. Replace it with: <pre><code>editor-analyze = analyze-all(pre-analysis, post-analysis, pp-message|&lt;language&gt;)\n</code></pre> with the <code>pre-analysis</code>, <code>post-analysis</code>, and <code>pp-message</code> arguments that you were using before. Also make sure the observer (in your esv) has the <code>(multifile)</code> property.</li> <li>The editor-save call to <code>analysis-save-default(|&lt;language&gt;)</code> has been removed, remove that call. You can remove <code>editor-save</code> entirely if you don\u2019t do any generation, also remove the <code>on save</code> strategy from ESV if you do. If you do generation but do not return a <code>(file, text)</code> tuple from editor-save, be sure to return a <code>!None()</code> to tell Spoofax that you\u2019re returning nothing.</li> <li>The <code>index-setup</code> and <code>task-setup</code> strategies have been removed, Spoofax Core does this for you now. Remove all calls to these strategies.</li> <li>Remove the path argument to <code>analysis-resolve</code> in <code>editor-resolve</code>.</li> <li>Remove the path argument to <code>analysis-propose-completions</code> in <code>editor-complete</code>.</li> <li>Remove the <code>debug-reanalyze</code> strategy, and remove it from your menu in ESV. You can reanalyze by cleaning the project.</li> </ul>"},{"location":"release/migrate/2.0.0/#esv","title":"ESV","text":"<ul> <li>The following ESV files are now deprecated, delete and remove any imports to these files:<ul> <li>editor/langname-Completions.esv</li> <li>editor/langname-Folding.esv</li> <li>editor/langname-Refactorings.esv</li> </ul> </li> <li>Previously generated ESV files in the editor directory are not generated any more. Delete the generated files and remove the imports to generated files.</li> <li>The colorer ESV file is now generated to src-gen/editor/Colorer.generated.esv, import it with <code>imports editor/Colorer.generated</code> in an ESV file.</li> <li>The generated syntax ESV file is no longer generated. If you were using the defaults from the generated file, add them to an ESV file: <pre><code>language\n\nline comment  : \"//\"\nblock comment : \"/*\" * \"*/\"\nfences        : [ ] ( ) { }\n</code></pre></li> <li>The outliner (editor/langname-Outliner.str) must be moved to the trans directory. Rename it to trans/outline.str, change its module to <code>outline</code>, and fix imports of the outliner. <li>Change the file name of the main ESV file to Main.esv, and change its module to <code>Main</code>.</li> <li>In the main ESV file:<ul> <li>Change the parse table: <pre><code>table : target/metaborg/sdf.tbl\n</code></pre></li> <li>Change the Stratego providers<ul> <li>For ctree projects:   <pre><code>provider : target/metaborg/stratego.ctree\n</code></pre></li> <li>For jar projects:   <pre><code>provider : target/metaborg/stratego.jar\n</code></pre></li> <li>For projects with Java strategies:   <pre><code>provider : target/metaborg/stratego.jar\nprovider : target/metaborg/stratego-javastrat.jar\n</code></pre></li> </ul> </li> </ul> </li>"},{"location":"release/migrate/2.0.0/#java-strategies","title":"Java strategies","text":"<p>If your project has Java strategies:</p> <ul> <li>Create the src/main/strategies directory.</li> <li>Move Java strategies from editor/java into the src/main/strategies directory. Be sure to preserve the existing Java package structure.</li> <li>Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project..., to update the Java source directories of the project.</li> </ul>"},{"location":"release/migrate/2.0.0/#dynsem","title":"DynSem","text":"<p>If your project has manual DynSem Java files:</p> <ul> <li>Create the src/main/ds directory.</li> <li>Move manual DynSem Java files from editor/java into the src/main/ds directory. Be sure to preserve the existing Java package structure.</li> <li>Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project..., to update the Java source directories of the project.</li> </ul>"},{"location":"release/migrate/2.0.0/#ant-build-customization","title":"Ant build customization","text":"<p>Language specification builds do not use Ant any more, so any customizations to the build.main.xml are lost. To perform an Ant task before and after the build, add the following configuration option to your metaborg.yaml file:</p> <pre><code>build:\nant:\n- phase: preCompile\nfile: ${path:root}/ant.xml\ntarget: generate-xml\n- phase: postCompile\nfile: ${path:root}/ant.xml\ntarget: package-xml\n</code></pre> <p>See the manual page on configuration for more information about configuring Ant build steps.</p>"},{"location":"release/migrate/2.0.0/#eclipse-plugin","title":"Eclipse plugin","text":"<p>Language specification projects are not Eclipse plugins anymore.</p>"},{"location":"release/migrate/2.0.0/#git","title":"Git","text":"<p>If you're using Git, the .gitignore file is replaced with a new one, add entries that you need again. All generated files that were previously not ignored, are ignored now. To delete all ignored files from the Git index (the files will remain on the filesystem but Git will forget about them), make sure all your useful changes are committed and pushed, then run the following commands:</p> <pre><code>git rm -r --cached .\ngit add .\ngit commit -am \"Remove ignored files\"\n</code></pre>"},{"location":"release/migrate/2.0.0/#building","title":"Building","text":"<p>When you are done with converting the project, build it with Cmd+Shift+B or Project \u2023 Build. If the build does not work, try cleaning the project first with Project \u2023 Clean, and then building again. Also make sure that Project \u2023 Build Automatically is turned on."},{"location":"release/migrate/2.1.0/","title":"Spoofax 2.1.0 Migration Guide","text":"<p>This migration guide describes the differences between Spoofax 2.0 and 2.1 and how to convert to 2.1.</p>"},{"location":"release/migrate/2.1.0/#new-stratego-library-for-spoofax","title":"New Stratego library for Spoofax","text":"<p>Historically, the <code>org.metaborg.meta.lib.analysis</code> library (also called the runtime libraries) from this repo, was first used as a library to support NaBL, TS, and task engine based static analysis. However, a lot of other functionality such as completions, refactoring, origin tracking, and annotation handling, was also added to the library for convenience. Likewise, the <code>src-gen/stratego/metaborg.str</code> generated file also contains arbitrary functionality such as parsing and import path primitives, and the <code>src-gen/editor/Colorer.generated</code> generated file contains a default coloring scheme.</p> <p>Since this kind of functionality does not belong the analysis library and generated files, we have moved this into a new library, <code>libspoofax</code>, which can be found at this repo.</p>"},{"location":"release/migrate/2.1.0/#migration","title":"Migration","text":"<p>The <code>org.metaborg.meta.lib.analysis</code> library still contains the old arbitrary functionality, but is now deprecated, meaning we will not update that functionality any more, and that it will be removed in a future version. Any functionality pertaining NaBL, TS, and task engine based static analysis will of course be retained. Likewise, the <code>src-gen/stratego/metaborg.str</code> and <code>src-gen/editor/Colorer.generated</code> generated files are also deprecated, meaning that they will stop being generated in a future version.</p> <p>The new <code>libspoofax</code> library is now required for every Spoofax project. Add a source dependency to <code>org.metaborg:meta.lib.spoofax:${metaborgVersion}</code> in your metaborg.yaml file. For example, change the following dependencies:</p> <pre><code>dependencies:\ncompile:\n- org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.nabl:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.ts:${metaborgVersion}\nsource:\n- org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion}\n</code></pre> <p>into:</p> <pre><code>dependencies:\ncompile:\n- org.metaborg:org.metaborg.meta.lang.esv:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.template:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.nabl:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lang.ts:${metaborgVersion}\nsource:\n- org.metaborg:meta.lib.spoofax:${metaborgVersion}\n- org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion}\n</code></pre> <p>If you do not use NaBL, TS, and task engine based analysis any more, you can also delete the <code>org.metaborg:org.metaborg.meta.lib.analysis:${metaborgVersion}</code> source dependency.</p> <p>Some imports have to be changed to point to the new <code>libspoofax</code> library:</p> <ul> <li>In <code>editor/Syntax.esv</code> or your equivalent ESV file that handles coloring:</li> <li>Change import <code>editor/Colorer.generated</code> to <code>libspoofax/color/default</code></li> <li>In <code>trans/analysis.str</code> for NaBL/TS projects:</li> <li>Add import <code>libspoofax/core/language</code></li> <li>In <code>trans/outline.str</code>:<ul> <li>Remove imports to the runtime libraries</li> <li>Add import <code>libspoofax/editor/outline</code></li> </ul> </li> <li>In <code>trans/pp.str</code>:<ul> <li>Remove imports to the runtime libraries</li> <li>Add imports <code>libspoofax/sdf/pp</code> and <code>libspoofax/editor/refactoring/-</code></li> </ul> </li> <li>In other Stratego files:<ul> <li>Remove all imports to the runtime libraries that do not pertain NaBL, TS, and task engine based static analysis, and replace them with <code>libspoofax</code> equivalents.</li> <li>Remove all imports to the <code>stratego/metaborg</code> generated file, and replace them with <code>libspoofax</code> equivalents.</li> </ul> </li> </ul> <p>Here is a list of other imports and strategies that were moved:</p> <ul> <li>Imports:<ul> <li><code>runtime/editor/origins</code> -&gt; <code>libspoofax/term/origin</code></li> <li><code>runtime/editor/annotations</code> -&gt; <code>libspoofax/term/annotation</code></li> <li><code>runtime/completion/-</code> -&gt; <code>libspoofax/editor/completion/-</code></li> </ul> </li> <li>Strategies:<ul> <li><code>*-at-position</code>: <code>libspoofax/term/position</code></li> <li><code>parse-file</code>: <code>libspoofax/core/parse</code></li> <li><code>language</code>: <code>libspoofax/core/language</code></li> <li><code>project-path</code>: <code>libspoofax/resource/path</code></li> <li><code>open-import</code>: <code>libspoofax/resource/cache</code></li> <li><code>refresh-workspace-file</code>: removed, not needed any more since all file system operations go though VFS, which routes them through Eclipse.</li> </ul> </li> </ul>"},{"location":"release/migrate/2.5.10/","title":"Spoofax 2.5.10 Migration Guide","text":"<p>A change in Statix need migration for users of the Stratego API.</p>"},{"location":"release/migrate/2.5.10/#sdf3","title":"SDF3","text":"<p>In an upcoming version of Spoofax 2 it will be required to properly declare sorts in SDF3 syntax definitions. Sorts for which context-free rules are defined should be declared in a <code>context-free sorts</code> block:</p> <pre><code>context-free sorts\nStmt Expr\n</code></pre> <p>Note: For backward compatibility, sorts declared in a plain <code>sorts</code> block are treated as context-free sorts. So this is equivalent and also fine:</p> <pre><code>sorts\nStmt Expr\n</code></pre> <p>Sorts for which lexical rules are defined should be declared in a <code>lexical sorts</code> block:</p> <pre><code>lexical sorts\nID INT STRING\n</code></pre> <p>Note: Lexical sorts are not supported in combination with <code>sdf2table: c</code>.</p>"},{"location":"release/migrate/2.5.10/#typesmart","title":"Typesmart","text":"<p>If your <code>metaborg.yaml</code> file still contains mention of Typesmart (e.g. <code>debug: typesmart: false</code>), you can remove it. See the release notes for why Typesmart support was removed.</p>"},{"location":"release/migrate/2.5.10/#stratego","title":"Stratego","text":"<p>Spoofax languages used to always generate <code>target/metaborg/stratego-javastrat.jar</code> which contains the compiled Java code from <code>src/main/stratego</code>. Conditional on your settings in the <code>metaborg.yaml</code> file, your Stratego code would be turned into <code>target/metaborg/stratego.ctree</code> or <code>target/metaborg/stratego.jar</code> depending on whether you chose compilation or interpretation. As of this release, there is no longer a separate <code>stratego-javastrat.jar</code>. Instead <code>stratego.jar</code> is always generated and always contains at least the compiled Java code from <code>src/main/stratego</code>. If you choose compilation for your Stratego code, the compiled Stratego code is added to the <code>stratego.jar</code> file as was already the case originally.</p> <p>What you need to do: Go to your <code>editor/main.esv</code> file and find the <code>provider: ...</code> lines (or search your other ESV files if it's not there). The line <code>provider: target/metaborg/stratego-javastrat.jar</code> should be replaced by <code>provider: target/metaborg/stratego.jar</code>. If you already have a <code>provider: target/metaborg/stratego.jar</code>, one is enough and you can remove the <code>stratego-javastrat.jar</code> provider directive entirely.</p>"},{"location":"release/migrate/2.5.10/#statix","title":"Statix","text":"<p>The AST property type is now a built-in property. Users of the Stratego API to get this property should change their API calls. Instead of</p> <pre><code>stx-get-ast-property(|a, \"type\")\n</code></pre> <p>one should now use:</p> <pre><code>stx-get-ast-type(|a)\n</code></pre>"},{"location":"release/migrate/2.5.10/#spt","title":"SPT","text":"<p>In SPT, <code>parse succeeds</code> tests will now fail when the input parses ambiguously. If this is intended, use <code>parse ambiguous</code> instead.</p>"},{"location":"release/migrate/2.5.15/","title":"Spoofax 2.5.15 Migration Guide","text":""},{"location":"release/migrate/2.5.15/#statix-injection-explication","title":"Statix Injection Explication","text":"<p>There was an issue with Statix injection explication where the origin of the top-level term was lost and this caused SPT tests of Stratego strategies on analyzed ASTs to fail. Fix this by wrapping the bodies of the <code>pre-analyze</code> and <code>post-analyze</code> strategies in <code>analyze.str</code> with <code>origin-track-forced</code>, like this:</p> <pre><code>imports libspoofax/term/origin\n\nrules\npre-analyze  = origin-track-forced(explicate-injections-MyLang-Start)\npost-analyze = origin-track-forced(implicate-injections-MyLang-Start)\n</code></pre> <p>This is already fixed in new projects.</p>"},{"location":"release/migrate/2.5.5/","title":"Spoofax 2.5.5 Migration Guide","text":"<p>A few changes in Statix need migration for specs written for older versions.</p>"},{"location":"release/migrate/2.5.5/#statix","title":"Statix","text":"<p>A few features in Statix were not well-defined and removed until a better way to support them is found. Therefore, the following changes may require you to make small modifications to a specification:</p> <ol> <li>Functional constraints can only have a single output.</li> <li>Regular expression and label order must be direct parameters to    queries.</li> <li>Namespace based query short-hands require</li> <li>a literal occurrence as argument, and</li> <li>an explicit resolution policy entry.</li> </ol>"},{"location":"release/migrate/2.5.5/#functional-constraint-outputs","title":"Functional constraint outputs","text":"<p>Functional constraints previously were allowed to have multiple output arguments, such as:</p> <pre><code>f : T * T -&gt; T * T`\n</code></pre> <p>This was sometimes indistinguishable from types with a single tuple output, such as:</p> <pre><code>f : T * T -&gt; (T * T)`\n</code></pre> <p>From now on, functional constraints can only have a single output. Constraints with multiple outputs need to be rewritten to return a tuple instead.</p>"},{"location":"release/migrate/2.5.5/#query-parameters","title":"Query parameters","text":"<p>Queries would accept arbitrary predicates for the label regular expression and label order. For example, a query could be written as:</p> <pre><code>query filter myWf and true\nmin myOrd and false\nin s |-&gt; _\n</code></pre> <p>with</p> <pre><code>myWf(ls) :- pathMatch[P*](ls).\n\nmyOrd(l1,l2) :- pathLt[$ &lt; P](l1,l2).\n</code></pre> <p>This is not possible anymore, instead the regular expression and label order must be direct parameters of the query. The query above should be directly written as:</p> <pre><code>query filter P* and true\nmin $ &lt; P and false\nin s |-&gt; _\n</code></pre> <p>The following syntax is still accepted, but deprecated:</p> <pre><code>query filter pathMatch[P*] and true\nmin pathLt[$ &lt; P] and false\nin s |-&gt; _\n</code></pre>"},{"location":"release/migrate/2.5.5/#namespace-based-resolution-shorthands","title":"Namespace-based resolution shorthands","text":"<p>The requirements for namespace-based resolution shorthands have become stricter.</p> <p>First, if they are used, ther emust be an explicit resolution policy for the namespace. For example, using a constraints such as:</p> <pre><code>Var{x@-} in s |-&gt; _\ntype of Var{x@-} in s |-&gt; _\n</code></pre> <p>requires in the signature at least:</p> <pre><code>signature\nname-resolution\nresolve Var\n</code></pre> <p>A full resolution policy with regular expression and label order looks like this:</p> <pre><code>signature\nname-resolution\nresolve Var filter P* min $ &lt; P\n</code></pre> <p>Second, the namespace-based constraints require an occurrence literal. The following does not work anymore:</p> <pre><code>d == Var{x@-},\nd in s |-&gt; _\n</code></pre> <p>The occurrence has to be repeated in the constraints, as:</p> <pre><code>Var{x@-} in s |-&gt; _\n</code></pre>"},{"location":"release/migrate/march2016_project_structure/","title":"Directory structure migration (March 2016)","text":"<p>To clean up the structure of a language specification project, we've made the following changes:</p> <ul> <li>ESV<ul> <li>Main ESV file must be at editor/Main.esv. If it does not exist, no packed ESV file will be generated.</li> <li>Packed ESV file: target/metaborg/editor.esv.af</li> </ul> </li> <li>SDF<ul> <li>The RTG and signatures files are no longer generated for SDF3 projects, since SDF3 generates its own signatures.</li> <li>The generated box pp files are no longer generated, and box pp files are no longer converted into pp.af files.</li> <li>Definition: src-gen/syntax/[LanguageName].def</li> <li>Permissive definition: src-gen/syntax/[LanguageName]-permissive.def</li> <li>Parenthesizer: src-gen/pp/[LanguageName]-parenthesize.str</li> <li>Parse table: target/metaborg/sdf.tbl</li> </ul> </li> <li>Stratego<ul> <li>'editor-common.generated' file: src-gen/stratego/metaborg.str</li> <li>Ctree: target/metaborg/stratego.ctree</li> <li>Generated Java files: src-gen/stratego-java</li> <li>JAR: target/metaborg/stratego.jar</li> <li>Java strategies: src/main/strategies</li> <li>Java strategies JAR: target/metaborg/stratego-javastrat.jar</li> <li>Build cache: target/stratego-cache</li> </ul> </li> <li>DynSem<ul> <li>Manual Java: src/main/ds</li> <li>Generated Java: src-gen/ds-java</li> </ul> </li> <li>Other<ul> <li>Pluto build cache: target/pluto</li> </ul> </li> </ul> <p>To migrate your project, make the following changes:</p> <ul> <li>Change the file name of the main ESV file to Main.esv, and change its module to <code>Main</code>.</li> <li>In the main ESV file:<ul> <li>Change the parse table: <pre><code>table : target/metaborg/sdf.tbl\n</code></pre></li> <li>Change the Stratego providers<ul> <li>For ctree projects:   <pre><code>provider : target/metaborg/stratego.ctree\n</code></pre></li> <li>For jar projects:   <pre><code>provider : target/metaborg/stratego.jar\n</code></pre></li> <li>For projects with Java strategies:   <code>esv   provider : target/metaborg/stratego.jar   provider : target/metaborg/stratego-javastrat.jar</code></li> </ul> </li> </ul> </li> <li>In all Stratego, NaBL, TS files<ul> <li>Instead of importing <code>lib/editor-common.generated</code>, import <code>stratego/metaborg</code>.</li> <li>Instead of importing <code>include/&lt;langname&gt;-parenthesize</code>, import <code>pp/&lt;langname&gt;-parenthesize</code>.</li> <li>If you're using SDF3:<ul> <li>Instead of importing the signatures from <code>include/&lt;langname&gt;</code>, import them from <code>signatures/&lt;langname&gt;-sig</code>. These signatures are spread over multiple files, import all the required files to fix errors, since the Stratego editor does not handle transitive imports. You can also use the wildcard import <code>signatures/-</code> to import all signature files, if your syntax definition is not spread over multiple directories.</li> </ul> </li> <li>If you're using SDF2 or an external definition file:<ul> <li>Instead of importing the signatures from <code>include/&lt;langname&gt;</code>, import them from <code>signatures/&lt;langname&gt;</code>.</li> </ul> </li> </ul> </li> <li>If your project has Java strategies:<ul> <li>Create the src/main/strategies directory.</li> <li>Move Java strategies from editor/java into the src/main/strategies directory. Be sure to preserve the existing Java package structure.</li> </ul> </li> <li>If your project has manual DynSem Java files:<ul> <li>Create the src/main/ds directory.</li> <li>Move manual DynSem Java files from editor/java into the src/main/ds directory. Be sure to preserve the existing Java package structure.</li> </ul> </li> <li>Perform a Maven update by right clicking the project and choosing Maven \u2023 Update Project.... Enable Force Update of Snapshots/Releases in the new window and press Ok. This updates the Java source directories of the project.</li> <li>If you are still using SDF2 instead of SDF3, add the following setting to the metaborg.yaml file: <pre><code>language:\nsdf:\nversion: sdf2\n</code></pre></li> </ul>"},{"location":"release/migrate/vnext/","title":"Spoofax vNext Migration Guide","text":"<p>This is a stub for the migration guide of the upcoming version of Spoofax.</p>"},{"location":"release/note/1.0.0/","title":"Spoofax 1.0.0 (28-12-2011)","text":"<p>We're pleased to announce the release of Spoofax 1.0.0. A number of significant new features have been added since the last stable release, a long list of bugs has been fixed, and various minor improvements were introduced.</p> <p>Highlights of the release include:</p> <ul> <li>Support for writing tests for language definitions</li> <li>Support for defining refactorings</li> <li>Major improvements to content completion:     Spoofax/289,     Spoofax/357</li> <li>Support for using rewrite rules to disambiguate syntax:     Spoofax/328</li> </ul> <p>In addition to these features, we're actively working on improving Spoofax with new features. In particular, we are now working on providing full support for debugging, on an interactive shell for Stratego and custom languages, and a new meta-language called SpoofaxLang to define languages in a more modular fashion.</p> <p>A full list of feature requests and issues addressed in the new version is provided at http://yellowgrass.org/tag/Spoofax/1.0.</p>"},{"location":"release/note/1.0.2/","title":"Spoofax 1.0.2 (15-02-2012)","text":"<p>Today we're releasing a minor maintenance release of Spoofax, version 1.0.2. This release fixes a memory leak that was introduced in the 1.0 release. There are no new features in this release, those will be included in the upcoming 1.1 release instead.</p>"},{"location":"release/note/1.1.0/","title":"Spoofax 1.1.0 (25-03-2013)","text":"<p>We are happy to announce the release of Spoofax 1.1! This is the first major release since version 1.0.2 and includes major features and improvements. Spoofax 1.1 supports all current Eclipse versions, up to version 4.2.2.</p>"},{"location":"release/note/1.1.0/#changes","title":"Changes","text":""},{"location":"release/note/1.1.0/#nabl","title":"NaBL","text":"<p>One of the most important improvements in Spoofax 1.1 is the inclusion of NaBL, the Spoofax Name Binding Language. NaBL is used in all new projects created and significantly simplifies name binding analysis, as well as any editor services that depend on it (e.g., code completion, reference resolving)</p> <p>NaBL is documented at the following pages:</p> <ul> <li>Research paper</li> </ul>"},{"location":"release/note/1.1.0/#other","title":"Other","text":"<p>Other highlights of the 1.1 release include:</p> <ul> <li>Improved build process: generated files can be deleted, building &amp; loading are separated, projects can be cleaned (http://yellowgrass.org/issue/Spoofax/577, http://yellowgrass.org/issue/Spoofax/591, http://yellowgrass.org/issue/Spoofax/578)</li> <li>Improved Stratego editor with multi-file reference resolving based on NaBL (http://yellowgrass.org/issue/Spoofax/12)</li> <li>Extended support for customizing refactoring UI (http://yellowgrass.org/issue/Spoofax/440)</li> <li>Automatic configuration of git/svn ignore settings (http://yellowgrass.org/issue/Spoofax/573)</li> <li>Added support loading for Java-based plugin dependencies, in case your plugin depends on some other plugin such as EMF (http://yellowgrass.org/issue/Spoofax/322)</li> </ul> <p>And there were a number of notable changes under the hood:</p> <ul> <li>Much improved completion engine (http://yellowgrass.org/issue/Spoofax/360)</li> <li>We now show a nice warning if Eclipse is not configured with a proper stack and heap size (http://yellowgrass.org/issue/Spoofax/86)</li> <li>Files are now queued for re-analysis even if their editor is not open (http://yellowgrass.org/issue/Spoofax/224)</li> </ul> <p>A comprehensive list of changes can be viewed at http://yellowgrass.org/tag/Spoofax/1.1.</p>"},{"location":"release/note/1.2.0/","title":"Spoofax 1.2.0 (13-08-2014)","text":"<p>We're happy to announce the release of Spoofax 1.2! This document describes the changes in Spoofax 1.2 since Spoofax 1.1.</p>"},{"location":"release/note/1.2.0/#changes","title":"Changes","text":""},{"location":"release/note/1.2.0/#editor-interface","title":"Editor interface","text":"<p>Several aspects of the editor interface for Spoofax languages have been improved.</p>"},{"location":"release/note/1.2.0/#menus","title":"Menus","text":"<p>Each language now has its own set of menus. These menus replace the <code>Transform</code> menu that was shared among all Spoofax-based languages.</p> <ul> <li>The new menus dynamically pop up in the Eclipse menus toolbar, based on the current active editor.</li> <li>There is now support for submenus, icons and menu separators.</li> </ul> <p>Contributors: Oskar van Rest</p>"},{"location":"release/note/1.2.0/#outline","title":"Outline","text":"<p>Editor outlines are now specified in Stratego instead of ESV, to allow for full customization.</p> <ul> <li>A library with reusable outline strategies is provided to allow you to quickly realize an outline.</li> <li>It is now possible to have icons in your outline.</li> <li>It is now possible to also base an outline on the current text selection instead of the complete text.</li> </ul> <p>Contributors: Oskar van Rest</p>"},{"location":"release/note/1.2.0/#properties-view","title":"Properties view","text":"<p>A property view has been added that shows properties for the selected AST node.</p> <ul> <li>By default, the new properties view integrates with NaBL and presents (NaBL) properties associated with the selected text in the editor.</li> <li>The properties view can be customized to show different kinds of properties, either to aid language development or to provide language users with additional information about their programs.</li> </ul> <p>Contributors: Daco Harkes, Oskar van Rest</p>"},{"location":"release/note/1.2.0/#meta-languages","title":"Meta-languages","text":"<p>We have created a new version of SDF, improved NaBL and developed a DSL for describing type systems: TS.</p>"},{"location":"release/note/1.2.0/#sdf3","title":"SDF3","text":"<p>SDF3 is the next iteration of SDF, replacing SDF2. The most important new features are:</p> <ul> <li>Productive productions can be used in context-free syntax sections, improving readability and consistency with main-stream grammar notation.</li> <li>Constructors are now formally integrated to the language. A productive production introduces the constructor directly after the left hand side non-terminal.</li> <li>By using constructors, productions can now be uniquely identified. Therefore, it is no longer necessary to repeat the entire production in the priorities section, but use its <code>Sort.Constructor</code> shorthand.</li> <li>Template productions are the major change from SDF2. They can be used to define what the concrete syntax of the language should look like. Syntactic completion and pretty-printer rules are automatically generated from templates.</li> </ul> <p>Documentation</p> <p>Contributors: Eduardo Amorim, Guido Wachsmuth</p>"},{"location":"release/note/1.2.0/#nabl","title":"NaBL","text":"<p>NaBL has received many bug fixes and several new features. New features include:</p> <ul> <li>Filter clauses can be used to constrain valid resolution targets based on properties such as types.</li> <li>Disambiguation clauses can be used to disambiguate resolutions based on relations between properties, for example type hierarchies.</li> <li>It is now possible to specify non-transitive scopes, in which resolution ignores lexical parent scopes.</li> <li>Where clauses can include constraints and type calculations in TS syntax.</li> <li>We added new scope calculation constructs, which can be used to navigate the scope hierarchy. For example, it is possible to calculate the surrounding class of the current variable scope.</li> </ul> <p>For examples of name binding rules, see the Java front project</p> <p>Contributors: Guido Wachsmuth, Gabri\u00ebl Konat</p>"},{"location":"release/note/1.2.0/#ts","title":"TS","text":"<p>TS is a new meta-language for the specification of type analysis that is complementary to NaBL. Type rules in TS define constraints on abstract syntax tree nodes and may compute a type or other property. In addition, type rules can define subtyping predicates (relations on types) and type functions.</p> <p>For examples of type system rules, see the Java front project</p> <p>Contributors: Eelco Visser, Guido Wachsmuth, Gabri\u00ebl Konat</p>"},{"location":"release/note/1.2.0/#command-line-integration","title":"Command-line integration","text":"<p>Programs of your language can now be parsed, analyzed, and transformed from the command-line using Sunshine (in contrast with an Eclipse). Sunshine can also be used as a Java API to develop new language tooling.</p> <p>Contributors: Vlad Vergu</p>"},{"location":"release/note/1.2.0/#finer-grained-incrementality","title":"Finer-grained incrementality","text":"<p>Incrementality in the previous version of Spoofax was based on files. Any file that changed, and any dependent files would be reparsed and reanalysed completely. In the new version of Spoofax, there is more fine-grained dependency tracking which allows more fine-grained incrementality. If a file changes, that file is reparsed, but only affected computations are recomputed, and other files are never reparsed. Name and type computations which are described in NaBL and TS are incrementally executed. Incrementality is powered by a task engine, described in our paper.</p> <p>Contributors: Gabri\u00ebl Konat, Guido Wachsmuth</p>"},{"location":"release/note/1.2.0/#modelware","title":"Modelware","text":"<p>Spoofax Modelware is a new Spoofax component that provides integration with the Eclipse Modeling Framework (EMF) and the Graphical Modeling Framework (GMF) to allow for real-time synchronized textual and graphical editors and/or views. It also allows you to use other EMF-based tooling in combination with Spoofax.</p> <p>Contributors: Oskar van Rest</p>"},{"location":"release/note/1.2.0/#documentation","title":"Documentation","text":"<p>We have moved most of our documentation to the doc repository on GitHub. We're still in the process of moving over other documentation and writing more documentation.</p> <p>There are also two new tutorials available:</p> <ul> <li>Questionaire language tutorial: learn to create a questionaire language. This tutorial was given in a hands-on session at the Code Generation conference in 2014.</li> <li>Compiler Construction lab assignments: a more in-depth tutorial. These are the assignments from our Compiler Construction lab where we teach students to create MiniJava inside Spoofax.</li> </ul> <p>Contributors: Guido Wachsmuth and others</p>"},{"location":"release/note/1.2.0/#other","title":"Other","text":"<p>To reduce maintenance effort, we have dropped support for Eclipse 3.7 (Indigo) and lower. We now support Eclipse 4.2 (Juno), 4.3 (Kepler), and 4.4 (Luna). We recommend you to download and install Eclipse 4.4 (Luna) for Java Developers.</p> <p>We have also dropped support for Java 5 and 6. Java 7 and 8 are supported, we recommend you to download and install Java 8. Note that on OSX, Java 6 is installed by default which is not enough to run Spoofax, install Java 8 from the previous link.</p> <p>All source code has been moved to our organization on GitHub. Feel free to fork our code and send pull requests for patches or improvements!</p> <p>More changes, additions, and bug fixes can be found in the roadmap on our issue tracker: http://yellowgrass.org/tag/Spoofax/1.2</p> <p>Contributors: Vlad Vergu, Gabri\u00ebl Konat</p>"},{"location":"release/note/1.3.0/","title":"Spoofax 1.3.0 (12-11-2014)","text":"<p>We're happy to announce the release of Spoofax 1.3, which improves SDF3, the build system for languages, and the build system for Spoofax itself.</p>"},{"location":"release/note/1.3.0/#porting","title":"Porting","text":""},{"location":"release/note/1.3.0/#language-projects","title":"Language projects","text":"<p>The build for language projects has changed since the last Spoofax, so your language projects need to be migrated. To automatically migrate your project, follow these steps:</p> <ol> <li>Right click the project in Eclipse</li> <li>Choose Spoofax -&gt; Upgrade Spoofax project</li> <li>Press Finish</li> </ol> <p>This will automatically upgrade your project to the latest format, after which you can build your project normally. The build might fail with:</p> <pre><code>sdf2parenthesize:\n\nBUILD FAILED\n/Users/gohla/spoofax/workspace/runtime-Spoofax/Entity/build.generated.xml:266: The following error occurred while executing this line:\nTarget \"sdf2parenthesize.helper\" does not exist in the project \"Entity\".\n</code></pre> <p>If this is the case, build again, because some files are only upgraded after building once.</p> <p>Compiled Java files are now stored in the <code>target/classes</code> directory instead of the <code>bin</code> directory, so the <code>bin</code> directory can be deleted.</p>"},{"location":"release/note/1.3.0/#sdf3-grammars","title":"SDF3 grammars","text":"<p>SDF2 and old SDF3 grammars can be migrated. Some manual changes might still be necessary since a sort cannot have more than one constructor with the same name and arity, and priority rules may contain the entire production instead of priority shorthands.</p>"},{"location":"release/note/1.3.0/#changes","title":"Changes","text":""},{"location":"release/note/1.3.0/#sdf3","title":"SDF3","text":"<p>Several improvements have been made to increase the consistency and robustness of SDF3.</p> <ul> <li> <p>Regular productive productions can be mixed with template productions in the context-free syntax section.</p> </li> <li> <p>Each production defines a non-unique sort and a unique constructor of that sort. References point to these definitions and errors are given for undefined elements in the grammar.</p> </li> <li> <p>Signatures are generated on-save following the sorts used in the right-hand side of a production and the sort and constructor that are being defined.</p> </li> <li> <p>All code generated from SDF3 grammars is organized in the <code>src-gen</code> directory of the project, which keeps Spoofax projects more clean and structured.</p> </li> </ul> <p>Contributors: Eduardo Amorim</p>"},{"location":"release/note/1.3.0/#building-language-projects","title":"Building language projects","text":"<p>Projects are built using Ant Macros tailored to make the build system more incremental.</p> <p>Language projects can now also be built on the command-line using Maven.</p> <p>Contributors: Eduardo Amorim, Gabri\u00ebl Konat</p>"},{"location":"release/note/1.3.0/#building-and-developing-spoofax","title":"Building and developing Spoofax","text":"<p>The build system for Spoofax itself has been refactored from a Nix build into a full Maven build. This enables local builds on any system that Maven supports, which is basically any system that supports Java. See the instructions on building Spoofax for more information follow the instructions on using MetaBorg Maven artifacts for more information. There is now also documentation on Setting up Eclipse for Spoofax development, which explains how to set up an environment for developing projects which are included in Spoofax.</p> <p>The nightly version of Spoofax is now built on our Jenkins server: http://buildfarm.metaborg.org/. It publishes artifacts to our artifact server: http://artifacts.metaborg.org/. To use these artifacts, read the instructions on the instructions on using MetaBorg Maven artifacts for more information.</p> <p>Contributors: Gabri\u00ebl Konat, Danny Groenewegen, Elmer van Chastelet</p>"},{"location":"release/note/1.3.0/#other","title":"Other","text":"<p>More changes, additions, and bug fixes can be found in the roadmap on our issue tracker: http://yellowgrass.org/tag/Spoofax/1.3</p>"},{"location":"release/note/1.3.1/","title":"Spoofax 1.3.1 (09-12-2014)","text":"<p>We're happy to announce the release of Spoofax 1.3.1, a maintenance release which fixes several issues in SDF3, and compatibility with Eclipse 4.3 (Kepler).</p>"},{"location":"release/note/1.3.1/#changes","title":"Changes","text":"<ul> <li>Fix: Allowing sequences in SDF3 lexical syntax.</li> <li>Fix: Allowing specific arguments of productions in SDF3 priorities.</li> <li>Fix: SDF3 outliner not working.</li> <li>Fix: Unable to install in Eclipse 4.3.</li> </ul> <p>Contributors: Eduardo Amorim</p>"},{"location":"release/note/1.4.0/","title":"Spoofax 1.4.0 (06-03-2015)","text":"<p>We're happy to announce the release of Spoofax 1.4.0, a minor release with SDF3 fixes and improvements to language plugins.</p>"},{"location":"release/note/1.4.0/#changes","title":"Changes","text":""},{"location":"release/note/1.4.0/#sdf3","title":"SDF3","text":"<ul> <li>Fix: Supporting Windows line endings in SDF3.</li> <li>Fix: Providing warnings for literals that could be placeholders.</li> </ul> <p>Contributors: Eduardo Amorim</p>"},{"location":"release/note/1.4.0/#language-plugins","title":"Language plugins","text":""},{"location":"release/note/1.4.0/#reduced-download-size-of-deployed-plugins","title":"Reduced download size of deployed plugins","text":"<p>Previously, when creating an Eclipse update site for your language (see tutorial), the result was a ~90MB download that included meta-tools such as SDF3 and NaBL. We brought the download size down to ~60MB by removing dependencies to some of the meta-tools, since end-users of deployed languages don't need them. In the future, we plan to bring the size further down by removing more dependencies.</p> <p>Contributors: Oskar van Rest</p>"},{"location":"release/note/1.4.0/#setting-java-vm-options-for-your-language","title":"Setting Java VM options for your language","text":"<p>For Spoofax and Spoofax-based languages to run smoothly, it is recommended to set Java's <code>-server</code> flag and to increase the stack size and memory allocation pool:</p> <ul> <li><code>-Xss&lt;size&gt;</code> specifies the thread stack size</li> <li><code>-Xmx&lt;size&gt;</code> specifies the maximum size, in bytes, of the memory allocation pool.</li> <li><code>-server</code> selects server application runtime optimizations.</li> </ul> <p>The server VM will take longer to start and \u201cwarm up\u201d but will be more aggressively optimized. The <code>-server</code>  option only affects 32-bit VMs and has influence on 64-bit VMs because these always use server optimizations. These options can be configured in <code>eclipse.ini</code> as described on the download page. The recommended settings for Spoofax are <code>-server -Xss8m -Xmx1024m</code> and a warning will pop-up if Eclipse is started with settings that are too low.</p> <p>Previously, the same settings were assumed for deployed plugins and were enforced by a similar pup-up warning. With Spoofax 1.4.0, language developers can choose their own Java VM settings, which are then recommended to end-users of their language. This can be configured in <code>editor/yourlang.main.esv</code>. The syntax is as follows:</p> <pre><code>jvm opts: [-server | -X[ss|mx]&lt;size&gt;[g|G|m|M|k|K]]+\n</code></pre> <p>For example: <code>jvm opts: -server -Xss8m -Xmx1024m</code>. If multiple Spoofax-based languages are installed, the configuration warning will tell how <code>eclipse.ini</code> needs to be updated such that the requirements of all languages are satisfied.</p> <p>Contributors: Oskar van Rest</p>"},{"location":"release/note/1.5.0/","title":"Spoofax 1.5.0 (18-12-2015)","text":"<p>We're happy to announce the release of Spoofax 1.5.0 with new SDF3 features and fixes, and support for Eclipse Mars.</p>"},{"location":"release/note/1.5.0/#changes","title":"Changes","text":""},{"location":"release/note/1.5.0/#sdf3","title":"SDF3","text":"<ul> <li>Feature: support for case insensitive keywords. All keywords in a template production are case insensitive if the production has the attribute <code>case-insensitive</code>.</li> <li>Feature: pretty-print ambiguous programs (by taking the first alternative).</li> <li>Feature: give an error if the filename does not match the module name.</li> <li>Fix: ESV generation with empty imports.</li> <li>Fix: disallow empty placeholders <code>&lt;&gt;</code> in template productions.</li> </ul> <p>Contributor: Eduardo Amorim</p>"},{"location":"release/note/1.5.0/#eclipse","title":"Eclipse","text":"<ul> <li>Feature: support for Eclipse Mars.</li> <li>Feature: generation of premade Eclipse installations with Spoofax installed.</li> </ul> <p>Contributor: Gabriel Konat</p>"},{"location":"release/note/1.5.0/#command-line-tools","title":"Command-line tools","text":"<ul> <li>Fix: Sunshine now pretty-prints ATerms before presenting them, mimicking the behavior in Eclipse.</li> </ul> <p>Contributor: Gabriel Konat</p>"},{"location":"release/note/2.0.0-beta1/","title":"Spoofax 2.0.0-beta1 (07-04-2016)","text":"<p>This is the first beta release of Spoofax 2.0. These notes provide the download links for the various artifacts.</p> <p>See the 2.0.0 release notes for more information about Spoofax 2.0. See the 2.0.0 migration guide for migrating a Spoofax 1.5 project to a Spoofax 2.0 project.</p>"},{"location":"release/note/2.0.0/","title":"Spoofax 2.0.0 (08-07-2016)","text":"<p>Spoofax 2.0 is a complete rewrite of Spoofax which improves the architecture by separating Spoofax into the Spoofax Core API and implementations on top of that API, massively improves the language development workflow, and properly supports language extension.</p> <p>See the corresponding migration guide for migrating from Spoofax 1.5 to Spoofax 2.0.</p>"},{"location":"release/note/2.0.0/#known-issues","title":"Known Issues","text":"<ul> <li>Stratego imports do not work. To work around this issue, add an explicit compile dependency to Stratego:</li> </ul> <pre><code>dependencies:\n  compile:\n  - org.metaborg:org.metaborg.meta.lang.stratego:${metaborgVersion}\n</code></pre>"},{"location":"release/note/2.0.0/#changes","title":"Changes","text":""},{"location":"release/note/2.0.0/#architecture","title":"Architecture","text":"<p>The biggest change in Spoofax 2.0 is the architecture. Previously, Spoofax was built on top of the Eclipse and IMP platform, meaning Spoofax was not usable outside of the Eclipse platform. In Spoofax 2.0, all platform-agnostic functionality such as language management, parsing, analysis, transformation, and editor services, are implemented in Spoofax Core, which is a portable Java library with an API. This means that the Spoofax language workbench, and any language implementations made with Spoofax, can now be used by any application, platform, or framework in the Java ecosystem.</p>"},{"location":"release/note/2.0.0/#integrations","title":"Integrations","text":"<p>We have integrated Spoofax Core with Eclipse, IntelliJ, Maven, and the command-line.</p> <p>We support the Eclipse platform through a new plugin that integrates Spoofax Core as an Eclipse plugin. The new Eclipse plugin supports language development in Eclipse, and supports exporting languages made with Spoofax as an Eclipse plugin with full-fledged editor support. We have also performed a more faithful Eclipse integration than Spoofax 1.5 did. For example, we now use natures to enable Spoofax for a project, use the incremental builder framework to allow suspending automatic builds, and use Eclipse's menu system for builders instead of non-standard buttons. See the migration guide for a full list of changes to the Eclipse plugin.</p> <p>IntelliJ is an experimentally supported platform through the Eclipse IntelliJ plugin. Languages can be developed in IntelliJ, and exported as IntelliJ plugins with full-fledged editor support.</p> <p>The Spoofax Maven plugin supports command-line builds and continuous integration of language implementations in Maven. Language implementations can be exported as Maven artifacts which can be depended on and used to build programs of that language.</p> <p>Command-line use of language implementations is supported through Sunshine's integration with Spoofax Core. Sunshine's command-line interface has been simplified to improve ease of use, and now also supports a server mode to reduce the high cost of starting a new JVM and loading a language.</p> <p>Furthermore, anyone can make new integrations using the Core API.</p>"},{"location":"release/note/2.0.0/#language-development-workflow","title":"Language Development Workflow","text":"<p>There are several improvements to the language development workflow in Spoofax 2.0.</p> <p>Almost all generated files are now generated to the src-gen directory of a language project. All required generated files are now (re)generated when building, so it is no longer necessary to commit generated files to source control. This results in much cleaner projects. Furthermore, the language build is now incremental, which speeds up the build in many cases.</p> <p>The bootstrapping process of meta-languages has been significantly improved by versioning languages. It is now possible to load multiple versions of the same language implementation into Spoofax. Meta-languages are bootstrapped by building them against baseline versions of the meta-languages. When a meta-language under development breaks, it is possible to revert back to a previous version to get things working again.</p>"},{"location":"release/note/2.0.0/#extension","title":"Extension","text":"<p>Spoofax 2.0 supports language extension on the source level, without the need to copy-paste files around. A dependency can be made from a language specification to another language specification, which then allows importing modules of the specification into the other. For example, language extensions can depend on a base language and extend its concepts. Those extensions can be composed together with the base language specification into a new language specification that contains the base and extensions.</p> <p>There is also limited support for dynamic extension, i.e. extension at the runtime level instead of the source level. A language implementation can be extended with new builders at runtime. This allows adding builders to existing language implementations, and supports separating the front-end and back-end of a language into multiple projects.</p>"},{"location":"release/note/2.0.0/#license","title":"License","text":"<p>The license has been changed from LPGLv2.1 to the Apache 2.0 license, to improve adoption of Spoofax. Any contributions made to Spoofax must be licensed under the Apache 2.0 license as well.</p>"},{"location":"release/note/2.0.0/#missing-features","title":"Missing Features","text":"<p>A few features didn't make it to Spoofax 2.0, with the biggest one being semantic completions.</p> <p>Semantic completions were already very dodgy in Spoofax 1.5, only working in some specific cases. This is why we did not port the completion algorithm from Spoofax 1.5 to 2.0, and are instead working on a new completion algorithm that will be included in a future version.</p> <p>Refactorings were already broken in Spoofax 1.5, so we did not port refactorings to Spoofax 2.0. In the future we will revisit refactorings for Spoofax 2.0 with our new meta-languages.</p> <p>The Spoofax modelware component was not ported to Spoofax 2.0 since we do not have the knowledge to port this component.</p> <p>Folding, realtime builders, and the eclipse.ini check are minor features that are not implemented in 2.0, but may be implemented in the future.</p> <p>A missing integration in Spoofax 2.0 is a Spoofax Gradle plugin, we are working on that integration for inclusion in a future version.</p>"},{"location":"release/note/2.1.0/","title":"Spoofax 2.1.0 (10-01-2017)","text":"<p>Spoofax 2.1 improves on Spoofax 2.0 with several bug fixes, an implementation of syntactic completions based on SDF3, and addition of the DynSem dynamic semantics specification meta-language.</p> <p>See the corresponding <code>migration guide &lt;2.1.0-migration-guide&gt;</code> for migrating from Spoofax 2.0 to Spoofax 2.1.</p>"},{"location":"release/note/2.1.0/#changes","title":"Changes","text":""},{"location":"release/note/2.1.0/#syntactic-completions","title":"Syntactic Completions","text":"<p>Spoofax now has support for syntactic completions. Syntactic completions are generated automatically from an SDF3 specification. New projects using SDF3 automatically support syntactic completions. Existing projects need to make a few changes, documented in the <code>migration guide &lt;new-completion-framework-migration-guide&gt;</code>{.interpreted-text role=\"ref\"}.</p>"},{"location":"release/note/2.1.0/#dynsem","title":"DynSem","text":"<p>DynSem is a DSL for concise and modular specification of dynamic semantics of programming languages. Fully functional interpreters are automatically derived from dynamic semantics specifications. For more information about DynSem, see the following sources:</p> <ul> <li>Paper</li> <li><code>Documentation &lt;dynsem-index&gt;</code></li> <li><code>Getting started tutorial &lt;dynsem-getting-started&gt;</code>{.interpreted-text     role=\"ref\"}</li> <li>Example language</li> </ul> <p>While DynSem was included in Spoofax 2.0.0, we did not advertise this as it was still under heavy development. Since 2.0.0, the following major improvements were made:</p> <ol> <li>Redesigned semantic component and explication     subsystem</li> <li>Support for tuples</li> <li><code>Updated tutorial for SIMPL &lt;dynsem-getting-started&gt;</code>{.interpreted-text     role=\"ref\"}</li> <li><code>Added support for unit testing and continuous integration of generated interpreters &lt;dynsem-ci&gt;</code>{.interpreted-text     role=\"ref\"}</li> </ol>"},{"location":"release/note/2.2.0/","title":"Spoofax 2.2.0 (18-04-2017)","text":"<p>Spoofax 2.2 improves on Spoofax 2.1 with a new NaBL2 constraint solver which is optimised for performance, improved progress reporting and cancellation in Eclipse, an experimental replacement for <code>sdf2table</code> which fixes several long-standing bugs, improvements to the core API, and several bug fixes.</p> <p>See the corresponding <code>migration guide &lt;2.2.0-migration-guide&gt;</code> for migrating from Spoofax 2.1 to Spoofax 2.2.</p>"},{"location":"release/note/2.2.0/#changes","title":"Changes","text":""},{"location":"release/note/2.2.0/#overall","title":"Overall","text":"<ul> <li>The deprecated libraries and files from Spoofax 2.1.0 have been     removed. If you have not done so yet, follow the     <code>Spoofax 2.1.0 migration guide &lt;2.1.0-migration-guide&gt;</code>{.interpreted-text     role=\"ref\"} to migrate your project to the new Spoofax library.</li> </ul>"},{"location":"release/note/2.2.0/#core-api","title":"Core API","text":"<ul> <li>Improve: Spoofax/190 - Extend API for language     discovery. This     deprecates several methods in the language discovery API, see the     <code>migration guide &lt;2.2.0-migration-guide&gt;</code>{.interpreted-text     role=\"ref\"} on how to migrate your code.</li> <li>Improve: Spoofax/193 - Stratego warnings in Spoofax language     projects with NaBL2     analysis. The excessive     number of warnings from Stratego compilation are now filtered out.</li> <li>Improve: Parsing and analysis can report progress and be cancelled.</li> <li>Improve: Builds now report progress.</li> <li>Fix: Path and project path that are passed to the editor hover     strategy are now consistent with paths passed to other strategies.</li> <li>Fix: Spoofax/187 - Provide simplified builder     API.</li> <li>Fix: Spoofax/188 - Java type error in documented language     processing code.</li> </ul>"},{"location":"release/note/2.2.0/#eclipse","title":"Eclipse","text":"<ul> <li>Upgrade: Eclipse Neon (4.6) is now required.</li> <li>Improve: Added several switches to the     <code>Spoofax (meta)</code> menu for     disabling analyses and builds, to improve usability in cases where     these operations are very slow.</li> <li>Improve: Bind new progress reporting and cancellation in core to     Eclipse progress monitors, enabling reporting of builds and     cancellation of analysis.</li> <li>Fix: Fix cancellation not being propagated in SubMonitors,     preventing cancellation from working in many places.</li> </ul>"},{"location":"release/note/2.2.0/#sdf3","title":"SDF3","text":"<ul> <li>Feature: Re-implemented the parse table generator in Java, removing     the dependency on a platform-specific <code>sdf2table</code> binary, and fixing     several long-standing bugs. This implementation is still being     tested, it is therefore only enabled after opt-in. To enable the new     implementation, set the following option in your     <code>metaborg.yaml</code> file:</li> </ul> <pre><code>language:\nsdf:\nsdf2table: java\n</code></pre> <ul> <li>Improve: Moved the <code>placeholder</code> and <code>pretty-print</code> options in the     <code>metaborg.yaml</code> file to be under     <code>language.sdf</code>, as in:</li> </ul> <pre><code>language:\nsdf:\nplaceholder:\nprefix: \"[[\"\nsuffix: \"]]\"\npretty-print: LangName\n</code></pre>"},{"location":"release/note/2.2.0/#nabl2","title":"NaBL2","text":"<ul> <li>Improve: Introduces a new solver implementation with improved     performance.</li> <li>Improve: Introduces separate signature sections for constructors,     relations, and functions.</li> <li>Deprecate: The types signature, which will be removed in the next     release.</li> </ul>"},{"location":"release/note/2.2.0/#spt","title":"SPT","text":"<ul> <li>Fix: Several origin tracking issues related to section markers.</li> </ul>"},{"location":"release/note/2.2.0/#dynsem","title":"DynSem","text":"<ul> <li>Fix: Analysis crashes on empty rules sections     (#161)</li> <li>Improve: Support for abrupt termination: automatic expansion and     propagation of read-write semantic components with default values</li> <li>Improve: Analysis performance improvements</li> </ul>"},{"location":"release/note/2.2.0/#downloads","title":"Downloads","text":""},{"location":"release/note/2.2.0/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.2.0/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.2.0/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.2.0/org.metaborg.spoofax.eclipse.updatesite-2.2.0-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.2.0/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.2.0</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.2.0/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.2.0/#core-api_1","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.2.0</code></li> </ul>"},{"location":"release/note/2.2.0/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.2.0/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.2.0</code>.</p>"},{"location":"release/note/2.2.1/","title":"Spoofax 2.2.1 (04-05-2017)","text":"<p>Spoofax 2.2.1 is a minor bugfix release.</p>"},{"location":"release/note/2.2.1/#changes","title":"Changes","text":""},{"location":"release/note/2.2.1/#overall","title":"Overall","text":"<ul> <li>Fix: error when generating projects with analysis enabled (which is     enabled by default).</li> <li>Fix: possibly erroneous completions file in spoofax meta library.</li> </ul>"},{"location":"release/note/2.2.1/#downloads","title":"Downloads","text":""},{"location":"release/note/2.2.1/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.2.1/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.2.1/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.2.1/org.metaborg.spoofax.eclipse.updatesite-2.2.1-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.2.1/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.2.1</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.2.1/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.2.1/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.2.1</code></li> </ul>"},{"location":"release/note/2.2.1/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.2.1/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.2.1</code>.</p>"},{"location":"release/note/2.3.0/","title":"Spoofax 2.3.0 (29-09-2017)","text":"<p>Spoofax 2.3 fixes several minor bugs, upgrades to the latest Eclipse and Java versions, includes improvements to SDF3 and NaBL2, and introduces experimental parse table generation and parsing features.</p>"},{"location":"release/note/2.3.0/#changes","title":"Changes","text":""},{"location":"release/note/2.3.0/#overall","title":"Overall","text":"<ul> <li>Improvement: made NaBL2 the default static semantics language.</li> <li>Improvement: put deprecated markers on NaBL+TS and Stratego as     static semantics languages, and SDF2 as syntax language.</li> <li>Improvement: allow configuration of source folders in metaborg.yaml.</li> <li>Improvement: allow multiple languages in source and export entries.</li> <li>Improvement: add dynsem as a compile dependency to newly generated     languages.</li> </ul>"},{"location":"release/note/2.3.0/#language-specification-build","title":"Language specification build","text":"<ul> <li>Fix: occasional NPEs when the build failed.</li> <li>Fix: hidden dependency error when building Stratego concrete syntax     extensions.</li> </ul>"},{"location":"release/note/2.3.0/#eclipse-plugin","title":"Eclipse plugin","text":"<ul> <li>Improvement: updated Eclipse instance generator to generate Eclipse     Oxygen instances.</li> <li>Improvement: updated Eclipse instance generator to include JDK     8u144b01.</li> <li>Improvement: do not reanalyze already analyzed files when opening an     editor.</li> <li>Improvement: use a default configuration if metaborg.yaml is not     present.</li> </ul>"},{"location":"release/note/2.3.0/#nabl2","title":"NaBL2","text":"<ul> <li>Improvement: extended Stratego API to query reference resolution.</li> <li>Improvement: add ? and + operators to regexp syntax for path     well-formedness.</li> <li>Fix: regexp normalization was only one level deep.</li> <li>Fix: non-termination in name resolution in the cases of a direct     cycle between a scope.</li> <li>Update: conform to latest DynSem version.</li> <li>Fix: support all Stratego constructor and sort names, by allowing     dashes and single quotes in sort and constructor names.</li> <li>Fix: do not crash if dynsem properties file is missing.</li> </ul>"},{"location":"release/note/2.3.0/#sdf3","title":"SDF3","text":"<ul> <li>Improvement: more stable SDF3 parser generator.</li> <li>Improvement: new parenthesizer that considers deep priority     conflicts.</li> <li>Improvement: (experimental) support for lazy parse table generation,     where the parse table is generated on-the-fly by the parser.</li> <li>Fix: bug in the SDF3 normalizer for groups of priorities outside of     a chain.</li> <li>Fix: added support for generating the parse table from a     \\\"permissive\\\" grammar</li> <li>Fix: not necessary to specify the parse table as <code>sdf-new.tbl</code> in     the ESV file when using the new parse table generator.</li> </ul>"},{"location":"release/note/2.3.0/#parser","title":"Parser","text":"<ul> <li>Added the new (experimental) SGLR parser implementation JSGLR2.</li> </ul>"},{"location":"release/note/2.3.0/#downloads","title":"Downloads","text":""},{"location":"release/note/2.3.0/#eclipse-plugin_1","title":"Eclipse plugin","text":""},{"location":"release/note/2.3.0/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.3.0/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.3.0/org.metaborg.spoofax.eclipse.updatesite-2.3.0-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.3.0/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.3.0</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.3.0/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.3.0/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.3.0</code></li> </ul>"},{"location":"release/note/2.3.0/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.3.0/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.3.0</code>.</p>"},{"location":"release/note/2.4.0/","title":"Spoofax 2.4.0 (09-01-2018)","text":"<p>Spoofax 2.4 fixes several bugs and includes a program generator.</p>"},{"location":"release/note/2.4.0/#changes","title":"Changes","text":""},{"location":"release/note/2.4.0/#eclipse-plugin","title":"Eclipse Plugin","text":"<ul> <li>Fix: re-parse and re-analyze open editors if the language is     reloaded.</li> </ul>"},{"location":"release/note/2.4.0/#nabl2","title":"NaBL2","text":"<ul> <li>Fix: use deep equality instead of object equality to compare     elements in set constraints.</li> <li>Fix: prevent clashes of variable names with known lower-case     Stratego constructors.</li> <li>Improvement: add strategies to the Stratego API to query references     and declaration associated with AST nodes.</li> <li>Fix: prevent exception traces when hovering over the editor.</li> <li>Fix: bug in Stratego generation when complex terms are used in     occurrences.</li> <li>Fix: bug where editor resolution would only consider leaf nodes, but     not parents if the leafs do not resolve.</li> <li>Fix: bug where sometimes error messages of files were lost.</li> </ul>"},{"location":"release/note/2.4.0/#parser","title":"Parser","text":"<ul> <li>Improvement: latest JSGLR2 performance optimizations.</li> <li>Fix: bug in JSGLR2 where non-default start symbols were not taken     into account.</li> </ul>"},{"location":"release/note/2.4.0/#downloads","title":"Downloads","text":""},{"location":"release/note/2.4.0/#eclipse-plugin_1","title":"Eclipse plugin","text":""},{"location":"release/note/2.4.0/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.4.0/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.4.0/org.metaborg.spoofax.eclipse.updatesite-2.4.0-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.4.0/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.4.0</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.4.0/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.4.0/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.4.0</code></li> </ul>"},{"location":"release/note/2.4.0/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.4.0/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.4.0</code>.</p>"},{"location":"release/note/2.4.1/","title":"Spoofax 2.4.1 (29-01-2018)","text":"<p>Spoofax 2.4.1 is a minor bugfix release.</p>"},{"location":"release/note/2.4.1/#changes","title":"Changes","text":"<ul> <li>Fix: remove dependency on <code>nativebundle</code> from <code>jsglr2</code>, preventing     native binaries (with a cygwin vulnerability) from showing up in     Spoofax Core.</li> <li>Update <code>jackson-core</code>, <code>jackson-databind</code>, <code>jackson-annotations</code>,     <code>jackson-dataformat-yaml</code> dependencies to <code>2.9.3</code> to avoid a     vulnerability in those libraries.</li> <li>Update <code>commons-configuration2</code> to <code>2.2</code>,     <code>commons-configuration2-jackson</code> to <code>0.7.0</code>, and <code>snakeyaml</code> to     <code>1.18</code>, for compatibility with <code>jackson</code> version <code>2.9.3</code>.</li> </ul>"},{"location":"release/note/2.4.1/#downloads","title":"Downloads","text":""},{"location":"release/note/2.4.1/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.4.1/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.4.1/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.4.1/org.metaborg.spoofax.eclipse.updatesite-2.4.1-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.4.1/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.4.1</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.4.1/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.4.1/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.4.1</code></li> </ul>"},{"location":"release/note/2.4.1/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.4.1/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.4.1</code>.</p>"},{"location":"release/note/2.5.0/","title":"Spoofax 2.5.0 (11-09-2018)","text":"<p>Spoofax 2.5 introduces FlowSpec, a new meta-language for intra-procedural data-flow analysis; layout-sensitive parsing in SDF3; and has several small improvements and bug fixes.</p>"},{"location":"release/note/2.5.0/#changes","title":"Changes","text":""},{"location":"release/note/2.5.0/#maven","title":"Maven","text":"<p>We updated the Guice version that Spoofax uses to 4.2.0. This has the cascading effect that we need Maven 3.5.4, since Spoofax is used in a maven plugin. Be sure to have this version of Maven installed, or you will run into <code>MethodNotFoundException</code> s for <code>com.google.inject.internal.*</code>.</p>"},{"location":"release/note/2.5.0/#core","title":"Core","text":"<p>The <code>constraint</code> analyzer was generalized:</p> <ul> <li>The <code>constraint</code> analyzer is now independent of NaBL2, and can be     used as a generic analysis mechanism from Stratego. The analysis     cycle and the Stratego interface to it are defined ans documented in     module <code>libspoofax/analysis/constraint</code>.</li> <li>Fixed a bug where ambiguity errors were not always correctly     reported.</li> </ul>"},{"location":"release/note/2.5.0/#flowspec","title":"FlowSpec","text":"<p>This release introduces FlowSpec, a new meta-language for intra-procedural data-flow analysis. See the documentation of the language for more details.</p>"},{"location":"release/note/2.5.0/#stratego","title":"Stratego","text":"<p>Stratego received some small patches to improve user experience.</p> <ul> <li>Stratego editor now gives warnings when using <code>left</code>, <code>right</code> and a     couple of other variables names as these are also constructors in     libstratego-sglr and interpreted as constructor match patterns.</li> <li>When the Stratego compiler generates names for code generation,     these now start with the source code name if available or with a     constant name related to the language feature (e.g. a <code>where(s)</code> is     turned into <code>?where243;s;!where243</code>). Since some generated names     turn up in a stack trace from a Stratego, this should improve     readability of the stack trace. Complex closures are still named     <code>lifted26</code>, as the compiler cannot replace humans in properly naming     things.</li> </ul>"},{"location":"release/note/2.5.0/#spt","title":"SPT","text":"<p>Problems related to escaping in string terms of expectations are fixed:</p> <ul> <li>Double quotes (<code>\"</code>) in expectation require escaping using     backslashes, but were not unescaped when comparing with actual parse     results. This made correct tests containing double quotes in strings     fail. This is fixed by unescaping the expectation terms.</li> <li>Formatting expectation terms as strings was different than default     ATerms (<code>\"</code> and <code>\\</code> were not escaped), which was confusing when a     test fails and the actual and expected terms were reported. This is     fixed by aligning the SPT expectation terms formatting with default     ATerm formatting.</li> </ul>"},{"location":"release/note/2.5.0/#nabl2","title":"NaBL2","text":"<p>Small usability improvements:</p> <ul> <li>Empty parameter tuples in rules can be omitted.</li> <li>Accidentally writing a dot instead of a comma before a recursive     rule invocation could make that constraint look like a rule without     constraints. Layout is now used to give a warning when such a case     is written.</li> <li>Fix import problems caused by <code>nabl2.runtime</code> exports. The exports     are restricted such that layout syntax and DynSem signatures are not     exported anymore. The sorts defined by the runtime are all prefixed     with <code>NaBL2</code> to prevent accidental merges with sorts from the     importing language.</li> <li>Allow all Stratego identifiers to be used as constructor names.</li> </ul> <p>Solver changes:</p> <ul> <li>Adopt new naming convention, with packages named <code>mb.nabl2.*</code>, and     artifacts named <code>nabl2.*</code>.</li> <li>Add classes for matching and subtitution of terms, independent of     unification.</li> <li>Use the generalized <code>constraint</code> analyzer for the NaBL2 analysis     strategy.</li> </ul>"},{"location":"release/note/2.5.0/#sdf3","title":"SDF3","text":"<p>The experimental support for generating Scala case classes from an SDF3 specification was removed. It was incomplete, unmaintained and unused.</p> <p>Added support for <code>Layout Declarations &lt;layout-declarations&gt;</code>{.interpreted-text role=\"ref\"} for layout-sensitive parsing and pretty-printing.</p>"},{"location":"release/note/2.5.0/#eclipse","title":"Eclipse","text":"<p>Small fixes and improvements:</p> <ul> <li>Execute builders for languages which have no analysis defined.     Previously builders would always wait until an analysis result was     produced.</li> <li>Cancel running SPT test suites. It is now possible to cancel a     running SPT test suite in the progress window.</li> </ul>"},{"location":"release/note/2.5.0/#intellij","title":"IntelliJ","text":"<p>Small fixes and improvements:</p> <ul> <li>Can now be installed into any latest IntelliJ, not just the last     version we tested</li> <li>By default runs in IntelliJ 2018.1.1</li> <li>Simplified project structure</li> <li>Updated dependencies</li> <li>Changes to support Java 9 in the future</li> </ul>"},{"location":"release/note/2.5.0/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.0/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.0/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.0/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.0/org.metaborg.spoofax.eclipse.updatesite-2.5.0-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.0/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.0</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.0/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.0/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.0</code></li> </ul>"},{"location":"release/note/2.5.0/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.0/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.0</code>.</p>"},{"location":"release/note/2.5.1/","title":"Spoofax 2.5.1 (02-10-2018)","text":"<p>Spoofax 2.5.1 is a minor bugfix release.</p>"},{"location":"release/note/2.5.1/#changes","title":"Changes","text":""},{"location":"release/note/2.5.1/#core","title":"Core","text":"<ul> <li>Fix: (Spoofax/242)     <code>StrategoMix.def</code> not found error, after incrementally building a     language specification project with a Stratego mix grammar.</li> </ul>"},{"location":"release/note/2.5.1/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.1/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.1/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.1/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.1/org.metaborg.spoofax.eclipse.updatesite-2.5.1-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.1/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.1</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.1/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.1/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.1</code></li> </ul>"},{"location":"release/note/2.5.1/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.1/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.1</code>.</p>"},{"location":"release/note/2.5.10/","title":"Spoofax 2.5.10 (07-07-2020)","text":"<p>Spoofax 2.5.10 contains several smaller improvements.</p>"},{"location":"release/note/2.5.10/#changes","title":"Changes","text":""},{"location":"release/note/2.5.10/#overall","title":"Overall","text":"<ul> <li> <p>Update Apache VFS2 to 2.6.0</p> </li> <li> <p>Support for TypeSmart was removed. We anticipate a more useable type     analysis for Stratego in the form of a gradual type system.</p> <p>The <code>metaborg.yaml</code> file of a generated project used to contain a <code>debug: typesmart: false</code>. This was to turn off the TypeSmart dynamic analysis by default. This analysis would stop any Stratego code when it tried to construct a tree that did not conform to the grammar of the project.</p> <p>To our knowledge TypeSmart was not used in any active Spoofax project. It did, however, slow down the build time of all Spoofax projects, because extraction of the grammar into a TypeSmart readable format had to be done even if the analysis was off for that project. These two points, and the anticipation of a gradual type system for Stratego, were the reasons to drop TypeSmart support.</p> </li> </ul>"},{"location":"release/note/2.5.10/#sdf3","title":"SDF3","text":"<p>Lexical and context-free sort declarations: In SDF3 you can now explicitly declare your sorts. Declare lexical sorts in a <code>lexical sorts</code> block, and context-free sorts in a <code>context-free sorts</code> block. Sorts declared in a kernel <code>sorts</code> block default to declaring context-free sorts until a suffix such as <code>-LEX</code> is added. Note that you have to use <code>sdf2table: java</code> to support lexical sorts.</p>"},{"location":"release/note/2.5.10/#statix","title":"Statix","text":"<ul> <li>New project that use Statix automatically have the Statix signature     generator enabled. For this to work properly, declare your lexical     and context-free sorts in SDF3 explicitly. See the     <code>Statix signature generator &lt;statix-signature-generator&gt;</code>{.interpreted-text     role=\"ref\"} documentation for more information.</li> <li>Statix specifications are now compiled as much as possible, even if     there are errors in some files. Errors in Statix files that are not     actually imported, do not cause analysis to fail on an empty     specification anymore.</li> <li>The AST property [type]{.title-ref} is now a built-in, which is     automatically used in the default editor hover strategy.</li> </ul>"},{"location":"release/note/2.5.10/#stratego","title":"Stratego","text":"<p>Combined compiled Stratego and helper code Compilation of Stratego and helper code written in Java (in <code>src/main/strategies</code>) is now combined in a single jar file per Spoofax language instead of two. See the migration guide for more information on what to change in your Spoofax project.</p>"},{"location":"release/note/2.5.10/#spt","title":"SPT","text":"<p>SPT gains support for the <code>parse ambiguous</code> expectation, which succeeds when a fragment parses successfully but with ambiguities. Tests with the <code>parse succeeds</code> expectation will now fail when the input parses ambiguously. To write tests for ambiguous parses, use the <code>parse ambiguous</code> expectation instead.</p>"},{"location":"release/note/2.5.10/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.10/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.10/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.10/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.10/org.metaborg.spoofax.eclipse.updatesite-2.5.10-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.10/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.10</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.10/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.10/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.10</code></li> </ul>"},{"location":"release/note/2.5.10/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.10/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.10</code>.</p>"},{"location":"release/note/2.5.11/","title":"Spoofax 2.5.11 (17-07-2020)","text":"<p>Spoofax 2.5.11 contains a dependency bugfix.</p>"},{"location":"release/note/2.5.11/#changes","title":"Changes","text":""},{"location":"release/note/2.5.11/#overall","title":"Overall","text":"<ul> <li>Exclude the <code>hadoop-hdfs-client</code> transitive dependency from Apache     VFS2</li> </ul>"},{"location":"release/note/2.5.11/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.11/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.11/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.11/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.11/org.metaborg.spoofax.eclipse.updatesite-2.5.11-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.11/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.11</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.11/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.11/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.11</code></li> </ul>"},{"location":"release/note/2.5.11/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.11/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.11</code>.</p>"},{"location":"release/note/2.5.12/","title":"Spoofax 2.5.12 (08-10-2020)","text":"<p>Spoofax 2.5.12 contains an experimental gradual type system for Stratego, performance improvements to NaBL2 and Statix, and updates to Eclipse installations and their embedded JREs.</p>"},{"location":"release/note/2.5.12/#changes","title":"Changes","text":""},{"location":"release/note/2.5.12/#stratego","title":"Stratego","text":"<p>Stratego has two new reserved words: <code>cast</code> and <code>is</code>. Local variables can be reserved words if they start with <code>'</code>, so you can use <code>'cast</code> and <code>'is</code>.</p> <p>Under the Stratego language options in your <code>metaborg.yaml</code> file you can turn on the gradual type system, if you use the incremental compiler. This option is <code>gradual: static</code>, and only tests the types statically. The default is <code>gradual: none</code> right now, meaning the gradual type system is not on by default. The <code>is</code> dynamic type check is not yet supported at runtime, you may get Java compilation errors when attempting to compile Stratego code with that. Dynamic type casts inserted by the gradual type system are also forthcoming, runtime support for this is not yet ready.</p>"},{"location":"release/note/2.5.12/#nabl2","title":"NaBL2","text":"<ul> <li>NaBL2 supports a new resolution algorithm based on fexid-point     environment computation instead of graph search, which can be     enabled by adding <code>strategy environments</code> to the <code>name-resolution</code>     signature section. It has much better performance characteristics,     especially when dealing with mutually importing scopes and     transitive imports. Compared the the search-based, the     environment-based algorithm can get stuck on scope graphs with     cycles involving scopes importing references that can be resolved     via that same scope. Note that the environment-based algorithm may     increase memory usage. The default remains the search-based     algorithm.</li> <li>If a file was already analyzed in the editor, it is not reanalyzed     on save anoymore.</li> </ul>"},{"location":"release/note/2.5.12/#statix","title":"Statix","text":"<ul> <li>Analysis times of large, multi-file Statix specifications has     improved significantly.</li> <li>If a file was already analyzed in the editor, it is not reanalyzed     on save anoymore.</li> </ul>"},{"location":"release/note/2.5.12/#eclipse","title":"Eclipse","text":"<ul> <li>Premade Eclipse installations have been updated from Eclipse Photon     to Eclipse 2020-6.</li> <li>Premade Eclipse installations for 32-bit Linux are no longer     created.</li> <li>Embedded JRE in premade Eclipse installations has been updated from     8u162 (Oracle JRE) to 8u265-b01 (AdoptOpenJDK).</li> </ul>"},{"location":"release/note/2.5.12/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.12/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.12/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.12/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.12/org.metaborg.spoofax.eclipse.updatesite-2.5.12-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.12/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.12</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.12/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.12/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.12</code></li> </ul>"},{"location":"release/note/2.5.12/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.12/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.12</code>.</p>"},{"location":"release/note/2.5.13/","title":"Spoofax 2.5.13 (20-11-2020)","text":"<p>Spoofax 2.5.13 contains a couple of small improvements.</p>"},{"location":"release/note/2.5.13/#changes","title":"Changes","text":""},{"location":"release/note/2.5.13/#sdf3","title":"SDF3","text":"<p><code>prefer</code> and <code>avoid</code> are now deprecated. Usages of the operators will be marked with a deprecation warning.</p>"},{"location":"release/note/2.5.13/#parser","title":"Parser","text":"<p>The JSGLR2 parser variants now report warnings on ambiguously parsed substrings. This includes ambiguities in lexical and layout syntax that do not result into <code>amb</code> nodes in the AST.</p>"},{"location":"release/note/2.5.13/#spt","title":"SPT","text":"<p>The <code>run</code> expectation now allows to call strategies with term arguments. It\\'s now also possible to test if a strategy failed. See the SPT documentation for more details.</p>"},{"location":"release/note/2.5.13/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.13/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.13/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.13/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.13/org.metaborg.spoofax.eclipse.updatesite-2.5.13-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.13/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.13</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.13/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.13/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.13</code></li> </ul>"},{"location":"release/note/2.5.13/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.13/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.13</code>.</p>"},{"location":"release/note/2.5.14/","title":"Spoofax 2.5.14 (16-12-2020)","text":"<p>Spoofax 2.5.14 was released.</p>"},{"location":"release/note/2.5.14/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.14/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.14/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.14/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.14/org.metaborg.spoofax.eclipse.updatesite-2.5.14-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.14/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.14</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.14/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.14/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.14</code></li> </ul>"},{"location":"release/note/2.5.14/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.14/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.14</code>.</p>"},{"location":"release/note/2.5.15/","title":"Spoofax 2.5.15 (11-05-2021)","text":"<p>Spoofax 2.5.15 contains a couple of small improvements and bug fixes, and supports the old SDF2-based parse table generator on macOS Catalina (10.15) and above.</p> <p>See the corresponding migration guide for migrating from Spoofax 2.5.14 to Spoofax 2.5.15.</p>"},{"location":"release/note/2.5.15/#changes","title":"Changes","text":""},{"location":"release/note/2.5.15/#macos","title":"macOS","text":"<ul> <li>On macOS, Spoofax temporarily requires     Docker and     <code>coreutils</code> when building Spoofax on macOS Catalina, Big Sur, or     newer. (This is only when you build Spoofax yourself instead of     downloading it for this website, it does not influence building     Spoofax projects.)</li> </ul>"},{"location":"release/note/2.5.15/#sdf3","title":"SDF3","text":"<ul> <li>Fixed tree indexes in layout constraints/declarations to make them     0-based.</li> <li>The generate namespaced grammar option will now generate the     namespaced grammar in <code>src-gen</code>. This feature can also be set to     generate the grammar automatically similar to other extractions of     the grammar like Stratego signatures. See the     documentation     for more information. Sadly, due to a bug in the changes for     automatic generation, a build in Eclipse of a language project with     namespaced grammar will work, but the build of that project with     Maven will not work.</li> </ul>"},{"location":"release/note/2.5.15/#statix","title":"Statix","text":"<ul> <li>Fixed origin tracking in Statix injection explication for new     projects that caused the top-level term of an AST to be missing when     a Stratego strategy is applied to an analyzed AST in an SPT test.</li> <li>Add a menu action to view the scope graph resulting from Statix     analysis.</li> <li>Deprecate namespaces, occurrences and query sugar.</li> <li>Fix bug in evaluation of <code>try</code> construct.</li> <li>Improvements to memory usage and runtime of the solver.</li> <li>Improve rule overlap handling: consider variables already bound to     the left more specific than concrete patterns, to keep with     left-to-right specificity.</li> <li>Add configuration settings to control trace length and term depth in     error messages.</li> </ul>"},{"location":"release/note/2.5.15/#stratego","title":"Stratego","text":"<ul> <li>The previously advertised incremental compiler was considered too     slow and attempts to make it faster made it less stable. It is     currently not recommended for general use, while we develop a new     version. The documentation on how to use contains a similar warning     now.</li> </ul>"},{"location":"release/note/2.5.15/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.15/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.15/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.15/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.15/org.metaborg.spoofax.eclipse.updatesite-2.5.15-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.15/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.15</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.15/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.15/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.15</code></li> </ul>"},{"location":"release/note/2.5.15/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.15/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.15</code>.</p>"},{"location":"release/note/2.5.16/","title":"Spoofax 2.5.16 (04-06-2021)","text":"<p>Spoofax 2.5.16 contains a couple of small improvements and bug fixes.</p>"},{"location":"release/note/2.5.16/#changes","title":"Changes","text":""},{"location":"release/note/2.5.16/#sdf3","title":"SDF3","text":"<ul> <li>Fix a bug with the automatic generation of namespaced grammars, which was introduced in the previous release.</li> </ul>"},{"location":"release/note/2.5.16/#statix","title":"Statix","text":"<ul> <li>Added <code>stc-get-ast-ref</code> rule to the Stratego API, which can be used to query <code>ref</code> properties.</li> <li>The Stratego primitives now issue console warnings when invalid labels or properties are used.</li> <li>Fixed a bug where <code>stx-get-scopegraph-data</code> would return unification variables instead of their values.</li> <li>Changed the default data order to <code>true</code>, to make queries where only a label order is provided apply shadowing as expected.</li> <li>Added a menu option to execute tests with the concurrent solver.</li> <li>Fixed a completeness bug in the traditional solver when executing queries in dataWf or dataLeq predicates.</li> </ul>"},{"location":"release/note/2.5.16/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.16/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.16/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.16/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.16/org.metaborg.spoofax.eclipse.updatesite-2.5.16-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.16/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.16</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.16/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.16/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.16</code></li> </ul>"},{"location":"release/note/2.5.16/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.16/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.16</code>.</p>"},{"location":"release/note/2.5.17/","title":"Spoofax 2.5.17 (06-07-2022)","text":"<p>Spoofax 2.5.17 contains the incremental Statix solver, Stratego 2, and several small improvements and dependency updates.</p>"},{"location":"release/note/2.5.17/#changes","title":"Changes","text":"<ul> <li>Fix issues with the <code>implodePT</code> and <code>sdf2table</code> Docker substitution scripts for MacOS 64-bit</li> <li>Update Apache Commons Compress dependency to 1.21</li> <li>Update Apache Commons IO dependency to 2.11.0</li> <li>Update Guice dependencies to 4.2.3</li> <li>Update Guava dependency to 30.1</li> <li>Add Guava FailureAccess dependency, required by Guava &gt;= 27.0</li> </ul>"},{"location":"release/note/2.5.17/#statix","title":"Statix","text":"<ul> <li>Integrate the Incremental Solver in Spoofax.</li> <li>Add menu options to inspect Term Properties.</li> <li>Fix issue where edges were closed twice in incremental solver when having debug log enabled.</li> <li>Deprecate the <code>concurrent</code> property in favor of the <code>mode</code> (for language projects) or <code>modes</code> (for example projects) properties.</li> <li>Allow singleton properties to be set to the same value multiple times.</li> <li>Reduce number of cascading messages (can be disabled using <code>runtime.statix.suppress-cascading-errors: false</code>).</li> <li>Show delay reasons and prevented completions on messages for unsolved constraints.</li> <li>Add <code>eq(term)</code> lambda sugar.</li> <li>Add <code>runtime.statix.test-log</code> option to show Statix test logging in the console.</li> <li>Fix bug where solver with return-on-first-error enabled would also return if the first failing constraint had a non-error message kind.</li> <li>Fix several serialization issues.</li> </ul>"},{"location":"release/note/2.5.17/#stratego","title":"Stratego","text":"<ul> <li>Stratego 2 was introduced as a new meta-language based on Stratego 1, the incremental compiler for Stratego, and the gradual type system developed for Stratego, packaged as one project under a single name. There is a migration guide from Stratego (1) to Stratego 2 under the How-Tos. This gradually typed version of Stratego comes with a standard library that also has gradual types. The editor will give underline where casts are inserted with notes. </li> <li>Stratego 2: Added the <code>&lt;*</code> (\"left try-some\") strategy combinator that tries to apply the left strategy, then the right, and only fails if both fail. <code>a &lt;* b</code> is sugar for <code>a &lt; b &lt;+ id + b</code>. </li> <li>Origin tracking is now documented in a page in the Background section of the website.</li> </ul>"},{"location":"release/note/2.5.17/#sdf","title":"SDF","text":"<ul> <li>Signature generator does not generate signatures for files whose module name ends with <code>_StrategoMix</code>.</li> </ul>"},{"location":"release/note/2.5.17/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.17/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.17/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.17/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.17/org.metaborg.spoofax.eclipse.updatesite-2.5.17-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.17/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.17</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.17/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.17/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.17</code></li> </ul>"},{"location":"release/note/2.5.17/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.17/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.17</code>.</p>"},{"location":"release/note/2.5.18/","title":"Spoofax 2.5.18 (14-11-2022)","text":"<p>Spoofax 2.5.18 updates several dependencies to avoid vulnerabilities.</p>"},{"location":"release/note/2.5.18/#changes","title":"Changes","text":"<p>The following dependencies were updated:</p> <ul> <li><code>org.apache.commons:commons-text</code>: 1.8 -&gt; 1.10.0</li> <li><code>com.fasterxml.jackson.core:jackson-core</code>: 2.12.6 -&gt; 2.14.0</li> <li><code>com.fasterxml.jackson.core:jackson-databind</code>: 2.12.6.1 -&gt; 2.14.0</li> <li><code>com.fasterxml.jackson.core:jackson-annotations</code>: 2.12.6 -&gt; 2.14.0</li> <li><code>com.fasterxml.jackson.dataformat:jackson-dataformat-yaml</code>: 2.12.6 -&gt; 2.14.0</li> <li><code>org.yaml:snakeyaml</code>: 1.26 -&gt; 1.33</li> <li><code>com.virtlink.commons:commons-configuration2-jackson</code>: 0.11.0 -&gt; 1.0.0</li> </ul>"},{"location":"release/note/2.5.18/#fixes","title":"Fixes","text":""},{"location":"release/note/2.5.18/#statix","title":"Statix","text":"<ul> <li>Fix non-deterministic ordering between non-linear variables and constants</li> </ul>"},{"location":"release/note/2.5.18/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.18/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.18/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.18/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.18/org.metaborg.spoofax.eclipse.updatesite-2.5.18-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.18/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.18</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.18/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.18/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.18</code></li> </ul>"},{"location":"release/note/2.5.18/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.18/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.18</code>.</p>"},{"location":"release/note/2.5.2/","title":"Spoofax 2.5.2 (12-03-2019)","text":"<p>Spoofax 2.5.2 is a minor bugfix and performance improvement release.</p>"},{"location":"release/note/2.5.2/#changes","title":"Changes","text":""},{"location":"release/note/2.5.2/#nabl2","title":"NaBL2","text":"<p>A bug introduced in 2.5.2 would remove the parse error in the editor as soon as analysis failed. This bug has been fixed.</p>"},{"location":"release/note/2.5.2/#flowspec","title":"FlowSpec","text":"<p>A whole host of bugs has been fixed in FlowSpec, mostly ones that lead to no clear error message. Much of the system has also been optimized for speed.</p>"},{"location":"release/note/2.5.2/#stratego","title":"Stratego","text":"<p>Separate compilation for Stratego was added in this release. It is currently still experimental. It is documented as a separate item under the Stratego documentation, including instructions on how to opt-in to it and what its limitations are.</p> <p>The Stratego primitives <code>all</code>, <code>some</code> and <code>one</code> sometimes lost annotations and origins of list tails when an element in the list was transformed. This bug has been fixed.</p> <p>The Stratego editor used to give spurious errors on missing variable definitions if those were list variables that were bound in a concrete syntax pattern. This long-standing bug has been fixed in this release.</p>"},{"location":"release/note/2.5.2/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.2/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.2/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.2/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.2/org.metaborg.spoofax.eclipse.updatesite-2.5.2-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.2/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.2</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.2/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.2/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.2</code></li> </ul>"},{"location":"release/note/2.5.2/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.2/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.2</code>.</p>"},{"location":"release/note/2.5.3/","title":"Spoofax 2.5.3 (02-05-2019)","text":"<p>Spoofax 2.5.3 is a minor release with bugfixes, performance improvements, and new small and/or experimental features.</p>"},{"location":"release/note/2.5.3/#changes","title":"Changes","text":""},{"location":"release/note/2.5.3/#overall","title":"Overall","text":"<ul> <li>Added support for getting the selected term in Stratego     builders/transformations. In the builder tuple     <code>(node, _, ast, path, projectPath)</code>, the first term (<code>node</code>) is now     the selected term when a builder is executed in the context of an     editor with a selection. The term is selected by finding the     outermost term that has an origin that fits in the selection.</li> <li>Fixed a bug that prevented source transformations from being run if     context or analysis were missing.</li> <li>Changed constraint analyzer to support more multi-file scenarios.</li> </ul>"},{"location":"release/note/2.5.3/#jsglr2","title":"JSGLR2","text":"<ul> <li>Added an incremental variant of the JSGLR2 parser (experimental).</li> </ul>"},{"location":"release/note/2.5.3/#nabl2","title":"NaBL2","text":"<ul> <li>Improved preformance of AST resolution lookups.</li> </ul>"},{"location":"release/note/2.5.3/#statix-experimental","title":"Statix (experimental)","text":"<ul> <li>Fixed bugs and improved performance.</li> </ul>"},{"location":"release/note/2.5.3/#eclipse","title":"Eclipse","text":"<ul> <li>Added a lifecycle mapping that adds a Spoofax nature to an imported     spoofax-project.</li> </ul>"},{"location":"release/note/2.5.3/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.3/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.3/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.3/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.3/org.metaborg.spoofax.eclipse.updatesite-2.5.3-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.3/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.3</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.3/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.3/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.3</code></li> </ul>"},{"location":"release/note/2.5.3/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.3/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.3</code>.</p>"},{"location":"release/note/2.5.4/","title":"Spoofax 2.5.4 (08-05-2019)","text":"<p>Spoofax 2.5.4 is a minor bugfix release.</p>"},{"location":"release/note/2.5.4/#changes","title":"Changes","text":""},{"location":"release/note/2.5.4/#maven","title":"Maven","text":"<ul> <li>Fixed failing SPT tests failing the build immediately. All SPT files     are processed and a summary of how many tests failed is shown at the     end.</li> <li>Fixed class loading errors at the end of Maven builds.</li> <li>Fixed application icon from showing up when building languages on     some platforms.</li> </ul>"},{"location":"release/note/2.5.4/#statix","title":"Statix","text":"<ul> <li>Fix Statix analysis crash when detailed logging is enabled.</li> </ul>"},{"location":"release/note/2.5.4/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.4/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.4/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.4/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.4/org.metaborg.spoofax.eclipse.updatesite-2.5.4-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.4/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.4</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.4/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.4/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.4</code></li> </ul>"},{"location":"release/note/2.5.4/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.4/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.4</code>.</p>"},{"location":"release/note/2.5.5/","title":"Spoofax 2.5.5 (23-05-2019)","text":"<p>Spoofax 2.5.5 is a minor bugfix release. There are a few incompatiable changes in Statix, which are described in the <code>migration guide &lt;2.5.5-migration-guide&gt;</code>.</p>"},{"location":"release/note/2.5.5/#changes","title":"Changes","text":""},{"location":"release/note/2.5.5/#overall","title":"Overall","text":"<ul> <li>Do not throw away error messages in unchanged files if other files     changed, when using constraint analyzer.</li> </ul>"},{"location":"release/note/2.5.5/#jsglr","title":"JSGLR","text":"<ul> <li>Add missing location information on sublists.</li> </ul>"},{"location":"release/note/2.5.5/#statix","title":"Statix","text":"<ul> <li>Improve speed of normalization.</li> <li>Add AST properties and editor reference resolution.</li> <li>Regular expression and label order are direct parameters to queries.     It is not possible anymore to pass an arbitary predicate there.</li> <li>Special path constraints are removed in favour of concrete path     terms that can be matched as terms.</li> <li>Functional constraints can only have a single output.</li> <li>Namespace based resolution short-hands must contain a occurrence     literal, and explicit resolution policies.</li> </ul>"},{"location":"release/note/2.5.5/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.5/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.5/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.5/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.5/org.metaborg.spoofax.eclipse.updatesite-2.5.5-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.5/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.5</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.5/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.5/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.5</code></li> </ul>"},{"location":"release/note/2.5.5/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.5/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.5</code>.</p>"},{"location":"release/note/2.5.6/","title":"Spoofax 2.5.6 (24-05-2019)","text":"<p>Spoofax 2.5.6 is a minor bugfix release.</p>"},{"location":"release/note/2.5.6/#changes","title":"Changes","text":""},{"location":"release/note/2.5.6/#overall","title":"Overall","text":""},{"location":"release/note/2.5.6/#statix","title":"Statix","text":"<ul> <li>Fix a crash in single-file analysis.</li> <li>Fix several bugs in scope extension checking.</li> <li>Fix bug in rule application that dropped cause.</li> </ul>"},{"location":"release/note/2.5.6/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.6/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.6/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.6/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.6/org.metaborg.spoofax.eclipse.updatesite-2.5.6-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.6/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.6</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.6/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.6/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.6</code></li> </ul>"},{"location":"release/note/2.5.6/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.6/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.6</code>.</p>"},{"location":"release/note/2.5.7/","title":"Spoofax 2.5.7 (26-06-2019)","text":"<p>Spoofax 2.5.7 includes minor bugfixes and improvements to the experimental Stratego separate compiler.</p>"},{"location":"release/note/2.5.7/#changes","title":"Changes","text":""},{"location":"release/note/2.5.7/#flowspec","title":"FlowSpec","text":"<p>Bugfix: Names with namespaces were broken in an earlier version during performance optimization. The error would like: <code>java.lang.AssertionError: Unrecognised Namespace: Namespace(\"Var\")</code>.</p>"},{"location":"release/note/2.5.7/#stratego","title":"Stratego","text":"<p>Stratego separate compilation is now switched to the new system. It no longer has any limitations that were previously mentioned. Do note that separate compilation will give the same stricter error messages that the editor does: You need to import anything you use, you cannot use something that another module imports that imports your module.</p>"},{"location":"release/note/2.5.7/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.7/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.7/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.7/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.7/org.metaborg.spoofax.eclipse.updatesite-2.5.7-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.7/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.7</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.7/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.7/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.7</code></li> </ul>"},{"location":"release/note/2.5.7/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.7/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.7</code>.</p>"},{"location":"release/note/2.5.8/","title":"Spoofax 2.5.8 (28-04-2020)","text":"<p>Spoofax 2.5.8 includes several bugfixes and improvements.</p>"},{"location":"release/note/2.5.8/#changes","title":"Changes","text":""},{"location":"release/note/2.5.8/#sdf","title":"SDF","text":"<ul> <li>The Java version of sdf2table is now slightly faster and takes up     less peak memory due to improvements in writing away the parsetable     to file.</li> <li>The old (Aster based) version of make-permissive (to add error     recovery to your grammar) used to be called in a way that create a     small memory leak, which would compound over time with subsequent     builds. This is has now been fixed. The old version of     make-permissive is only in effect if you use <code>sdf2table: c</code> in your     <code>metaborg.yaml</code> file.</li> </ul>"},{"location":"release/note/2.5.8/#parser","title":"Parser","text":"<ul> <li>Add two experimental variants to the JSGLR2 parser: <code>recovery</code> and     <code>recovery-incremental</code>.</li> <li>Add Unicode support to the JSGLR1 and JSGLR2 parsers. The     meta-languages themselves do not support Unicode yet, because they     are bootstrapped with and old version of SDF3. However, other     languages built with Spoofax can use Unicode.</li> <li>Add logging to the JSGLR2 parser. Configure by setting     <code>language.sdf.jsglr2-logging</code> to <code>all</code>, <code>none</code>, <code>minimal</code>, <code>parsing</code>     or <code>recovery</code> in <code>metaborg.yaml</code>.</li> </ul>"},{"location":"release/note/2.5.8/#programmatic-api","title":"Programmatic API","text":"<ul> <li><code>TermFactory</code> for building Stratego terms now supports a builder for     lists that creates an arraylist-like structure instead of the     standard linkedlist-like structure. This is typically more efficient     for building stratego list terms in Java.</li> <li>Add <code>org.spoofax.terms.util.TermUtils</code> class with functions for     working with terms. This replaces the equivalent (now deprecated)     functions in <code>org.spoofax.interpreter.core.Tools</code>.</li> </ul>"},{"location":"release/note/2.5.8/#nabl2","title":"NaBL2","text":"<ul> <li>Improve error message location when scopes are used as term indices.</li> <li>Dropped support for polymorphism, which was unsound.</li> <li>Small improvements to solver performance.</li> <li>Add support for external calls for language with Stratego JAR     compilation.</li> </ul>"},{"location":"release/note/2.5.8/#statix","title":"Statix","text":"<ul> <li><code>Ability to automatically generate &lt;statix-signature-generator&gt;</code>{.interpreted-text     role=\"ref\"} Statix signatures from SDF3 specifications.</li> <li>Add support for importing other modules in Statix specifications.</li> <li>Add support for custom messages, and a <code>try</code> construct for warnings     and notes.</li> <li>Add support for adding multiple values to AST properties.</li> <li>Improve disunification support in the solver.</li> <li>Extend reserved keywords to fix parsing problems.</li> <li>Several smaller bugfixes.</li> </ul>"},{"location":"release/note/2.5.8/#overall","title":"Overall","text":"<ul> <li>Fixed several issues with files not being released properly, causing     file I/O errors on Windows.</li> </ul>"},{"location":"release/note/2.5.8/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.8/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.8/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.8/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.8/org.metaborg.spoofax.eclipse.updatesite-2.5.8-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.8/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.8</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.8/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.8/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.8</code></li> </ul>"},{"location":"release/note/2.5.8/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.8/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.8</code>.</p>"},{"location":"release/note/2.5.9/","title":"Spoofax 2.5.9 (08-05-2020)","text":"<p>Spoofax 2.5.9 includes dependency upgrades.</p>"},{"location":"release/note/2.5.9/#changes","title":"Changes","text":""},{"location":"release/note/2.5.9/#overall","title":"Overall","text":"<p>The following dependencies of Spoofax Core have been updated to the latest version:</p> <ul> <li><code>com.netflix.rxjava:rxjava:0.20.7</code> -&gt;     <code>io.reactivex.rxjava3:rxjava:3.0.2</code><ul> <li>New transitive dependency:     <code>org.reactivestreams:reactive-streams:1.0.3</code></li> </ul> </li> <li><code>org.apache.commons:commons-configuration2:2.2</code> -&gt;     <code>org.apache.commons:commons-configuration2:2.7</code><ul> <li>New transitive dependency: <code>org.apache.commons:commons-text:1.8</code></li> </ul> </li> <li><code>com.virtlink.commons:commons-configuration2-jackson:0.7.0</code> -&gt;     <code>com.virtlink.commons:commons-configuration2-jackson:0.10.0</code></li> <li><code>com.fasterxml.jackson.core:jackson-core:2.9.5</code> -&gt;     <code>com.fasterxml.jackson.core:jackson-core:2.11.0</code></li> <li><code>com.fasterxml.jackson.core:jackson-databind:2.9.5</code> -&gt;     <code>com.fasterxml.jackson.core:jackson-databind:2.11.0</code></li> <li><code>com.fasterxml.jackson.core:jackson-annotations:2.9.5</code> -&gt;     <code>com.fasterxml.jackson.core:jackson-annotations:2.11.0</code></li> <li><code>com.fasterxml.jackson.core:jackson-dataformat-yaml:2.9.5</code> -&gt;     <code>com.fasterxml.jackson.core:jackson-dataformat-yaml:2.11.0</code></li> <li><code>org.yaml:snakeyaml:1.18</code> -&gt; <code>org.yaml:snakeyaml:1.26</code></li> </ul> <p>The following dependencies of Spoofax-Meta Core have been updated:</p> <ul> <li><code>org.apache.commons:commons-compress:1.16.1</code> -&gt;     <code>org.apache.commons:commons-compress:1.20</code></li> </ul>"},{"location":"release/note/2.5.9/#downloads","title":"Downloads","text":""},{"location":"release/note/2.5.9/#eclipse-plugin","title":"Eclipse plugin","text":""},{"location":"release/note/2.5.9/#premade-eclipse-installations","title":"Premade Eclipse installations","text":"<p>With embedded JRE:</p> <ul> <li> macOS 64-bit with embedded JVM</li> <li> Linux 64-bit with embedded JVM</li> <li> Windows 64-bit with embedded JVM</li> <li> Windows 32-bit with embedded JVM</li> </ul> <p>Without embedded JRE:</p> <ul> <li> macOS 64-bit</li> <li> Linux 64-bit</li> <li> Windows 64-bit</li> <li> Windows 32-bit</li> </ul>"},{"location":"release/note/2.5.9/#update-site","title":"Update site","text":"<ul> <li>Eclipse update site: <code>https://artifacts.metaborg.org/content/unzip/releases-unzipped/org/metaborg/org.metaborg.spoofax.eclipse.updatesite/2.5.9/org.metaborg.spoofax.eclipse.updatesite-2.5.9-assembly.zip-unzip/</code></li> <li>Eclipse update site archive</li> </ul>"},{"location":"release/note/2.5.9/#intellij-plugin","title":"IntelliJ plugin","text":"<ul> <li>IntelliJ update site: <code>https://artifacts.metaborg.org/service/local/artifact/maven/redirect?r=releases&amp;g=org.metaborg&amp;a=org.metaborg.intellij.dist&amp;p=zip&amp;v=2.5.9</code></li> <li>IntelliJ update site archive</li> </ul>"},{"location":"release/note/2.5.9/#command-line-utilities","title":"Command-line utilities","text":"<ul> <li>Sunshine JAR</li> <li>SPT testrunner JAR</li> </ul>"},{"location":"release/note/2.5.9/#core-api","title":"Core API","text":"<ul> <li>Spoofax Core Uber JAR</li> <li>Spoofax Core uber Maven artifact: <code>org.metaborg:org.metaborg.spoofax.core.uber:2.5.9</code></li> </ul>"},{"location":"release/note/2.5.9/#strategoxt","title":"StrategoXT","text":"<ul> <li>Stratego/XT distribution</li> <li>Stratego/XT JAR</li> </ul>"},{"location":"release/note/2.5.9/#maven-artifacts","title":"Maven artifacts","text":"<p>Maven artifacts can be found on our artifact server. The Maven version used for this release is <code>2.5.9</code>.</p>"},{"location":"release/note/vnext/","title":"Spoofax vNext","text":"<p>These are the release notes for the upcoming version of Spoofax.</p> <p>See the corresponding migration guide for migrating from Spoofax vPrev to Spoofax vNext.</p>"},{"location":"release/note/vnext/#changes","title":"Changes","text":""},{"location":"support/","title":"Support","text":"<p>Spoofax is an open source project. We welcome contributions from the community.</p> <p>Spoofax is developed by the TU Delft Programming Languages group. We do our best to make Spoofax usable by everyone and to help you when you encounter issues. However, our resources are limited, so please be patient.</p>"},{"location":"support/#fontawesome-solid-question-circle-i-have-a-question","title":":fontawesome-solid-question-circle:\u00a0 I have a question","text":"<p>The search functionality of this documentation should bring you right to a relevant How-to or Reference page.</p> <p>If this doesn't answer your question, please join us in the SLDE/#spoofax-users Slack channel and ask your question there. To get access, drop us a line.</p> <p>Please do not make an issue with your question on the Github repository.</p>"},{"location":"support/#i-found-a-bug","title":"I found a bug","text":"<p>Search the Issues to ensure the bug has not been reported before.</p> <p>If the bug is new, open a new issue with a clear title and description. Please indicate:</p> <ul> <li>what you did (i.e., how to reproduce),</li> <li>what you expected to happen,</li> <li>what actually happened,</li> <li>what version of Spoofax and Eclipse you are using, and</li> <li>any logs, exceptions, and stack traces relevant to the bug.</li> </ul> <p>Try to include as much relevant information as you have. For example, a code sample or executable test case are very helpful.</p> Getting the Spoofax and Eclipse version <p>In Eclipse, go to the Spoofax (meta) menu, and click Report issue. Copy the displayed version information from this dialog into your issue.</p>"},{"location":"support/#i-wrote-a-patch-with-a-cosmetic-change","title":"I wrote a patch with a cosmetic change","text":"<p>Please do not submit pull requests for cosmetic changes, such as whitespace and formatting changes.</p>"},{"location":"support/#fontawesome-solid-band-aid-i-wrote-a-patch-with-a-bug-fix","title":":fontawesome-solid-band-aid:\u00a0 I wrote a patch with a bug fix","text":"<p>Thank you! Please open a GitHub pull request with the patch.</p>"},{"location":"support/#fontawesome-solid-first-aid-i-wrote-a-patch-that-adds-a-new-feature-or-changes-an-existing-one","title":":fontawesome-solid-first-aid:\u00a0 I wrote a patch that adds a new feature or changes an existing one","text":"<p>Please open an issue first, so we can discuss the change.</p>"},{"location":"support/#i-want-to-contribute-to-the-documentation-or-test-suite","title":"I want to contribute to the documentation or test suite","text":"<p>Thank you! Please open a GitHub pull request with the patch.</p> <p>Thank you for your contributions!</p> <p>\u2014 The Spoofax Team</p>"},{"location":"support/contributions/","title":"Contributions","text":"<p>Spoofax and its components have been developed by many researchers, student, and developers supported by universities and funding agencies.</p>"},{"location":"support/contributions/#universities","title":"Universities","text":"<p>The main research effort on Spoofax and it predecessors (SDF2, Stratego, XT) was conducted at the following universities:</p> <ul> <li>University of Amsterdam</li> <li>Oregon Graduate Institute</li> <li>Utrecht University</li> <li>University of Bergen</li> <li>Delft University of Technology</li> </ul>"},{"location":"support/contributions/#funding","title":"Funding","text":"<p>Funding was provided by the following funding agencies and companies:</p> <ul> <li>The Netherlands Organisation for Scientific Research (NWO)</li> <li>Philips Research</li> <li>Oracle Labs</li> <li>Capes, Coordenaca de Bolsas, Brasil</li> </ul>"},{"location":"support/contributions/#tooling","title":"Tooling","text":"<p>The following tools were used to develop and maintain Spoofax:</p> <ul> <li> \u2014 We use the YourKit Java profiler to diagnose and fix performance problems in Spoofax, provided free-of-charge by YourKit.</li> </ul>"},{"location":"support/contributions/#contributors","title":"Contributors","text":"<p>Many people have contributed to Spoofax as bachelor student, master student, PhD student, postdoc, professor, or as an external contributor. This is an attempt at listing at least the main contributors to the various main projects.</p> <ul> <li>SDF2<ul> <li>Eelco Visser</li> <li>Jeroen Scheerder</li> <li>Mark van den Brand</li> <li>Jurgen Vinju</li> </ul> </li> <li>Stratego/XT<ul> <li>Eelco Visser</li> <li>Martin Bravenboer</li> <li>Karina Olmos</li> <li>Karl Trygve Kalleberg</li> <li>Anya Bagge</li> <li>Joost Visser</li> <li>Merijn de Jonge</li> <li>Rob Vermaas</li> <li>Eelco Dolstra</li> </ul> </li> <li>Spoofax 1<ul> <li>Eelco Visser</li> <li>Lennart Kats</li> <li>Oskar van Rest</li> <li>Karl Trygve Kalleberg</li> <li>Rob Vermaas</li> <li>Guido Wachsmuth</li> <li>Maartje de Jonge</li> <li>Ricky Lindeman</li> <li>Sebastian Erdweg</li> <li>Tobi Vollebregt</li> </ul> </li> <li>Spoofax 2<ul> <li>Eelco Visser</li> <li>Gabri\u00ebl Konat</li> <li>Eduardo Souza</li> <li>Vlad Vergu</li> <li>Volker Lanting</li> <li>Daniel A. A. Pelsmaeker</li> <li>Andrew Tolmach</li> <li>Pierre N\u00e9ron</li> <li>Hendrik van Antwerpen</li> <li>Volker Lanting</li> <li>Martijn Dwars</li> <li>Tobi Vollebregt</li> <li>Nathan Bruning</li> <li>Maarten Sijm</li> <li>Jasper Denkers</li> <li>Phil Misteli</li> <li>Daco Harkes</li> </ul> </li> <li>JSGLR2<ul> <li>Eelco Visser</li> <li>Jasper Denkers</li> <li>Karl Trygve</li> <li>Lennart Kats</li> <li>Maarten Sijm</li> <li>Maartje de Jonge</li> <li>Gabri\u00ebl Konat</li> <li>Eduardo Souza</li> </ul> </li> <li>SDF3<ul> <li>Eelco Visser</li> <li>Eduardo Souza</li> <li>Gabri\u00ebl Konat</li> <li>Daniel A. A. Pelsmaeker</li> <li>Jasper Denkers</li> </ul> </li> <li>NaBL2 &amp; Statix<ul> <li>Eelco Visser</li> <li>Hendrik van Antwerpen</li> <li>Guido Wachsmuth</li> <li>Gabri\u00ebl Konat</li> <li>Jeff Smits</li> <li>Aron Zwaan</li> <li>Daniel A. A. Pelsmaeker</li> <li>Phil Misteli</li> </ul> </li> <li>Dynsem<ul> <li>Eelco Visser</li> <li>Vlag Vergu</li> <li>Casper Back Poulsen</li> <li>Hendrik van Antwerpen</li> <li>Gabri\u00ebl Konat</li> </ul> </li> <li>Flowspec<ul> <li>Eelco Visser</li> <li>Jeff Smits</li> <li>Hendrik van Antwerpen</li> </ul> </li> <li>SPT<ul> <li>Eelco Visser</li> <li>Gabri\u00ebl Konat</li> <li>Lennart Kats</li> <li>Volker Lanting</li> <li>Daniel A. A. Pelsmaeker</li> <li>Phil Misteli</li> </ul> </li> <li>Stratego<ul> <li>Eelco Visser</li> <li>Jeff Smits</li> <li>Gabri\u00ebl Konat</li> <li>Maartje de Jonge</li> <li>Oskar van Rest</li> <li>Nathan Bruning</li> </ul> </li> <li>Spoofax 3<ul> <li>Eelco Visser</li> <li>Gabri\u00ebl Konat</li> <li>Daniel A. A. Pelsmaeker</li> <li>Aron Zwaan</li> </ul> </li> <li>PIE<ul> <li>Eelco Visser</li> <li>Gabri\u00ebl Konat</li> <li>Ivo Wilms</li> </ul> </li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This page lists tutorials that take you step-by-step through a project to learn a variety of concepts and aspects of Spoofax in a specific scope. For guides on achieving specific tasks, see the How To's section. For the Spoofax language reference, see the References section.</p> <p>No tutorials yet.</p>"}]}